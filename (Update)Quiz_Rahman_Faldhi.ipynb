{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(Update)Quiz_Rahman_Faldhi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPAZwrdeom6K"
      },
      "source": [
        "# Quiz 2 (Deep Learning)\n",
        "\n",
        "**Waktu**: 120 menit\n",
        "\n",
        "**Tujuan**: Melakukan evaluasi terhadap pemahaman mengenai Machine Learning\n",
        "\n",
        "Gunakan library Tensorflow untuk memecahkan masalah dibawah! \n",
        "\n",
        "Jelaskan hal-hal berikut:\n",
        "  1. Yang dilakukan ketika feature engineering\n",
        "  2. Susunan neural network yang dipakai\n",
        "  3. Hyperparameter yang dipakai\n",
        "  4. Hasil terbaik yang didapat\n",
        "  5. Hasil interpretasi grafik loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRKdfJj7ooDH"
      },
      "source": [
        "1. Lakukan prediksi terhadap dataset CIFAR-10!\n",
        "\n",
        "  **Hint**: Gunakan function load_data seperti berikut untuk mendapatkan training & validation set (https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar10/load_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us4karaDoW8-"
      },
      "source": [
        "#Nomor 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUwUcequoUt8"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from skimage import feature\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKqy_xnWoGRU",
        "outputId": "5288de86-4826-466d-b82f-8fc83ab34cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "(feature_train, label_train), (feature_test, label_test) = tf.keras.datasets.cifar10.load_data()\n",
        "print(\"Train\", feature_train.shape, label_train.shape)\n",
        "print(\"Test\", feature_test.shape, label_test.shape)\n",
        "\n",
        "plt.imshow(feature_train[10], cmap=plt.get_cmap('gray'))"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train (50000, 32, 32, 3) (50000, 1)\n",
            "Test (10000, 32, 32, 3) (10000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8b1135df60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AKySuvuotMm",
        "outputId": "bdf96f0f-4bc0-4d6c-dbab-8727deeb50e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(feature_train.shape) #untuk mengembalikan nilai shape list berupa integer yang menunjukan panjang dimensi list"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLJAYJMPtgSf"
      },
      "source": [
        "def preprocess(image, image_size=128):\n",
        "\t\timage = cv.cvtColor(image, cv.COLOR_BGR2GRAY) # Ubah mehjadi grayscale\n",
        "\t\timage = cv.resize(image, (image_size, image_size)) # Resize gambar menjadi suatu ukuran (default = 128)\n",
        "\t\timage = cv.threshold(image, 0, 255, cv.THRESH_BINARY_INV | cv.THRESH_OTSU)[1] # Melakukan thresholding dan mengambil hasil gambar thresholding\n",
        "\t\treturn image"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp0hfsZ0sKgW"
      },
      "source": [
        "##Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csIIyHDCsE63"
      },
      "source": [
        "feature_train = feature_train.reshape((feature_train.shape[0], 32, 32, 3)) #32 merupakan size, dan 3 merupakan dimensi\n",
        "feature_test = feature_test.reshape((feature_test.shape[0], 32, 32, 3))"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_NdBmmRvL9W",
        "outputId": "3a6f446f-770a-479e-c39f-2f29d0699714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "label_train = to_categorical(label_train)           #mengkategorikan label train dengan 0 dan 1\n",
        "label_test = to_categorical(label_test)             #mengkategorikan label test dengan 0 dan 1\n",
        "\n",
        "print(label_train)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XufMuEEzvZWx"
      },
      "source": [
        "feature_train = feature_train.astype('float32') #mengubah data type ke float\n",
        "feature_test = feature_test.astype('float32')\n",
        "\n",
        "feature_train = feature_train / 255.0 #Normalisasi data agar data bernilai dari 0 hingga 1\n",
        "feature_test = feature_test / 255.0"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TURU5Sbtve50"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZSKQJ9GvtJO"
      },
      "source": [
        "##Deeper CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5NXhtq1wW-5",
        "outputId": "f37711c8-3b2e-4237-a7aa-35159ab7b180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "deeper_model = Sequential()\n",
        "deeper_model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(32, 32, 3))) # Convolution, 32 filters, masing-masing dengan kernel 3x3\n",
        "deeper_model.add(MaxPooling2D((2, 2))) # Pooling\n",
        "deeper_model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "deeper_model.add(MaxPooling2D((2, 2))) # Pooling\n",
        "\n",
        "deeper_model.add(Flatten()) # Flatten hasil output\n",
        "\n",
        "# Fully connected layer\n",
        "deeper_model.add(Dense(100, activation='relu', kernel_initializer='he_uniform')) # Activation relu dipakai, ini salah satu function yang paling banyak dipakai\n",
        "deeper_model.add(Dense(10, activation='softmax')) # Activation softmax dipakai untuk classification, nilai 10 karena terdapat 10 class (0-9)\n",
        "\n",
        "opt = SGD(lr=0.001, momentum=0.9) # Optimizer (Stochastic Gradient Descent), untuk mencari minima dari grafik fungsi loss\n",
        "\n",
        "deeper_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) # Loss Function\n",
        "deeper_model.summary()\n",
        "\n",
        "history_cnn = deeper_model.fit(feature_train, label_train, batch_size=128, validation_data=(feature_test, label_test), epochs=50)\n",
        "\n",
        "loss, accuracy = deeper_model.evaluate(feature_test,  label_test, verbose=2)\n",
        "\n",
        "print(\"Test accuracy:\", accuracy)\n",
        "print(\"Test loss:\", loss)\n",
        "\n"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 100)               230500    \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 250,902\n",
            "Trainable params: 250,902\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.9775 - accuracy: 0.2876 - val_loss: 1.7725 - val_accuracy: 0.3786\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.6950 - accuracy: 0.3982 - val_loss: 1.6106 - val_accuracy: 0.4305\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.5572 - accuracy: 0.4477 - val_loss: 1.5482 - val_accuracy: 0.4526\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.4679 - accuracy: 0.4778 - val_loss: 1.4229 - val_accuracy: 0.4980\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.3910 - accuracy: 0.5057 - val_loss: 1.3756 - val_accuracy: 0.5120\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.3359 - accuracy: 0.5287 - val_loss: 1.3358 - val_accuracy: 0.5262\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.2898 - accuracy: 0.5449 - val_loss: 1.2810 - val_accuracy: 0.5417\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.2499 - accuracy: 0.5593 - val_loss: 1.2730 - val_accuracy: 0.5544\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.2118 - accuracy: 0.5750 - val_loss: 1.2183 - val_accuracy: 0.5707\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.1806 - accuracy: 0.5860 - val_loss: 1.2226 - val_accuracy: 0.5639\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.1503 - accuracy: 0.5980 - val_loss: 1.1818 - val_accuracy: 0.5898\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.1264 - accuracy: 0.6091 - val_loss: 1.1997 - val_accuracy: 0.5823\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.1023 - accuracy: 0.6153 - val_loss: 1.1440 - val_accuracy: 0.5980\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.0804 - accuracy: 0.6241 - val_loss: 1.1431 - val_accuracy: 0.6056\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.0584 - accuracy: 0.6320 - val_loss: 1.1588 - val_accuracy: 0.6015\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.0431 - accuracy: 0.6391 - val_loss: 1.1280 - val_accuracy: 0.6111\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.0199 - accuracy: 0.6470 - val_loss: 1.0767 - val_accuracy: 0.6295\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.0021 - accuracy: 0.6527 - val_loss: 1.0653 - val_accuracy: 0.6303\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.9883 - accuracy: 0.6577 - val_loss: 1.0745 - val_accuracy: 0.6271\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.9747 - accuracy: 0.6624 - val_loss: 1.0670 - val_accuracy: 0.6300\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.9575 - accuracy: 0.6698 - val_loss: 1.0370 - val_accuracy: 0.6454\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.9469 - accuracy: 0.6729 - val_loss: 1.0522 - val_accuracy: 0.6352\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.9286 - accuracy: 0.6794 - val_loss: 1.0402 - val_accuracy: 0.6429\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.9182 - accuracy: 0.6835 - val_loss: 1.0421 - val_accuracy: 0.6397\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.9109 - accuracy: 0.6853 - val_loss: 1.0133 - val_accuracy: 0.6515\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8958 - accuracy: 0.6909 - val_loss: 1.0356 - val_accuracy: 0.6434\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8782 - accuracy: 0.6971 - val_loss: 1.0190 - val_accuracy: 0.6500\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8630 - accuracy: 0.7039 - val_loss: 1.0142 - val_accuracy: 0.6521\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8531 - accuracy: 0.7064 - val_loss: 0.9877 - val_accuracy: 0.6630\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8466 - accuracy: 0.7088 - val_loss: 0.9968 - val_accuracy: 0.6562\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8341 - accuracy: 0.7133 - val_loss: 1.0241 - val_accuracy: 0.6489\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8242 - accuracy: 0.7178 - val_loss: 0.9829 - val_accuracy: 0.6641\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8109 - accuracy: 0.7215 - val_loss: 0.9840 - val_accuracy: 0.6634\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.8004 - accuracy: 0.7265 - val_loss: 1.0206 - val_accuracy: 0.6508\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.7931 - accuracy: 0.7272 - val_loss: 0.9861 - val_accuracy: 0.6599\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.7793 - accuracy: 0.7330 - val_loss: 0.9941 - val_accuracy: 0.6620\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.7745 - accuracy: 0.7321 - val_loss: 0.9825 - val_accuracy: 0.6677\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.7632 - accuracy: 0.7398 - val_loss: 1.0016 - val_accuracy: 0.6658\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.7492 - accuracy: 0.7431 - val_loss: 0.9613 - val_accuracy: 0.6755\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.7402 - accuracy: 0.7490 - val_loss: 0.9663 - val_accuracy: 0.6758\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.7313 - accuracy: 0.7492 - val_loss: 0.9936 - val_accuracy: 0.6634\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.7238 - accuracy: 0.7520 - val_loss: 0.9700 - val_accuracy: 0.6719\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.7101 - accuracy: 0.7583 - val_loss: 0.9666 - val_accuracy: 0.6774\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.7027 - accuracy: 0.7604 - val_loss: 0.9769 - val_accuracy: 0.6747\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.6921 - accuracy: 0.7643 - val_loss: 0.9697 - val_accuracy: 0.6743\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.6804 - accuracy: 0.7683 - val_loss: 0.9625 - val_accuracy: 0.6774\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.6715 - accuracy: 0.7714 - val_loss: 0.9694 - val_accuracy: 0.6760\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.6659 - accuracy: 0.7730 - val_loss: 0.9828 - val_accuracy: 0.6693\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.6487 - accuracy: 0.7796 - val_loss: 1.0402 - val_accuracy: 0.6614\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 0.6442 - accuracy: 0.7798 - val_loss: 0.9691 - val_accuracy: 0.6787\n",
            "313/313 - 1s - loss: 0.9691 - accuracy: 0.6787\n",
            "Test accuracy: 0.6786999702453613\n",
            "Test loss: 0.969078779220581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2JwBShwypH5",
        "outputId": "01ce34d0-8232-425a-a86f-d2f8b5c7de3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_dataframec = pd.DataFrame(history_cnn.history)\n",
        "history_dataframec['epoch'] = history_cnn.epoch\n",
        "history_dataframec\n",
        "history_dataframec.sort_values(by='val_accuracy', ascending=True)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.977478</td>\n",
              "      <td>0.28760</td>\n",
              "      <td>1.772544</td>\n",
              "      <td>0.3786</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.694971</td>\n",
              "      <td>0.39822</td>\n",
              "      <td>1.610626</td>\n",
              "      <td>0.4305</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.557232</td>\n",
              "      <td>0.44774</td>\n",
              "      <td>1.548215</td>\n",
              "      <td>0.4526</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.467920</td>\n",
              "      <td>0.47778</td>\n",
              "      <td>1.422916</td>\n",
              "      <td>0.4980</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.390985</td>\n",
              "      <td>0.50572</td>\n",
              "      <td>1.375577</td>\n",
              "      <td>0.5120</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.335903</td>\n",
              "      <td>0.52868</td>\n",
              "      <td>1.335754</td>\n",
              "      <td>0.5262</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.289837</td>\n",
              "      <td>0.54486</td>\n",
              "      <td>1.281009</td>\n",
              "      <td>0.5417</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.249939</td>\n",
              "      <td>0.55928</td>\n",
              "      <td>1.272959</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.180624</td>\n",
              "      <td>0.58598</td>\n",
              "      <td>1.222639</td>\n",
              "      <td>0.5639</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.211780</td>\n",
              "      <td>0.57500</td>\n",
              "      <td>1.218320</td>\n",
              "      <td>0.5707</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.126423</td>\n",
              "      <td>0.60914</td>\n",
              "      <td>1.199742</td>\n",
              "      <td>0.5823</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.150299</td>\n",
              "      <td>0.59800</td>\n",
              "      <td>1.181838</td>\n",
              "      <td>0.5898</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.102319</td>\n",
              "      <td>0.61534</td>\n",
              "      <td>1.144022</td>\n",
              "      <td>0.5980</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.058419</td>\n",
              "      <td>0.63200</td>\n",
              "      <td>1.158848</td>\n",
              "      <td>0.6015</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.080428</td>\n",
              "      <td>0.62412</td>\n",
              "      <td>1.143086</td>\n",
              "      <td>0.6056</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.043146</td>\n",
              "      <td>0.63906</td>\n",
              "      <td>1.127983</td>\n",
              "      <td>0.6111</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.988263</td>\n",
              "      <td>0.65768</td>\n",
              "      <td>1.074473</td>\n",
              "      <td>0.6271</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.019884</td>\n",
              "      <td>0.64704</td>\n",
              "      <td>1.076698</td>\n",
              "      <td>0.6295</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.974709</td>\n",
              "      <td>0.66244</td>\n",
              "      <td>1.066954</td>\n",
              "      <td>0.6300</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.002102</td>\n",
              "      <td>0.65268</td>\n",
              "      <td>1.065286</td>\n",
              "      <td>0.6303</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.946859</td>\n",
              "      <td>0.67294</td>\n",
              "      <td>1.052193</td>\n",
              "      <td>0.6352</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.918221</td>\n",
              "      <td>0.68346</td>\n",
              "      <td>1.042104</td>\n",
              "      <td>0.6397</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.928596</td>\n",
              "      <td>0.67940</td>\n",
              "      <td>1.040188</td>\n",
              "      <td>0.6429</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.895802</td>\n",
              "      <td>0.69092</td>\n",
              "      <td>1.035554</td>\n",
              "      <td>0.6434</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.957470</td>\n",
              "      <td>0.66980</td>\n",
              "      <td>1.036978</td>\n",
              "      <td>0.6454</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.834113</td>\n",
              "      <td>0.71334</td>\n",
              "      <td>1.024100</td>\n",
              "      <td>0.6489</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.878165</td>\n",
              "      <td>0.69706</td>\n",
              "      <td>1.018973</td>\n",
              "      <td>0.6500</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.800405</td>\n",
              "      <td>0.72654</td>\n",
              "      <td>1.020632</td>\n",
              "      <td>0.6508</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.910934</td>\n",
              "      <td>0.68528</td>\n",
              "      <td>1.013309</td>\n",
              "      <td>0.6515</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.862977</td>\n",
              "      <td>0.70392</td>\n",
              "      <td>1.014215</td>\n",
              "      <td>0.6521</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.846646</td>\n",
              "      <td>0.70880</td>\n",
              "      <td>0.996842</td>\n",
              "      <td>0.6562</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.793125</td>\n",
              "      <td>0.72722</td>\n",
              "      <td>0.986053</td>\n",
              "      <td>0.6599</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.648745</td>\n",
              "      <td>0.77960</td>\n",
              "      <td>1.040150</td>\n",
              "      <td>0.6614</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.779260</td>\n",
              "      <td>0.73302</td>\n",
              "      <td>0.994139</td>\n",
              "      <td>0.6620</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.853100</td>\n",
              "      <td>0.70642</td>\n",
              "      <td>0.987662</td>\n",
              "      <td>0.6630</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.810910</td>\n",
              "      <td>0.72148</td>\n",
              "      <td>0.983952</td>\n",
              "      <td>0.6634</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.731283</td>\n",
              "      <td>0.74918</td>\n",
              "      <td>0.993582</td>\n",
              "      <td>0.6634</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.824186</td>\n",
              "      <td>0.71780</td>\n",
              "      <td>0.982892</td>\n",
              "      <td>0.6641</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.763159</td>\n",
              "      <td>0.73976</td>\n",
              "      <td>1.001568</td>\n",
              "      <td>0.6658</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.774539</td>\n",
              "      <td>0.73214</td>\n",
              "      <td>0.982550</td>\n",
              "      <td>0.6677</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.665947</td>\n",
              "      <td>0.77304</td>\n",
              "      <td>0.982838</td>\n",
              "      <td>0.6693</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.723831</td>\n",
              "      <td>0.75202</td>\n",
              "      <td>0.969966</td>\n",
              "      <td>0.6719</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.692138</td>\n",
              "      <td>0.76428</td>\n",
              "      <td>0.969676</td>\n",
              "      <td>0.6743</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.702682</td>\n",
              "      <td>0.76042</td>\n",
              "      <td>0.976864</td>\n",
              "      <td>0.6747</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.749161</td>\n",
              "      <td>0.74310</td>\n",
              "      <td>0.961322</td>\n",
              "      <td>0.6755</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.740235</td>\n",
              "      <td>0.74896</td>\n",
              "      <td>0.966254</td>\n",
              "      <td>0.6758</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.671494</td>\n",
              "      <td>0.77136</td>\n",
              "      <td>0.969371</td>\n",
              "      <td>0.6760</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.710063</td>\n",
              "      <td>0.75834</td>\n",
              "      <td>0.966599</td>\n",
              "      <td>0.6774</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.680420</td>\n",
              "      <td>0.76834</td>\n",
              "      <td>0.962537</td>\n",
              "      <td>0.6774</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.644192</td>\n",
              "      <td>0.77978</td>\n",
              "      <td>0.969078</td>\n",
              "      <td>0.6787</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "0   1.977478   0.28760  1.772544        0.3786      0\n",
              "1   1.694971   0.39822  1.610626        0.4305      1\n",
              "2   1.557232   0.44774  1.548215        0.4526      2\n",
              "3   1.467920   0.47778  1.422916        0.4980      3\n",
              "4   1.390985   0.50572  1.375577        0.5120      4\n",
              "5   1.335903   0.52868  1.335754        0.5262      5\n",
              "6   1.289837   0.54486  1.281009        0.5417      6\n",
              "7   1.249939   0.55928  1.272959        0.5544      7\n",
              "9   1.180624   0.58598  1.222639        0.5639      9\n",
              "8   1.211780   0.57500  1.218320        0.5707      8\n",
              "11  1.126423   0.60914  1.199742        0.5823     11\n",
              "10  1.150299   0.59800  1.181838        0.5898     10\n",
              "12  1.102319   0.61534  1.144022        0.5980     12\n",
              "14  1.058419   0.63200  1.158848        0.6015     14\n",
              "13  1.080428   0.62412  1.143086        0.6056     13\n",
              "15  1.043146   0.63906  1.127983        0.6111     15\n",
              "18  0.988263   0.65768  1.074473        0.6271     18\n",
              "16  1.019884   0.64704  1.076698        0.6295     16\n",
              "19  0.974709   0.66244  1.066954        0.6300     19\n",
              "17  1.002102   0.65268  1.065286        0.6303     17\n",
              "21  0.946859   0.67294  1.052193        0.6352     21\n",
              "23  0.918221   0.68346  1.042104        0.6397     23\n",
              "22  0.928596   0.67940  1.040188        0.6429     22\n",
              "25  0.895802   0.69092  1.035554        0.6434     25\n",
              "20  0.957470   0.66980  1.036978        0.6454     20\n",
              "30  0.834113   0.71334  1.024100        0.6489     30\n",
              "26  0.878165   0.69706  1.018973        0.6500     26\n",
              "33  0.800405   0.72654  1.020632        0.6508     33\n",
              "24  0.910934   0.68528  1.013309        0.6515     24\n",
              "27  0.862977   0.70392  1.014215        0.6521     27\n",
              "29  0.846646   0.70880  0.996842        0.6562     29\n",
              "34  0.793125   0.72722  0.986053        0.6599     34\n",
              "48  0.648745   0.77960  1.040150        0.6614     48\n",
              "35  0.779260   0.73302  0.994139        0.6620     35\n",
              "28  0.853100   0.70642  0.987662        0.6630     28\n",
              "32  0.810910   0.72148  0.983952        0.6634     32\n",
              "40  0.731283   0.74918  0.993582        0.6634     40\n",
              "31  0.824186   0.71780  0.982892        0.6641     31\n",
              "37  0.763159   0.73976  1.001568        0.6658     37\n",
              "36  0.774539   0.73214  0.982550        0.6677     36\n",
              "47  0.665947   0.77304  0.982838        0.6693     47\n",
              "41  0.723831   0.75202  0.969966        0.6719     41\n",
              "44  0.692138   0.76428  0.969676        0.6743     44\n",
              "43  0.702682   0.76042  0.976864        0.6747     43\n",
              "38  0.749161   0.74310  0.961322        0.6755     38\n",
              "39  0.740235   0.74896  0.966254        0.6758     39\n",
              "46  0.671494   0.77136  0.969371        0.6760     46\n",
              "42  0.710063   0.75834  0.966599        0.6774     42\n",
              "45  0.680420   0.76834  0.962537        0.6774     45\n",
              "49  0.644192   0.77978  0.969078        0.6787     49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5jWzeVIyEXt"
      },
      "source": [
        "def plot_loss(hstr):\n",
        "  plt.plot(hstr.history['loss'], label='loss')\n",
        "  plt.plot(hstr.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4D4xgspxUJA",
        "outputId": "140a12b7-4fa8-46ad-ff52-b768fc448c7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(history_cnn)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r328Sd2BhKA7"
      },
      "source": [
        "nilai akurasi terbaik didapat pada epoch ke 49 dengan nilai 0.67 serta val_loss 0.96 dan loss 0.77"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Rw9jUJstvQE"
      },
      "source": [
        "#Nomor 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsAR8fEft5xf"
      },
      "source": [
        "2. Lakukan prediksi terhadap dataset `ionosphere_data_kaggle.csv`. \n",
        "\n",
        "  **Catatan**: \n",
        "  \n",
        "  - Split dataset menggunakan library scikit-learn dengan perbandingan 80:20 dan random_state=10.\n",
        "\n",
        "  - Hasil prediksi dapat ditemui di kolom *label*.\n",
        "\n",
        "  - Penjelasan dataset: https://archive.ics.uci.edu/ml/datasets/Ionosphere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESCnwC00us7e"
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/My Drive/dataset_quiz/ionosphere_data_kaggle.csv')"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5VP2b1j38zT"
      },
      "source": [
        "##Data Cleaning and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiEriHtq1wsf",
        "outputId": "d79a5f44-440a-4553-c852-62883a928989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99539</td>\n",
              "      <td>-0.05889</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>0.02306</td>\n",
              "      <td>0.83398</td>\n",
              "      <td>-0.37708</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.03760</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>-0.17755</td>\n",
              "      <td>0.59755</td>\n",
              "      <td>-0.44945</td>\n",
              "      <td>0.60536</td>\n",
              "      <td>-0.38223</td>\n",
              "      <td>0.84356</td>\n",
              "      <td>-0.38542</td>\n",
              "      <td>0.58212</td>\n",
              "      <td>-0.32192</td>\n",
              "      <td>0.56971</td>\n",
              "      <td>-0.29674</td>\n",
              "      <td>0.36946</td>\n",
              "      <td>-0.47357</td>\n",
              "      <td>0.56811</td>\n",
              "      <td>-0.51171</td>\n",
              "      <td>0.41078</td>\n",
              "      <td>-0.46168</td>\n",
              "      <td>0.21266</td>\n",
              "      <td>-0.34090</td>\n",
              "      <td>0.42267</td>\n",
              "      <td>-0.54487</td>\n",
              "      <td>0.18641</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.18829</td>\n",
              "      <td>0.93035</td>\n",
              "      <td>-0.36156</td>\n",
              "      <td>-0.10868</td>\n",
              "      <td>-0.93597</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.04549</td>\n",
              "      <td>0.50874</td>\n",
              "      <td>-0.67743</td>\n",
              "      <td>0.34432</td>\n",
              "      <td>-0.69707</td>\n",
              "      <td>-0.51685</td>\n",
              "      <td>-0.97515</td>\n",
              "      <td>0.05499</td>\n",
              "      <td>-0.62237</td>\n",
              "      <td>0.33109</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.13151</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>-0.18056</td>\n",
              "      <td>-0.35734</td>\n",
              "      <td>-0.20332</td>\n",
              "      <td>-0.26569</td>\n",
              "      <td>-0.20468</td>\n",
              "      <td>-0.18401</td>\n",
              "      <td>-0.19040</td>\n",
              "      <td>-0.11593</td>\n",
              "      <td>-0.16626</td>\n",
              "      <td>-0.06288</td>\n",
              "      <td>-0.13738</td>\n",
              "      <td>-0.02447</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.03365</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00485</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.88965</td>\n",
              "      <td>0.01198</td>\n",
              "      <td>0.73082</td>\n",
              "      <td>0.05346</td>\n",
              "      <td>0.85443</td>\n",
              "      <td>0.00827</td>\n",
              "      <td>0.54591</td>\n",
              "      <td>0.00299</td>\n",
              "      <td>0.83775</td>\n",
              "      <td>-0.13644</td>\n",
              "      <td>0.75535</td>\n",
              "      <td>-0.08540</td>\n",
              "      <td>0.70887</td>\n",
              "      <td>-0.27502</td>\n",
              "      <td>0.43385</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.57528</td>\n",
              "      <td>-0.40220</td>\n",
              "      <td>0.58984</td>\n",
              "      <td>-0.22145</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>-0.17365</td>\n",
              "      <td>0.60436</td>\n",
              "      <td>-0.24180</td>\n",
              "      <td>0.56045</td>\n",
              "      <td>-0.38238</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.45161</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.71216</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.14516</td>\n",
              "      <td>0.54094</td>\n",
              "      <td>-0.39330</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.54467</td>\n",
              "      <td>-0.69975</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.90695</td>\n",
              "      <td>0.51613</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.20099</td>\n",
              "      <td>0.25682</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.32382</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.02401</td>\n",
              "      <td>0.94140</td>\n",
              "      <td>0.06531</td>\n",
              "      <td>0.92106</td>\n",
              "      <td>-0.23255</td>\n",
              "      <td>0.77152</td>\n",
              "      <td>-0.16399</td>\n",
              "      <td>0.52798</td>\n",
              "      <td>-0.20275</td>\n",
              "      <td>0.56409</td>\n",
              "      <td>-0.00712</td>\n",
              "      <td>0.34395</td>\n",
              "      <td>-0.27457</td>\n",
              "      <td>0.52940</td>\n",
              "      <td>-0.21780</td>\n",
              "      <td>0.45107</td>\n",
              "      <td>-0.17813</td>\n",
              "      <td>0.05982</td>\n",
              "      <td>-0.35575</td>\n",
              "      <td>0.02309</td>\n",
              "      <td>-0.52879</td>\n",
              "      <td>0.03286</td>\n",
              "      <td>-0.65158</td>\n",
              "      <td>0.13290</td>\n",
              "      <td>-0.53206</td>\n",
              "      <td>0.02431</td>\n",
              "      <td>-0.62197</td>\n",
              "      <td>-0.05707</td>\n",
              "      <td>-0.59573</td>\n",
              "      <td>-0.04608</td>\n",
              "      <td>-0.65697</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   feature1  feature2  feature3  ...  feature33  feature34  label\n",
              "0         1         0   0.99539  ...    0.18641   -0.45300      g\n",
              "1         1         0   1.00000  ...   -0.13738   -0.02447      b\n",
              "2         1         0   1.00000  ...    0.56045   -0.38238      g\n",
              "3         1         0   1.00000  ...   -0.32382    1.00000      b\n",
              "4         1         0   1.00000  ...   -0.04608   -0.65697      g\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTK6fPCE1CKL",
        "outputId": "f758d803-3905-4c4c-de27-e1facb157a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.0</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.891738</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.641342</td>\n",
              "      <td>0.044372</td>\n",
              "      <td>0.601068</td>\n",
              "      <td>0.115889</td>\n",
              "      <td>0.550095</td>\n",
              "      <td>0.119360</td>\n",
              "      <td>0.511848</td>\n",
              "      <td>0.181345</td>\n",
              "      <td>0.476183</td>\n",
              "      <td>0.155040</td>\n",
              "      <td>0.400801</td>\n",
              "      <td>0.093414</td>\n",
              "      <td>0.344159</td>\n",
              "      <td>0.071132</td>\n",
              "      <td>0.381949</td>\n",
              "      <td>-0.003617</td>\n",
              "      <td>0.359390</td>\n",
              "      <td>-0.024025</td>\n",
              "      <td>0.336695</td>\n",
              "      <td>0.008296</td>\n",
              "      <td>0.362475</td>\n",
              "      <td>-0.057406</td>\n",
              "      <td>0.396135</td>\n",
              "      <td>-0.071187</td>\n",
              "      <td>0.541641</td>\n",
              "      <td>-0.069538</td>\n",
              "      <td>0.378445</td>\n",
              "      <td>-0.027907</td>\n",
              "      <td>0.352514</td>\n",
              "      <td>-0.003794</td>\n",
              "      <td>0.349364</td>\n",
              "      <td>0.014480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.311155</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.497708</td>\n",
              "      <td>0.441435</td>\n",
              "      <td>0.519862</td>\n",
              "      <td>0.460810</td>\n",
              "      <td>0.492654</td>\n",
              "      <td>0.520750</td>\n",
              "      <td>0.507066</td>\n",
              "      <td>0.483851</td>\n",
              "      <td>0.563496</td>\n",
              "      <td>0.494817</td>\n",
              "      <td>0.622186</td>\n",
              "      <td>0.494873</td>\n",
              "      <td>0.652828</td>\n",
              "      <td>0.458371</td>\n",
              "      <td>0.618020</td>\n",
              "      <td>0.496762</td>\n",
              "      <td>0.626267</td>\n",
              "      <td>0.519076</td>\n",
              "      <td>0.609828</td>\n",
              "      <td>0.518166</td>\n",
              "      <td>0.603767</td>\n",
              "      <td>0.527456</td>\n",
              "      <td>0.578451</td>\n",
              "      <td>0.508495</td>\n",
              "      <td>0.516205</td>\n",
              "      <td>0.550025</td>\n",
              "      <td>0.575886</td>\n",
              "      <td>0.507974</td>\n",
              "      <td>0.571483</td>\n",
              "      <td>0.513574</td>\n",
              "      <td>0.522663</td>\n",
              "      <td>0.468337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.472135</td>\n",
              "      <td>-0.064735</td>\n",
              "      <td>0.412660</td>\n",
              "      <td>-0.024795</td>\n",
              "      <td>0.211310</td>\n",
              "      <td>-0.054840</td>\n",
              "      <td>0.087110</td>\n",
              "      <td>-0.048075</td>\n",
              "      <td>0.021120</td>\n",
              "      <td>-0.065265</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.073725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.081705</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.225690</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.234670</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.243870</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.366885</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.332390</td>\n",
              "      <td>0.286435</td>\n",
              "      <td>-0.443165</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.236885</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.242595</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.165350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.871110</td>\n",
              "      <td>0.016310</td>\n",
              "      <td>0.809200</td>\n",
              "      <td>0.022800</td>\n",
              "      <td>0.728730</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.684210</td>\n",
              "      <td>0.018290</td>\n",
              "      <td>0.667980</td>\n",
              "      <td>0.028250</td>\n",
              "      <td>0.644070</td>\n",
              "      <td>0.030270</td>\n",
              "      <td>0.601940</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.590910</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.576190</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.499090</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.531760</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.553890</td>\n",
              "      <td>-0.015050</td>\n",
              "      <td>0.708240</td>\n",
              "      <td>-0.017690</td>\n",
              "      <td>0.496640</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.442770</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.409560</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.194185</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.334655</td>\n",
              "      <td>0.969240</td>\n",
              "      <td>0.445675</td>\n",
              "      <td>0.953240</td>\n",
              "      <td>0.534195</td>\n",
              "      <td>0.957895</td>\n",
              "      <td>0.482375</td>\n",
              "      <td>0.955505</td>\n",
              "      <td>0.374860</td>\n",
              "      <td>0.919330</td>\n",
              "      <td>0.308975</td>\n",
              "      <td>0.935705</td>\n",
              "      <td>0.195285</td>\n",
              "      <td>0.899265</td>\n",
              "      <td>0.134370</td>\n",
              "      <td>0.894865</td>\n",
              "      <td>0.188760</td>\n",
              "      <td>0.911235</td>\n",
              "      <td>0.164630</td>\n",
              "      <td>0.905240</td>\n",
              "      <td>0.156765</td>\n",
              "      <td>0.999945</td>\n",
              "      <td>0.153535</td>\n",
              "      <td>0.883465</td>\n",
              "      <td>0.154075</td>\n",
              "      <td>0.857620</td>\n",
              "      <td>0.200120</td>\n",
              "      <td>0.813765</td>\n",
              "      <td>0.171660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         feature1  feature2    feature3  ...   feature32   feature33   feature34\n",
              "count  351.000000     351.0  351.000000  ...  351.000000  351.000000  351.000000\n",
              "mean     0.891738       0.0    0.641342  ...   -0.003794    0.349364    0.014480\n",
              "std      0.311155       0.0    0.497708  ...    0.513574    0.522663    0.468337\n",
              "min      0.000000       0.0   -1.000000  ...   -1.000000   -1.000000   -1.000000\n",
              "25%      1.000000       0.0    0.472135  ...   -0.242595    0.000000   -0.165350\n",
              "50%      1.000000       0.0    0.871110  ...    0.000000    0.409560    0.000000\n",
              "75%      1.000000       0.0    1.000000  ...    0.200120    0.813765    0.171660\n",
              "max      1.000000       0.0    1.000000  ...    1.000000    1.000000    1.000000\n",
              "\n",
              "[8 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS1vYtbk142N",
        "outputId": "43ca6cd1-5758-471f-9df9-03d3bcb387b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "dataset[\"label\"].value_counts() #menghitung total g dan b pada feature label"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "g    225\n",
              "b    126\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRFxqDlr3CRC",
        "outputId": "87ed1326-7665-4149-9c09-16dc3b1b8da2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "cleanup_label = {\"label\":     {\"g\": 0, \"b\": 1}} \n",
        "\n",
        "dataset.replace(cleanup_label, inplace=True) #mengganti label g dan b ke 0 dan 1\n",
        "dataset.head()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99539</td>\n",
              "      <td>-0.05889</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>0.02306</td>\n",
              "      <td>0.83398</td>\n",
              "      <td>-0.37708</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.03760</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>-0.17755</td>\n",
              "      <td>0.59755</td>\n",
              "      <td>-0.44945</td>\n",
              "      <td>0.60536</td>\n",
              "      <td>-0.38223</td>\n",
              "      <td>0.84356</td>\n",
              "      <td>-0.38542</td>\n",
              "      <td>0.58212</td>\n",
              "      <td>-0.32192</td>\n",
              "      <td>0.56971</td>\n",
              "      <td>-0.29674</td>\n",
              "      <td>0.36946</td>\n",
              "      <td>-0.47357</td>\n",
              "      <td>0.56811</td>\n",
              "      <td>-0.51171</td>\n",
              "      <td>0.41078</td>\n",
              "      <td>-0.46168</td>\n",
              "      <td>0.21266</td>\n",
              "      <td>-0.34090</td>\n",
              "      <td>0.42267</td>\n",
              "      <td>-0.54487</td>\n",
              "      <td>0.18641</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.18829</td>\n",
              "      <td>0.93035</td>\n",
              "      <td>-0.36156</td>\n",
              "      <td>-0.10868</td>\n",
              "      <td>-0.93597</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.04549</td>\n",
              "      <td>0.50874</td>\n",
              "      <td>-0.67743</td>\n",
              "      <td>0.34432</td>\n",
              "      <td>-0.69707</td>\n",
              "      <td>-0.51685</td>\n",
              "      <td>-0.97515</td>\n",
              "      <td>0.05499</td>\n",
              "      <td>-0.62237</td>\n",
              "      <td>0.33109</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.13151</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>-0.18056</td>\n",
              "      <td>-0.35734</td>\n",
              "      <td>-0.20332</td>\n",
              "      <td>-0.26569</td>\n",
              "      <td>-0.20468</td>\n",
              "      <td>-0.18401</td>\n",
              "      <td>-0.19040</td>\n",
              "      <td>-0.11593</td>\n",
              "      <td>-0.16626</td>\n",
              "      <td>-0.06288</td>\n",
              "      <td>-0.13738</td>\n",
              "      <td>-0.02447</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.03365</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00485</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.88965</td>\n",
              "      <td>0.01198</td>\n",
              "      <td>0.73082</td>\n",
              "      <td>0.05346</td>\n",
              "      <td>0.85443</td>\n",
              "      <td>0.00827</td>\n",
              "      <td>0.54591</td>\n",
              "      <td>0.00299</td>\n",
              "      <td>0.83775</td>\n",
              "      <td>-0.13644</td>\n",
              "      <td>0.75535</td>\n",
              "      <td>-0.08540</td>\n",
              "      <td>0.70887</td>\n",
              "      <td>-0.27502</td>\n",
              "      <td>0.43385</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.57528</td>\n",
              "      <td>-0.40220</td>\n",
              "      <td>0.58984</td>\n",
              "      <td>-0.22145</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>-0.17365</td>\n",
              "      <td>0.60436</td>\n",
              "      <td>-0.24180</td>\n",
              "      <td>0.56045</td>\n",
              "      <td>-0.38238</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.45161</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.71216</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.14516</td>\n",
              "      <td>0.54094</td>\n",
              "      <td>-0.39330</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.54467</td>\n",
              "      <td>-0.69975</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.90695</td>\n",
              "      <td>0.51613</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.20099</td>\n",
              "      <td>0.25682</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.32382</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.02401</td>\n",
              "      <td>0.94140</td>\n",
              "      <td>0.06531</td>\n",
              "      <td>0.92106</td>\n",
              "      <td>-0.23255</td>\n",
              "      <td>0.77152</td>\n",
              "      <td>-0.16399</td>\n",
              "      <td>0.52798</td>\n",
              "      <td>-0.20275</td>\n",
              "      <td>0.56409</td>\n",
              "      <td>-0.00712</td>\n",
              "      <td>0.34395</td>\n",
              "      <td>-0.27457</td>\n",
              "      <td>0.52940</td>\n",
              "      <td>-0.21780</td>\n",
              "      <td>0.45107</td>\n",
              "      <td>-0.17813</td>\n",
              "      <td>0.05982</td>\n",
              "      <td>-0.35575</td>\n",
              "      <td>0.02309</td>\n",
              "      <td>-0.52879</td>\n",
              "      <td>0.03286</td>\n",
              "      <td>-0.65158</td>\n",
              "      <td>0.13290</td>\n",
              "      <td>-0.53206</td>\n",
              "      <td>0.02431</td>\n",
              "      <td>-0.62197</td>\n",
              "      <td>-0.05707</td>\n",
              "      <td>-0.59573</td>\n",
              "      <td>-0.04608</td>\n",
              "      <td>-0.65697</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   feature1  feature2  feature3  ...  feature33  feature34  label\n",
              "0         1         0   0.99539  ...    0.18641   -0.45300      0\n",
              "1         1         0   1.00000  ...   -0.13738   -0.02447      1\n",
              "2         1         0   1.00000  ...    0.56045   -0.38238      0\n",
              "3         1         0   1.00000  ...   -0.32382    1.00000      1\n",
              "4         1         0   1.00000  ...   -0.04608   -0.65697      0\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzQu8OJDVfZU"
      },
      "source": [
        "#karena features 2 nilainya 0 semua, dilihat dari dataset.describe(), maka saya mendrop feature 2\n",
        "dataset=dataset.drop(['feature2'], axis=1)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ledlAmmP6lVo",
        "outputId": "2966198f-177a-467a-f7e4-3a3831575ac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "dataset.columns"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['feature1', 'feature3', 'feature4', 'feature5', 'feature6', 'feature7',\n",
              "       'feature8', 'feature9', 'feature10', 'feature11', 'feature12',\n",
              "       'feature13', 'feature14', 'feature15', 'feature16', 'feature17',\n",
              "       'feature18', 'feature19', 'feature20', 'feature21', 'feature22',\n",
              "       'feature23', 'feature24', 'feature25', 'feature26', 'feature27',\n",
              "       'feature28', 'feature29', 'feature30', 'feature31', 'feature32',\n",
              "       'feature33', 'feature34', 'label'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aP1EJsw4e1e"
      },
      "source": [
        "label2 = dataset['label']\n",
        "features2 = dataset.drop(['label'], axis=1) #menentukan prediksi menggunakan fitur label"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTvU1Yuh3u-A"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.StandardScaler() #menggunakan preprocesing standar scaler\n",
        "\n",
        "features2 = scaler.fit_transform(features2.values)\n",
        "label2 = scaler.fit_transform(label2.values.reshape(-1,1)).flatten() #nilai label di flatten"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1d_qwMR5nnQ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "feature_train2, feature_test2, label_train2, label_test2 = train_test_split(features2, label2, test_size=0.2, random_state=10) #perbandingan test dan train 80:20"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umzd8JSE7MBe"
      },
      "source": [
        "##Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SypTwmR7E-N",
        "outputId": "7b75b25e-28c4-4cc5-a289-a607ac6be029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "lm2 = LinearRegression()\n",
        "lm2.fit(feature_train2, label_train2)\n",
        "\n",
        "predictions2 = lm2.predict(feature_test2)\n",
        "\n",
        "mse2 = mean_squared_error(label_test2, predictions2)\n",
        "mae2 = mean_absolute_error(label_test2, predictions2)\n",
        "r22 = r2_score(label_test2, predictions2)\n",
        "print(\"MSE (Mean Squared Error)\", mse2)\n",
        "print(\"MAE (Mean Absolute Error)\", mae2)\n",
        "print(\"r^2 score\", r22)\n",
        "print('RMSE (Root Mean Squared Error', np.sqrt(mean_squared_error(label_test2, predictions2)))"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE (Mean Squared Error) 0.5166231048008582\n",
            "MAE (Mean Absolute Error) 0.489963573081488\n",
            "r^2 score 0.45717445202229534\n",
            "RMSE (Root Mean Squared Error 0.7187649857921977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FzCskROBu_S"
      },
      "source": [
        "Kesimpulan: nilai r2 score yang didapat rendah, yaitu 0.45"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lns3K2CsAdC9"
      },
      "source": [
        "##Wider Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK-OTCi45-PK",
        "outputId": "69ed8bb4-c164-4947-ddf6-f73f6a23b25b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "wider_model2 = Sequential()\n",
        "wider_model2.add(Dense(40, input_dim=33, kernel_initializer='normal', activation='relu')) #neuron pada wider 40 dan input dim sebanyak fitur yaitu 33\n",
        "wider_model2.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "wider_model2.compile(loss='mean_squared_error', optimizer='adam') #menggunakan optimizer adam\n",
        "\n",
        "historyw2 = wider_model2.fit(x=feature_train2, y=label_train2, validation_data=(feature_test2, label_test2), epochs=100, batch_size=8) "
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.8981 - val_loss: 0.7387\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6516 - val_loss: 0.5405\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4517 - val_loss: 0.4537\n",
            "Epoch 4/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.4420\n",
            "Epoch 5/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3323 - val_loss: 0.4302\n",
            "Epoch 6/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3050 - val_loss: 0.4099\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2775 - val_loss: 0.3980\n",
            "Epoch 8/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2602 - val_loss: 0.3844\n",
            "Epoch 9/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.3758\n",
            "Epoch 10/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2360 - val_loss: 0.3643\n",
            "Epoch 11/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2210 - val_loss: 0.3544\n",
            "Epoch 12/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2102 - val_loss: 0.3464\n",
            "Epoch 13/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2007 - val_loss: 0.3313\n",
            "Epoch 14/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1941 - val_loss: 0.3296\n",
            "Epoch 15/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1880 - val_loss: 0.3242\n",
            "Epoch 16/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1808 - val_loss: 0.3150\n",
            "Epoch 17/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1741 - val_loss: 0.3180\n",
            "Epoch 18/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1671 - val_loss: 0.3144\n",
            "Epoch 19/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1647 - val_loss: 0.3115\n",
            "Epoch 20/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1578 - val_loss: 0.3051\n",
            "Epoch 21/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1527 - val_loss: 0.3064\n",
            "Epoch 22/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1478 - val_loss: 0.3048\n",
            "Epoch 23/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1445 - val_loss: 0.3058\n",
            "Epoch 24/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 0.3018\n",
            "Epoch 25/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1370 - val_loss: 0.2924\n",
            "Epoch 26/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1340 - val_loss: 0.3080\n",
            "Epoch 27/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1261 - val_loss: 0.3016\n",
            "Epoch 28/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1261 - val_loss: 0.3147\n",
            "Epoch 29/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.3016\n",
            "Epoch 30/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1189 - val_loss: 0.3099\n",
            "Epoch 31/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1157 - val_loss: 0.3053\n",
            "Epoch 32/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1137 - val_loss: 0.3132\n",
            "Epoch 33/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1142 - val_loss: 0.3235\n",
            "Epoch 34/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1125 - val_loss: 0.3250\n",
            "Epoch 35/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1066 - val_loss: 0.3150\n",
            "Epoch 36/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1031 - val_loss: 0.3200\n",
            "Epoch 37/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.3270\n",
            "Epoch 38/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0991 - val_loss: 0.3334\n",
            "Epoch 39/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0959 - val_loss: 0.3325\n",
            "Epoch 40/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0919 - val_loss: 0.3382\n",
            "Epoch 41/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0936 - val_loss: 0.3262\n",
            "Epoch 42/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.3507\n",
            "Epoch 43/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.3467\n",
            "Epoch 44/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.3384\n",
            "Epoch 45/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.3576\n",
            "Epoch 46/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.3564\n",
            "Epoch 47/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.3575\n",
            "Epoch 48/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0813 - val_loss: 0.3638\n",
            "Epoch 49/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.3734\n",
            "Epoch 50/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 0.3810\n",
            "Epoch 51/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.3513\n",
            "Epoch 52/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.3757\n",
            "Epoch 53/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.3702\n",
            "Epoch 54/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.3698\n",
            "Epoch 55/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.3725\n",
            "Epoch 56/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.3884\n",
            "Epoch 57/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.3926\n",
            "Epoch 58/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.3891\n",
            "Epoch 59/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.3875\n",
            "Epoch 60/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.3917\n",
            "Epoch 61/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.3830\n",
            "Epoch 62/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0616 - val_loss: 0.4017\n",
            "Epoch 63/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.3927\n",
            "Epoch 64/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.4103\n",
            "Epoch 65/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.3969\n",
            "Epoch 66/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.4016\n",
            "Epoch 67/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 0.3916\n",
            "Epoch 68/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.3977\n",
            "Epoch 69/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.4044\n",
            "Epoch 70/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.4159\n",
            "Epoch 71/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.4170\n",
            "Epoch 72/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0501 - val_loss: 0.4190\n",
            "Epoch 73/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.4233\n",
            "Epoch 74/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.4275\n",
            "Epoch 75/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.4308\n",
            "Epoch 76/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.4367\n",
            "Epoch 77/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.4211\n",
            "Epoch 78/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.4265\n",
            "Epoch 79/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.4283\n",
            "Epoch 80/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.4318\n",
            "Epoch 81/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.4292\n",
            "Epoch 82/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.4472\n",
            "Epoch 83/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.4435\n",
            "Epoch 84/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.4539\n",
            "Epoch 85/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.4429\n",
            "Epoch 86/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.4459\n",
            "Epoch 87/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.4561\n",
            "Epoch 88/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.4531\n",
            "Epoch 89/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.4618\n",
            "Epoch 90/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.4492\n",
            "Epoch 91/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.4518\n",
            "Epoch 92/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.4702\n",
            "Epoch 93/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.4691\n",
            "Epoch 94/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.4680\n",
            "Epoch 95/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.4645\n",
            "Epoch 96/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.4907\n",
            "Epoch 97/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.4844\n",
            "Epoch 98/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.4736\n",
            "Epoch 99/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.4902\n",
            "Epoch 100/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.4899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM1LLjTV7X0U",
        "outputId": "ae0d2fc2-6313-4c09-ff3a-b6c795eb3039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(historyw2)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlmDWCjrBg1B"
      },
      "source": [
        "Kesimpulan: pada grafik val loss yang stabil berada di sekitaran epoch 18 dengan nilai loss: 0.16 dan val_loss: 0.31"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpU0aqO1B6FG"
      },
      "source": [
        "##Deeper Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olImGTCGB8RE",
        "outputId": "4061305c-9c4f-4646-9221-09b427084646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "deeper_model2 = Sequential()\n",
        "deeper_model2.add(Dense(33, input_dim=33, kernel_initializer='normal', activation='relu'))\n",
        "deeper_model2.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
        "deeper_model2.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "deeper_model2.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "historyd2 = deeper_model2.fit(x=feature_train2, y=label_train2, validation_data=(feature_test2, label_test2), epochs=100, batch_size=8)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.9946 - val_loss: 0.9169\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.8132\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7398 - val_loss: 0.6275\n",
            "Epoch 4/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4875 - val_loss: 0.4843\n",
            "Epoch 5/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3602 - val_loss: 0.4507\n",
            "Epoch 6/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3083 - val_loss: 0.4265\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2771 - val_loss: 0.4134\n",
            "Epoch 8/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2537 - val_loss: 0.3902\n",
            "Epoch 9/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2339 - val_loss: 0.3919\n",
            "Epoch 10/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2189 - val_loss: 0.3602\n",
            "Epoch 11/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2110 - val_loss: 0.3497\n",
            "Epoch 12/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1944 - val_loss: 0.3306\n",
            "Epoch 13/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1808 - val_loss: 0.3316\n",
            "Epoch 14/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1689 - val_loss: 0.3225\n",
            "Epoch 15/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1575 - val_loss: 0.3047\n",
            "Epoch 16/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1504 - val_loss: 0.2956\n",
            "Epoch 17/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1423 - val_loss: 0.3009\n",
            "Epoch 18/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1356 - val_loss: 0.2912\n",
            "Epoch 19/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1291 - val_loss: 0.2759\n",
            "Epoch 20/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1238 - val_loss: 0.2787\n",
            "Epoch 21/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1183 - val_loss: 0.2818\n",
            "Epoch 22/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1106 - val_loss: 0.2749\n",
            "Epoch 23/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1100 - val_loss: 0.2822\n",
            "Epoch 24/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1008 - val_loss: 0.2859\n",
            "Epoch 25/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0977 - val_loss: 0.2770\n",
            "Epoch 26/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0951 - val_loss: 0.2602\n",
            "Epoch 27/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0885 - val_loss: 0.2717\n",
            "Epoch 28/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0903 - val_loss: 0.2818\n",
            "Epoch 29/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.2554\n",
            "Epoch 30/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.2625\n",
            "Epoch 31/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.2467\n",
            "Epoch 32/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 0.2675\n",
            "Epoch 33/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.2570\n",
            "Epoch 34/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.2698\n",
            "Epoch 35/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.2777\n",
            "Epoch 36/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.2505\n",
            "Epoch 37/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.2577\n",
            "Epoch 38/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.2823\n",
            "Epoch 39/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.2674\n",
            "Epoch 40/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 0.2761\n",
            "Epoch 41/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.2778\n",
            "Epoch 42/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.2691\n",
            "Epoch 43/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.2718\n",
            "Epoch 44/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.2646\n",
            "Epoch 45/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.2568\n",
            "Epoch 46/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.2596\n",
            "Epoch 47/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.2961\n",
            "Epoch 48/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.2647\n",
            "Epoch 49/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.2670\n",
            "Epoch 50/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.2726\n",
            "Epoch 51/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.2742\n",
            "Epoch 52/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.2811\n",
            "Epoch 53/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.2591\n",
            "Epoch 54/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.2841\n",
            "Epoch 55/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.2575\n",
            "Epoch 56/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.2866\n",
            "Epoch 57/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.2707\n",
            "Epoch 58/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.2960\n",
            "Epoch 59/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.3056\n",
            "Epoch 60/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.2906\n",
            "Epoch 61/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.2780\n",
            "Epoch 62/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0424 - val_loss: 0.2917\n",
            "Epoch 63/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.3038\n",
            "Epoch 64/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.3012\n",
            "Epoch 65/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.2827\n",
            "Epoch 66/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.2851\n",
            "Epoch 67/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.2931\n",
            "Epoch 68/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.3043\n",
            "Epoch 69/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.2802\n",
            "Epoch 70/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.2875\n",
            "Epoch 71/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.2883\n",
            "Epoch 72/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.2923\n",
            "Epoch 73/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.2776\n",
            "Epoch 74/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.2870\n",
            "Epoch 75/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.3103\n",
            "Epoch 76/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0340 - val_loss: 0.3293\n",
            "Epoch 77/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.2890\n",
            "Epoch 78/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.2997\n",
            "Epoch 79/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.3157\n",
            "Epoch 80/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.3021\n",
            "Epoch 81/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.3125\n",
            "Epoch 82/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.3027\n",
            "Epoch 83/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.3098\n",
            "Epoch 84/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.3040\n",
            "Epoch 85/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.3099\n",
            "Epoch 86/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.3181\n",
            "Epoch 87/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.3153\n",
            "Epoch 88/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.3068\n",
            "Epoch 89/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.3038\n",
            "Epoch 90/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.3121\n",
            "Epoch 91/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.3231\n",
            "Epoch 92/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.3262\n",
            "Epoch 93/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.3364\n",
            "Epoch 94/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.3091\n",
            "Epoch 95/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.3194\n",
            "Epoch 96/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.3289\n",
            "Epoch 97/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.3337\n",
            "Epoch 98/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.3091\n",
            "Epoch 99/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.3412\n",
            "Epoch 100/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.3108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El7adzfgCMZu",
        "outputId": "23713d4d-c8fc-4bad-f348-8e7c86f482db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(historyd)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M085e8ovGpXx"
      },
      "source": [
        "berdasarkan diagram, val_los yang lumayan stabil berada pada kisaran epoch 30 - 35"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4AwJKBQCvxB"
      },
      "source": [
        "Untuk deeper, val_loss terendah sekitar 0.24 dan loss 0.08"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvmoSd59yTZx"
      },
      "source": [
        "##Mencari nilai terbaik berdasarkan optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EWUstrOyZby"
      },
      "source": [
        "###Wider Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpmbPN7eyrEQ"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "opt_sgd=SGD(lr=0.01, momentum=0.9)\n",
        "opt_Adadelta=Adadelta(lr=0.001, rho=0.95, epsilon=1e-07)\n",
        "opt_Adamax=Adamax(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
        "opt_RMSprop=RMSprop(lr=0.001,rho=0.9, momentum=0.0, epsilon=1e-07, centered=False)\n",
        "\n",
        "def wide_opt2(optim):\n",
        "  wider_model2 = Sequential()\n",
        "  wider_model2.add(Dense(40, input_dim=33, kernel_initializer='normal', activation='relu')) #neuron pada wider 40 dan input dim sebanyak fitur yaitu 33\n",
        "  wider_model2.add(Dense(1, kernel_initializer='normal'))\n",
        "  opt=optim\n",
        "  wider_model2.compile(loss='mean_squared_error', optimizer=opt) #menggunakan optimizer adam\n",
        "\n",
        "  historyw2 = wider_model2.fit(x=feature_train2, y=label_train2, validation_data=(feature_test2, label_test2), epochs=1000, batch_size=8) \n",
        "  plot_loss(historyw2)"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjoZFo6qzI4D"
      },
      "source": [
        "####SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3tyjuCNzSyo",
        "outputId": "4be57cd3-f1bb-4852-ce60-7f1e659de0f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wide_opt2(opt_sgd)"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7285 - val_loss: 0.5388\n",
            "Epoch 2/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4317 - val_loss: 0.4541\n",
            "Epoch 3/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2941 - val_loss: 0.3940\n",
            "Epoch 4/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2400 - val_loss: 0.4013\n",
            "Epoch 5/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2055 - val_loss: 0.3648\n",
            "Epoch 6/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2241 - val_loss: 0.2915\n",
            "Epoch 7/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1989 - val_loss: 0.3412\n",
            "Epoch 8/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1538 - val_loss: 0.3112\n",
            "Epoch 9/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1462 - val_loss: 0.3228\n",
            "Epoch 10/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1354 - val_loss: 0.2907\n",
            "Epoch 11/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1285 - val_loss: 0.3181\n",
            "Epoch 12/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.3398\n",
            "Epoch 13/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1097 - val_loss: 0.3432\n",
            "Epoch 14/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1120 - val_loss: 0.3451\n",
            "Epoch 15/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1137 - val_loss: 0.3602\n",
            "Epoch 16/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1208 - val_loss: 0.3110\n",
            "Epoch 17/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.3238\n",
            "Epoch 18/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1072 - val_loss: 0.3638\n",
            "Epoch 19/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1117 - val_loss: 0.3406\n",
            "Epoch 20/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.4078\n",
            "Epoch 21/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1269 - val_loss: 0.3530\n",
            "Epoch 22/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1264 - val_loss: 0.4294\n",
            "Epoch 23/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1018 - val_loss: 0.3365\n",
            "Epoch 24/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1028 - val_loss: 0.4179\n",
            "Epoch 25/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1157 - val_loss: 0.4507\n",
            "Epoch 26/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1238 - val_loss: 0.3285\n",
            "Epoch 27/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1007 - val_loss: 0.3543\n",
            "Epoch 28/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0887 - val_loss: 0.3386\n",
            "Epoch 29/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.3590\n",
            "Epoch 30/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.3577\n",
            "Epoch 31/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.3614\n",
            "Epoch 32/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.3809\n",
            "Epoch 33/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.4300\n",
            "Epoch 34/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.4249\n",
            "Epoch 35/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.4115\n",
            "Epoch 36/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.3808\n",
            "Epoch 37/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.4042\n",
            "Epoch 38/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.4178\n",
            "Epoch 39/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.4084\n",
            "Epoch 40/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.3934\n",
            "Epoch 41/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.4097\n",
            "Epoch 42/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.4340\n",
            "Epoch 43/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.4323\n",
            "Epoch 44/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0557 - val_loss: 0.3958\n",
            "Epoch 45/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.4252\n",
            "Epoch 46/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.4389\n",
            "Epoch 47/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.4370\n",
            "Epoch 48/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.4358\n",
            "Epoch 49/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.4422\n",
            "Epoch 50/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.4651\n",
            "Epoch 51/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.4684\n",
            "Epoch 52/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.4847\n",
            "Epoch 53/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.4208\n",
            "Epoch 54/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0675 - val_loss: 0.4766\n",
            "Epoch 55/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.4410\n",
            "Epoch 56/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.4254\n",
            "Epoch 57/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.4236\n",
            "Epoch 58/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.4949\n",
            "Epoch 59/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.4227\n",
            "Epoch 60/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.4849\n",
            "Epoch 61/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.4514\n",
            "Epoch 62/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.4667\n",
            "Epoch 63/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.4717\n",
            "Epoch 64/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.4708\n",
            "Epoch 65/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.5246\n",
            "Epoch 66/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.4779\n",
            "Epoch 67/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.5206\n",
            "Epoch 68/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.4801\n",
            "Epoch 69/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.4914\n",
            "Epoch 70/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.4971\n",
            "Epoch 71/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.5925\n",
            "Epoch 72/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0838 - val_loss: 0.4733\n",
            "Epoch 73/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.5372\n",
            "Epoch 74/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.4583\n",
            "Epoch 75/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.4587\n",
            "Epoch 76/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.4745\n",
            "Epoch 77/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.4741\n",
            "Epoch 78/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.4873\n",
            "Epoch 79/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.4482\n",
            "Epoch 80/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.4787\n",
            "Epoch 81/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.5136\n",
            "Epoch 82/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.4818\n",
            "Epoch 83/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.5194\n",
            "Epoch 84/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.5042\n",
            "Epoch 85/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.5436\n",
            "Epoch 86/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.5227\n",
            "Epoch 87/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.5194\n",
            "Epoch 88/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.5354\n",
            "Epoch 89/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.5493\n",
            "Epoch 90/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0512 - val_loss: 0.5304\n",
            "Epoch 91/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.5203\n",
            "Epoch 92/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.5317\n",
            "Epoch 93/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.5081\n",
            "Epoch 94/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.5303\n",
            "Epoch 95/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.5124\n",
            "Epoch 96/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.5319\n",
            "Epoch 97/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.5282\n",
            "Epoch 98/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0347 - val_loss: 0.5611\n",
            "Epoch 99/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.5369\n",
            "Epoch 100/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0345 - val_loss: 0.5784\n",
            "Epoch 101/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.5278\n",
            "Epoch 102/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.5546\n",
            "Epoch 103/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.5641\n",
            "Epoch 104/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.5807\n",
            "Epoch 105/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.5212\n",
            "Epoch 106/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.5484\n",
            "Epoch 107/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.5114\n",
            "Epoch 108/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.5363\n",
            "Epoch 109/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.5895\n",
            "Epoch 110/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0344 - val_loss: 0.5655\n",
            "Epoch 111/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.5527\n",
            "Epoch 112/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.5557\n",
            "Epoch 113/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0342 - val_loss: 0.5684\n",
            "Epoch 114/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.5424\n",
            "Epoch 115/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.5197\n",
            "Epoch 116/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.5801\n",
            "Epoch 117/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.5586\n",
            "Epoch 118/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0615 - val_loss: 0.5042\n",
            "Epoch 119/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.5248\n",
            "Epoch 120/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.4662\n",
            "Epoch 121/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.5631\n",
            "Epoch 122/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.5306\n",
            "Epoch 123/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.5213\n",
            "Epoch 124/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.5299\n",
            "Epoch 125/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.5693\n",
            "Epoch 126/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.5470\n",
            "Epoch 127/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.5661\n",
            "Epoch 128/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.5819\n",
            "Epoch 129/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.6037\n",
            "Epoch 130/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.5332\n",
            "Epoch 131/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.5532\n",
            "Epoch 132/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.5757\n",
            "Epoch 133/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.6031\n",
            "Epoch 134/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0329 - val_loss: 0.5902\n",
            "Epoch 135/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.6027\n",
            "Epoch 136/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.5931\n",
            "Epoch 137/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.6012\n",
            "Epoch 138/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.5710\n",
            "Epoch 139/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0329 - val_loss: 0.6218\n",
            "Epoch 140/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.5695\n",
            "Epoch 141/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.6146\n",
            "Epoch 142/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.5867\n",
            "Epoch 143/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.6041\n",
            "Epoch 144/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.6100\n",
            "Epoch 145/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.6175\n",
            "Epoch 146/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.6187\n",
            "Epoch 147/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.6819\n",
            "Epoch 148/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.5520\n",
            "Epoch 149/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.6276\n",
            "Epoch 150/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.5425\n",
            "Epoch 151/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0325 - val_loss: 0.5501\n",
            "Epoch 152/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.6004\n",
            "Epoch 153/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0339 - val_loss: 0.5703\n",
            "Epoch 154/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.6296\n",
            "Epoch 155/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.5836\n",
            "Epoch 156/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.5916\n",
            "Epoch 157/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.5861\n",
            "Epoch 158/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.6613\n",
            "Epoch 159/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.6200\n",
            "Epoch 160/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.6381\n",
            "Epoch 161/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.6314\n",
            "Epoch 162/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.6672\n",
            "Epoch 163/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.6130\n",
            "Epoch 164/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0339 - val_loss: 0.6550\n",
            "Epoch 165/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.6239\n",
            "Epoch 166/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.6233\n",
            "Epoch 167/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.6027\n",
            "Epoch 168/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.6620\n",
            "Epoch 169/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.5948\n",
            "Epoch 170/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.6073\n",
            "Epoch 171/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.6352\n",
            "Epoch 172/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.5926\n",
            "Epoch 173/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.6294\n",
            "Epoch 174/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.6105\n",
            "Epoch 175/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.6022\n",
            "Epoch 176/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.6785\n",
            "Epoch 177/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.6496\n",
            "Epoch 178/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.6308\n",
            "Epoch 179/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.6527\n",
            "Epoch 180/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.6121\n",
            "Epoch 181/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.6465\n",
            "Epoch 182/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.6617\n",
            "Epoch 183/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.6303\n",
            "Epoch 184/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.6697\n",
            "Epoch 185/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.6599\n",
            "Epoch 186/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.6614\n",
            "Epoch 187/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.7001\n",
            "Epoch 188/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.6613\n",
            "Epoch 189/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.7013\n",
            "Epoch 190/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.6501\n",
            "Epoch 191/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.6615\n",
            "Epoch 192/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.6489\n",
            "Epoch 193/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.6927\n",
            "Epoch 194/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.6391\n",
            "Epoch 195/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.6964\n",
            "Epoch 196/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0347 - val_loss: 0.6214\n",
            "Epoch 197/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.6410\n",
            "Epoch 198/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0448 - val_loss: 0.5654\n",
            "Epoch 199/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.6170\n",
            "Epoch 200/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.5782\n",
            "Epoch 201/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0349 - val_loss: 0.6054\n",
            "Epoch 202/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.5547\n",
            "Epoch 203/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.6167\n",
            "Epoch 204/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.6012\n",
            "Epoch 205/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.5799\n",
            "Epoch 206/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0339 - val_loss: 0.5888\n",
            "Epoch 207/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.5893\n",
            "Epoch 208/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.5600\n",
            "Epoch 209/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.5175\n",
            "Epoch 210/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.5365\n",
            "Epoch 211/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.5753\n",
            "Epoch 212/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.5494\n",
            "Epoch 213/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.5667\n",
            "Epoch 214/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.5918\n",
            "Epoch 215/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.5777\n",
            "Epoch 216/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.6147\n",
            "Epoch 217/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.6104\n",
            "Epoch 218/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.6050\n",
            "Epoch 219/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.6453\n",
            "Epoch 220/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.6535\n",
            "Epoch 221/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.6210\n",
            "Epoch 222/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.6807\n",
            "Epoch 223/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.6190\n",
            "Epoch 224/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.6670\n",
            "Epoch 225/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.6138\n",
            "Epoch 226/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.6306\n",
            "Epoch 227/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.6508\n",
            "Epoch 228/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.6718\n",
            "Epoch 229/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.5952\n",
            "Epoch 230/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.6398\n",
            "Epoch 231/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.6576\n",
            "Epoch 232/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.6426\n",
            "Epoch 233/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.6339\n",
            "Epoch 234/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.6162\n",
            "Epoch 235/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.6617\n",
            "Epoch 236/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0319 - val_loss: 0.6294\n",
            "Epoch 237/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.6093\n",
            "Epoch 238/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.6155\n",
            "Epoch 239/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.6030\n",
            "Epoch 240/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.5711\n",
            "Epoch 241/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.6361\n",
            "Epoch 242/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.6575\n",
            "Epoch 243/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.6167\n",
            "Epoch 244/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.6392\n",
            "Epoch 245/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.7010\n",
            "Epoch 246/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.6445\n",
            "Epoch 247/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.6673\n",
            "Epoch 248/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.5693\n",
            "Epoch 249/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.6254\n",
            "Epoch 250/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.6357\n",
            "Epoch 251/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.6467\n",
            "Epoch 252/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.6241\n",
            "Epoch 253/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.6753\n",
            "Epoch 254/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.6186\n",
            "Epoch 255/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.6581\n",
            "Epoch 256/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.6473\n",
            "Epoch 257/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.6348\n",
            "Epoch 258/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.6708\n",
            "Epoch 259/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.6877\n",
            "Epoch 260/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.6559\n",
            "Epoch 261/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.6695\n",
            "Epoch 262/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.6946\n",
            "Epoch 263/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.6834\n",
            "Epoch 264/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.6923\n",
            "Epoch 265/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.6779\n",
            "Epoch 266/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0340 - val_loss: 0.6852\n",
            "Epoch 267/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.7207\n",
            "Epoch 268/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.6393\n",
            "Epoch 269/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.7007\n",
            "Epoch 270/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0562 - val_loss: 0.5866\n",
            "Epoch 271/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.5724\n",
            "Epoch 272/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.5899\n",
            "Epoch 273/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.5839\n",
            "Epoch 274/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.6265\n",
            "Epoch 275/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.6064\n",
            "Epoch 276/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.6512\n",
            "Epoch 277/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.6323\n",
            "Epoch 278/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.6705\n",
            "Epoch 279/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.6432\n",
            "Epoch 280/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.6920\n",
            "Epoch 281/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.6506\n",
            "Epoch 282/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.6913\n",
            "Epoch 283/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.6854\n",
            "Epoch 284/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.6885\n",
            "Epoch 285/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.7105\n",
            "Epoch 286/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.7109\n",
            "Epoch 287/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.6875\n",
            "Epoch 288/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.6768\n",
            "Epoch 289/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.7070\n",
            "Epoch 290/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.6884\n",
            "Epoch 291/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.6883\n",
            "Epoch 292/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.7191\n",
            "Epoch 293/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.7510\n",
            "Epoch 294/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.6740\n",
            "Epoch 295/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.7110\n",
            "Epoch 296/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0321 - val_loss: 0.6566\n",
            "Epoch 297/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.6166\n",
            "Epoch 298/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.6279\n",
            "Epoch 299/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.6174\n",
            "Epoch 300/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.6429\n",
            "Epoch 301/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.6625\n",
            "Epoch 302/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0324 - val_loss: 0.6918\n",
            "Epoch 303/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.6938\n",
            "Epoch 304/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.5674\n",
            "Epoch 305/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.6477\n",
            "Epoch 306/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.6555\n",
            "Epoch 307/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.6392\n",
            "Epoch 308/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.6562\n",
            "Epoch 309/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.6774\n",
            "Epoch 310/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.6963\n",
            "Epoch 311/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.6829\n",
            "Epoch 312/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.7266\n",
            "Epoch 313/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.6973\n",
            "Epoch 314/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.6588\n",
            "Epoch 315/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.6775\n",
            "Epoch 316/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.6950\n",
            "Epoch 317/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.7288\n",
            "Epoch 318/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.7167\n",
            "Epoch 319/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.7627\n",
            "Epoch 320/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.7291\n",
            "Epoch 321/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.7286\n",
            "Epoch 322/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.7307\n",
            "Epoch 323/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.7169\n",
            "Epoch 324/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.7317\n",
            "Epoch 325/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.7039\n",
            "Epoch 326/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.7417\n",
            "Epoch 327/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.7124\n",
            "Epoch 328/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.7217\n",
            "Epoch 329/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.6919\n",
            "Epoch 330/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.7196\n",
            "Epoch 331/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.7408\n",
            "Epoch 332/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.7079\n",
            "Epoch 333/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.7087\n",
            "Epoch 334/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.7064\n",
            "Epoch 335/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.7041\n",
            "Epoch 336/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.6890\n",
            "Epoch 337/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.7218\n",
            "Epoch 338/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.6731\n",
            "Epoch 339/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.7252\n",
            "Epoch 340/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.7044\n",
            "Epoch 341/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.7870\n",
            "Epoch 342/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.6364\n",
            "Epoch 343/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.7422\n",
            "Epoch 344/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.7182\n",
            "Epoch 345/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.7202\n",
            "Epoch 346/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.7011\n",
            "Epoch 347/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.6636\n",
            "Epoch 348/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.6860\n",
            "Epoch 349/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.6736\n",
            "Epoch 350/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.6975\n",
            "Epoch 351/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.6998\n",
            "Epoch 352/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.7114\n",
            "Epoch 353/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.6849\n",
            "Epoch 354/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.7491\n",
            "Epoch 355/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.7051\n",
            "Epoch 356/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.7633\n",
            "Epoch 357/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.7166\n",
            "Epoch 358/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.7678\n",
            "Epoch 359/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.7531\n",
            "Epoch 360/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.7666\n",
            "Epoch 361/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.7903\n",
            "Epoch 362/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.7017\n",
            "Epoch 363/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.7022\n",
            "Epoch 364/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.6667\n",
            "Epoch 365/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.7851\n",
            "Epoch 366/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.6561\n",
            "Epoch 367/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.6995\n",
            "Epoch 368/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0329 - val_loss: 0.7034\n",
            "Epoch 369/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0339 - val_loss: 0.6829\n",
            "Epoch 370/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.7181\n",
            "Epoch 371/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.6973\n",
            "Epoch 372/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.7285\n",
            "Epoch 373/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.7155\n",
            "Epoch 374/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.6507\n",
            "Epoch 375/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.7945\n",
            "Epoch 376/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.6495\n",
            "Epoch 377/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.7192\n",
            "Epoch 378/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.6802\n",
            "Epoch 379/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.7197\n",
            "Epoch 380/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.7063\n",
            "Epoch 381/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.7298\n",
            "Epoch 382/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.7325\n",
            "Epoch 383/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.7189\n",
            "Epoch 384/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.7950\n",
            "Epoch 385/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.7508\n",
            "Epoch 386/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.7658\n",
            "Epoch 387/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.7312\n",
            "Epoch 388/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.7361\n",
            "Epoch 389/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.6684\n",
            "Epoch 390/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.6968\n",
            "Epoch 391/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0639 - val_loss: 0.6677\n",
            "Epoch 392/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.5974\n",
            "Epoch 393/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.6258\n",
            "Epoch 394/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.6373\n",
            "Epoch 395/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.6637\n",
            "Epoch 396/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.7013\n",
            "Epoch 397/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.6554\n",
            "Epoch 398/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.7240\n",
            "Epoch 399/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.7144\n",
            "Epoch 400/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.7226\n",
            "Epoch 401/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.7247\n",
            "Epoch 402/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.7578\n",
            "Epoch 403/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.6934\n",
            "Epoch 404/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.6630\n",
            "Epoch 405/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.7084\n",
            "Epoch 406/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.6702\n",
            "Epoch 407/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.7474\n",
            "Epoch 408/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.6999\n",
            "Epoch 409/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.7157\n",
            "Epoch 410/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.7004\n",
            "Epoch 411/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.7495\n",
            "Epoch 412/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.7200\n",
            "Epoch 413/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.7375\n",
            "Epoch 414/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.7501\n",
            "Epoch 415/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.6910\n",
            "Epoch 416/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.7277\n",
            "Epoch 417/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.7034\n",
            "Epoch 418/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.7609\n",
            "Epoch 419/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.7152\n",
            "Epoch 420/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.7760\n",
            "Epoch 421/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.6933\n",
            "Epoch 422/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.7273\n",
            "Epoch 423/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.6644\n",
            "Epoch 424/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.6000\n",
            "Epoch 425/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.8007\n",
            "Epoch 426/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.6533\n",
            "Epoch 427/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.6470\n",
            "Epoch 428/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.6634\n",
            "Epoch 429/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.6945\n",
            "Epoch 430/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.6851\n",
            "Epoch 431/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.6871\n",
            "Epoch 432/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.7025\n",
            "Epoch 433/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.6708\n",
            "Epoch 434/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.6609\n",
            "Epoch 435/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.6978\n",
            "Epoch 436/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.6644\n",
            "Epoch 437/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.7309\n",
            "Epoch 438/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.7230\n",
            "Epoch 439/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.7543\n",
            "Epoch 440/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.7260\n",
            "Epoch 441/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.7024\n",
            "Epoch 442/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.6881\n",
            "Epoch 443/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.7325\n",
            "Epoch 444/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.6720\n",
            "Epoch 445/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.6995\n",
            "Epoch 446/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.7116\n",
            "Epoch 447/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.7167\n",
            "Epoch 448/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.7598\n",
            "Epoch 449/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.6878\n",
            "Epoch 450/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.7646\n",
            "Epoch 451/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.6881\n",
            "Epoch 452/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.7237\n",
            "Epoch 453/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.6559\n",
            "Epoch 454/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.8014\n",
            "Epoch 455/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.7073\n",
            "Epoch 456/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.7076\n",
            "Epoch 457/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.6240\n",
            "Epoch 458/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.6853\n",
            "Epoch 459/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.6726\n",
            "Epoch 460/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.6939\n",
            "Epoch 461/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.6947\n",
            "Epoch 462/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.7122\n",
            "Epoch 463/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.7348\n",
            "Epoch 464/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.7491\n",
            "Epoch 465/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.7255\n",
            "Epoch 466/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.7272\n",
            "Epoch 467/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.7103\n",
            "Epoch 468/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.7712\n",
            "Epoch 469/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.7152\n",
            "Epoch 470/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.7552\n",
            "Epoch 471/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.7184\n",
            "Epoch 472/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.7929\n",
            "Epoch 473/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.7225\n",
            "Epoch 474/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.7425\n",
            "Epoch 475/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.6783\n",
            "Epoch 476/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.7250\n",
            "Epoch 477/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.7492\n",
            "Epoch 478/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.7072\n",
            "Epoch 479/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.7177\n",
            "Epoch 480/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.7126\n",
            "Epoch 481/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.7338\n",
            "Epoch 482/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.6972\n",
            "Epoch 483/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.7288\n",
            "Epoch 484/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.6815\n",
            "Epoch 485/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.7141\n",
            "Epoch 486/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.6916\n",
            "Epoch 487/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.6736\n",
            "Epoch 488/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.7456\n",
            "Epoch 489/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.7150\n",
            "Epoch 490/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.7637\n",
            "Epoch 491/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.7339\n",
            "Epoch 492/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.6741\n",
            "Epoch 493/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.6937\n",
            "Epoch 494/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.7186\n",
            "Epoch 495/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.7443\n",
            "Epoch 496/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.6421\n",
            "Epoch 497/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.7225\n",
            "Epoch 498/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.6418\n",
            "Epoch 499/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.7248\n",
            "Epoch 500/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.7087\n",
            "Epoch 501/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.6990\n",
            "Epoch 502/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.6962\n",
            "Epoch 503/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.7464\n",
            "Epoch 504/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.7180\n",
            "Epoch 505/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.6960\n",
            "Epoch 506/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.7213\n",
            "Epoch 507/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.7316\n",
            "Epoch 508/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.7464\n",
            "Epoch 509/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.7411\n",
            "Epoch 510/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.7682\n",
            "Epoch 511/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.7348\n",
            "Epoch 512/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.7150\n",
            "Epoch 513/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.7584\n",
            "Epoch 514/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.7511\n",
            "Epoch 515/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.7594\n",
            "Epoch 516/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.7378\n",
            "Epoch 517/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.7497\n",
            "Epoch 518/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.7356\n",
            "Epoch 519/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.7674\n",
            "Epoch 520/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.7555\n",
            "Epoch 521/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.7551\n",
            "Epoch 522/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.7463\n",
            "Epoch 523/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.7567\n",
            "Epoch 524/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.7378\n",
            "Epoch 525/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.7593\n",
            "Epoch 526/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.7504\n",
            "Epoch 527/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.7240\n",
            "Epoch 528/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.7778\n",
            "Epoch 529/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.7516\n",
            "Epoch 530/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.7114\n",
            "Epoch 531/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.8431\n",
            "Epoch 532/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.7339\n",
            "Epoch 533/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.6765\n",
            "Epoch 534/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.6700\n",
            "Epoch 535/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.6748\n",
            "Epoch 536/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.7014\n",
            "Epoch 537/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.6978\n",
            "Epoch 538/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.6686\n",
            "Epoch 539/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.6972\n",
            "Epoch 540/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.7413\n",
            "Epoch 541/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.6879\n",
            "Epoch 542/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.7493\n",
            "Epoch 543/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.7057\n",
            "Epoch 544/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.7236\n",
            "Epoch 545/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.6939\n",
            "Epoch 546/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.7409\n",
            "Epoch 547/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.7133\n",
            "Epoch 548/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.7379\n",
            "Epoch 549/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.7380\n",
            "Epoch 550/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.7533\n",
            "Epoch 551/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.7655\n",
            "Epoch 552/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.7241\n",
            "Epoch 553/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.7345\n",
            "Epoch 554/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.7555\n",
            "Epoch 555/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.7842\n",
            "Epoch 556/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.7747\n",
            "Epoch 557/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.7504\n",
            "Epoch 558/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.7740\n",
            "Epoch 559/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.7287\n",
            "Epoch 560/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.7631\n",
            "Epoch 561/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.7292\n",
            "Epoch 562/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.6881\n",
            "Epoch 563/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.7038\n",
            "Epoch 564/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.6912\n",
            "Epoch 565/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.7484\n",
            "Epoch 566/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.7022\n",
            "Epoch 567/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.7179\n",
            "Epoch 568/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.7604\n",
            "Epoch 569/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.7274\n",
            "Epoch 570/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.7327\n",
            "Epoch 571/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.6942\n",
            "Epoch 572/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.7471\n",
            "Epoch 573/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.7420\n",
            "Epoch 574/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.7484\n",
            "Epoch 575/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.6207\n",
            "Epoch 576/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.7544\n",
            "Epoch 577/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.6921\n",
            "Epoch 578/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.6709\n",
            "Epoch 579/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.6559\n",
            "Epoch 580/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.6510\n",
            "Epoch 581/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.6601\n",
            "Epoch 582/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.7302\n",
            "Epoch 583/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.6833\n",
            "Epoch 584/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.7350\n",
            "Epoch 585/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.6987\n",
            "Epoch 586/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.7303\n",
            "Epoch 587/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.7558\n",
            "Epoch 588/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.7255\n",
            "Epoch 589/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.6896\n",
            "Epoch 590/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.7065\n",
            "Epoch 591/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.7325\n",
            "Epoch 592/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.7007\n",
            "Epoch 593/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.7720\n",
            "Epoch 594/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.6945\n",
            "Epoch 595/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.7628\n",
            "Epoch 596/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.7146\n",
            "Epoch 597/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.7195\n",
            "Epoch 598/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.7625\n",
            "Epoch 599/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.7209\n",
            "Epoch 600/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.7487\n",
            "Epoch 601/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.7197\n",
            "Epoch 602/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.7849\n",
            "Epoch 603/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.6384\n",
            "Epoch 604/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.6405\n",
            "Epoch 605/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.7002\n",
            "Epoch 606/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.7905\n",
            "Epoch 607/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.6976\n",
            "Epoch 608/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.7023\n",
            "Epoch 609/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.6527\n",
            "Epoch 610/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.6550\n",
            "Epoch 611/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.6949\n",
            "Epoch 612/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.6756\n",
            "Epoch 613/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.7037\n",
            "Epoch 614/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.6778\n",
            "Epoch 615/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.7240\n",
            "Epoch 616/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.6519\n",
            "Epoch 617/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.6838\n",
            "Epoch 618/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.7179\n",
            "Epoch 619/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.7445\n",
            "Epoch 620/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.7664\n",
            "Epoch 621/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.7166\n",
            "Epoch 622/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.7123\n",
            "Epoch 623/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.7286\n",
            "Epoch 624/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.7145\n",
            "Epoch 625/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.7291\n",
            "Epoch 626/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.7681\n",
            "Epoch 627/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.6980\n",
            "Epoch 628/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.7301\n",
            "Epoch 629/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.7521\n",
            "Epoch 630/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.7519\n",
            "Epoch 631/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.7657\n",
            "Epoch 632/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.7206\n",
            "Epoch 633/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.7677\n",
            "Epoch 634/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.7401\n",
            "Epoch 635/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.7656\n",
            "Epoch 636/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.7498\n",
            "Epoch 637/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.7481\n",
            "Epoch 638/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.7681\n",
            "Epoch 639/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.7474\n",
            "Epoch 640/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.7463\n",
            "Epoch 641/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.7747\n",
            "Epoch 642/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.7570\n",
            "Epoch 643/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.7558\n",
            "Epoch 644/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.7458\n",
            "Epoch 645/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.7494\n",
            "Epoch 646/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.7950\n",
            "Epoch 647/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.7432\n",
            "Epoch 648/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.7461\n",
            "Epoch 649/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.8443\n",
            "Epoch 650/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.7206\n",
            "Epoch 651/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.6714\n",
            "Epoch 652/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.7826\n",
            "Epoch 653/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.6782\n",
            "Epoch 654/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.7617\n",
            "Epoch 655/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.6804\n",
            "Epoch 656/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.7481\n",
            "Epoch 657/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.7157\n",
            "Epoch 658/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.7572\n",
            "Epoch 659/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.7249\n",
            "Epoch 660/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.7334\n",
            "Epoch 661/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.7262\n",
            "Epoch 662/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.7500\n",
            "Epoch 663/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.7195\n",
            "Epoch 664/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.7063\n",
            "Epoch 665/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.6739\n",
            "Epoch 666/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.7756\n",
            "Epoch 667/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.7021\n",
            "Epoch 668/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.7789\n",
            "Epoch 669/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.7681\n",
            "Epoch 670/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.7293\n",
            "Epoch 671/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.7149\n",
            "Epoch 672/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.7429\n",
            "Epoch 673/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.7042\n",
            "Epoch 674/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.7379\n",
            "Epoch 675/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.7139\n",
            "Epoch 676/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.7857\n",
            "Epoch 677/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.8484\n",
            "Epoch 678/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.6527\n",
            "Epoch 679/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.6951\n",
            "Epoch 680/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.6568\n",
            "Epoch 681/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.7800\n",
            "Epoch 682/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.7393\n",
            "Epoch 683/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.6844\n",
            "Epoch 684/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.7136\n",
            "Epoch 685/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.7187\n",
            "Epoch 686/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.7417\n",
            "Epoch 687/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.7135\n",
            "Epoch 688/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.7172\n",
            "Epoch 689/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.7060\n",
            "Epoch 690/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.7146\n",
            "Epoch 691/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.7277\n",
            "Epoch 692/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.6881\n",
            "Epoch 693/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.7605\n",
            "Epoch 694/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.7022\n",
            "Epoch 695/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.7564\n",
            "Epoch 696/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.7441\n",
            "Epoch 697/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.7443\n",
            "Epoch 698/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.7654\n",
            "Epoch 699/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.7700\n",
            "Epoch 700/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.7364\n",
            "Epoch 701/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.7793\n",
            "Epoch 702/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.7728\n",
            "Epoch 703/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.7914\n",
            "Epoch 704/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.7638\n",
            "Epoch 705/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.7842\n",
            "Epoch 706/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.7726\n",
            "Epoch 707/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.7961\n",
            "Epoch 708/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.7824\n",
            "Epoch 709/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.7873\n",
            "Epoch 710/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.7951\n",
            "Epoch 711/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.8091\n",
            "Epoch 712/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.7719\n",
            "Epoch 713/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.7857\n",
            "Epoch 714/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.7846\n",
            "Epoch 715/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.8080\n",
            "Epoch 716/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.8270\n",
            "Epoch 717/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.7641\n",
            "Epoch 718/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.7784\n",
            "Epoch 719/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.7897\n",
            "Epoch 720/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.7557\n",
            "Epoch 721/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.7691\n",
            "Epoch 722/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.7929\n",
            "Epoch 723/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.7492\n",
            "Epoch 724/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.7439\n",
            "Epoch 725/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.7584\n",
            "Epoch 726/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.7679\n",
            "Epoch 727/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.7615\n",
            "Epoch 728/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.7909\n",
            "Epoch 729/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.7863\n",
            "Epoch 730/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.8074\n",
            "Epoch 731/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.7168\n",
            "Epoch 732/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.7808\n",
            "Epoch 733/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.7600\n",
            "Epoch 734/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.7944\n",
            "Epoch 735/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.7728\n",
            "Epoch 736/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.8135\n",
            "Epoch 737/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.7908\n",
            "Epoch 738/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.7895\n",
            "Epoch 739/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.7801\n",
            "Epoch 740/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.7881\n",
            "Epoch 741/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.7852\n",
            "Epoch 742/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.7785\n",
            "Epoch 743/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.7251\n",
            "Epoch 744/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.8172\n",
            "Epoch 745/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.7481\n",
            "Epoch 746/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.7869\n",
            "Epoch 747/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.7696\n",
            "Epoch 748/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.7748\n",
            "Epoch 749/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.7679\n",
            "Epoch 750/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.7024\n",
            "Epoch 751/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.7028\n",
            "Epoch 752/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.6013\n",
            "Epoch 753/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.7066\n",
            "Epoch 754/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.6762\n",
            "Epoch 755/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.7474\n",
            "Epoch 756/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.7117\n",
            "Epoch 757/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.7449\n",
            "Epoch 758/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.7473\n",
            "Epoch 759/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.7485\n",
            "Epoch 760/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.7012\n",
            "Epoch 761/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.7450\n",
            "Epoch 762/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.7305\n",
            "Epoch 763/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.7089\n",
            "Epoch 764/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.7483\n",
            "Epoch 765/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.7061\n",
            "Epoch 766/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.6955\n",
            "Epoch 767/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.7522\n",
            "Epoch 768/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.7329\n",
            "Epoch 769/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.7307\n",
            "Epoch 770/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.7736\n",
            "Epoch 771/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.7549\n",
            "Epoch 772/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.7952\n",
            "Epoch 773/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.7504\n",
            "Epoch 774/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.7795\n",
            "Epoch 775/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.7817\n",
            "Epoch 776/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.7513\n",
            "Epoch 777/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.7911\n",
            "Epoch 778/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.7685\n",
            "Epoch 779/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.8147\n",
            "Epoch 780/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.7825\n",
            "Epoch 781/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.8082\n",
            "Epoch 782/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.8072\n",
            "Epoch 783/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.8095\n",
            "Epoch 784/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.7938\n",
            "Epoch 785/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.8137\n",
            "Epoch 786/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.8019\n",
            "Epoch 787/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.8058\n",
            "Epoch 788/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.8309\n",
            "Epoch 789/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.7933\n",
            "Epoch 790/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.7852\n",
            "Epoch 791/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.8052\n",
            "Epoch 792/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.7898\n",
            "Epoch 793/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.8338\n",
            "Epoch 794/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.7824\n",
            "Epoch 795/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.7933\n",
            "Epoch 796/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.8240\n",
            "Epoch 797/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.8128\n",
            "Epoch 798/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.8053\n",
            "Epoch 799/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.7902\n",
            "Epoch 800/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.7891\n",
            "Epoch 801/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.8144\n",
            "Epoch 802/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.8455\n",
            "Epoch 803/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.7259\n",
            "Epoch 804/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0613 - val_loss: 0.6920\n",
            "Epoch 805/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1277 - val_loss: 0.7226\n",
            "Epoch 806/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0970 - val_loss: 0.6372\n",
            "Epoch 807/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.6549\n",
            "Epoch 808/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0329 - val_loss: 0.6108\n",
            "Epoch 809/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.6540\n",
            "Epoch 810/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.6671\n",
            "Epoch 811/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.6545\n",
            "Epoch 812/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.7168\n",
            "Epoch 813/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.7237\n",
            "Epoch 814/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.7177\n",
            "Epoch 815/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.7561\n",
            "Epoch 816/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.7727\n",
            "Epoch 817/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.7617\n",
            "Epoch 818/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.7546\n",
            "Epoch 819/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.7689\n",
            "Epoch 820/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.7674\n",
            "Epoch 821/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.7686\n",
            "Epoch 822/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.7855\n",
            "Epoch 823/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.8121\n",
            "Epoch 824/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.7996\n",
            "Epoch 825/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.7744\n",
            "Epoch 826/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.7599\n",
            "Epoch 827/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.7863\n",
            "Epoch 828/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.7562\n",
            "Epoch 829/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.8298\n",
            "Epoch 830/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.7760\n",
            "Epoch 831/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.8307\n",
            "Epoch 832/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.7655\n",
            "Epoch 833/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.7825\n",
            "Epoch 834/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.7802\n",
            "Epoch 835/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.8280\n",
            "Epoch 836/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.7343\n",
            "Epoch 837/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.7551\n",
            "Epoch 838/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.7746\n",
            "Epoch 839/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.8151\n",
            "Epoch 840/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.7503\n",
            "Epoch 841/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.7699\n",
            "Epoch 842/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.7757\n",
            "Epoch 843/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.8031\n",
            "Epoch 844/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.8100\n",
            "Epoch 845/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.7445\n",
            "Epoch 846/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.7634\n",
            "Epoch 847/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.7325\n",
            "Epoch 848/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.7708\n",
            "Epoch 849/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.7664\n",
            "Epoch 850/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.7722\n",
            "Epoch 851/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.7828\n",
            "Epoch 852/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.7557\n",
            "Epoch 853/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.7484\n",
            "Epoch 854/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.7692\n",
            "Epoch 855/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.7747\n",
            "Epoch 856/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.7683\n",
            "Epoch 857/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.7893\n",
            "Epoch 858/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.7783\n",
            "Epoch 859/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.7774\n",
            "Epoch 860/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.8454\n",
            "Epoch 861/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.7515\n",
            "Epoch 862/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.7998\n",
            "Epoch 863/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.8081\n",
            "Epoch 864/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.7653\n",
            "Epoch 865/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.7939\n",
            "Epoch 866/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.8077\n",
            "Epoch 867/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.7931\n",
            "Epoch 868/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.7953\n",
            "Epoch 869/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.7980\n",
            "Epoch 870/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.7691\n",
            "Epoch 871/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.7895\n",
            "Epoch 872/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.7653\n",
            "Epoch 873/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.8505\n",
            "Epoch 874/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.7578\n",
            "Epoch 875/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.7836\n",
            "Epoch 876/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.8122\n",
            "Epoch 877/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.8048\n",
            "Epoch 878/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.8195\n",
            "Epoch 879/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.8261\n",
            "Epoch 880/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.8283\n",
            "Epoch 881/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.8217\n",
            "Epoch 882/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.8530\n",
            "Epoch 883/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.7898\n",
            "Epoch 884/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.8487\n",
            "Epoch 885/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.7973\n",
            "Epoch 886/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.8723\n",
            "Epoch 887/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.8079\n",
            "Epoch 888/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.8343\n",
            "Epoch 889/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.8081\n",
            "Epoch 890/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.8224\n",
            "Epoch 891/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.8162\n",
            "Epoch 892/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.8333\n",
            "Epoch 893/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.7874\n",
            "Epoch 894/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.8614\n",
            "Epoch 895/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.8217\n",
            "Epoch 896/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.7889\n",
            "Epoch 897/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.7893\n",
            "Epoch 898/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.8542\n",
            "Epoch 899/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.7978\n",
            "Epoch 900/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.8353\n",
            "Epoch 901/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.8366\n",
            "Epoch 902/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0424 - val_loss: 0.7965\n",
            "Epoch 903/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.8221\n",
            "Epoch 904/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1017 - val_loss: 0.7221\n",
            "Epoch 905/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0635 - val_loss: 0.6714\n",
            "Epoch 906/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.7054\n",
            "Epoch 907/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.7192\n",
            "Epoch 908/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.7167\n",
            "Epoch 909/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.7263\n",
            "Epoch 910/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.7056\n",
            "Epoch 911/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.7430\n",
            "Epoch 912/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.7775\n",
            "Epoch 913/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.7596\n",
            "Epoch 914/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.7973\n",
            "Epoch 915/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.7848\n",
            "Epoch 916/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.7909\n",
            "Epoch 917/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.7695\n",
            "Epoch 918/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.8231\n",
            "Epoch 919/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.7921\n",
            "Epoch 920/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.8535\n",
            "Epoch 921/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.8054\n",
            "Epoch 922/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.8106\n",
            "Epoch 923/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.8364\n",
            "Epoch 924/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.8219\n",
            "Epoch 925/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.8468\n",
            "Epoch 926/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.8503\n",
            "Epoch 927/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.8179\n",
            "Epoch 928/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.8299\n",
            "Epoch 929/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.8369\n",
            "Epoch 930/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.8480\n",
            "Epoch 931/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.8460\n",
            "Epoch 932/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.8543\n",
            "Epoch 933/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.8691\n",
            "Epoch 934/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.8333\n",
            "Epoch 935/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.8529\n",
            "Epoch 936/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.8597\n",
            "Epoch 937/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.8369\n",
            "Epoch 938/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.8365\n",
            "Epoch 939/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.8234\n",
            "Epoch 940/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.7898\n",
            "Epoch 941/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.7768\n",
            "Epoch 942/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.8549\n",
            "Epoch 943/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.8299\n",
            "Epoch 944/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.8373\n",
            "Epoch 945/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.8184\n",
            "Epoch 946/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.8870\n",
            "Epoch 947/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.8045\n",
            "Epoch 948/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.8140\n",
            "Epoch 949/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.7750\n",
            "Epoch 950/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.8536\n",
            "Epoch 951/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.8306\n",
            "Epoch 952/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.8299\n",
            "Epoch 953/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.7800\n",
            "Epoch 954/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.8749\n",
            "Epoch 955/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.7990\n",
            "Epoch 956/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.7785\n",
            "Epoch 957/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.8051\n",
            "Epoch 958/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.8063\n",
            "Epoch 959/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.8114\n",
            "Epoch 960/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.7241\n",
            "Epoch 961/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.8416\n",
            "Epoch 962/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.8116\n",
            "Epoch 963/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.8197\n",
            "Epoch 964/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.7613\n",
            "Epoch 965/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.7957\n",
            "Epoch 966/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.7637\n",
            "Epoch 967/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.8259\n",
            "Epoch 968/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.7847\n",
            "Epoch 969/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.8051\n",
            "Epoch 970/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.7937\n",
            "Epoch 971/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.8117\n",
            "Epoch 972/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.8371\n",
            "Epoch 973/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.7995\n",
            "Epoch 974/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.8269\n",
            "Epoch 975/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.7919\n",
            "Epoch 976/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.8343\n",
            "Epoch 977/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.7821\n",
            "Epoch 978/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.7962\n",
            "Epoch 979/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.8209\n",
            "Epoch 980/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.8445\n",
            "Epoch 981/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.8708\n",
            "Epoch 982/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.8723\n",
            "Epoch 983/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.8482\n",
            "Epoch 984/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.8169\n",
            "Epoch 985/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.8152\n",
            "Epoch 986/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.8339\n",
            "Epoch 987/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.7978\n",
            "Epoch 988/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.8075\n",
            "Epoch 989/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.7758\n",
            "Epoch 990/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.7985\n",
            "Epoch 991/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.8415\n",
            "Epoch 992/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.7682\n",
            "Epoch 993/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.7776\n",
            "Epoch 994/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.6989\n",
            "Epoch 995/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.7870\n",
            "Epoch 996/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.7889\n",
            "Epoch 997/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.7377\n",
            "Epoch 998/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.8715\n",
            "Epoch 999/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.7528\n",
            "Epoch 1000/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.7717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBWzNyI3zTXq"
      },
      "source": [
        "####Adamax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxyEd90yzIJ-",
        "outputId": "fa41876e-3683-49fd-9519-3fa772d6343d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wide_opt2(opt_Adamax)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.9229 - val_loss: 0.8527\n",
            "Epoch 2/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8299 - val_loss: 0.7805\n",
            "Epoch 3/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7449 - val_loss: 0.7077\n",
            "Epoch 4/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6613 - val_loss: 0.6381\n",
            "Epoch 5/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5826 - val_loss: 0.5821\n",
            "Epoch 6/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5177 - val_loss: 0.5403\n",
            "Epoch 7/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4689 - val_loss: 0.5110\n",
            "Epoch 8/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4311 - val_loss: 0.4917\n",
            "Epoch 9/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4009 - val_loss: 0.4776\n",
            "Epoch 10/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3767 - val_loss: 0.4701\n",
            "Epoch 11/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3582 - val_loss: 0.4617\n",
            "Epoch 12/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3423 - val_loss: 0.4586\n",
            "Epoch 13/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3279 - val_loss: 0.4540\n",
            "Epoch 14/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3175 - val_loss: 0.4495\n",
            "Epoch 15/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3046 - val_loss: 0.4426\n",
            "Epoch 16/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2953 - val_loss: 0.4388\n",
            "Epoch 17/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2854 - val_loss: 0.4347\n",
            "Epoch 18/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2778 - val_loss: 0.4305\n",
            "Epoch 19/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2698 - val_loss: 0.4269\n",
            "Epoch 20/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2631 - val_loss: 0.4216\n",
            "Epoch 21/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2582 - val_loss: 0.4142\n",
            "Epoch 22/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2512 - val_loss: 0.4123\n",
            "Epoch 23/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2448 - val_loss: 0.4072\n",
            "Epoch 24/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2406 - val_loss: 0.4030\n",
            "Epoch 25/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2356 - val_loss: 0.3969\n",
            "Epoch 26/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2312 - val_loss: 0.3970\n",
            "Epoch 27/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2259 - val_loss: 0.3891\n",
            "Epoch 28/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2212 - val_loss: 0.3875\n",
            "Epoch 29/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2171 - val_loss: 0.3834\n",
            "Epoch 30/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2139 - val_loss: 0.3775\n",
            "Epoch 31/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2096 - val_loss: 0.3751\n",
            "Epoch 32/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2058 - val_loss: 0.3712\n",
            "Epoch 33/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2021 - val_loss: 0.3669\n",
            "Epoch 34/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1991 - val_loss: 0.3645\n",
            "Epoch 35/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1959 - val_loss: 0.3597\n",
            "Epoch 36/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1927 - val_loss: 0.3593\n",
            "Epoch 37/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1891 - val_loss: 0.3559\n",
            "Epoch 38/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1869 - val_loss: 0.3519\n",
            "Epoch 39/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1838 - val_loss: 0.3511\n",
            "Epoch 40/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1813 - val_loss: 0.3492\n",
            "Epoch 41/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1783 - val_loss: 0.3441\n",
            "Epoch 42/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1764 - val_loss: 0.3410\n",
            "Epoch 43/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1736 - val_loss: 0.3391\n",
            "Epoch 44/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1714 - val_loss: 0.3388\n",
            "Epoch 45/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1694 - val_loss: 0.3335\n",
            "Epoch 46/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1659 - val_loss: 0.3335\n",
            "Epoch 47/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1647 - val_loss: 0.3317\n",
            "Epoch 48/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1623 - val_loss: 0.3296\n",
            "Epoch 49/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.3280\n",
            "Epoch 50/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1588 - val_loss: 0.3263\n",
            "Epoch 51/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1566 - val_loss: 0.3254\n",
            "Epoch 52/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1561 - val_loss: 0.3244\n",
            "Epoch 53/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1538 - val_loss: 0.3249\n",
            "Epoch 54/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1531 - val_loss: 0.3245\n",
            "Epoch 55/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1494 - val_loss: 0.3189\n",
            "Epoch 56/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1493 - val_loss: 0.3205\n",
            "Epoch 57/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1474 - val_loss: 0.3192\n",
            "Epoch 58/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.3185\n",
            "Epoch 59/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1447 - val_loss: 0.3151\n",
            "Epoch 60/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1422 - val_loss: 0.3163\n",
            "Epoch 61/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1408 - val_loss: 0.3146\n",
            "Epoch 62/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1389 - val_loss: 0.3144\n",
            "Epoch 63/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.3135\n",
            "Epoch 64/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1365 - val_loss: 0.3120\n",
            "Epoch 65/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1346 - val_loss: 0.3143\n",
            "Epoch 66/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1331 - val_loss: 0.3114\n",
            "Epoch 67/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1316 - val_loss: 0.3156\n",
            "Epoch 68/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1302 - val_loss: 0.3126\n",
            "Epoch 69/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1293 - val_loss: 0.3139\n",
            "Epoch 70/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1274 - val_loss: 0.3130\n",
            "Epoch 71/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1262 - val_loss: 0.3115\n",
            "Epoch 72/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1253 - val_loss: 0.3192\n",
            "Epoch 73/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1245 - val_loss: 0.3122\n",
            "Epoch 74/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1228 - val_loss: 0.3143\n",
            "Epoch 75/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1211 - val_loss: 0.3143\n",
            "Epoch 76/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.3155\n",
            "Epoch 77/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1190 - val_loss: 0.3150\n",
            "Epoch 78/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.3123\n",
            "Epoch 79/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1159 - val_loss: 0.3155\n",
            "Epoch 80/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1151 - val_loss: 0.3160\n",
            "Epoch 81/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1136 - val_loss: 0.3151\n",
            "Epoch 82/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1129 - val_loss: 0.3156\n",
            "Epoch 83/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1115 - val_loss: 0.3152\n",
            "Epoch 84/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1103 - val_loss: 0.3136\n",
            "Epoch 85/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1091 - val_loss: 0.3175\n",
            "Epoch 86/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1085 - val_loss: 0.3162\n",
            "Epoch 87/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1072 - val_loss: 0.3176\n",
            "Epoch 88/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1064 - val_loss: 0.3188\n",
            "Epoch 89/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1062 - val_loss: 0.3181\n",
            "Epoch 90/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1047 - val_loss: 0.3158\n",
            "Epoch 91/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1034 - val_loss: 0.3230\n",
            "Epoch 92/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1019 - val_loss: 0.3164\n",
            "Epoch 93/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1011 - val_loss: 0.3198\n",
            "Epoch 94/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0995 - val_loss: 0.3210\n",
            "Epoch 95/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0989 - val_loss: 0.3227\n",
            "Epoch 96/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1001 - val_loss: 0.3226\n",
            "Epoch 97/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0974 - val_loss: 0.3177\n",
            "Epoch 98/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0966 - val_loss: 0.3217\n",
            "Epoch 99/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0964 - val_loss: 0.3219\n",
            "Epoch 100/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0947 - val_loss: 0.3216\n",
            "Epoch 101/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0937 - val_loss: 0.3229\n",
            "Epoch 102/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0927 - val_loss: 0.3233\n",
            "Epoch 103/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.3263\n",
            "Epoch 104/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0911 - val_loss: 0.3242\n",
            "Epoch 105/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.3285\n",
            "Epoch 106/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0896 - val_loss: 0.3269\n",
            "Epoch 107/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.3301\n",
            "Epoch 108/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.3298\n",
            "Epoch 109/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.3308\n",
            "Epoch 110/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0862 - val_loss: 0.3309\n",
            "Epoch 111/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.3338\n",
            "Epoch 112/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.3346\n",
            "Epoch 113/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.3356\n",
            "Epoch 114/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.3363\n",
            "Epoch 115/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0821 - val_loss: 0.3388\n",
            "Epoch 116/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.3378\n",
            "Epoch 117/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.3374\n",
            "Epoch 118/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.3423\n",
            "Epoch 119/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.3390\n",
            "Epoch 120/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.3385\n",
            "Epoch 121/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.3453\n",
            "Epoch 122/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.3433\n",
            "Epoch 123/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.3451\n",
            "Epoch 124/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.3479\n",
            "Epoch 125/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.3452\n",
            "Epoch 126/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.3509\n",
            "Epoch 127/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.3488\n",
            "Epoch 128/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.3528\n",
            "Epoch 129/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.3522\n",
            "Epoch 130/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.3571\n",
            "Epoch 131/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.3555\n",
            "Epoch 132/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.3585\n",
            "Epoch 133/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.3593\n",
            "Epoch 134/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.3622\n",
            "Epoch 135/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.3621\n",
            "Epoch 136/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.3631\n",
            "Epoch 137/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.3638\n",
            "Epoch 138/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0670 - val_loss: 0.3638\n",
            "Epoch 139/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.3690\n",
            "Epoch 140/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.3735\n",
            "Epoch 141/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0653 - val_loss: 0.3694\n",
            "Epoch 142/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.3722\n",
            "Epoch 143/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.3726\n",
            "Epoch 144/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.3735\n",
            "Epoch 145/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0631 - val_loss: 0.3774\n",
            "Epoch 146/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.3761\n",
            "Epoch 147/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.3795\n",
            "Epoch 148/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.3805\n",
            "Epoch 149/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.3817\n",
            "Epoch 150/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.3869\n",
            "Epoch 151/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.3839\n",
            "Epoch 152/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.3884\n",
            "Epoch 153/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.3885\n",
            "Epoch 154/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.3888\n",
            "Epoch 155/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.3882\n",
            "Epoch 156/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.3925\n",
            "Epoch 157/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.3935\n",
            "Epoch 158/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0565 - val_loss: 0.3960\n",
            "Epoch 159/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.3956\n",
            "Epoch 160/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.3966\n",
            "Epoch 161/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.4022\n",
            "Epoch 162/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0549 - val_loss: 0.4002\n",
            "Epoch 163/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.4026\n",
            "Epoch 164/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0536 - val_loss: 0.4058\n",
            "Epoch 165/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.4073\n",
            "Epoch 166/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.4058\n",
            "Epoch 167/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.4115\n",
            "Epoch 168/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.4097\n",
            "Epoch 169/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.4136\n",
            "Epoch 170/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0517 - val_loss: 0.4166\n",
            "Epoch 171/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.4165\n",
            "Epoch 172/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0510 - val_loss: 0.4155\n",
            "Epoch 173/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.4181\n",
            "Epoch 174/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.4188\n",
            "Epoch 175/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.4219\n",
            "Epoch 176/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.4231\n",
            "Epoch 177/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.4270\n",
            "Epoch 178/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.4234\n",
            "Epoch 179/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.4279\n",
            "Epoch 180/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.4329\n",
            "Epoch 181/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.4278\n",
            "Epoch 182/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.4317\n",
            "Epoch 183/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.4389\n",
            "Epoch 184/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.4331\n",
            "Epoch 185/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.4395\n",
            "Epoch 186/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.4400\n",
            "Epoch 187/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.4374\n",
            "Epoch 188/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.4430\n",
            "Epoch 189/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.4411\n",
            "Epoch 190/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.4420\n",
            "Epoch 191/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.4475\n",
            "Epoch 192/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.4487\n",
            "Epoch 193/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.4500\n",
            "Epoch 194/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.4517\n",
            "Epoch 195/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.4521\n",
            "Epoch 196/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.4539\n",
            "Epoch 197/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.4579\n",
            "Epoch 198/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.4609\n",
            "Epoch 199/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.4570\n",
            "Epoch 200/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.4583\n",
            "Epoch 201/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.4647\n",
            "Epoch 202/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.4617\n",
            "Epoch 203/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.4686\n",
            "Epoch 204/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.4668\n",
            "Epoch 205/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.4717\n",
            "Epoch 206/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.4696\n",
            "Epoch 207/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.4700\n",
            "Epoch 208/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.4743\n",
            "Epoch 209/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.4714\n",
            "Epoch 210/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.4758\n",
            "Epoch 211/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.4750\n",
            "Epoch 212/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.4771\n",
            "Epoch 213/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.4799\n",
            "Epoch 214/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.4829\n",
            "Epoch 215/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.4823\n",
            "Epoch 216/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.4851\n",
            "Epoch 217/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.4872\n",
            "Epoch 218/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.4883\n",
            "Epoch 219/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.4868\n",
            "Epoch 220/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.4944\n",
            "Epoch 221/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.4936\n",
            "Epoch 222/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.4914\n",
            "Epoch 223/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.4921\n",
            "Epoch 224/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.4968\n",
            "Epoch 225/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.4948\n",
            "Epoch 226/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.5036\n",
            "Epoch 227/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.4951\n",
            "Epoch 228/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.5049\n",
            "Epoch 229/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.5033\n",
            "Epoch 230/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.5060\n",
            "Epoch 231/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.5040\n",
            "Epoch 232/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.5101\n",
            "Epoch 233/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.5114\n",
            "Epoch 234/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.5140\n",
            "Epoch 235/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.5106\n",
            "Epoch 236/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.5148\n",
            "Epoch 237/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.5128\n",
            "Epoch 238/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0355 - val_loss: 0.5134\n",
            "Epoch 239/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0349 - val_loss: 0.5223\n",
            "Epoch 240/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.5161\n",
            "Epoch 241/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0345 - val_loss: 0.5194\n",
            "Epoch 242/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.5227\n",
            "Epoch 243/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0342 - val_loss: 0.5238\n",
            "Epoch 244/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0339 - val_loss: 0.5254\n",
            "Epoch 245/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.5271\n",
            "Epoch 246/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0340 - val_loss: 0.5230\n",
            "Epoch 247/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.5322\n",
            "Epoch 248/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.5276\n",
            "Epoch 249/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.5328\n",
            "Epoch 250/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.5329\n",
            "Epoch 251/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0331 - val_loss: 0.5393\n",
            "Epoch 252/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.5397\n",
            "Epoch 253/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0340 - val_loss: 0.5377\n",
            "Epoch 254/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0331 - val_loss: 0.5401\n",
            "Epoch 255/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.5389\n",
            "Epoch 256/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.5435\n",
            "Epoch 257/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0320 - val_loss: 0.5374\n",
            "Epoch 258/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0329 - val_loss: 0.5473\n",
            "Epoch 259/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0316 - val_loss: 0.5446\n",
            "Epoch 260/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.5464\n",
            "Epoch 261/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0320 - val_loss: 0.5518\n",
            "Epoch 262/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.5527\n",
            "Epoch 263/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.5501\n",
            "Epoch 264/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0314 - val_loss: 0.5533\n",
            "Epoch 265/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0319 - val_loss: 0.5542\n",
            "Epoch 266/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.5596\n",
            "Epoch 267/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.5562\n",
            "Epoch 268/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.5585\n",
            "Epoch 269/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.5624\n",
            "Epoch 270/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.5708\n",
            "Epoch 271/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0320 - val_loss: 0.5629\n",
            "Epoch 272/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.5661\n",
            "Epoch 273/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.5601\n",
            "Epoch 274/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.5659\n",
            "Epoch 275/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.5662\n",
            "Epoch 276/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.5706\n",
            "Epoch 277/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.5711\n",
            "Epoch 278/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.5680\n",
            "Epoch 279/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.5780\n",
            "Epoch 280/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.5735\n",
            "Epoch 281/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.5761\n",
            "Epoch 282/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.5735\n",
            "Epoch 283/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.5777\n",
            "Epoch 284/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.5806\n",
            "Epoch 285/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.5828\n",
            "Epoch 286/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.5805\n",
            "Epoch 287/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.5824\n",
            "Epoch 288/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.5908\n",
            "Epoch 289/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.5834\n",
            "Epoch 290/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.5914\n",
            "Epoch 291/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.5849\n",
            "Epoch 292/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.5913\n",
            "Epoch 293/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.5912\n",
            "Epoch 294/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.5947\n",
            "Epoch 295/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.5983\n",
            "Epoch 296/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.5914\n",
            "Epoch 297/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.6030\n",
            "Epoch 298/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.6007\n",
            "Epoch 299/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.5977\n",
            "Epoch 300/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.5993\n",
            "Epoch 301/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.5998\n",
            "Epoch 302/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.6071\n",
            "Epoch 303/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.6018\n",
            "Epoch 304/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.6024\n",
            "Epoch 305/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.6092\n",
            "Epoch 306/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.6091\n",
            "Epoch 307/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.6161\n",
            "Epoch 308/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.6090\n",
            "Epoch 309/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.6133\n",
            "Epoch 310/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.6160\n",
            "Epoch 311/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.6158\n",
            "Epoch 312/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.6205\n",
            "Epoch 313/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.6223\n",
            "Epoch 314/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.6187\n",
            "Epoch 315/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.6173\n",
            "Epoch 316/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.6281\n",
            "Epoch 317/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.6181\n",
            "Epoch 318/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.6279\n",
            "Epoch 319/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.6328\n",
            "Epoch 320/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.6298\n",
            "Epoch 321/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.6304\n",
            "Epoch 322/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.6392\n",
            "Epoch 323/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.6350\n",
            "Epoch 324/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.6381\n",
            "Epoch 325/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.6376\n",
            "Epoch 326/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.6446\n",
            "Epoch 327/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.6412\n",
            "Epoch 328/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.6397\n",
            "Epoch 329/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.6426\n",
            "Epoch 330/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.6454\n",
            "Epoch 331/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.6449\n",
            "Epoch 332/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.6525\n",
            "Epoch 333/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.6473\n",
            "Epoch 334/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.6584\n",
            "Epoch 335/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.6523\n",
            "Epoch 336/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.6549\n",
            "Epoch 337/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.6677\n",
            "Epoch 338/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.6608\n",
            "Epoch 339/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.6601\n",
            "Epoch 340/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.6619\n",
            "Epoch 341/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.6599\n",
            "Epoch 342/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.6695\n",
            "Epoch 343/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.6622\n",
            "Epoch 344/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.6613\n",
            "Epoch 345/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.6656\n",
            "Epoch 346/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.6685\n",
            "Epoch 347/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.6784\n",
            "Epoch 348/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.6645\n",
            "Epoch 349/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.6696\n",
            "Epoch 350/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.6707\n",
            "Epoch 351/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.6673\n",
            "Epoch 352/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.6745\n",
            "Epoch 353/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.6772\n",
            "Epoch 354/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.6764\n",
            "Epoch 355/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.6786\n",
            "Epoch 356/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.6768\n",
            "Epoch 357/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.6693\n",
            "Epoch 358/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.6840\n",
            "Epoch 359/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.6836\n",
            "Epoch 360/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.6877\n",
            "Epoch 361/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.6912\n",
            "Epoch 362/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.6908\n",
            "Epoch 363/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.6882\n",
            "Epoch 364/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.6898\n",
            "Epoch 365/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.6894\n",
            "Epoch 366/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.6931\n",
            "Epoch 367/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.6901\n",
            "Epoch 368/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.7015\n",
            "Epoch 369/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.6901\n",
            "Epoch 370/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.6952\n",
            "Epoch 371/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.6916\n",
            "Epoch 372/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.6903\n",
            "Epoch 373/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.6997\n",
            "Epoch 374/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.6929\n",
            "Epoch 375/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.6994\n",
            "Epoch 376/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.7044\n",
            "Epoch 377/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.7029\n",
            "Epoch 378/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.7059\n",
            "Epoch 379/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.7030\n",
            "Epoch 380/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.7084\n",
            "Epoch 381/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.7058\n",
            "Epoch 382/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.7035\n",
            "Epoch 383/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.7066\n",
            "Epoch 384/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.7064\n",
            "Epoch 385/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.7074\n",
            "Epoch 386/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.7118\n",
            "Epoch 387/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.7108\n",
            "Epoch 388/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.7132\n",
            "Epoch 389/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.7156\n",
            "Epoch 390/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.7168\n",
            "Epoch 391/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.7237\n",
            "Epoch 392/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.7172\n",
            "Epoch 393/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.7180\n",
            "Epoch 394/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.7176\n",
            "Epoch 395/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.7170\n",
            "Epoch 396/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.7202\n",
            "Epoch 397/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.7244\n",
            "Epoch 398/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.7315\n",
            "Epoch 399/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.7194\n",
            "Epoch 400/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.7281\n",
            "Epoch 401/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.7243\n",
            "Epoch 402/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.7338\n",
            "Epoch 403/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.7156\n",
            "Epoch 404/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.7335\n",
            "Epoch 405/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.7296\n",
            "Epoch 406/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.7314\n",
            "Epoch 407/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.7334\n",
            "Epoch 408/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.7342\n",
            "Epoch 409/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.7359\n",
            "Epoch 410/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.7339\n",
            "Epoch 411/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.7285\n",
            "Epoch 412/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.7408\n",
            "Epoch 413/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.7405\n",
            "Epoch 414/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.7349\n",
            "Epoch 415/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.7292\n",
            "Epoch 416/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.7435\n",
            "Epoch 417/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.7458\n",
            "Epoch 418/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.7403\n",
            "Epoch 419/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.7482\n",
            "Epoch 420/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.7512\n",
            "Epoch 421/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.7520\n",
            "Epoch 422/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.7569\n",
            "Epoch 423/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.7432\n",
            "Epoch 424/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.7579\n",
            "Epoch 425/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.7535\n",
            "Epoch 426/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.7554\n",
            "Epoch 427/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.7598\n",
            "Epoch 428/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.7573\n",
            "Epoch 429/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.7645\n",
            "Epoch 430/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.7505\n",
            "Epoch 431/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.7588\n",
            "Epoch 432/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.7610\n",
            "Epoch 433/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.7578\n",
            "Epoch 434/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.7643\n",
            "Epoch 435/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.7635\n",
            "Epoch 436/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.7638\n",
            "Epoch 437/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.7591\n",
            "Epoch 438/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.7713\n",
            "Epoch 439/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.7717\n",
            "Epoch 440/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.7754\n",
            "Epoch 441/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.7763\n",
            "Epoch 442/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.7746\n",
            "Epoch 443/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.7785\n",
            "Epoch 444/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.7775\n",
            "Epoch 445/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.7742\n",
            "Epoch 446/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.7882\n",
            "Epoch 447/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.7755\n",
            "Epoch 448/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.7789\n",
            "Epoch 449/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.7861\n",
            "Epoch 450/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.7814\n",
            "Epoch 451/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.7902\n",
            "Epoch 452/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.7912\n",
            "Epoch 453/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.7825\n",
            "Epoch 454/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.7875\n",
            "Epoch 455/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.7876\n",
            "Epoch 456/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.7921\n",
            "Epoch 457/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.7928\n",
            "Epoch 458/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.7961\n",
            "Epoch 459/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.7899\n",
            "Epoch 460/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.8036\n",
            "Epoch 461/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.7917\n",
            "Epoch 462/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.8225\n",
            "Epoch 463/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.8030\n",
            "Epoch 464/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.7995\n",
            "Epoch 465/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.8070\n",
            "Epoch 466/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.8024\n",
            "Epoch 467/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.8027\n",
            "Epoch 468/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.8171\n",
            "Epoch 469/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.8086\n",
            "Epoch 470/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.8101\n",
            "Epoch 471/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.8133\n",
            "Epoch 472/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.8095\n",
            "Epoch 473/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.8134\n",
            "Epoch 474/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.8206\n",
            "Epoch 475/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.8149\n",
            "Epoch 476/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.8150\n",
            "Epoch 477/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.8237\n",
            "Epoch 478/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.8228\n",
            "Epoch 479/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.8250\n",
            "Epoch 480/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.8273\n",
            "Epoch 481/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.8297\n",
            "Epoch 482/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.8338\n",
            "Epoch 483/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.8264\n",
            "Epoch 484/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.8275\n",
            "Epoch 485/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.8286\n",
            "Epoch 486/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.8333\n",
            "Epoch 487/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.8354\n",
            "Epoch 488/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.8326\n",
            "Epoch 489/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.8260\n",
            "Epoch 490/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.8300\n",
            "Epoch 491/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.8282\n",
            "Epoch 492/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.8376\n",
            "Epoch 493/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.8332\n",
            "Epoch 494/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.8341\n",
            "Epoch 495/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.8376\n",
            "Epoch 496/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.8378\n",
            "Epoch 497/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.8422\n",
            "Epoch 498/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.8325\n",
            "Epoch 499/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.8386\n",
            "Epoch 500/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.8350\n",
            "Epoch 501/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.8464\n",
            "Epoch 502/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.8481\n",
            "Epoch 503/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.8426\n",
            "Epoch 504/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.8374\n",
            "Epoch 505/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.8461\n",
            "Epoch 506/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.8460\n",
            "Epoch 507/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.8519\n",
            "Epoch 508/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.8486\n",
            "Epoch 509/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.8432\n",
            "Epoch 510/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.8474\n",
            "Epoch 511/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.8414\n",
            "Epoch 512/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.8632\n",
            "Epoch 513/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.8617\n",
            "Epoch 514/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.8585\n",
            "Epoch 515/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.8559\n",
            "Epoch 516/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.8562\n",
            "Epoch 517/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.8556\n",
            "Epoch 518/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.8731\n",
            "Epoch 519/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.8597\n",
            "Epoch 520/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.8594\n",
            "Epoch 521/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.8665\n",
            "Epoch 522/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.8638\n",
            "Epoch 523/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.8578\n",
            "Epoch 524/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.8719\n",
            "Epoch 525/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.8627\n",
            "Epoch 526/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.8829\n",
            "Epoch 527/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.8787\n",
            "Epoch 528/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.8665\n",
            "Epoch 529/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.8827\n",
            "Epoch 530/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.8666\n",
            "Epoch 531/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.8802\n",
            "Epoch 532/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.8666\n",
            "Epoch 533/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.8767\n",
            "Epoch 534/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.8739\n",
            "Epoch 535/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.8701\n",
            "Epoch 536/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.8730\n",
            "Epoch 537/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.8778\n",
            "Epoch 538/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.8679\n",
            "Epoch 539/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.8764\n",
            "Epoch 540/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.8870\n",
            "Epoch 541/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.8764\n",
            "Epoch 542/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.8797\n",
            "Epoch 543/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.8855\n",
            "Epoch 544/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.8777\n",
            "Epoch 545/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.8906\n",
            "Epoch 546/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.8754\n",
            "Epoch 547/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.8710\n",
            "Epoch 548/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.8872\n",
            "Epoch 549/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.8875\n",
            "Epoch 550/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.8835\n",
            "Epoch 551/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.8816\n",
            "Epoch 552/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.8817\n",
            "Epoch 553/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.8861\n",
            "Epoch 554/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.8867\n",
            "Epoch 555/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.8944\n",
            "Epoch 556/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.8952\n",
            "Epoch 557/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.8869\n",
            "Epoch 558/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.9022\n",
            "Epoch 559/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.8935\n",
            "Epoch 560/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.8985\n",
            "Epoch 561/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.8903\n",
            "Epoch 562/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.9009\n",
            "Epoch 563/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.9120\n",
            "Epoch 564/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.8977\n",
            "Epoch 565/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.8992\n",
            "Epoch 566/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.9030\n",
            "Epoch 567/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.8922\n",
            "Epoch 568/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.9059\n",
            "Epoch 569/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.8978\n",
            "Epoch 570/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.8925\n",
            "Epoch 571/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.9137\n",
            "Epoch 572/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.8967\n",
            "Epoch 573/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.9080\n",
            "Epoch 574/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.8980\n",
            "Epoch 575/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.9093\n",
            "Epoch 576/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.9038\n",
            "Epoch 577/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.9124\n",
            "Epoch 578/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.9126\n",
            "Epoch 579/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.9115\n",
            "Epoch 580/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.9050\n",
            "Epoch 581/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.9134\n",
            "Epoch 582/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.9162\n",
            "Epoch 583/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.9052\n",
            "Epoch 584/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.9008\n",
            "Epoch 585/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.9161\n",
            "Epoch 586/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.9137\n",
            "Epoch 587/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.9072\n",
            "Epoch 588/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.9243\n",
            "Epoch 589/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.9170\n",
            "Epoch 590/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.9165\n",
            "Epoch 591/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.9117\n",
            "Epoch 592/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.9190\n",
            "Epoch 593/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.9165\n",
            "Epoch 594/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.9226\n",
            "Epoch 595/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.9172\n",
            "Epoch 596/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.9208\n",
            "Epoch 597/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.9232\n",
            "Epoch 598/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.9189\n",
            "Epoch 599/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.9161\n",
            "Epoch 600/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.9297\n",
            "Epoch 601/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.9349\n",
            "Epoch 602/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.9278\n",
            "Epoch 603/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.9313\n",
            "Epoch 604/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.9184\n",
            "Epoch 605/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.9333\n",
            "Epoch 606/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.9296\n",
            "Epoch 607/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.9393\n",
            "Epoch 608/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.9275\n",
            "Epoch 609/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.9238\n",
            "Epoch 610/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.9346\n",
            "Epoch 611/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.9463\n",
            "Epoch 612/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.9253\n",
            "Epoch 613/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.9263\n",
            "Epoch 614/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.9213\n",
            "Epoch 615/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.9279\n",
            "Epoch 616/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.9397\n",
            "Epoch 617/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.9328\n",
            "Epoch 618/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.9243\n",
            "Epoch 619/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.9407\n",
            "Epoch 620/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.9358\n",
            "Epoch 621/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.9573\n",
            "Epoch 622/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.9478\n",
            "Epoch 623/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.9487\n",
            "Epoch 624/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.9436\n",
            "Epoch 625/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.9444\n",
            "Epoch 626/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.9464\n",
            "Epoch 627/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.9463\n",
            "Epoch 628/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.9350\n",
            "Epoch 629/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.9530\n",
            "Epoch 630/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.9465\n",
            "Epoch 631/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.9518\n",
            "Epoch 632/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.9526\n",
            "Epoch 633/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.9543\n",
            "Epoch 634/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.9612\n",
            "Epoch 635/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.9571\n",
            "Epoch 636/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.9475\n",
            "Epoch 637/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.9566\n",
            "Epoch 638/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.9495\n",
            "Epoch 639/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.9475\n",
            "Epoch 640/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.9612\n",
            "Epoch 641/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.9547\n",
            "Epoch 642/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.9475\n",
            "Epoch 643/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.9757\n",
            "Epoch 644/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.9662\n",
            "Epoch 645/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.9682\n",
            "Epoch 646/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.9690\n",
            "Epoch 647/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.9685\n",
            "Epoch 648/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.9670\n",
            "Epoch 649/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.9619\n",
            "Epoch 650/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.9647\n",
            "Epoch 651/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.9709\n",
            "Epoch 652/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.9690\n",
            "Epoch 653/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.9801\n",
            "Epoch 654/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.9696\n",
            "Epoch 655/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.9703\n",
            "Epoch 656/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.9664\n",
            "Epoch 657/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.9675\n",
            "Epoch 658/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.9795\n",
            "Epoch 659/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.9898\n",
            "Epoch 660/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.9693\n",
            "Epoch 661/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.9697\n",
            "Epoch 662/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.9804\n",
            "Epoch 663/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.9605\n",
            "Epoch 664/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.9783\n",
            "Epoch 665/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.9748\n",
            "Epoch 666/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.9816\n",
            "Epoch 667/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.9888\n",
            "Epoch 668/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.9886\n",
            "Epoch 669/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.9701\n",
            "Epoch 670/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.9767\n",
            "Epoch 671/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.9695\n",
            "Epoch 672/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.9932\n",
            "Epoch 673/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.9814\n",
            "Epoch 674/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.9892\n",
            "Epoch 675/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.9759\n",
            "Epoch 676/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.9835\n",
            "Epoch 677/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.9836\n",
            "Epoch 678/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.9900\n",
            "Epoch 679/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.9767\n",
            "Epoch 680/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.9871\n",
            "Epoch 681/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.9752\n",
            "Epoch 682/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.9962\n",
            "Epoch 683/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 1.0023\n",
            "Epoch 684/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.9983\n",
            "Epoch 685/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.9887\n",
            "Epoch 686/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.9881\n",
            "Epoch 687/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.9836\n",
            "Epoch 688/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.9875\n",
            "Epoch 689/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.9887\n",
            "Epoch 690/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.9993\n",
            "Epoch 691/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.9920\n",
            "Epoch 692/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.9929\n",
            "Epoch 693/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.9952\n",
            "Epoch 694/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.9943\n",
            "Epoch 695/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 1.0015\n",
            "Epoch 696/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.9945\n",
            "Epoch 697/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 1.0046\n",
            "Epoch 698/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.9936\n",
            "Epoch 699/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 1.0062\n",
            "Epoch 700/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.9941\n",
            "Epoch 701/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.9972\n",
            "Epoch 702/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.9996\n",
            "Epoch 703/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.9955\n",
            "Epoch 704/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 1.0052\n",
            "Epoch 705/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 1.0042\n",
            "Epoch 706/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 1.0026\n",
            "Epoch 707/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 1.0105\n",
            "Epoch 708/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 1.0056\n",
            "Epoch 709/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 1.0092\n",
            "Epoch 710/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.9999\n",
            "Epoch 711/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.9928\n",
            "Epoch 712/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 1.0060\n",
            "Epoch 713/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.9916\n",
            "Epoch 714/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 1.0089\n",
            "Epoch 715/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 1.0093\n",
            "Epoch 716/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 1.0057\n",
            "Epoch 717/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 1.0138\n",
            "Epoch 718/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 1.0070\n",
            "Epoch 719/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 1.0028\n",
            "Epoch 720/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 1.0127\n",
            "Epoch 721/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 1.0071\n",
            "Epoch 722/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 1.0135\n",
            "Epoch 723/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 1.0065\n",
            "Epoch 724/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 1.0057\n",
            "Epoch 725/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 1.0041\n",
            "Epoch 726/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 1.0045\n",
            "Epoch 727/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 1.0064\n",
            "Epoch 728/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 1.0095\n",
            "Epoch 729/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 1.0236\n",
            "Epoch 730/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 1.0039\n",
            "Epoch 731/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 1.0127\n",
            "Epoch 732/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 1.0173\n",
            "Epoch 733/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 1.0181\n",
            "Epoch 734/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 1.0135\n",
            "Epoch 735/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 1.0107\n",
            "Epoch 736/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 1.0229\n",
            "Epoch 737/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 1.0314\n",
            "Epoch 738/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 1.0186\n",
            "Epoch 739/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 1.0180\n",
            "Epoch 740/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 1.0135\n",
            "Epoch 741/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 1.0121\n",
            "Epoch 742/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 1.0215\n",
            "Epoch 743/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 1.0171\n",
            "Epoch 744/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 1.0264\n",
            "Epoch 745/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 1.0149\n",
            "Epoch 746/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 1.0254\n",
            "Epoch 747/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 1.0329\n",
            "Epoch 748/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 1.0305\n",
            "Epoch 749/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 1.0191\n",
            "Epoch 750/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 1.0337\n",
            "Epoch 751/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 1.0332\n",
            "Epoch 752/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 1.0275\n",
            "Epoch 753/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 1.0211\n",
            "Epoch 754/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 1.0241\n",
            "Epoch 755/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 1.0312\n",
            "Epoch 756/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 1.0356\n",
            "Epoch 757/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 1.0313\n",
            "Epoch 758/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 1.0233\n",
            "Epoch 759/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 1.0277\n",
            "Epoch 760/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 1.0351\n",
            "Epoch 761/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 1.0328\n",
            "Epoch 762/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 1.0234\n",
            "Epoch 763/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 1.0334\n",
            "Epoch 764/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 1.0319\n",
            "Epoch 765/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 1.0264\n",
            "Epoch 766/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 1.0378\n",
            "Epoch 767/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 1.0327\n",
            "Epoch 768/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 1.0404\n",
            "Epoch 769/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 1.0425\n",
            "Epoch 770/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 1.0330\n",
            "Epoch 771/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 1.0450\n",
            "Epoch 772/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 1.0352\n",
            "Epoch 773/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 1.0385\n",
            "Epoch 774/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 1.0450\n",
            "Epoch 775/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 1.0355\n",
            "Epoch 776/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 1.0420\n",
            "Epoch 777/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 1.0262\n",
            "Epoch 778/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 1.0448\n",
            "Epoch 779/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 1.0467\n",
            "Epoch 780/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 1.0459\n",
            "Epoch 781/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 1.0389\n",
            "Epoch 782/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 1.0632\n",
            "Epoch 783/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 1.0393\n",
            "Epoch 784/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 1.0486\n",
            "Epoch 785/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 1.0505\n",
            "Epoch 786/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 1.0451\n",
            "Epoch 787/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 1.0450\n",
            "Epoch 788/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 1.0554\n",
            "Epoch 789/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 1.0484\n",
            "Epoch 790/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 1.0583\n",
            "Epoch 791/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 1.0472\n",
            "Epoch 792/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 1.0492\n",
            "Epoch 793/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 1.0469\n",
            "Epoch 794/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 1.0559\n",
            "Epoch 795/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 1.0500\n",
            "Epoch 796/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 1.0596\n",
            "Epoch 797/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 1.0515\n",
            "Epoch 798/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 1.0562\n",
            "Epoch 799/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 1.0542\n",
            "Epoch 800/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 1.0524\n",
            "Epoch 801/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 1.0522\n",
            "Epoch 802/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 1.0646\n",
            "Epoch 803/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 1.0500\n",
            "Epoch 804/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 1.0425\n",
            "Epoch 805/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 1.0500\n",
            "Epoch 806/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 1.0531\n",
            "Epoch 807/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 1.0517\n",
            "Epoch 808/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 1.0513\n",
            "Epoch 809/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.0502\n",
            "Epoch 810/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 1.0569\n",
            "Epoch 811/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.0546\n",
            "Epoch 812/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.0725\n",
            "Epoch 813/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 1.0589\n",
            "Epoch 814/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 1.0511\n",
            "Epoch 815/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.0617\n",
            "Epoch 816/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 1.0554\n",
            "Epoch 817/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 1.0567\n",
            "Epoch 818/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 1.0668\n",
            "Epoch 819/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.0590\n",
            "Epoch 820/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.0661\n",
            "Epoch 821/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.0484\n",
            "Epoch 822/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 1.0696\n",
            "Epoch 823/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 1.0502\n",
            "Epoch 824/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 1.0631\n",
            "Epoch 825/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.0796\n",
            "Epoch 826/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 1.0754\n",
            "Epoch 827/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 1.0543\n",
            "Epoch 828/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.0661\n",
            "Epoch 829/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 1.0665\n",
            "Epoch 830/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 1.0684\n",
            "Epoch 831/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 1.0632\n",
            "Epoch 832/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.0750\n",
            "Epoch 833/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.0661\n",
            "Epoch 834/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.0661\n",
            "Epoch 835/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 1.0611\n",
            "Epoch 836/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 1.0706\n",
            "Epoch 837/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 1.0721\n",
            "Epoch 838/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 1.0719\n",
            "Epoch 839/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 1.0667\n",
            "Epoch 840/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 1.0725\n",
            "Epoch 841/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 1.0692\n",
            "Epoch 842/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.0731\n",
            "Epoch 843/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 1.0728\n",
            "Epoch 844/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.0810\n",
            "Epoch 845/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 1.0668\n",
            "Epoch 846/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 1.0667\n",
            "Epoch 847/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.0741\n",
            "Epoch 848/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.0785\n",
            "Epoch 849/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 1.0855\n",
            "Epoch 850/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 1.0846\n",
            "Epoch 851/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 1.0798\n",
            "Epoch 852/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 1.0904\n",
            "Epoch 853/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 1.0779\n",
            "Epoch 854/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.0751\n",
            "Epoch 855/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 1.0816\n",
            "Epoch 856/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 1.0770\n",
            "Epoch 857/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.0878\n",
            "Epoch 858/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.0796\n",
            "Epoch 859/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.0778\n",
            "Epoch 860/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 1.0829\n",
            "Epoch 861/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.0744\n",
            "Epoch 862/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 1.0771\n",
            "Epoch 863/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 1.0812\n",
            "Epoch 864/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 1.0801\n",
            "Epoch 865/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 1.0745\n",
            "Epoch 866/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 1.0823\n",
            "Epoch 867/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 1.0842\n",
            "Epoch 868/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 1.0807\n",
            "Epoch 869/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.0887\n",
            "Epoch 870/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.0997\n",
            "Epoch 871/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.0907\n",
            "Epoch 872/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 1.0929\n",
            "Epoch 873/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 1.0877\n",
            "Epoch 874/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.0911\n",
            "Epoch 875/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.0873\n",
            "Epoch 876/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.0903\n",
            "Epoch 877/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.0835\n",
            "Epoch 878/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 1.0983\n",
            "Epoch 879/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 1.0870\n",
            "Epoch 880/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.0900\n",
            "Epoch 881/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 1.0953\n",
            "Epoch 882/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 1.0886\n",
            "Epoch 883/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 1.1061\n",
            "Epoch 884/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.0945\n",
            "Epoch 885/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.1107\n",
            "Epoch 886/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 1.0869\n",
            "Epoch 887/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 1.0926\n",
            "Epoch 888/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 1.0929\n",
            "Epoch 889/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 1.1054\n",
            "Epoch 890/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 1.0899\n",
            "Epoch 891/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 1.0901\n",
            "Epoch 892/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.1050\n",
            "Epoch 893/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 1.0989\n",
            "Epoch 894/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 1.0984\n",
            "Epoch 895/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 1.0995\n",
            "Epoch 896/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 1.1015\n",
            "Epoch 897/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 1.1029\n",
            "Epoch 898/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 1.1029\n",
            "Epoch 899/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.1003\n",
            "Epoch 900/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 1.1076\n",
            "Epoch 901/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.1061\n",
            "Epoch 902/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 1.0939\n",
            "Epoch 903/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.1023\n",
            "Epoch 904/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 1.1016\n",
            "Epoch 905/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 1.0978\n",
            "Epoch 906/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.0942\n",
            "Epoch 907/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 1.1114\n",
            "Epoch 908/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 1.1099\n",
            "Epoch 909/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 1.1023\n",
            "Epoch 910/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 1.1029\n",
            "Epoch 911/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 1.1128\n",
            "Epoch 912/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 1.1027\n",
            "Epoch 913/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.1006\n",
            "Epoch 914/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.1117\n",
            "Epoch 915/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.1115\n",
            "Epoch 916/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.1056\n",
            "Epoch 917/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 1.1148\n",
            "Epoch 918/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 1.1105\n",
            "Epoch 919/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 1.1153\n",
            "Epoch 920/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 1.1091\n",
            "Epoch 921/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.1088\n",
            "Epoch 922/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.1062\n",
            "Epoch 923/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.1105\n",
            "Epoch 924/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 1.1061\n",
            "Epoch 925/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 1.1110\n",
            "Epoch 926/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 1.1104\n",
            "Epoch 927/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 1.1174\n",
            "Epoch 928/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 1.1119\n",
            "Epoch 929/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 1.1143\n",
            "Epoch 930/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 1.1066\n",
            "Epoch 931/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.1217\n",
            "Epoch 932/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 1.1023\n",
            "Epoch 933/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 1.1215\n",
            "Epoch 934/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 1.1159\n",
            "Epoch 935/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 1.1134\n",
            "Epoch 936/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 1.1163\n",
            "Epoch 937/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 1.1241\n",
            "Epoch 938/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 1.1022\n",
            "Epoch 939/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 1.1244\n",
            "Epoch 940/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 1.1266\n",
            "Epoch 941/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 1.1255\n",
            "Epoch 942/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 1.1233\n",
            "Epoch 943/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 1.1241\n",
            "Epoch 944/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 1.1186\n",
            "Epoch 945/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 1.1259\n",
            "Epoch 946/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 1.1215\n",
            "Epoch 947/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 1.1286\n",
            "Epoch 948/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 1.1194\n",
            "Epoch 949/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 1.1358\n",
            "Epoch 950/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 1.1186\n",
            "Epoch 951/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 1.1310\n",
            "Epoch 952/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 1.1252\n",
            "Epoch 953/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 1.1440\n",
            "Epoch 954/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 1.1184\n",
            "Epoch 955/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 1.1261\n",
            "Epoch 956/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.1232\n",
            "Epoch 957/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.1218\n",
            "Epoch 958/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 1.1207\n",
            "Epoch 959/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 1.1269\n",
            "Epoch 960/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 1.1247\n",
            "Epoch 961/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 1.1279\n",
            "Epoch 962/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 1.1219\n",
            "Epoch 963/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 1.1245\n",
            "Epoch 964/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 1.1365\n",
            "Epoch 965/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 1.1355\n",
            "Epoch 966/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 1.1281\n",
            "Epoch 967/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 1.1254\n",
            "Epoch 968/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 1.1397\n",
            "Epoch 969/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 1.1229\n",
            "Epoch 970/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 1.1326\n",
            "Epoch 971/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 1.1381\n",
            "Epoch 972/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 1.1437\n",
            "Epoch 973/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 1.1373\n",
            "Epoch 974/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 1.1341\n",
            "Epoch 975/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 1.1395\n",
            "Epoch 976/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 1.1315\n",
            "Epoch 977/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 1.1389\n",
            "Epoch 978/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 1.1376\n",
            "Epoch 979/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 1.1315\n",
            "Epoch 980/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 1.1445\n",
            "Epoch 981/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 1.1218\n",
            "Epoch 982/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 1.1371\n",
            "Epoch 983/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 1.1446\n",
            "Epoch 984/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 1.1412\n",
            "Epoch 985/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 1.1376\n",
            "Epoch 986/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 1.1374\n",
            "Epoch 987/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 1.1467\n",
            "Epoch 988/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 1.1431\n",
            "Epoch 989/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 1.1398\n",
            "Epoch 990/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 1.1410\n",
            "Epoch 991/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 1.1421\n",
            "Epoch 992/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 1.1521\n",
            "Epoch 993/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 1.1430\n",
            "Epoch 994/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 1.1425\n",
            "Epoch 995/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 1.1490\n",
            "Epoch 996/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 1.1492\n",
            "Epoch 997/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 1.1417\n",
            "Epoch 998/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 1.1378\n",
            "Epoch 999/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 1.1486\n",
            "Epoch 1000/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 1.1429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVX5SQ7jzWm3"
      },
      "source": [
        "####Adadelta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryL0h3zXzaLv",
        "outputId": "8322ba53-0d71-40fd-8f9f-97fb3addcaa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wide_opt2(opt_Adadelta)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.0150 - val_loss: 0.9807\n",
            "Epoch 2/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0147 - val_loss: 0.9804\n",
            "Epoch 3/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0145 - val_loss: 0.9802\n",
            "Epoch 4/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0142 - val_loss: 0.9800\n",
            "Epoch 5/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0139 - val_loss: 0.9797\n",
            "Epoch 6/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0137 - val_loss: 0.9795\n",
            "Epoch 7/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0134 - val_loss: 0.9793\n",
            "Epoch 8/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0132 - val_loss: 0.9791\n",
            "Epoch 9/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0130 - val_loss: 0.9789\n",
            "Epoch 10/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0127 - val_loss: 0.9786\n",
            "Epoch 11/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0125 - val_loss: 0.9784\n",
            "Epoch 12/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0123 - val_loss: 0.9782\n",
            "Epoch 13/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0120 - val_loss: 0.9780\n",
            "Epoch 14/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0118 - val_loss: 0.9778\n",
            "Epoch 15/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0116 - val_loss: 0.9776\n",
            "Epoch 16/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0114 - val_loss: 0.9774\n",
            "Epoch 17/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0112 - val_loss: 0.9772\n",
            "Epoch 18/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0109 - val_loss: 0.9770\n",
            "Epoch 19/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0107 - val_loss: 0.9768\n",
            "Epoch 20/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0105 - val_loss: 0.9766\n",
            "Epoch 21/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0103 - val_loss: 0.9764\n",
            "Epoch 22/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0101 - val_loss: 0.9762\n",
            "Epoch 23/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0098 - val_loss: 0.9760\n",
            "Epoch 24/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 0.9758\n",
            "Epoch 25/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0094 - val_loss: 0.9756\n",
            "Epoch 26/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0092 - val_loss: 0.9754\n",
            "Epoch 27/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0090 - val_loss: 0.9752\n",
            "Epoch 28/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0088 - val_loss: 0.9750\n",
            "Epoch 29/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0085 - val_loss: 0.9748\n",
            "Epoch 30/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0083 - val_loss: 0.9746\n",
            "Epoch 31/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0081 - val_loss: 0.9744\n",
            "Epoch 32/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0079 - val_loss: 0.9742\n",
            "Epoch 33/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0077 - val_loss: 0.9740\n",
            "Epoch 34/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0075 - val_loss: 0.9739\n",
            "Epoch 35/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0073 - val_loss: 0.9737\n",
            "Epoch 36/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0070 - val_loss: 0.9735\n",
            "Epoch 37/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 0.9733\n",
            "Epoch 38/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0066 - val_loss: 0.9731\n",
            "Epoch 39/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0064 - val_loss: 0.9729\n",
            "Epoch 40/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0062 - val_loss: 0.9727\n",
            "Epoch 41/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0060 - val_loss: 0.9725\n",
            "Epoch 42/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0058 - val_loss: 0.9723\n",
            "Epoch 43/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0056 - val_loss: 0.9721\n",
            "Epoch 44/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0054 - val_loss: 0.9719\n",
            "Epoch 45/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0051 - val_loss: 0.9717\n",
            "Epoch 46/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0049 - val_loss: 0.9715\n",
            "Epoch 47/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0047 - val_loss: 0.9713\n",
            "Epoch 48/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0045 - val_loss: 0.9711\n",
            "Epoch 49/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0043 - val_loss: 0.9709\n",
            "Epoch 50/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0041 - val_loss: 0.9707\n",
            "Epoch 51/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0038 - val_loss: 0.9705\n",
            "Epoch 52/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0036 - val_loss: 0.9704\n",
            "Epoch 53/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0034 - val_loss: 0.9702\n",
            "Epoch 54/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0032 - val_loss: 0.9700\n",
            "Epoch 55/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 0.9698\n",
            "Epoch 56/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0028 - val_loss: 0.9696\n",
            "Epoch 57/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0026 - val_loss: 0.9694\n",
            "Epoch 58/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0024 - val_loss: 0.9692\n",
            "Epoch 59/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0021 - val_loss: 0.9690\n",
            "Epoch 60/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0019 - val_loss: 0.9688\n",
            "Epoch 61/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0017 - val_loss: 0.9686\n",
            "Epoch 62/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0015 - val_loss: 0.9684\n",
            "Epoch 63/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0013 - val_loss: 0.9682\n",
            "Epoch 64/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.9680\n",
            "Epoch 65/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0009 - val_loss: 0.9678\n",
            "Epoch 66/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0007 - val_loss: 0.9676\n",
            "Epoch 67/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 0.9674\n",
            "Epoch 68/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 0.9672\n",
            "Epoch 69/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 0.9670\n",
            "Epoch 70/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9669\n",
            "Epoch 71/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9667\n",
            "Epoch 72/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9665\n",
            "Epoch 73/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9663\n",
            "Epoch 74/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9661\n",
            "Epoch 75/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9659\n",
            "Epoch 76/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9657\n",
            "Epoch 77/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 0.9655\n",
            "Epoch 78/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9653\n",
            "Epoch 79/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 0.9651\n",
            "Epoch 80/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 0.9649\n",
            "Epoch 81/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 0.9647\n",
            "Epoch 82/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 0.9645\n",
            "Epoch 83/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 0.9643\n",
            "Epoch 84/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9968 - val_loss: 0.9641\n",
            "Epoch 85/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9966 - val_loss: 0.9639\n",
            "Epoch 86/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9964 - val_loss: 0.9638\n",
            "Epoch 87/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9962 - val_loss: 0.9636\n",
            "Epoch 88/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9960 - val_loss: 0.9634\n",
            "Epoch 89/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9958 - val_loss: 0.9632\n",
            "Epoch 90/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9956 - val_loss: 0.9630\n",
            "Epoch 91/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9954 - val_loss: 0.9628\n",
            "Epoch 92/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9952 - val_loss: 0.9626\n",
            "Epoch 93/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9949 - val_loss: 0.9624\n",
            "Epoch 94/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9947 - val_loss: 0.9622\n",
            "Epoch 95/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9945 - val_loss: 0.9620\n",
            "Epoch 96/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9943 - val_loss: 0.9619\n",
            "Epoch 97/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9941 - val_loss: 0.9617\n",
            "Epoch 98/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 0.9615\n",
            "Epoch 99/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9937 - val_loss: 0.9613\n",
            "Epoch 100/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 0.9611\n",
            "Epoch 101/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 0.9609\n",
            "Epoch 102/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 0.9607\n",
            "Epoch 103/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 0.9605\n",
            "Epoch 104/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9926 - val_loss: 0.9603\n",
            "Epoch 105/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 0.9601\n",
            "Epoch 106/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9922 - val_loss: 0.9599\n",
            "Epoch 107/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9920 - val_loss: 0.9597\n",
            "Epoch 108/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9918 - val_loss: 0.9595\n",
            "Epoch 109/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9916 - val_loss: 0.9594\n",
            "Epoch 110/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9914 - val_loss: 0.9592\n",
            "Epoch 111/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9912 - val_loss: 0.9590\n",
            "Epoch 112/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 0.9588\n",
            "Epoch 113/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9907 - val_loss: 0.9586\n",
            "Epoch 114/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9905 - val_loss: 0.9584\n",
            "Epoch 115/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9903 - val_loss: 0.9582\n",
            "Epoch 116/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9901 - val_loss: 0.9580\n",
            "Epoch 117/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9899 - val_loss: 0.9578\n",
            "Epoch 118/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9897 - val_loss: 0.9576\n",
            "Epoch 119/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9895 - val_loss: 0.9574\n",
            "Epoch 120/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9893 - val_loss: 0.9573\n",
            "Epoch 121/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9891 - val_loss: 0.9571\n",
            "Epoch 122/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9888 - val_loss: 0.9569\n",
            "Epoch 123/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9886 - val_loss: 0.9567\n",
            "Epoch 124/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9884 - val_loss: 0.9565\n",
            "Epoch 125/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9882 - val_loss: 0.9563\n",
            "Epoch 126/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9880 - val_loss: 0.9561\n",
            "Epoch 127/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9878 - val_loss: 0.9559\n",
            "Epoch 128/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9876 - val_loss: 0.9558\n",
            "Epoch 129/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9874 - val_loss: 0.9556\n",
            "Epoch 130/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9872 - val_loss: 0.9554\n",
            "Epoch 131/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9870 - val_loss: 0.9552\n",
            "Epoch 132/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9868 - val_loss: 0.9550\n",
            "Epoch 133/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9866 - val_loss: 0.9548\n",
            "Epoch 134/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9864 - val_loss: 0.9546\n",
            "Epoch 135/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9862 - val_loss: 0.9544\n",
            "Epoch 136/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9860 - val_loss: 0.9543\n",
            "Epoch 137/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9858 - val_loss: 0.9541\n",
            "Epoch 138/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9855 - val_loss: 0.9539\n",
            "Epoch 139/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9853 - val_loss: 0.9537\n",
            "Epoch 140/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9851 - val_loss: 0.9535\n",
            "Epoch 141/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9849 - val_loss: 0.9533\n",
            "Epoch 142/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9847 - val_loss: 0.9531\n",
            "Epoch 143/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9845 - val_loss: 0.9530\n",
            "Epoch 144/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9843 - val_loss: 0.9528\n",
            "Epoch 145/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9841 - val_loss: 0.9526\n",
            "Epoch 146/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9839 - val_loss: 0.9524\n",
            "Epoch 147/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9837 - val_loss: 0.9522\n",
            "Epoch 148/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9835 - val_loss: 0.9520\n",
            "Epoch 149/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9833 - val_loss: 0.9518\n",
            "Epoch 150/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9831 - val_loss: 0.9516\n",
            "Epoch 151/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9829 - val_loss: 0.9514\n",
            "Epoch 152/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9827 - val_loss: 0.9513\n",
            "Epoch 153/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9824 - val_loss: 0.9511\n",
            "Epoch 154/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9822 - val_loss: 0.9509\n",
            "Epoch 155/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9820 - val_loss: 0.9507\n",
            "Epoch 156/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9818 - val_loss: 0.9505\n",
            "Epoch 157/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9816 - val_loss: 0.9503\n",
            "Epoch 158/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9814 - val_loss: 0.9501\n",
            "Epoch 159/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9812 - val_loss: 0.9500\n",
            "Epoch 160/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9810 - val_loss: 0.9498\n",
            "Epoch 161/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9808 - val_loss: 0.9496\n",
            "Epoch 162/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9806 - val_loss: 0.9494\n",
            "Epoch 163/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9804 - val_loss: 0.9492\n",
            "Epoch 164/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9802 - val_loss: 0.9490\n",
            "Epoch 165/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9800 - val_loss: 0.9488\n",
            "Epoch 166/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9798 - val_loss: 0.9487\n",
            "Epoch 167/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9796 - val_loss: 0.9485\n",
            "Epoch 168/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9794 - val_loss: 0.9483\n",
            "Epoch 169/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9791 - val_loss: 0.9481\n",
            "Epoch 170/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9789 - val_loss: 0.9479\n",
            "Epoch 171/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9787 - val_loss: 0.9477\n",
            "Epoch 172/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9785 - val_loss: 0.9475\n",
            "Epoch 173/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9783 - val_loss: 0.9474\n",
            "Epoch 174/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9781 - val_loss: 0.9472\n",
            "Epoch 175/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9779 - val_loss: 0.9470\n",
            "Epoch 176/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9777 - val_loss: 0.9468\n",
            "Epoch 177/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9775 - val_loss: 0.9466\n",
            "Epoch 178/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9773 - val_loss: 0.9464\n",
            "Epoch 179/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9771 - val_loss: 0.9462\n",
            "Epoch 180/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9769 - val_loss: 0.9461\n",
            "Epoch 181/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9767 - val_loss: 0.9459\n",
            "Epoch 182/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9765 - val_loss: 0.9457\n",
            "Epoch 183/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9763 - val_loss: 0.9455\n",
            "Epoch 184/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9761 - val_loss: 0.9453\n",
            "Epoch 185/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9758 - val_loss: 0.9451\n",
            "Epoch 186/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9756 - val_loss: 0.9449\n",
            "Epoch 187/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9754 - val_loss: 0.9447\n",
            "Epoch 188/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9752 - val_loss: 0.9446\n",
            "Epoch 189/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9750 - val_loss: 0.9444\n",
            "Epoch 190/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9748 - val_loss: 0.9442\n",
            "Epoch 191/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9746 - val_loss: 0.9440\n",
            "Epoch 192/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9744 - val_loss: 0.9438\n",
            "Epoch 193/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9742 - val_loss: 0.9436\n",
            "Epoch 194/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9740 - val_loss: 0.9435\n",
            "Epoch 195/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9738 - val_loss: 0.9433\n",
            "Epoch 196/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9736 - val_loss: 0.9431\n",
            "Epoch 197/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9734 - val_loss: 0.9429\n",
            "Epoch 198/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9732 - val_loss: 0.9427\n",
            "Epoch 199/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9730 - val_loss: 0.9425\n",
            "Epoch 200/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9728 - val_loss: 0.9423\n",
            "Epoch 201/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9726 - val_loss: 0.9422\n",
            "Epoch 202/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9724 - val_loss: 0.9420\n",
            "Epoch 203/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9722 - val_loss: 0.9418\n",
            "Epoch 204/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9720 - val_loss: 0.9416\n",
            "Epoch 205/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9718 - val_loss: 0.9414\n",
            "Epoch 206/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9716 - val_loss: 0.9412\n",
            "Epoch 207/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9714 - val_loss: 0.9411\n",
            "Epoch 208/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9712 - val_loss: 0.9409\n",
            "Epoch 209/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9709 - val_loss: 0.9407\n",
            "Epoch 210/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9707 - val_loss: 0.9405\n",
            "Epoch 211/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9705 - val_loss: 0.9403\n",
            "Epoch 212/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9703 - val_loss: 0.9401\n",
            "Epoch 213/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9701 - val_loss: 0.9400\n",
            "Epoch 214/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9699 - val_loss: 0.9398\n",
            "Epoch 215/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9697 - val_loss: 0.9396\n",
            "Epoch 216/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9695 - val_loss: 0.9394\n",
            "Epoch 217/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9693 - val_loss: 0.9392\n",
            "Epoch 218/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9691 - val_loss: 0.9390\n",
            "Epoch 219/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9689 - val_loss: 0.9389\n",
            "Epoch 220/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9687 - val_loss: 0.9387\n",
            "Epoch 221/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9685 - val_loss: 0.9385\n",
            "Epoch 222/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9683 - val_loss: 0.9383\n",
            "Epoch 223/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9681 - val_loss: 0.9381\n",
            "Epoch 224/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9679 - val_loss: 0.9379\n",
            "Epoch 225/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9677 - val_loss: 0.9378\n",
            "Epoch 226/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9675 - val_loss: 0.9376\n",
            "Epoch 227/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9673 - val_loss: 0.9374\n",
            "Epoch 228/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9671 - val_loss: 0.9372\n",
            "Epoch 229/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9669 - val_loss: 0.9370\n",
            "Epoch 230/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9667 - val_loss: 0.9368\n",
            "Epoch 231/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9665 - val_loss: 0.9367\n",
            "Epoch 232/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9663 - val_loss: 0.9365\n",
            "Epoch 233/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9661 - val_loss: 0.9363\n",
            "Epoch 234/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9659 - val_loss: 0.9361\n",
            "Epoch 235/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9657 - val_loss: 0.9359\n",
            "Epoch 236/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9655 - val_loss: 0.9358\n",
            "Epoch 237/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9653 - val_loss: 0.9356\n",
            "Epoch 238/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9651 - val_loss: 0.9354\n",
            "Epoch 239/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9649 - val_loss: 0.9352\n",
            "Epoch 240/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9647 - val_loss: 0.9350\n",
            "Epoch 241/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9645 - val_loss: 0.9349\n",
            "Epoch 242/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9643 - val_loss: 0.9347\n",
            "Epoch 243/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9641 - val_loss: 0.9345\n",
            "Epoch 244/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9639 - val_loss: 0.9343\n",
            "Epoch 245/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9637 - val_loss: 0.9341\n",
            "Epoch 246/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9635 - val_loss: 0.9339\n",
            "Epoch 247/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9633 - val_loss: 0.9338\n",
            "Epoch 248/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9631 - val_loss: 0.9336\n",
            "Epoch 249/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9629 - val_loss: 0.9334\n",
            "Epoch 250/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9627 - val_loss: 0.9332\n",
            "Epoch 251/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9625 - val_loss: 0.9330\n",
            "Epoch 252/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9623 - val_loss: 0.9329\n",
            "Epoch 253/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9621 - val_loss: 0.9327\n",
            "Epoch 254/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9619 - val_loss: 0.9325\n",
            "Epoch 255/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9617 - val_loss: 0.9323\n",
            "Epoch 256/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9615 - val_loss: 0.9321\n",
            "Epoch 257/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9613 - val_loss: 0.9320\n",
            "Epoch 258/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9611 - val_loss: 0.9318\n",
            "Epoch 259/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9609 - val_loss: 0.9316\n",
            "Epoch 260/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9607 - val_loss: 0.9314\n",
            "Epoch 261/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9605 - val_loss: 0.9312\n",
            "Epoch 262/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9603 - val_loss: 0.9310\n",
            "Epoch 263/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9601 - val_loss: 0.9309\n",
            "Epoch 264/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9599 - val_loss: 0.9307\n",
            "Epoch 265/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9597 - val_loss: 0.9305\n",
            "Epoch 266/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9595 - val_loss: 0.9303\n",
            "Epoch 267/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9593 - val_loss: 0.9302\n",
            "Epoch 268/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9591 - val_loss: 0.9300\n",
            "Epoch 269/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9589 - val_loss: 0.9298\n",
            "Epoch 270/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9587 - val_loss: 0.9296\n",
            "Epoch 271/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9585 - val_loss: 0.9294\n",
            "Epoch 272/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9582 - val_loss: 0.9293\n",
            "Epoch 273/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9580 - val_loss: 0.9291\n",
            "Epoch 274/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9578 - val_loss: 0.9289\n",
            "Epoch 275/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9576 - val_loss: 0.9287\n",
            "Epoch 276/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9574 - val_loss: 0.9285\n",
            "Epoch 277/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9572 - val_loss: 0.9284\n",
            "Epoch 278/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9570 - val_loss: 0.9282\n",
            "Epoch 279/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9568 - val_loss: 0.9280\n",
            "Epoch 280/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9566 - val_loss: 0.9278\n",
            "Epoch 281/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9564 - val_loss: 0.9276\n",
            "Epoch 282/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9562 - val_loss: 0.9275\n",
            "Epoch 283/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9560 - val_loss: 0.9273\n",
            "Epoch 284/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9558 - val_loss: 0.9271\n",
            "Epoch 285/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9556 - val_loss: 0.9269\n",
            "Epoch 286/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9554 - val_loss: 0.9267\n",
            "Epoch 287/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9552 - val_loss: 0.9266\n",
            "Epoch 288/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9550 - val_loss: 0.9264\n",
            "Epoch 289/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9548 - val_loss: 0.9262\n",
            "Epoch 290/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9546 - val_loss: 0.9260\n",
            "Epoch 291/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9544 - val_loss: 0.9258\n",
            "Epoch 292/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 0.9256\n",
            "Epoch 293/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9540 - val_loss: 0.9255\n",
            "Epoch 294/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9538 - val_loss: 0.9253\n",
            "Epoch 295/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9536 - val_loss: 0.9251\n",
            "Epoch 296/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9534 - val_loss: 0.9249\n",
            "Epoch 297/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9532 - val_loss: 0.9247\n",
            "Epoch 298/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9530 - val_loss: 0.9246\n",
            "Epoch 299/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9528 - val_loss: 0.9244\n",
            "Epoch 300/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9526 - val_loss: 0.9242\n",
            "Epoch 301/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9524 - val_loss: 0.9240\n",
            "Epoch 302/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9522 - val_loss: 0.9238\n",
            "Epoch 303/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9520 - val_loss: 0.9236\n",
            "Epoch 304/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9518 - val_loss: 0.9235\n",
            "Epoch 305/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9516 - val_loss: 0.9233\n",
            "Epoch 306/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9514 - val_loss: 0.9231\n",
            "Epoch 307/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9512 - val_loss: 0.9229\n",
            "Epoch 308/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9509 - val_loss: 0.9227\n",
            "Epoch 309/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9507 - val_loss: 0.9226\n",
            "Epoch 310/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9505 - val_loss: 0.9224\n",
            "Epoch 311/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9503 - val_loss: 0.9222\n",
            "Epoch 312/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9501 - val_loss: 0.9220\n",
            "Epoch 313/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9499 - val_loss: 0.9218\n",
            "Epoch 314/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9497 - val_loss: 0.9217\n",
            "Epoch 315/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9495 - val_loss: 0.9215\n",
            "Epoch 316/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9493 - val_loss: 0.9213\n",
            "Epoch 317/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9491 - val_loss: 0.9211\n",
            "Epoch 318/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9489 - val_loss: 0.9209\n",
            "Epoch 319/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9487 - val_loss: 0.9207\n",
            "Epoch 320/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9485 - val_loss: 0.9206\n",
            "Epoch 321/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9483 - val_loss: 0.9204\n",
            "Epoch 322/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9481 - val_loss: 0.9202\n",
            "Epoch 323/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9479 - val_loss: 0.9200\n",
            "Epoch 324/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9477 - val_loss: 0.9198\n",
            "Epoch 325/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9475 - val_loss: 0.9197\n",
            "Epoch 326/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9473 - val_loss: 0.9195\n",
            "Epoch 327/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9471 - val_loss: 0.9193\n",
            "Epoch 328/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9469 - val_loss: 0.9191\n",
            "Epoch 329/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9467 - val_loss: 0.9189\n",
            "Epoch 330/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9465 - val_loss: 0.9187\n",
            "Epoch 331/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9463 - val_loss: 0.9186\n",
            "Epoch 332/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9461 - val_loss: 0.9184\n",
            "Epoch 333/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9459 - val_loss: 0.9182\n",
            "Epoch 334/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9457 - val_loss: 0.9180\n",
            "Epoch 335/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9455 - val_loss: 0.9178\n",
            "Epoch 336/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9453 - val_loss: 0.9177\n",
            "Epoch 337/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9451 - val_loss: 0.9175\n",
            "Epoch 338/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9449 - val_loss: 0.9173\n",
            "Epoch 339/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9447 - val_loss: 0.9171\n",
            "Epoch 340/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9445 - val_loss: 0.9169\n",
            "Epoch 341/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9443 - val_loss: 0.9168\n",
            "Epoch 342/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9441 - val_loss: 0.9166\n",
            "Epoch 343/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9439 - val_loss: 0.9164\n",
            "Epoch 344/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9437 - val_loss: 0.9162\n",
            "Epoch 345/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 0.9160\n",
            "Epoch 346/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9433 - val_loss: 0.9159\n",
            "Epoch 347/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9431 - val_loss: 0.9157\n",
            "Epoch 348/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9429 - val_loss: 0.9155\n",
            "Epoch 349/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9427 - val_loss: 0.9153\n",
            "Epoch 350/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9425 - val_loss: 0.9151\n",
            "Epoch 351/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9423 - val_loss: 0.9149\n",
            "Epoch 352/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.9148\n",
            "Epoch 353/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 0.9146\n",
            "Epoch 354/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9417 - val_loss: 0.9144\n",
            "Epoch 355/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9415 - val_loss: 0.9142\n",
            "Epoch 356/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9413 - val_loss: 0.9140\n",
            "Epoch 357/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9411 - val_loss: 0.9139\n",
            "Epoch 358/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9409 - val_loss: 0.9137\n",
            "Epoch 359/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9407 - val_loss: 0.9135\n",
            "Epoch 360/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9404 - val_loss: 0.9133\n",
            "Epoch 361/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9402 - val_loss: 0.9131\n",
            "Epoch 362/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9400 - val_loss: 0.9129\n",
            "Epoch 363/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 0.9128\n",
            "Epoch 364/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9396 - val_loss: 0.9126\n",
            "Epoch 365/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9394 - val_loss: 0.9124\n",
            "Epoch 366/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9392 - val_loss: 0.9122\n",
            "Epoch 367/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9390 - val_loss: 0.9120\n",
            "Epoch 368/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9388 - val_loss: 0.9118\n",
            "Epoch 369/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9386 - val_loss: 0.9117\n",
            "Epoch 370/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9384 - val_loss: 0.9115\n",
            "Epoch 371/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9382 - val_loss: 0.9113\n",
            "Epoch 372/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9380 - val_loss: 0.9111\n",
            "Epoch 373/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9378 - val_loss: 0.9109\n",
            "Epoch 374/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9376 - val_loss: 0.9108\n",
            "Epoch 375/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9374 - val_loss: 0.9106\n",
            "Epoch 376/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9372 - val_loss: 0.9104\n",
            "Epoch 377/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9370 - val_loss: 0.9102\n",
            "Epoch 378/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9368 - val_loss: 0.9100\n",
            "Epoch 379/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9366 - val_loss: 0.9098\n",
            "Epoch 380/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9364 - val_loss: 0.9097\n",
            "Epoch 381/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9362 - val_loss: 0.9095\n",
            "Epoch 382/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9093\n",
            "Epoch 383/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9358 - val_loss: 0.9091\n",
            "Epoch 384/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9356 - val_loss: 0.9089\n",
            "Epoch 385/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.9087\n",
            "Epoch 386/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9352 - val_loss: 0.9086\n",
            "Epoch 387/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9350 - val_loss: 0.9084\n",
            "Epoch 388/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9348 - val_loss: 0.9082\n",
            "Epoch 389/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9346 - val_loss: 0.9080\n",
            "Epoch 390/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9344 - val_loss: 0.9078\n",
            "Epoch 391/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9342 - val_loss: 0.9077\n",
            "Epoch 392/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9340 - val_loss: 0.9075\n",
            "Epoch 393/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9338 - val_loss: 0.9073\n",
            "Epoch 394/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9336 - val_loss: 0.9071\n",
            "Epoch 395/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9334 - val_loss: 0.9069\n",
            "Epoch 396/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9332 - val_loss: 0.9068\n",
            "Epoch 397/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9330 - val_loss: 0.9066\n",
            "Epoch 398/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9328 - val_loss: 0.9064\n",
            "Epoch 399/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 0.9062\n",
            "Epoch 400/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9324 - val_loss: 0.9060\n",
            "Epoch 401/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9322 - val_loss: 0.9059\n",
            "Epoch 402/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9320 - val_loss: 0.9057\n",
            "Epoch 403/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9318 - val_loss: 0.9055\n",
            "Epoch 404/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9316 - val_loss: 0.9053\n",
            "Epoch 405/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9314 - val_loss: 0.9051\n",
            "Epoch 406/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9311 - val_loss: 0.9050\n",
            "Epoch 407/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9309 - val_loss: 0.9048\n",
            "Epoch 408/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9307 - val_loss: 0.9046\n",
            "Epoch 409/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9305 - val_loss: 0.9044\n",
            "Epoch 410/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9303 - val_loss: 0.9042\n",
            "Epoch 411/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9301 - val_loss: 0.9041\n",
            "Epoch 412/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9299 - val_loss: 0.9039\n",
            "Epoch 413/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9297 - val_loss: 0.9037\n",
            "Epoch 414/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9295 - val_loss: 0.9035\n",
            "Epoch 415/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9293 - val_loss: 0.9034\n",
            "Epoch 416/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9032\n",
            "Epoch 417/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9289 - val_loss: 0.9030\n",
            "Epoch 418/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9287 - val_loss: 0.9028\n",
            "Epoch 419/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9285 - val_loss: 0.9026\n",
            "Epoch 420/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9283 - val_loss: 0.9025\n",
            "Epoch 421/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9281 - val_loss: 0.9023\n",
            "Epoch 422/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9279 - val_loss: 0.9021\n",
            "Epoch 423/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9277 - val_loss: 0.9019\n",
            "Epoch 424/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9275 - val_loss: 0.9017\n",
            "Epoch 425/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9273 - val_loss: 0.9016\n",
            "Epoch 426/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 0.9014\n",
            "Epoch 427/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9269 - val_loss: 0.9012\n",
            "Epoch 428/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9267 - val_loss: 0.9010\n",
            "Epoch 429/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9265 - val_loss: 0.9009\n",
            "Epoch 430/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9263 - val_loss: 0.9007\n",
            "Epoch 431/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9261 - val_loss: 0.9005\n",
            "Epoch 432/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9259 - val_loss: 0.9003\n",
            "Epoch 433/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9257 - val_loss: 0.9001\n",
            "Epoch 434/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9255 - val_loss: 0.9000\n",
            "Epoch 435/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9253 - val_loss: 0.8998\n",
            "Epoch 436/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9251 - val_loss: 0.8996\n",
            "Epoch 437/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9248 - val_loss: 0.8994\n",
            "Epoch 438/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9246 - val_loss: 0.8992\n",
            "Epoch 439/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9244 - val_loss: 0.8991\n",
            "Epoch 440/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9242 - val_loss: 0.8989\n",
            "Epoch 441/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9240 - val_loss: 0.8987\n",
            "Epoch 442/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9238 - val_loss: 0.8985\n",
            "Epoch 443/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9236 - val_loss: 0.8983\n",
            "Epoch 444/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9234 - val_loss: 0.8982\n",
            "Epoch 445/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9232 - val_loss: 0.8980\n",
            "Epoch 446/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9230 - val_loss: 0.8978\n",
            "Epoch 447/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9228 - val_loss: 0.8976\n",
            "Epoch 448/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9226 - val_loss: 0.8975\n",
            "Epoch 449/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9224 - val_loss: 0.8973\n",
            "Epoch 450/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9222 - val_loss: 0.8971\n",
            "Epoch 451/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9220 - val_loss: 0.8969\n",
            "Epoch 452/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 0.8967\n",
            "Epoch 453/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9216 - val_loss: 0.8966\n",
            "Epoch 454/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9214 - val_loss: 0.8964\n",
            "Epoch 455/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9212 - val_loss: 0.8962\n",
            "Epoch 456/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9210 - val_loss: 0.8960\n",
            "Epoch 457/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9208 - val_loss: 0.8959\n",
            "Epoch 458/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9206 - val_loss: 0.8957\n",
            "Epoch 459/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9204 - val_loss: 0.8955\n",
            "Epoch 460/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9202 - val_loss: 0.8953\n",
            "Epoch 461/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 0.8952\n",
            "Epoch 462/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9198 - val_loss: 0.8950\n",
            "Epoch 463/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9196 - val_loss: 0.8948\n",
            "Epoch 464/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9194 - val_loss: 0.8946\n",
            "Epoch 465/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9192 - val_loss: 0.8944\n",
            "Epoch 466/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 0.8942\n",
            "Epoch 467/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9187 - val_loss: 0.8941\n",
            "Epoch 468/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9185 - val_loss: 0.8939\n",
            "Epoch 469/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.8937\n",
            "Epoch 470/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.8935\n",
            "Epoch 471/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9179 - val_loss: 0.8934\n",
            "Epoch 472/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9177 - val_loss: 0.8932\n",
            "Epoch 473/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9175 - val_loss: 0.8930\n",
            "Epoch 474/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9173 - val_loss: 0.8928\n",
            "Epoch 475/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9171 - val_loss: 0.8926\n",
            "Epoch 476/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9169 - val_loss: 0.8925\n",
            "Epoch 477/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9167 - val_loss: 0.8923\n",
            "Epoch 478/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9165 - val_loss: 0.8921\n",
            "Epoch 479/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9163 - val_loss: 0.8919\n",
            "Epoch 480/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9161 - val_loss: 0.8917\n",
            "Epoch 481/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9159 - val_loss: 0.8916\n",
            "Epoch 482/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9157 - val_loss: 0.8914\n",
            "Epoch 483/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9155 - val_loss: 0.8912\n",
            "Epoch 484/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9153 - val_loss: 0.8910\n",
            "Epoch 485/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9151 - val_loss: 0.8909\n",
            "Epoch 486/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9149 - val_loss: 0.8907\n",
            "Epoch 487/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9147 - val_loss: 0.8905\n",
            "Epoch 488/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9145 - val_loss: 0.8903\n",
            "Epoch 489/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9143 - val_loss: 0.8901\n",
            "Epoch 490/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9141 - val_loss: 0.8900\n",
            "Epoch 491/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9139 - val_loss: 0.8898\n",
            "Epoch 492/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9137 - val_loss: 0.8896\n",
            "Epoch 493/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9134 - val_loss: 0.8894\n",
            "Epoch 494/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9132 - val_loss: 0.8893\n",
            "Epoch 495/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9130 - val_loss: 0.8891\n",
            "Epoch 496/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9128 - val_loss: 0.8889\n",
            "Epoch 497/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9126 - val_loss: 0.8887\n",
            "Epoch 498/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9124 - val_loss: 0.8885\n",
            "Epoch 499/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9122 - val_loss: 0.8884\n",
            "Epoch 500/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9120 - val_loss: 0.8882\n",
            "Epoch 501/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9118 - val_loss: 0.8880\n",
            "Epoch 502/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9116 - val_loss: 0.8878\n",
            "Epoch 503/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9114 - val_loss: 0.8876\n",
            "Epoch 504/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9112 - val_loss: 0.8875\n",
            "Epoch 505/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9110 - val_loss: 0.8873\n",
            "Epoch 506/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9108 - val_loss: 0.8871\n",
            "Epoch 507/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9106 - val_loss: 0.8869\n",
            "Epoch 508/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9104 - val_loss: 0.8867\n",
            "Epoch 509/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9102 - val_loss: 0.8866\n",
            "Epoch 510/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9100 - val_loss: 0.8864\n",
            "Epoch 511/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9098 - val_loss: 0.8862\n",
            "Epoch 512/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9096 - val_loss: 0.8860\n",
            "Epoch 513/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9093 - val_loss: 0.8858\n",
            "Epoch 514/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9091 - val_loss: 0.8857\n",
            "Epoch 515/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9089 - val_loss: 0.8855\n",
            "Epoch 516/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9087 - val_loss: 0.8853\n",
            "Epoch 517/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9085 - val_loss: 0.8851\n",
            "Epoch 518/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9083 - val_loss: 0.8849\n",
            "Epoch 519/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9081 - val_loss: 0.8848\n",
            "Epoch 520/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9079 - val_loss: 0.8846\n",
            "Epoch 521/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9077 - val_loss: 0.8844\n",
            "Epoch 522/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9075 - val_loss: 0.8842\n",
            "Epoch 523/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9073 - val_loss: 0.8840\n",
            "Epoch 524/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9071 - val_loss: 0.8839\n",
            "Epoch 525/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9069 - val_loss: 0.8837\n",
            "Epoch 526/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9067 - val_loss: 0.8835\n",
            "Epoch 527/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9065 - val_loss: 0.8833\n",
            "Epoch 528/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9063 - val_loss: 0.8831\n",
            "Epoch 529/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9061 - val_loss: 0.8830\n",
            "Epoch 530/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9058 - val_loss: 0.8828\n",
            "Epoch 531/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9056 - val_loss: 0.8826\n",
            "Epoch 532/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9054 - val_loss: 0.8824\n",
            "Epoch 533/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9052 - val_loss: 0.8822\n",
            "Epoch 534/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9050 - val_loss: 0.8821\n",
            "Epoch 535/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9048 - val_loss: 0.8819\n",
            "Epoch 536/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9046 - val_loss: 0.8817\n",
            "Epoch 537/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9044 - val_loss: 0.8815\n",
            "Epoch 538/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9042 - val_loss: 0.8813\n",
            "Epoch 539/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9040 - val_loss: 0.8812\n",
            "Epoch 540/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9038 - val_loss: 0.8810\n",
            "Epoch 541/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9036 - val_loss: 0.8808\n",
            "Epoch 542/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9034 - val_loss: 0.8806\n",
            "Epoch 543/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9032 - val_loss: 0.8805\n",
            "Epoch 544/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9030 - val_loss: 0.8803\n",
            "Epoch 545/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9028 - val_loss: 0.8801\n",
            "Epoch 546/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9026 - val_loss: 0.8799\n",
            "Epoch 547/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9024 - val_loss: 0.8797\n",
            "Epoch 548/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9022 - val_loss: 0.8796\n",
            "Epoch 549/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9020 - val_loss: 0.8794\n",
            "Epoch 550/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9018 - val_loss: 0.8792\n",
            "Epoch 551/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9015 - val_loss: 0.8790\n",
            "Epoch 552/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9013 - val_loss: 0.8788\n",
            "Epoch 553/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9011 - val_loss: 0.8787\n",
            "Epoch 554/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9009 - val_loss: 0.8785\n",
            "Epoch 555/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9007 - val_loss: 0.8783\n",
            "Epoch 556/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9005 - val_loss: 0.8781\n",
            "Epoch 557/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9003 - val_loss: 0.8779\n",
            "Epoch 558/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9001 - val_loss: 0.8777\n",
            "Epoch 559/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8999 - val_loss: 0.8776\n",
            "Epoch 560/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8997 - val_loss: 0.8774\n",
            "Epoch 561/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8995 - val_loss: 0.8772\n",
            "Epoch 562/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8993 - val_loss: 0.8770\n",
            "Epoch 563/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8991 - val_loss: 0.8768\n",
            "Epoch 564/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8989 - val_loss: 0.8767\n",
            "Epoch 565/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8987 - val_loss: 0.8765\n",
            "Epoch 566/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8984 - val_loss: 0.8763\n",
            "Epoch 567/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8982 - val_loss: 0.8761\n",
            "Epoch 568/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8980 - val_loss: 0.8759\n",
            "Epoch 569/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8978 - val_loss: 0.8758\n",
            "Epoch 570/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8976 - val_loss: 0.8756\n",
            "Epoch 571/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8974 - val_loss: 0.8754\n",
            "Epoch 572/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8972 - val_loss: 0.8752\n",
            "Epoch 573/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8970 - val_loss: 0.8750\n",
            "Epoch 574/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8968 - val_loss: 0.8749\n",
            "Epoch 575/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8966 - val_loss: 0.8747\n",
            "Epoch 576/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8964 - val_loss: 0.8745\n",
            "Epoch 577/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8962 - val_loss: 0.8743\n",
            "Epoch 578/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8960 - val_loss: 0.8741\n",
            "Epoch 579/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8958 - val_loss: 0.8739\n",
            "Epoch 580/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8956 - val_loss: 0.8738\n",
            "Epoch 581/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8954 - val_loss: 0.8736\n",
            "Epoch 582/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8952 - val_loss: 0.8734\n",
            "Epoch 583/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8949 - val_loss: 0.8732\n",
            "Epoch 584/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8947 - val_loss: 0.8730\n",
            "Epoch 585/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8945 - val_loss: 0.8729\n",
            "Epoch 586/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8943 - val_loss: 0.8727\n",
            "Epoch 587/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8941 - val_loss: 0.8725\n",
            "Epoch 588/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8939 - val_loss: 0.8723\n",
            "Epoch 589/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8937 - val_loss: 0.8721\n",
            "Epoch 590/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8935 - val_loss: 0.8720\n",
            "Epoch 591/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8933 - val_loss: 0.8718\n",
            "Epoch 592/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8931 - val_loss: 0.8716\n",
            "Epoch 593/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8929 - val_loss: 0.8714\n",
            "Epoch 594/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8927 - val_loss: 0.8712\n",
            "Epoch 595/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8925 - val_loss: 0.8711\n",
            "Epoch 596/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8923 - val_loss: 0.8709\n",
            "Epoch 597/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8920 - val_loss: 0.8707\n",
            "Epoch 598/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8918 - val_loss: 0.8705\n",
            "Epoch 599/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8916 - val_loss: 0.8703\n",
            "Epoch 600/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8914 - val_loss: 0.8701\n",
            "Epoch 601/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8912 - val_loss: 0.8700\n",
            "Epoch 602/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8910 - val_loss: 0.8698\n",
            "Epoch 603/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8908 - val_loss: 0.8696\n",
            "Epoch 604/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8906 - val_loss: 0.8694\n",
            "Epoch 605/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8904 - val_loss: 0.8692\n",
            "Epoch 606/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8902 - val_loss: 0.8691\n",
            "Epoch 607/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8899 - val_loss: 0.8689\n",
            "Epoch 608/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8897 - val_loss: 0.8687\n",
            "Epoch 609/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8895 - val_loss: 0.8685\n",
            "Epoch 610/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8893 - val_loss: 0.8683\n",
            "Epoch 611/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8891 - val_loss: 0.8681\n",
            "Epoch 612/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8889 - val_loss: 0.8680\n",
            "Epoch 613/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8887 - val_loss: 0.8678\n",
            "Epoch 614/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8885 - val_loss: 0.8676\n",
            "Epoch 615/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8883 - val_loss: 0.8674\n",
            "Epoch 616/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8881 - val_loss: 0.8672\n",
            "Epoch 617/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8878 - val_loss: 0.8670\n",
            "Epoch 618/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8876 - val_loss: 0.8669\n",
            "Epoch 619/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8874 - val_loss: 0.8667\n",
            "Epoch 620/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8872 - val_loss: 0.8665\n",
            "Epoch 621/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8870 - val_loss: 0.8663\n",
            "Epoch 622/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8868 - val_loss: 0.8661\n",
            "Epoch 623/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8866 - val_loss: 0.8659\n",
            "Epoch 624/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8864 - val_loss: 0.8658\n",
            "Epoch 625/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8862 - val_loss: 0.8656\n",
            "Epoch 626/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8859 - val_loss: 0.8654\n",
            "Epoch 627/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8857 - val_loss: 0.8652\n",
            "Epoch 628/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8855 - val_loss: 0.8650\n",
            "Epoch 629/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8853 - val_loss: 0.8648\n",
            "Epoch 630/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8851 - val_loss: 0.8647\n",
            "Epoch 631/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8849 - val_loss: 0.8645\n",
            "Epoch 632/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8847 - val_loss: 0.8643\n",
            "Epoch 633/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8844 - val_loss: 0.8641\n",
            "Epoch 634/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8842 - val_loss: 0.8639\n",
            "Epoch 635/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8840 - val_loss: 0.8637\n",
            "Epoch 636/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8838 - val_loss: 0.8635\n",
            "Epoch 637/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8836 - val_loss: 0.8634\n",
            "Epoch 638/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8834 - val_loss: 0.8632\n",
            "Epoch 639/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8832 - val_loss: 0.8630\n",
            "Epoch 640/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8829 - val_loss: 0.8628\n",
            "Epoch 641/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8827 - val_loss: 0.8626\n",
            "Epoch 642/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8825 - val_loss: 0.8624\n",
            "Epoch 643/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8823 - val_loss: 0.8623\n",
            "Epoch 644/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8821 - val_loss: 0.8621\n",
            "Epoch 645/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8819 - val_loss: 0.8619\n",
            "Epoch 646/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8817 - val_loss: 0.8617\n",
            "Epoch 647/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8815 - val_loss: 0.8615\n",
            "Epoch 648/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8812 - val_loss: 0.8613\n",
            "Epoch 649/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8810 - val_loss: 0.8612\n",
            "Epoch 650/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8808 - val_loss: 0.8610\n",
            "Epoch 651/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8806 - val_loss: 0.8608\n",
            "Epoch 652/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8804 - val_loss: 0.8606\n",
            "Epoch 653/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8802 - val_loss: 0.8604\n",
            "Epoch 654/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8800 - val_loss: 0.8602\n",
            "Epoch 655/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8798 - val_loss: 0.8600\n",
            "Epoch 656/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8796 - val_loss: 0.8599\n",
            "Epoch 657/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8793 - val_loss: 0.8597\n",
            "Epoch 658/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8791 - val_loss: 0.8595\n",
            "Epoch 659/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8789 - val_loss: 0.8593\n",
            "Epoch 660/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8787 - val_loss: 0.8591\n",
            "Epoch 661/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8785 - val_loss: 0.8589\n",
            "Epoch 662/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8783 - val_loss: 0.8588\n",
            "Epoch 663/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8781 - val_loss: 0.8586\n",
            "Epoch 664/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8779 - val_loss: 0.8584\n",
            "Epoch 665/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8777 - val_loss: 0.8582\n",
            "Epoch 666/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8774 - val_loss: 0.8580\n",
            "Epoch 667/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8772 - val_loss: 0.8578\n",
            "Epoch 668/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8770 - val_loss: 0.8577\n",
            "Epoch 669/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8768 - val_loss: 0.8575\n",
            "Epoch 670/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8766 - val_loss: 0.8573\n",
            "Epoch 671/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8764 - val_loss: 0.8571\n",
            "Epoch 672/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8762 - val_loss: 0.8569\n",
            "Epoch 673/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8760 - val_loss: 0.8567\n",
            "Epoch 674/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8757 - val_loss: 0.8566\n",
            "Epoch 675/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8755 - val_loss: 0.8564\n",
            "Epoch 676/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8753 - val_loss: 0.8562\n",
            "Epoch 677/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8751 - val_loss: 0.8560\n",
            "Epoch 678/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8749 - val_loss: 0.8558\n",
            "Epoch 679/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8747 - val_loss: 0.8556\n",
            "Epoch 680/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8745 - val_loss: 0.8555\n",
            "Epoch 681/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8743 - val_loss: 0.8553\n",
            "Epoch 682/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8741 - val_loss: 0.8551\n",
            "Epoch 683/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8739 - val_loss: 0.8549\n",
            "Epoch 684/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8736 - val_loss: 0.8547\n",
            "Epoch 685/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8734 - val_loss: 0.8545\n",
            "Epoch 686/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8732 - val_loss: 0.8544\n",
            "Epoch 687/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8730 - val_loss: 0.8542\n",
            "Epoch 688/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8728 - val_loss: 0.8540\n",
            "Epoch 689/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8726 - val_loss: 0.8538\n",
            "Epoch 690/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8724 - val_loss: 0.8536\n",
            "Epoch 691/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8722 - val_loss: 0.8534\n",
            "Epoch 692/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8719 - val_loss: 0.8532\n",
            "Epoch 693/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8717 - val_loss: 0.8531\n",
            "Epoch 694/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8715 - val_loss: 0.8529\n",
            "Epoch 695/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8713 - val_loss: 0.8527\n",
            "Epoch 696/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8711 - val_loss: 0.8525\n",
            "Epoch 697/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8709 - val_loss: 0.8523\n",
            "Epoch 698/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8706 - val_loss: 0.8521\n",
            "Epoch 699/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8704 - val_loss: 0.8519\n",
            "Epoch 700/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8702 - val_loss: 0.8517\n",
            "Epoch 701/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8700 - val_loss: 0.8515\n",
            "Epoch 702/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8698 - val_loss: 0.8513\n",
            "Epoch 703/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8696 - val_loss: 0.8512\n",
            "Epoch 704/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8693 - val_loss: 0.8510\n",
            "Epoch 705/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8691 - val_loss: 0.8508\n",
            "Epoch 706/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8689 - val_loss: 0.8506\n",
            "Epoch 707/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8687 - val_loss: 0.8504\n",
            "Epoch 708/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8685 - val_loss: 0.8502\n",
            "Epoch 709/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8683 - val_loss: 0.8500\n",
            "Epoch 710/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8681 - val_loss: 0.8499\n",
            "Epoch 711/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8678 - val_loss: 0.8497\n",
            "Epoch 712/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8676 - val_loss: 0.8495\n",
            "Epoch 713/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8674 - val_loss: 0.8493\n",
            "Epoch 714/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8672 - val_loss: 0.8491\n",
            "Epoch 715/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8670 - val_loss: 0.8489\n",
            "Epoch 716/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8668 - val_loss: 0.8487\n",
            "Epoch 717/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8666 - val_loss: 0.8485\n",
            "Epoch 718/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8663 - val_loss: 0.8484\n",
            "Epoch 719/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8661 - val_loss: 0.8482\n",
            "Epoch 720/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8659 - val_loss: 0.8480\n",
            "Epoch 721/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8657 - val_loss: 0.8478\n",
            "Epoch 722/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8655 - val_loss: 0.8476\n",
            "Epoch 723/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8653 - val_loss: 0.8474\n",
            "Epoch 724/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8651 - val_loss: 0.8472\n",
            "Epoch 725/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8648 - val_loss: 0.8471\n",
            "Epoch 726/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8646 - val_loss: 0.8469\n",
            "Epoch 727/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8644 - val_loss: 0.8467\n",
            "Epoch 728/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8642 - val_loss: 0.8465\n",
            "Epoch 729/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8640 - val_loss: 0.8463\n",
            "Epoch 730/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8638 - val_loss: 0.8461\n",
            "Epoch 731/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8636 - val_loss: 0.8459\n",
            "Epoch 732/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8634 - val_loss: 0.8458\n",
            "Epoch 733/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8631 - val_loss: 0.8456\n",
            "Epoch 734/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8629 - val_loss: 0.8454\n",
            "Epoch 735/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8627 - val_loss: 0.8452\n",
            "Epoch 736/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8625 - val_loss: 0.8450\n",
            "Epoch 737/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8623 - val_loss: 0.8448\n",
            "Epoch 738/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8621 - val_loss: 0.8446\n",
            "Epoch 739/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8618 - val_loss: 0.8444\n",
            "Epoch 740/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8616 - val_loss: 0.8443\n",
            "Epoch 741/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8614 - val_loss: 0.8441\n",
            "Epoch 742/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8612 - val_loss: 0.8439\n",
            "Epoch 743/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8610 - val_loss: 0.8437\n",
            "Epoch 744/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8608 - val_loss: 0.8435\n",
            "Epoch 745/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8605 - val_loss: 0.8433\n",
            "Epoch 746/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8603 - val_loss: 0.8431\n",
            "Epoch 747/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8601 - val_loss: 0.8429\n",
            "Epoch 748/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8599 - val_loss: 0.8427\n",
            "Epoch 749/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8597 - val_loss: 0.8426\n",
            "Epoch 750/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8594 - val_loss: 0.8424\n",
            "Epoch 751/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8592 - val_loss: 0.8422\n",
            "Epoch 752/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8590 - val_loss: 0.8420\n",
            "Epoch 753/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8588 - val_loss: 0.8418\n",
            "Epoch 754/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8586 - val_loss: 0.8416\n",
            "Epoch 755/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8584 - val_loss: 0.8414\n",
            "Epoch 756/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8581 - val_loss: 0.8412\n",
            "Epoch 757/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8579 - val_loss: 0.8410\n",
            "Epoch 758/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8577 - val_loss: 0.8409\n",
            "Epoch 759/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8575 - val_loss: 0.8407\n",
            "Epoch 760/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8573 - val_loss: 0.8405\n",
            "Epoch 761/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8570 - val_loss: 0.8403\n",
            "Epoch 762/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8568 - val_loss: 0.8401\n",
            "Epoch 763/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8566 - val_loss: 0.8399\n",
            "Epoch 764/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8564 - val_loss: 0.8397\n",
            "Epoch 765/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8562 - val_loss: 0.8395\n",
            "Epoch 766/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8560 - val_loss: 0.8393\n",
            "Epoch 767/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8557 - val_loss: 0.8391\n",
            "Epoch 768/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8555 - val_loss: 0.8390\n",
            "Epoch 769/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8553 - val_loss: 0.8388\n",
            "Epoch 770/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8551 - val_loss: 0.8386\n",
            "Epoch 771/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8549 - val_loss: 0.8384\n",
            "Epoch 772/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8546 - val_loss: 0.8382\n",
            "Epoch 773/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8544 - val_loss: 0.8380\n",
            "Epoch 774/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8542 - val_loss: 0.8378\n",
            "Epoch 775/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8540 - val_loss: 0.8376\n",
            "Epoch 776/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8538 - val_loss: 0.8374\n",
            "Epoch 777/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8536 - val_loss: 0.8372\n",
            "Epoch 778/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8533 - val_loss: 0.8371\n",
            "Epoch 779/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8531 - val_loss: 0.8369\n",
            "Epoch 780/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8529 - val_loss: 0.8367\n",
            "Epoch 781/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8527 - val_loss: 0.8365\n",
            "Epoch 782/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8525 - val_loss: 0.8363\n",
            "Epoch 783/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8522 - val_loss: 0.8361\n",
            "Epoch 784/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8520 - val_loss: 0.8359\n",
            "Epoch 785/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8518 - val_loss: 0.8357\n",
            "Epoch 786/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8516 - val_loss: 0.8355\n",
            "Epoch 787/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8514 - val_loss: 0.8353\n",
            "Epoch 788/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8512 - val_loss: 0.8351\n",
            "Epoch 789/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8509 - val_loss: 0.8350\n",
            "Epoch 790/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8507 - val_loss: 0.8348\n",
            "Epoch 791/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8505 - val_loss: 0.8346\n",
            "Epoch 792/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8503 - val_loss: 0.8344\n",
            "Epoch 793/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8500 - val_loss: 0.8342\n",
            "Epoch 794/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8498 - val_loss: 0.8340\n",
            "Epoch 795/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8496 - val_loss: 0.8338\n",
            "Epoch 796/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8494 - val_loss: 0.8336\n",
            "Epoch 797/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8492 - val_loss: 0.8334\n",
            "Epoch 798/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8490 - val_loss: 0.8332\n",
            "Epoch 799/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8487 - val_loss: 0.8331\n",
            "Epoch 800/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8485 - val_loss: 0.8329\n",
            "Epoch 801/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8483 - val_loss: 0.8327\n",
            "Epoch 802/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8481 - val_loss: 0.8325\n",
            "Epoch 803/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8479 - val_loss: 0.8323\n",
            "Epoch 804/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8476 - val_loss: 0.8321\n",
            "Epoch 805/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8474 - val_loss: 0.8319\n",
            "Epoch 806/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8472 - val_loss: 0.8317\n",
            "Epoch 807/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8470 - val_loss: 0.8315\n",
            "Epoch 808/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8468 - val_loss: 0.8313\n",
            "Epoch 809/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8465 - val_loss: 0.8311\n",
            "Epoch 810/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8463 - val_loss: 0.8309\n",
            "Epoch 811/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8461 - val_loss: 0.8307\n",
            "Epoch 812/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8459 - val_loss: 0.8306\n",
            "Epoch 813/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8456 - val_loss: 0.8304\n",
            "Epoch 814/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8454 - val_loss: 0.8302\n",
            "Epoch 815/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8452 - val_loss: 0.8300\n",
            "Epoch 816/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8450 - val_loss: 0.8298\n",
            "Epoch 817/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8447 - val_loss: 0.8296\n",
            "Epoch 818/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8445 - val_loss: 0.8294\n",
            "Epoch 819/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8443 - val_loss: 0.8292\n",
            "Epoch 820/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8441 - val_loss: 0.8290\n",
            "Epoch 821/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8439 - val_loss: 0.8288\n",
            "Epoch 822/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8436 - val_loss: 0.8286\n",
            "Epoch 823/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8434 - val_loss: 0.8284\n",
            "Epoch 824/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8432 - val_loss: 0.8282\n",
            "Epoch 825/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8429 - val_loss: 0.8280\n",
            "Epoch 826/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8427 - val_loss: 0.8278\n",
            "Epoch 827/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8425 - val_loss: 0.8276\n",
            "Epoch 828/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8423 - val_loss: 0.8274\n",
            "Epoch 829/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8420 - val_loss: 0.8272\n",
            "Epoch 830/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8418 - val_loss: 0.8270\n",
            "Epoch 831/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8416 - val_loss: 0.8268\n",
            "Epoch 832/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8414 - val_loss: 0.8267\n",
            "Epoch 833/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8411 - val_loss: 0.8265\n",
            "Epoch 834/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8409 - val_loss: 0.8263\n",
            "Epoch 835/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8407 - val_loss: 0.8261\n",
            "Epoch 836/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8405 - val_loss: 0.8259\n",
            "Epoch 837/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8402 - val_loss: 0.8257\n",
            "Epoch 838/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8400 - val_loss: 0.8255\n",
            "Epoch 839/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8398 - val_loss: 0.8253\n",
            "Epoch 840/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8396 - val_loss: 0.8251\n",
            "Epoch 841/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8393 - val_loss: 0.8249\n",
            "Epoch 842/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8391 - val_loss: 0.8247\n",
            "Epoch 843/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8389 - val_loss: 0.8245\n",
            "Epoch 844/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8387 - val_loss: 0.8243\n",
            "Epoch 845/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8384 - val_loss: 0.8241\n",
            "Epoch 846/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8382 - val_loss: 0.8239\n",
            "Epoch 847/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8380 - val_loss: 0.8237\n",
            "Epoch 848/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8378 - val_loss: 0.8236\n",
            "Epoch 849/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8376 - val_loss: 0.8234\n",
            "Epoch 850/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8373 - val_loss: 0.8232\n",
            "Epoch 851/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8371 - val_loss: 0.8230\n",
            "Epoch 852/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8369 - val_loss: 0.8228\n",
            "Epoch 853/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8367 - val_loss: 0.8226\n",
            "Epoch 854/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8364 - val_loss: 0.8224\n",
            "Epoch 855/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8362 - val_loss: 0.8222\n",
            "Epoch 856/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8360 - val_loss: 0.8220\n",
            "Epoch 857/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8358 - val_loss: 0.8218\n",
            "Epoch 858/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8355 - val_loss: 0.8216\n",
            "Epoch 859/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8353 - val_loss: 0.8214\n",
            "Epoch 860/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8351 - val_loss: 0.8212\n",
            "Epoch 861/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8349 - val_loss: 0.8210\n",
            "Epoch 862/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8346 - val_loss: 0.8208\n",
            "Epoch 863/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8344 - val_loss: 0.8206\n",
            "Epoch 864/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8342 - val_loss: 0.8204\n",
            "Epoch 865/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8339 - val_loss: 0.8203\n",
            "Epoch 866/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8337 - val_loss: 0.8201\n",
            "Epoch 867/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8335 - val_loss: 0.8199\n",
            "Epoch 868/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8333 - val_loss: 0.8197\n",
            "Epoch 869/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8331 - val_loss: 0.8195\n",
            "Epoch 870/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8328 - val_loss: 0.8193\n",
            "Epoch 871/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8326 - val_loss: 0.8191\n",
            "Epoch 872/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8324 - val_loss: 0.8189\n",
            "Epoch 873/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8322 - val_loss: 0.8187\n",
            "Epoch 874/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8320 - val_loss: 0.8185\n",
            "Epoch 875/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8317 - val_loss: 0.8184\n",
            "Epoch 876/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8315 - val_loss: 0.8182\n",
            "Epoch 877/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8313 - val_loss: 0.8180\n",
            "Epoch 878/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8311 - val_loss: 0.8178\n",
            "Epoch 879/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8308 - val_loss: 0.8176\n",
            "Epoch 880/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8306 - val_loss: 0.8174\n",
            "Epoch 881/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8304 - val_loss: 0.8172\n",
            "Epoch 882/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8302 - val_loss: 0.8170\n",
            "Epoch 883/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8299 - val_loss: 0.8168\n",
            "Epoch 884/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8297 - val_loss: 0.8166\n",
            "Epoch 885/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8295 - val_loss: 0.8164\n",
            "Epoch 886/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8293 - val_loss: 0.8162\n",
            "Epoch 887/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8290 - val_loss: 0.8160\n",
            "Epoch 888/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8288 - val_loss: 0.8158\n",
            "Epoch 889/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8286 - val_loss: 0.8157\n",
            "Epoch 890/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8284 - val_loss: 0.8155\n",
            "Epoch 891/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8281 - val_loss: 0.8153\n",
            "Epoch 892/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8279 - val_loss: 0.8151\n",
            "Epoch 893/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8277 - val_loss: 0.8149\n",
            "Epoch 894/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8275 - val_loss: 0.8147\n",
            "Epoch 895/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8272 - val_loss: 0.8145\n",
            "Epoch 896/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8270 - val_loss: 0.8143\n",
            "Epoch 897/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8268 - val_loss: 0.8141\n",
            "Epoch 898/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8265 - val_loss: 0.8139\n",
            "Epoch 899/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8263 - val_loss: 0.8137\n",
            "Epoch 900/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8261 - val_loss: 0.8135\n",
            "Epoch 901/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8259 - val_loss: 0.8133\n",
            "Epoch 902/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8256 - val_loss: 0.8131\n",
            "Epoch 903/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8254 - val_loss: 0.8129\n",
            "Epoch 904/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8252 - val_loss: 0.8127\n",
            "Epoch 905/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8249 - val_loss: 0.8125\n",
            "Epoch 906/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8247 - val_loss: 0.8123\n",
            "Epoch 907/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8245 - val_loss: 0.8121\n",
            "Epoch 908/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8243 - val_loss: 0.8119\n",
            "Epoch 909/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8240 - val_loss: 0.8117\n",
            "Epoch 910/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8238 - val_loss: 0.8116\n",
            "Epoch 911/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8236 - val_loss: 0.8114\n",
            "Epoch 912/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8233 - val_loss: 0.8112\n",
            "Epoch 913/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8231 - val_loss: 0.8110\n",
            "Epoch 914/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8229 - val_loss: 0.8108\n",
            "Epoch 915/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8227 - val_loss: 0.8106\n",
            "Epoch 916/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8224 - val_loss: 0.8104\n",
            "Epoch 917/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8222 - val_loss: 0.8102\n",
            "Epoch 918/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8220 - val_loss: 0.8100\n",
            "Epoch 919/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8218 - val_loss: 0.8098\n",
            "Epoch 920/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8215 - val_loss: 0.8096\n",
            "Epoch 921/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8213 - val_loss: 0.8094\n",
            "Epoch 922/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8211 - val_loss: 0.8092\n",
            "Epoch 923/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8209 - val_loss: 0.8090\n",
            "Epoch 924/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8206 - val_loss: 0.8088\n",
            "Epoch 925/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8204 - val_loss: 0.8086\n",
            "Epoch 926/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8202 - val_loss: 0.8084\n",
            "Epoch 927/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8199 - val_loss: 0.8082\n",
            "Epoch 928/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8197 - val_loss: 0.8080\n",
            "Epoch 929/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8195 - val_loss: 0.8078\n",
            "Epoch 930/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8193 - val_loss: 0.8076\n",
            "Epoch 931/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8190 - val_loss: 0.8074\n",
            "Epoch 932/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8188 - val_loss: 0.8072\n",
            "Epoch 933/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8186 - val_loss: 0.8070\n",
            "Epoch 934/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8183 - val_loss: 0.8068\n",
            "Epoch 935/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8181 - val_loss: 0.8066\n",
            "Epoch 936/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8179 - val_loss: 0.8065\n",
            "Epoch 937/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8177 - val_loss: 0.8063\n",
            "Epoch 938/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8174 - val_loss: 0.8061\n",
            "Epoch 939/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8172 - val_loss: 0.8059\n",
            "Epoch 940/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8170 - val_loss: 0.8057\n",
            "Epoch 941/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8167 - val_loss: 0.8055\n",
            "Epoch 942/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8165 - val_loss: 0.8053\n",
            "Epoch 943/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8163 - val_loss: 0.8051\n",
            "Epoch 944/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8161 - val_loss: 0.8049\n",
            "Epoch 945/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8158 - val_loss: 0.8047\n",
            "Epoch 946/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8156 - val_loss: 0.8045\n",
            "Epoch 947/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8154 - val_loss: 0.8043\n",
            "Epoch 948/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8151 - val_loss: 0.8041\n",
            "Epoch 949/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8149 - val_loss: 0.8039\n",
            "Epoch 950/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8147 - val_loss: 0.8037\n",
            "Epoch 951/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8145 - val_loss: 0.8035\n",
            "Epoch 952/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8142 - val_loss: 0.8033\n",
            "Epoch 953/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8140 - val_loss: 0.8031\n",
            "Epoch 954/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8138 - val_loss: 0.8029\n",
            "Epoch 955/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8135 - val_loss: 0.8027\n",
            "Epoch 956/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8133 - val_loss: 0.8025\n",
            "Epoch 957/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8131 - val_loss: 0.8023\n",
            "Epoch 958/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8129 - val_loss: 0.8021\n",
            "Epoch 959/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8126 - val_loss: 0.8019\n",
            "Epoch 960/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8124 - val_loss: 0.8017\n",
            "Epoch 961/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8122 - val_loss: 0.8015\n",
            "Epoch 962/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8119 - val_loss: 0.8013\n",
            "Epoch 963/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8117 - val_loss: 0.8011\n",
            "Epoch 964/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8115 - val_loss: 0.8009\n",
            "Epoch 965/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8112 - val_loss: 0.8007\n",
            "Epoch 966/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8110 - val_loss: 0.8005\n",
            "Epoch 967/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8108 - val_loss: 0.8003\n",
            "Epoch 968/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8105 - val_loss: 0.8001\n",
            "Epoch 969/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8103 - val_loss: 0.7999\n",
            "Epoch 970/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8101 - val_loss: 0.7997\n",
            "Epoch 971/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8098 - val_loss: 0.7995\n",
            "Epoch 972/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8096 - val_loss: 0.7993\n",
            "Epoch 973/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8094 - val_loss: 0.7991\n",
            "Epoch 974/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8092 - val_loss: 0.7989\n",
            "Epoch 975/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8089 - val_loss: 0.7987\n",
            "Epoch 976/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8087 - val_loss: 0.7985\n",
            "Epoch 977/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8085 - val_loss: 0.7983\n",
            "Epoch 978/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8083 - val_loss: 0.7981\n",
            "Epoch 979/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8080 - val_loss: 0.7979\n",
            "Epoch 980/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8078 - val_loss: 0.7977\n",
            "Epoch 981/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8076 - val_loss: 0.7975\n",
            "Epoch 982/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8074 - val_loss: 0.7973\n",
            "Epoch 983/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8071 - val_loss: 0.7971\n",
            "Epoch 984/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8069 - val_loss: 0.7969\n",
            "Epoch 985/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8067 - val_loss: 0.7967\n",
            "Epoch 986/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8064 - val_loss: 0.7965\n",
            "Epoch 987/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8062 - val_loss: 0.7963\n",
            "Epoch 988/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8060 - val_loss: 0.7961\n",
            "Epoch 989/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8058 - val_loss: 0.7959\n",
            "Epoch 990/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8055 - val_loss: 0.7957\n",
            "Epoch 991/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8053 - val_loss: 0.7955\n",
            "Epoch 992/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8051 - val_loss: 0.7953\n",
            "Epoch 993/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8048 - val_loss: 0.7951\n",
            "Epoch 994/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8046 - val_loss: 0.7949\n",
            "Epoch 995/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8043 - val_loss: 0.7947\n",
            "Epoch 996/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8041 - val_loss: 0.7945\n",
            "Epoch 997/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8039 - val_loss: 0.7943\n",
            "Epoch 998/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8036 - val_loss: 0.7941\n",
            "Epoch 999/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8034 - val_loss: 0.7939\n",
            "Epoch 1000/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8032 - val_loss: 0.7937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZssYHZazasc"
      },
      "source": [
        "####RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at8CgP2mzcx1",
        "outputId": "d2b17c49-24f5-4c58-ddfb-bf8112111140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wide_opt2(opt_RMSprop)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.8108 - val_loss: 0.6611\n",
            "Epoch 2/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5568 - val_loss: 0.5025\n",
            "Epoch 3/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4233 - val_loss: 0.4589\n",
            "Epoch 4/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3652 - val_loss: 0.4446\n",
            "Epoch 5/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3264 - val_loss: 0.4364\n",
            "Epoch 6/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2988 - val_loss: 0.4215\n",
            "Epoch 7/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2776 - val_loss: 0.4027\n",
            "Epoch 8/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2570 - val_loss: 0.3931\n",
            "Epoch 9/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2466 - val_loss: 0.3755\n",
            "Epoch 10/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2320 - val_loss: 0.3721\n",
            "Epoch 11/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2221 - val_loss: 0.3687\n",
            "Epoch 12/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2125 - val_loss: 0.3492\n",
            "Epoch 13/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2068 - val_loss: 0.3386\n",
            "Epoch 14/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1931 - val_loss: 0.3349\n",
            "Epoch 15/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1882 - val_loss: 0.3350\n",
            "Epoch 16/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1790 - val_loss: 0.3267\n",
            "Epoch 17/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1718 - val_loss: 0.3313\n",
            "Epoch 18/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1682 - val_loss: 0.3145\n",
            "Epoch 19/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1626 - val_loss: 0.3181\n",
            "Epoch 20/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1589 - val_loss: 0.3111\n",
            "Epoch 21/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1528 - val_loss: 0.3141\n",
            "Epoch 22/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.3174\n",
            "Epoch 23/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1405 - val_loss: 0.3035\n",
            "Epoch 24/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1371 - val_loss: 0.3021\n",
            "Epoch 25/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1338 - val_loss: 0.3097\n",
            "Epoch 26/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1274 - val_loss: 0.2963\n",
            "Epoch 27/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1241 - val_loss: 0.3019\n",
            "Epoch 28/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1218 - val_loss: 0.3088\n",
            "Epoch 29/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1164 - val_loss: 0.3095\n",
            "Epoch 30/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1120 - val_loss: 0.3172\n",
            "Epoch 31/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.3281\n",
            "Epoch 32/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1069 - val_loss: 0.3310\n",
            "Epoch 33/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1026 - val_loss: 0.3176\n",
            "Epoch 34/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1020 - val_loss: 0.3206\n",
            "Epoch 35/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0989 - val_loss: 0.3360\n",
            "Epoch 36/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0955 - val_loss: 0.3486\n",
            "Epoch 37/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0956 - val_loss: 0.3355\n",
            "Epoch 38/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0920 - val_loss: 0.3481\n",
            "Epoch 39/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.3565\n",
            "Epoch 40/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.3607\n",
            "Epoch 41/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0862 - val_loss: 0.3726\n",
            "Epoch 42/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.3550\n",
            "Epoch 43/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0822 - val_loss: 0.3711\n",
            "Epoch 44/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.3719\n",
            "Epoch 45/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.3876\n",
            "Epoch 46/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.3889\n",
            "Epoch 47/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.3945\n",
            "Epoch 48/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.3791\n",
            "Epoch 49/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.4025\n",
            "Epoch 50/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.4100\n",
            "Epoch 51/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.4176\n",
            "Epoch 52/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.4144\n",
            "Epoch 53/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.4407\n",
            "Epoch 54/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.4424\n",
            "Epoch 55/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 0.4466\n",
            "Epoch 56/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.4353\n",
            "Epoch 57/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.4501\n",
            "Epoch 58/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.4512\n",
            "Epoch 59/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.4568\n",
            "Epoch 60/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.4606\n",
            "Epoch 61/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.4601\n",
            "Epoch 62/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.4574\n",
            "Epoch 63/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.4657\n",
            "Epoch 64/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.4766\n",
            "Epoch 65/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.4787\n",
            "Epoch 66/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.4887\n",
            "Epoch 67/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.4921\n",
            "Epoch 68/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.5014\n",
            "Epoch 69/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.5203\n",
            "Epoch 70/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.5003\n",
            "Epoch 71/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.5211\n",
            "Epoch 72/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.5164\n",
            "Epoch 73/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.5239\n",
            "Epoch 74/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0509 - val_loss: 0.5272\n",
            "Epoch 75/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.5399\n",
            "Epoch 76/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.5187\n",
            "Epoch 77/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.5559\n",
            "Epoch 78/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.5341\n",
            "Epoch 79/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.5481\n",
            "Epoch 80/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.5453\n",
            "Epoch 81/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.5642\n",
            "Epoch 82/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.5621\n",
            "Epoch 83/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.5772\n",
            "Epoch 84/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.5706\n",
            "Epoch 85/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.5755\n",
            "Epoch 86/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.6022\n",
            "Epoch 87/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.5748\n",
            "Epoch 88/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.5751\n",
            "Epoch 89/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.6007\n",
            "Epoch 90/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.5948\n",
            "Epoch 91/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.6063\n",
            "Epoch 92/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.5920\n",
            "Epoch 93/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.6067\n",
            "Epoch 94/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.6005\n",
            "Epoch 95/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.6054\n",
            "Epoch 96/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.6123\n",
            "Epoch 97/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.6106\n",
            "Epoch 98/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.6227\n",
            "Epoch 99/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.6143\n",
            "Epoch 100/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.6330\n",
            "Epoch 101/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.6149\n",
            "Epoch 102/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.6354\n",
            "Epoch 103/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.6488\n",
            "Epoch 104/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.6572\n",
            "Epoch 105/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.6629\n",
            "Epoch 106/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 0.6680\n",
            "Epoch 107/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.6845\n",
            "Epoch 108/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.6780\n",
            "Epoch 109/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.6811\n",
            "Epoch 110/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0336 - val_loss: 0.6760\n",
            "Epoch 111/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.6911\n",
            "Epoch 112/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 0.6877\n",
            "Epoch 113/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 0.7086\n",
            "Epoch 114/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.7041\n",
            "Epoch 115/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.7073\n",
            "Epoch 116/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.6994\n",
            "Epoch 117/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0347 - val_loss: 0.7117\n",
            "Epoch 118/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.7302\n",
            "Epoch 119/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.6951\n",
            "Epoch 120/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.7222\n",
            "Epoch 121/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.6988\n",
            "Epoch 122/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0316 - val_loss: 0.7194\n",
            "Epoch 123/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.7267\n",
            "Epoch 124/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.7216\n",
            "Epoch 125/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0325 - val_loss: 0.7309\n",
            "Epoch 126/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.7513\n",
            "Epoch 127/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0322 - val_loss: 0.7529\n",
            "Epoch 128/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.7503\n",
            "Epoch 129/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.7291\n",
            "Epoch 130/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.7542\n",
            "Epoch 131/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.7385\n",
            "Epoch 132/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.7617\n",
            "Epoch 133/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.7490\n",
            "Epoch 134/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.7579\n",
            "Epoch 135/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.7708\n",
            "Epoch 136/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.7535\n",
            "Epoch 137/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.7850\n",
            "Epoch 138/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.8017\n",
            "Epoch 139/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.7624\n",
            "Epoch 140/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.7725\n",
            "Epoch 141/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.7873\n",
            "Epoch 142/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.7702\n",
            "Epoch 143/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.7899\n",
            "Epoch 144/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.7771\n",
            "Epoch 145/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.7820\n",
            "Epoch 146/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.8021\n",
            "Epoch 147/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.7987\n",
            "Epoch 148/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.8147\n",
            "Epoch 149/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.8025\n",
            "Epoch 150/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.8097\n",
            "Epoch 151/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.8455\n",
            "Epoch 152/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.8258\n",
            "Epoch 153/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.8038\n",
            "Epoch 154/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.8236\n",
            "Epoch 155/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.8407\n",
            "Epoch 156/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.8332\n",
            "Epoch 157/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.8477\n",
            "Epoch 158/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0258 - val_loss: 0.8456\n",
            "Epoch 159/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.8336\n",
            "Epoch 160/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.8524\n",
            "Epoch 161/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.8513\n",
            "Epoch 162/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.8643\n",
            "Epoch 163/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0276 - val_loss: 0.8528\n",
            "Epoch 164/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.8580\n",
            "Epoch 165/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.8445\n",
            "Epoch 166/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.8480\n",
            "Epoch 167/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.8602\n",
            "Epoch 168/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.8726\n",
            "Epoch 169/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.8589\n",
            "Epoch 170/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.8586\n",
            "Epoch 171/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.8616\n",
            "Epoch 172/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.8432\n",
            "Epoch 173/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.8800\n",
            "Epoch 174/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.8698\n",
            "Epoch 175/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.8716\n",
            "Epoch 176/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.8817\n",
            "Epoch 177/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.8650\n",
            "Epoch 178/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.8694\n",
            "Epoch 179/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.9011\n",
            "Epoch 180/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.8974\n",
            "Epoch 181/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.8949\n",
            "Epoch 182/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.9015\n",
            "Epoch 183/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.9017\n",
            "Epoch 184/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.8958\n",
            "Epoch 185/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.9090\n",
            "Epoch 186/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.8913\n",
            "Epoch 187/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.9326\n",
            "Epoch 188/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.9245\n",
            "Epoch 189/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.9128\n",
            "Epoch 190/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.8994\n",
            "Epoch 191/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.9459\n",
            "Epoch 192/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.9287\n",
            "Epoch 193/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.9371\n",
            "Epoch 194/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.9411\n",
            "Epoch 195/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.9416\n",
            "Epoch 196/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.9373\n",
            "Epoch 197/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.9542\n",
            "Epoch 198/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.9241\n",
            "Epoch 199/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.9537\n",
            "Epoch 200/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.9369\n",
            "Epoch 201/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.9585\n",
            "Epoch 202/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.9627\n",
            "Epoch 203/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.9588\n",
            "Epoch 204/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.9682\n",
            "Epoch 205/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.9255\n",
            "Epoch 206/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.9331\n",
            "Epoch 207/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.9556\n",
            "Epoch 208/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.9594\n",
            "Epoch 209/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.9725\n",
            "Epoch 210/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.9325\n",
            "Epoch 211/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.9401\n",
            "Epoch 212/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.9729\n",
            "Epoch 213/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.9606\n",
            "Epoch 214/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.9766\n",
            "Epoch 215/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.9611\n",
            "Epoch 216/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.9990\n",
            "Epoch 217/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.9897\n",
            "Epoch 218/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 1.0134\n",
            "Epoch 219/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.9772\n",
            "Epoch 220/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.9852\n",
            "Epoch 221/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.9567\n",
            "Epoch 222/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 1.0092\n",
            "Epoch 223/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 1.0194\n",
            "Epoch 224/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.9876\n",
            "Epoch 225/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.9677\n",
            "Epoch 226/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.9696\n",
            "Epoch 227/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 1.0171\n",
            "Epoch 228/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 1.0053\n",
            "Epoch 229/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 1.0024\n",
            "Epoch 230/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 1.0272\n",
            "Epoch 231/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 1.0263\n",
            "Epoch 232/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 1.0126\n",
            "Epoch 233/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 1.0095\n",
            "Epoch 234/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 1.0514\n",
            "Epoch 235/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 1.0137\n",
            "Epoch 236/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 1.0512\n",
            "Epoch 237/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 1.0003\n",
            "Epoch 238/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 1.0329\n",
            "Epoch 239/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 1.0401\n",
            "Epoch 240/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 1.0249\n",
            "Epoch 241/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 1.0186\n",
            "Epoch 242/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 1.0389\n",
            "Epoch 243/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 1.0510\n",
            "Epoch 244/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 1.0559\n",
            "Epoch 245/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 1.0362\n",
            "Epoch 246/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 1.0612\n",
            "Epoch 247/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 1.0464\n",
            "Epoch 248/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 1.0322\n",
            "Epoch 249/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 1.0337\n",
            "Epoch 250/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 1.0353\n",
            "Epoch 251/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 1.0655\n",
            "Epoch 252/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 1.0422\n",
            "Epoch 253/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 1.0611\n",
            "Epoch 254/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 1.1072\n",
            "Epoch 255/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 1.0627\n",
            "Epoch 256/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 1.0979\n",
            "Epoch 257/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 1.0536\n",
            "Epoch 258/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 1.0994\n",
            "Epoch 259/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 1.0643\n",
            "Epoch 260/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 1.0842\n",
            "Epoch 261/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 1.1141\n",
            "Epoch 262/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 1.0895\n",
            "Epoch 263/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 1.0932\n",
            "Epoch 264/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 1.0626\n",
            "Epoch 265/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 1.0853\n",
            "Epoch 266/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 1.0919\n",
            "Epoch 267/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 1.0803\n",
            "Epoch 268/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 1.0865\n",
            "Epoch 269/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 1.1196\n",
            "Epoch 270/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 1.0795\n",
            "Epoch 271/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 1.1024\n",
            "Epoch 272/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 1.0666\n",
            "Epoch 273/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 1.0989\n",
            "Epoch 274/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 1.1164\n",
            "Epoch 275/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 1.0925\n",
            "Epoch 276/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 1.0803\n",
            "Epoch 277/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 1.1194\n",
            "Epoch 278/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 1.0800\n",
            "Epoch 279/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 1.1168\n",
            "Epoch 280/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 1.0975\n",
            "Epoch 281/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 1.1161\n",
            "Epoch 282/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 1.0995\n",
            "Epoch 283/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 1.1159\n",
            "Epoch 284/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 1.0898\n",
            "Epoch 285/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 1.0632\n",
            "Epoch 286/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 1.1365\n",
            "Epoch 287/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 1.0815\n",
            "Epoch 288/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 1.1517\n",
            "Epoch 289/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 1.0615\n",
            "Epoch 290/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 1.1403\n",
            "Epoch 291/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 1.1252\n",
            "Epoch 292/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 1.1040\n",
            "Epoch 293/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 1.1371\n",
            "Epoch 294/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 1.1374\n",
            "Epoch 295/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 1.1498\n",
            "Epoch 296/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 1.1326\n",
            "Epoch 297/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 1.1206\n",
            "Epoch 298/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 1.1312\n",
            "Epoch 299/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 1.1319\n",
            "Epoch 300/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 1.1222\n",
            "Epoch 301/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 1.1386\n",
            "Epoch 302/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 1.1090\n",
            "Epoch 303/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 1.1403\n",
            "Epoch 304/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 1.1320\n",
            "Epoch 305/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 1.1624\n",
            "Epoch 306/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 1.1225\n",
            "Epoch 307/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 1.1307\n",
            "Epoch 308/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 1.1072\n",
            "Epoch 309/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 1.1437\n",
            "Epoch 310/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 1.1237\n",
            "Epoch 311/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 1.1166\n",
            "Epoch 312/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 1.1432\n",
            "Epoch 313/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 1.1119\n",
            "Epoch 314/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 1.1069\n",
            "Epoch 315/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 1.1272\n",
            "Epoch 316/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 1.1039\n",
            "Epoch 317/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 1.1226\n",
            "Epoch 318/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 1.1168\n",
            "Epoch 319/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 1.1172\n",
            "Epoch 320/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 1.1069\n",
            "Epoch 321/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 1.1235\n",
            "Epoch 322/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 1.1264\n",
            "Epoch 323/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 1.1233\n",
            "Epoch 324/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 1.1290\n",
            "Epoch 325/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 1.1520\n",
            "Epoch 326/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 1.1462\n",
            "Epoch 327/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 1.1486\n",
            "Epoch 328/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 1.1097\n",
            "Epoch 329/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 1.1208\n",
            "Epoch 330/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 1.1713\n",
            "Epoch 331/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 1.1475\n",
            "Epoch 332/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 1.1530\n",
            "Epoch 333/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 1.1535\n",
            "Epoch 334/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 1.1827\n",
            "Epoch 335/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 1.1234\n",
            "Epoch 336/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 1.1781\n",
            "Epoch 337/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 1.1266\n",
            "Epoch 338/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 1.1609\n",
            "Epoch 339/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 1.1576\n",
            "Epoch 340/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 1.1436\n",
            "Epoch 341/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 1.1228\n",
            "Epoch 342/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 1.1625\n",
            "Epoch 343/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 1.1506\n",
            "Epoch 344/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 1.1434\n",
            "Epoch 345/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 1.1589\n",
            "Epoch 346/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 1.1446\n",
            "Epoch 347/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 1.1496\n",
            "Epoch 348/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 1.1369\n",
            "Epoch 349/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 1.1833\n",
            "Epoch 350/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 1.1452\n",
            "Epoch 351/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 1.1748\n",
            "Epoch 352/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 1.1655\n",
            "Epoch 353/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 1.1380\n",
            "Epoch 354/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 1.1587\n",
            "Epoch 355/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 1.1623\n",
            "Epoch 356/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 1.1728\n",
            "Epoch 357/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 1.1693\n",
            "Epoch 358/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 1.1788\n",
            "Epoch 359/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 1.1833\n",
            "Epoch 360/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 1.1985\n",
            "Epoch 361/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 1.1582\n",
            "Epoch 362/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 1.1686\n",
            "Epoch 363/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 1.1471\n",
            "Epoch 364/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 1.1818\n",
            "Epoch 365/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 1.1808\n",
            "Epoch 366/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 1.1849\n",
            "Epoch 367/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 1.1642\n",
            "Epoch 368/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 1.1663\n",
            "Epoch 369/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 1.1340\n",
            "Epoch 370/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 1.1356\n",
            "Epoch 371/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 1.1586\n",
            "Epoch 372/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 1.1983\n",
            "Epoch 373/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 1.1702\n",
            "Epoch 374/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 1.1541\n",
            "Epoch 375/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 1.1744\n",
            "Epoch 376/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 1.1725\n",
            "Epoch 377/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 1.1576\n",
            "Epoch 378/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 1.1761\n",
            "Epoch 379/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 1.1899\n",
            "Epoch 380/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 1.1905\n",
            "Epoch 381/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 1.1621\n",
            "Epoch 382/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 1.2006\n",
            "Epoch 383/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 1.1623\n",
            "Epoch 384/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 1.1824\n",
            "Epoch 385/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 1.1523\n",
            "Epoch 386/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 1.1756\n",
            "Epoch 387/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 1.1607\n",
            "Epoch 388/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 1.1704\n",
            "Epoch 389/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 1.1931\n",
            "Epoch 390/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 1.1626\n",
            "Epoch 391/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 1.1753\n",
            "Epoch 392/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 1.1721\n",
            "Epoch 393/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 1.1631\n",
            "Epoch 394/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 1.2280\n",
            "Epoch 395/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 1.1796\n",
            "Epoch 396/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 1.1821\n",
            "Epoch 397/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 1.1693\n",
            "Epoch 398/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 1.2150\n",
            "Epoch 399/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 1.2008\n",
            "Epoch 400/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 1.1789\n",
            "Epoch 401/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 1.1920\n",
            "Epoch 402/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 1.2056\n",
            "Epoch 403/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 1.1760\n",
            "Epoch 404/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 1.1856\n",
            "Epoch 405/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 1.2085\n",
            "Epoch 406/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 1.1847\n",
            "Epoch 407/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 1.2055\n",
            "Epoch 408/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 1.1700\n",
            "Epoch 409/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 1.2062\n",
            "Epoch 410/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 1.2057\n",
            "Epoch 411/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 1.2267\n",
            "Epoch 412/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 1.1802\n",
            "Epoch 413/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 1.2086\n",
            "Epoch 414/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 1.1895\n",
            "Epoch 415/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 1.2174\n",
            "Epoch 416/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 1.1864\n",
            "Epoch 417/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 1.1927\n",
            "Epoch 418/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 1.1886\n",
            "Epoch 419/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 1.1904\n",
            "Epoch 420/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 1.2000\n",
            "Epoch 421/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 1.1794\n",
            "Epoch 422/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 1.1730\n",
            "Epoch 423/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 1.1693\n",
            "Epoch 424/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 1.1808\n",
            "Epoch 425/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 1.1999\n",
            "Epoch 426/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 1.1946\n",
            "Epoch 427/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 1.1952\n",
            "Epoch 428/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 1.2031\n",
            "Epoch 429/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 1.1881\n",
            "Epoch 430/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 1.1887\n",
            "Epoch 431/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 1.2236\n",
            "Epoch 432/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 1.1834\n",
            "Epoch 433/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 1.2211\n",
            "Epoch 434/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 1.1927\n",
            "Epoch 435/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 1.2081\n",
            "Epoch 436/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 1.2091\n",
            "Epoch 437/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 1.1944\n",
            "Epoch 438/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 1.2107\n",
            "Epoch 439/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 1.1799\n",
            "Epoch 440/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 1.2305\n",
            "Epoch 441/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 1.2071\n",
            "Epoch 442/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 1.1921\n",
            "Epoch 443/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 1.1917\n",
            "Epoch 444/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 1.2276\n",
            "Epoch 445/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 1.2195\n",
            "Epoch 446/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 1.2175\n",
            "Epoch 447/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 1.2025\n",
            "Epoch 448/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 1.2227\n",
            "Epoch 449/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 1.1929\n",
            "Epoch 450/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 1.2311\n",
            "Epoch 451/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 1.2248\n",
            "Epoch 452/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 1.2042\n",
            "Epoch 453/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 1.1953\n",
            "Epoch 454/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 1.1949\n",
            "Epoch 455/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 1.1946\n",
            "Epoch 456/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 1.2130\n",
            "Epoch 457/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 1.2450\n",
            "Epoch 458/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 1.2199\n",
            "Epoch 459/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 1.2484\n",
            "Epoch 460/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 1.2257\n",
            "Epoch 461/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 1.2330\n",
            "Epoch 462/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 1.2137\n",
            "Epoch 463/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 1.2161\n",
            "Epoch 464/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 1.2096\n",
            "Epoch 465/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 1.2411\n",
            "Epoch 466/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 1.2340\n",
            "Epoch 467/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 1.1757\n",
            "Epoch 468/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 1.2408\n",
            "Epoch 469/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 1.2277\n",
            "Epoch 470/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 1.2285\n",
            "Epoch 471/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 1.2430\n",
            "Epoch 472/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 1.2012\n",
            "Epoch 473/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 1.2389\n",
            "Epoch 474/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 1.2213\n",
            "Epoch 475/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 1.1907\n",
            "Epoch 476/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 1.2200\n",
            "Epoch 477/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 1.2242\n",
            "Epoch 478/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 1.1937\n",
            "Epoch 479/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 1.2740\n",
            "Epoch 480/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 1.2120\n",
            "Epoch 481/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 1.2382\n",
            "Epoch 482/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 1.2621\n",
            "Epoch 483/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 1.2252\n",
            "Epoch 484/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 1.2461\n",
            "Epoch 485/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 1.2666\n",
            "Epoch 486/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 1.2314\n",
            "Epoch 487/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 1.2475\n",
            "Epoch 488/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 1.2452\n",
            "Epoch 489/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 1.2065\n",
            "Epoch 490/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 1.2392\n",
            "Epoch 491/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 1.2215\n",
            "Epoch 492/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 1.2518\n",
            "Epoch 493/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 1.2184\n",
            "Epoch 494/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 1.2296\n",
            "Epoch 495/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 1.2280\n",
            "Epoch 496/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 1.2502\n",
            "Epoch 497/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 1.2194\n",
            "Epoch 498/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 1.2559\n",
            "Epoch 499/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 1.1922\n",
            "Epoch 500/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 1.2356\n",
            "Epoch 501/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 1.2418\n",
            "Epoch 502/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 1.2275\n",
            "Epoch 503/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 1.2366\n",
            "Epoch 504/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 1.2127\n",
            "Epoch 505/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 1.2240\n",
            "Epoch 506/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 1.2503\n",
            "Epoch 507/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 1.2138\n",
            "Epoch 508/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 1.2508\n",
            "Epoch 509/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 1.2493\n",
            "Epoch 510/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 1.2253\n",
            "Epoch 511/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 1.2305\n",
            "Epoch 512/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 1.2040\n",
            "Epoch 513/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 1.2286\n",
            "Epoch 514/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 1.1957\n",
            "Epoch 515/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 1.2252\n",
            "Epoch 516/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 1.2383\n",
            "Epoch 517/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 1.2408\n",
            "Epoch 518/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 1.2443\n",
            "Epoch 519/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 1.2370\n",
            "Epoch 520/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 1.2610\n",
            "Epoch 521/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 1.2233\n",
            "Epoch 522/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 1.2394\n",
            "Epoch 523/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 1.2165\n",
            "Epoch 524/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 1.2328\n",
            "Epoch 525/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 1.2173\n",
            "Epoch 526/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 1.2290\n",
            "Epoch 527/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 1.2375\n",
            "Epoch 528/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 1.2160\n",
            "Epoch 529/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 1.2734\n",
            "Epoch 530/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 1.2233\n",
            "Epoch 531/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 1.1870\n",
            "Epoch 532/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 1.2237\n",
            "Epoch 533/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 1.2120\n",
            "Epoch 534/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 1.2515\n",
            "Epoch 535/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 1.2241\n",
            "Epoch 536/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 1.2290\n",
            "Epoch 537/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 1.2481\n",
            "Epoch 538/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 1.2395\n",
            "Epoch 539/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 1.2255\n",
            "Epoch 540/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 1.2139\n",
            "Epoch 541/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 1.2090\n",
            "Epoch 542/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 1.2069\n",
            "Epoch 543/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 1.2730\n",
            "Epoch 544/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 1.2234\n",
            "Epoch 545/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 1.2280\n",
            "Epoch 546/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 1.2308\n",
            "Epoch 547/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 1.2191\n",
            "Epoch 548/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 1.2233\n",
            "Epoch 549/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 1.2542\n",
            "Epoch 550/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 1.1898\n",
            "Epoch 551/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 1.2327\n",
            "Epoch 552/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 1.2359\n",
            "Epoch 553/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 1.2457\n",
            "Epoch 554/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 1.2323\n",
            "Epoch 555/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 1.2440\n",
            "Epoch 556/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 1.2309\n",
            "Epoch 557/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 1.2258\n",
            "Epoch 558/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 1.2548\n",
            "Epoch 559/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 1.2506\n",
            "Epoch 560/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 1.2410\n",
            "Epoch 561/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 1.2518\n",
            "Epoch 562/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 1.2364\n",
            "Epoch 563/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 1.2176\n",
            "Epoch 564/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 1.2257\n",
            "Epoch 565/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 1.2421\n",
            "Epoch 566/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 1.2354\n",
            "Epoch 567/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 1.2610\n",
            "Epoch 568/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 1.2240\n",
            "Epoch 569/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 1.2581\n",
            "Epoch 570/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 1.2304\n",
            "Epoch 571/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 1.2543\n",
            "Epoch 572/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 1.2584\n",
            "Epoch 573/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 1.2515\n",
            "Epoch 574/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 1.2135\n",
            "Epoch 575/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 1.3036\n",
            "Epoch 576/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 1.2629\n",
            "Epoch 577/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 1.2277\n",
            "Epoch 578/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 1.2299\n",
            "Epoch 579/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 1.2522\n",
            "Epoch 580/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 1.2402\n",
            "Epoch 581/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 1.2512\n",
            "Epoch 582/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 1.2601\n",
            "Epoch 583/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 1.2719\n",
            "Epoch 584/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 1.2425\n",
            "Epoch 585/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 1.2361\n",
            "Epoch 586/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 1.2525\n",
            "Epoch 587/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 1.2394\n",
            "Epoch 588/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 1.2719\n",
            "Epoch 589/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 1.2422\n",
            "Epoch 590/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 1.2300\n",
            "Epoch 591/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 1.2670\n",
            "Epoch 592/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 1.2212\n",
            "Epoch 593/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 1.2642\n",
            "Epoch 594/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 1.2065\n",
            "Epoch 595/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 1.2141\n",
            "Epoch 596/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 1.2384\n",
            "Epoch 597/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 1.2312\n",
            "Epoch 598/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 1.2569\n",
            "Epoch 599/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 1.2267\n",
            "Epoch 600/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 1.2514\n",
            "Epoch 601/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 1.2697\n",
            "Epoch 602/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 1.2195\n",
            "Epoch 603/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 1.2397\n",
            "Epoch 604/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2339\n",
            "Epoch 605/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 1.2347\n",
            "Epoch 606/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 1.2465\n",
            "Epoch 607/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 1.2401\n",
            "Epoch 608/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 1.2767\n",
            "Epoch 609/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 1.2385\n",
            "Epoch 610/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 1.2615\n",
            "Epoch 611/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 1.2871\n",
            "Epoch 612/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 1.2326\n",
            "Epoch 613/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 1.2325\n",
            "Epoch 614/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 1.2214\n",
            "Epoch 615/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 1.2440\n",
            "Epoch 616/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 1.2530\n",
            "Epoch 617/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 1.2205\n",
            "Epoch 618/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 1.2775\n",
            "Epoch 619/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 1.2347\n",
            "Epoch 620/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 1.2384\n",
            "Epoch 621/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 1.2487\n",
            "Epoch 622/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 1.2575\n",
            "Epoch 623/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 1.2211\n",
            "Epoch 624/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 1.2334\n",
            "Epoch 625/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2417\n",
            "Epoch 626/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 1.2513\n",
            "Epoch 627/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 1.2309\n",
            "Epoch 628/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2378\n",
            "Epoch 629/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 1.2144\n",
            "Epoch 630/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 1.2489\n",
            "Epoch 631/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 1.2226\n",
            "Epoch 632/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 1.2736\n",
            "Epoch 633/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 1.2411\n",
            "Epoch 634/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 1.2628\n",
            "Epoch 635/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 1.2565\n",
            "Epoch 636/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 1.2914\n",
            "Epoch 637/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 1.2113\n",
            "Epoch 638/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2819\n",
            "Epoch 639/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 1.2121\n",
            "Epoch 640/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 1.2479\n",
            "Epoch 641/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2692\n",
            "Epoch 642/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 1.2606\n",
            "Epoch 643/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 1.2294\n",
            "Epoch 644/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2670\n",
            "Epoch 645/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 1.2127\n",
            "Epoch 646/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 1.2358\n",
            "Epoch 647/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 1.2401\n",
            "Epoch 648/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 1.2485\n",
            "Epoch 649/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 1.2846\n",
            "Epoch 650/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 1.2656\n",
            "Epoch 651/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 1.2532\n",
            "Epoch 652/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 1.2478\n",
            "Epoch 653/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2440\n",
            "Epoch 654/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 1.2524\n",
            "Epoch 655/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 1.2412\n",
            "Epoch 656/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 1.2281\n",
            "Epoch 657/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2234\n",
            "Epoch 658/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2657\n",
            "Epoch 659/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 1.2452\n",
            "Epoch 660/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 1.2579\n",
            "Epoch 661/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2299\n",
            "Epoch 662/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 1.2565\n",
            "Epoch 663/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 1.2624\n",
            "Epoch 664/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 1.2544\n",
            "Epoch 665/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 1.2651\n",
            "Epoch 666/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 1.2584\n",
            "Epoch 667/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 1.2376\n",
            "Epoch 668/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 1.2408\n",
            "Epoch 669/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 1.2606\n",
            "Epoch 670/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2158\n",
            "Epoch 671/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 1.2711\n",
            "Epoch 672/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 1.2217\n",
            "Epoch 673/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 1.2617\n",
            "Epoch 674/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2362\n",
            "Epoch 675/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 1.2790\n",
            "Epoch 676/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 1.2642\n",
            "Epoch 677/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 1.2456\n",
            "Epoch 678/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 1.2572\n",
            "Epoch 679/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 1.2574\n",
            "Epoch 680/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 1.2622\n",
            "Epoch 681/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 1.2388\n",
            "Epoch 682/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 1.2570\n",
            "Epoch 683/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 1.2925\n",
            "Epoch 684/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 1.2431\n",
            "Epoch 685/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 1.2803\n",
            "Epoch 686/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2944\n",
            "Epoch 687/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 1.2634\n",
            "Epoch 688/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 1.2857\n",
            "Epoch 689/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 1.2620\n",
            "Epoch 690/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 1.2483\n",
            "Epoch 691/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 1.2570\n",
            "Epoch 692/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 1.2510\n",
            "Epoch 693/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 1.2880\n",
            "Epoch 694/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 1.2598\n",
            "Epoch 695/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2577\n",
            "Epoch 696/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 1.2786\n",
            "Epoch 697/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 1.2612\n",
            "Epoch 698/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 1.2394\n",
            "Epoch 699/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 1.2646\n",
            "Epoch 700/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 1.2495\n",
            "Epoch 701/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 1.3038\n",
            "Epoch 702/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2464\n",
            "Epoch 703/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 1.2798\n",
            "Epoch 704/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 1.2624\n",
            "Epoch 705/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 1.2409\n",
            "Epoch 706/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2677\n",
            "Epoch 707/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 1.2595\n",
            "Epoch 708/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2585\n",
            "Epoch 709/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2759\n",
            "Epoch 710/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 1.2563\n",
            "Epoch 711/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2582\n",
            "Epoch 712/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 1.2719\n",
            "Epoch 713/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 1.2360\n",
            "Epoch 714/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 1.2771\n",
            "Epoch 715/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 1.2443\n",
            "Epoch 716/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 1.2572\n",
            "Epoch 717/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 1.2545\n",
            "Epoch 718/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2594\n",
            "Epoch 719/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 1.2703\n",
            "Epoch 720/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2619\n",
            "Epoch 721/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 1.2656\n",
            "Epoch 722/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 1.2150\n",
            "Epoch 723/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 1.2515\n",
            "Epoch 724/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2652\n",
            "Epoch 725/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 1.2730\n",
            "Epoch 726/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2687\n",
            "Epoch 727/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 1.2364\n",
            "Epoch 728/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2774\n",
            "Epoch 729/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2810\n",
            "Epoch 730/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 1.2410\n",
            "Epoch 731/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 1.2606\n",
            "Epoch 732/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2405\n",
            "Epoch 733/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 1.2524\n",
            "Epoch 734/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 1.2362\n",
            "Epoch 735/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 1.2988\n",
            "Epoch 736/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2157\n",
            "Epoch 737/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 1.2795\n",
            "Epoch 738/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 1.2408\n",
            "Epoch 739/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.2931\n",
            "Epoch 740/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 1.2635\n",
            "Epoch 741/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2459\n",
            "Epoch 742/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 1.2995\n",
            "Epoch 743/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 1.2540\n",
            "Epoch 744/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.2663\n",
            "Epoch 745/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 1.2585\n",
            "Epoch 746/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2604\n",
            "Epoch 747/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 1.2721\n",
            "Epoch 748/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 1.2496\n",
            "Epoch 749/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 1.2456\n",
            "Epoch 750/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 1.2194\n",
            "Epoch 751/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 1.2716\n",
            "Epoch 752/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 1.2676\n",
            "Epoch 753/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 1.2406\n",
            "Epoch 754/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2636\n",
            "Epoch 755/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 1.2474\n",
            "Epoch 756/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2398\n",
            "Epoch 757/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 1.2743\n",
            "Epoch 758/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 1.2464\n",
            "Epoch 759/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 1.2518\n",
            "Epoch 760/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 1.2398\n",
            "Epoch 761/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2558\n",
            "Epoch 762/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2638\n",
            "Epoch 763/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2450\n",
            "Epoch 764/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 1.2459\n",
            "Epoch 765/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 1.2445\n",
            "Epoch 766/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 1.2655\n",
            "Epoch 767/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 1.2700\n",
            "Epoch 768/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 1.2487\n",
            "Epoch 769/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 1.2368\n",
            "Epoch 770/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.2404\n",
            "Epoch 771/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2597\n",
            "Epoch 772/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2549\n",
            "Epoch 773/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 1.2201\n",
            "Epoch 774/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 1.2730\n",
            "Epoch 775/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 1.2516\n",
            "Epoch 776/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2791\n",
            "Epoch 777/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.2324\n",
            "Epoch 778/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 1.2519\n",
            "Epoch 779/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2375\n",
            "Epoch 780/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2559\n",
            "Epoch 781/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2492\n",
            "Epoch 782/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 1.2281\n",
            "Epoch 783/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2777\n",
            "Epoch 784/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 1.2243\n",
            "Epoch 785/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 1.2762\n",
            "Epoch 786/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 1.2481\n",
            "Epoch 787/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 1.2841\n",
            "Epoch 788/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 1.2454\n",
            "Epoch 789/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 1.2483\n",
            "Epoch 790/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 1.2515\n",
            "Epoch 791/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.2247\n",
            "Epoch 792/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2380\n",
            "Epoch 793/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2312\n",
            "Epoch 794/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 1.2655\n",
            "Epoch 795/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 1.2612\n",
            "Epoch 796/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 1.2393\n",
            "Epoch 797/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 1.2117\n",
            "Epoch 798/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.2680\n",
            "Epoch 799/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2619\n",
            "Epoch 800/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 1.2658\n",
            "Epoch 801/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2571\n",
            "Epoch 802/1000\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 1.2551\n",
            "Epoch 803/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 1.2321\n",
            "Epoch 804/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.2654\n",
            "Epoch 805/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2629\n",
            "Epoch 806/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 1.2653\n",
            "Epoch 807/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2321\n",
            "Epoch 808/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 1.2598\n",
            "Epoch 809/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 1.2161\n",
            "Epoch 810/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 1.2232\n",
            "Epoch 811/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2217\n",
            "Epoch 812/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 1.2586\n",
            "Epoch 813/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 1.2647\n",
            "Epoch 814/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 1.2192\n",
            "Epoch 815/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.2818\n",
            "Epoch 816/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 1.2434\n",
            "Epoch 817/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 1.2284\n",
            "Epoch 818/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2288\n",
            "Epoch 819/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 1.2629\n",
            "Epoch 820/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 1.2629\n",
            "Epoch 821/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 1.2333\n",
            "Epoch 822/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 1.2727\n",
            "Epoch 823/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 1.2535\n",
            "Epoch 824/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 1.2572\n",
            "Epoch 825/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 1.2626\n",
            "Epoch 826/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 1.2470\n",
            "Epoch 827/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2485\n",
            "Epoch 828/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 1.2172\n",
            "Epoch 829/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2600\n",
            "Epoch 830/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 1.2582\n",
            "Epoch 831/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 1.2347\n",
            "Epoch 832/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2410\n",
            "Epoch 833/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 1.2774\n",
            "Epoch 834/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 1.2275\n",
            "Epoch 835/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 1.2692\n",
            "Epoch 836/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 1.2663\n",
            "Epoch 837/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 1.2794\n",
            "Epoch 838/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 1.2566\n",
            "Epoch 839/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 1.2709\n",
            "Epoch 840/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2777\n",
            "Epoch 841/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 1.2607\n",
            "Epoch 842/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 1.2806\n",
            "Epoch 843/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 1.2726\n",
            "Epoch 844/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 1.2479\n",
            "Epoch 845/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 1.2432\n",
            "Epoch 846/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2084\n",
            "Epoch 847/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 1.2631\n",
            "Epoch 848/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2354\n",
            "Epoch 849/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 1.2646\n",
            "Epoch 850/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 1.2375\n",
            "Epoch 851/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 1.2900\n",
            "Epoch 852/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2307\n",
            "Epoch 853/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 1.3124\n",
            "Epoch 854/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2392\n",
            "Epoch 855/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 1.2664\n",
            "Epoch 856/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2684\n",
            "Epoch 857/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 1.2635\n",
            "Epoch 858/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 1.2643\n",
            "Epoch 859/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2721\n",
            "Epoch 860/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2708\n",
            "Epoch 861/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 1.2938\n",
            "Epoch 862/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2653\n",
            "Epoch 863/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 1.3112\n",
            "Epoch 864/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2474\n",
            "Epoch 865/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 1.2713\n",
            "Epoch 866/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 1.2764\n",
            "Epoch 867/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 1.2353\n",
            "Epoch 868/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 1.2620\n",
            "Epoch 869/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 1.2543\n",
            "Epoch 870/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2976\n",
            "Epoch 871/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 1.2460\n",
            "Epoch 872/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 1.2831\n",
            "Epoch 873/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.2715\n",
            "Epoch 874/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.3001\n",
            "Epoch 875/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2593\n",
            "Epoch 876/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 1.2631\n",
            "Epoch 877/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2736\n",
            "Epoch 878/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 1.2857\n",
            "Epoch 879/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 1.2835\n",
            "Epoch 880/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2533\n",
            "Epoch 881/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 1.2807\n",
            "Epoch 882/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 1.2172\n",
            "Epoch 883/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2628\n",
            "Epoch 884/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 1.2483\n",
            "Epoch 885/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 1.2875\n",
            "Epoch 886/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 1.2594\n",
            "Epoch 887/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 1.2929\n",
            "Epoch 888/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 1.2612\n",
            "Epoch 889/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 1.2609\n",
            "Epoch 890/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 1.2662\n",
            "Epoch 891/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2752\n",
            "Epoch 892/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 1.2695\n",
            "Epoch 893/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2422\n",
            "Epoch 894/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 1.2662\n",
            "Epoch 895/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.2882\n",
            "Epoch 896/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 1.2738\n",
            "Epoch 897/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 1.2447\n",
            "Epoch 898/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 1.2766\n",
            "Epoch 899/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 1.2353\n",
            "Epoch 900/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2710\n",
            "Epoch 901/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 1.2457\n",
            "Epoch 902/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 1.2737\n",
            "Epoch 903/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2517\n",
            "Epoch 904/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 1.2685\n",
            "Epoch 905/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 1.2355\n",
            "Epoch 906/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 1.2575\n",
            "Epoch 907/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 1.2999\n",
            "Epoch 908/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 1.2353\n",
            "Epoch 909/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 1.2678\n",
            "Epoch 910/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 1.2540\n",
            "Epoch 911/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 1.2504\n",
            "Epoch 912/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 1.2602\n",
            "Epoch 913/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 1.2939\n",
            "Epoch 914/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 1.2594\n",
            "Epoch 915/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 1.2561\n",
            "Epoch 916/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 1.2679\n",
            "Epoch 917/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 1.2352\n",
            "Epoch 918/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 1.2654\n",
            "Epoch 919/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 1.2452\n",
            "Epoch 920/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 1.2653\n",
            "Epoch 921/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.2522\n",
            "Epoch 922/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.2829\n",
            "Epoch 923/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 1.2431\n",
            "Epoch 924/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 1.2616\n",
            "Epoch 925/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 1.2601\n",
            "Epoch 926/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 1.2792\n",
            "Epoch 927/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 1.2476\n",
            "Epoch 928/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 1.2728\n",
            "Epoch 929/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 1.2870\n",
            "Epoch 930/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 1.2707\n",
            "Epoch 931/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 1.2489\n",
            "Epoch 932/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 1.2911\n",
            "Epoch 933/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2571\n",
            "Epoch 934/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.3037\n",
            "Epoch 935/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 1.2791\n",
            "Epoch 936/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 1.2760\n",
            "Epoch 937/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 1.2994\n",
            "Epoch 938/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 1.2779\n",
            "Epoch 939/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 1.2571\n",
            "Epoch 940/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.2569\n",
            "Epoch 941/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 1.3123\n",
            "Epoch 942/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 1.2611\n",
            "Epoch 943/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 1.3145\n",
            "Epoch 944/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 1.2607\n",
            "Epoch 945/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 1.3075\n",
            "Epoch 946/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 1.2673\n",
            "Epoch 947/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 1.3063\n",
            "Epoch 948/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 1.2853\n",
            "Epoch 949/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 1.2780\n",
            "Epoch 950/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 1.2665\n",
            "Epoch 951/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 1.2531\n",
            "Epoch 952/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 1.2725\n",
            "Epoch 953/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2589\n",
            "Epoch 954/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 1.2979\n",
            "Epoch 955/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2540\n",
            "Epoch 956/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 1.2885\n",
            "Epoch 957/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.2650\n",
            "Epoch 958/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 1.2635\n",
            "Epoch 959/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 1.2502\n",
            "Epoch 960/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 1.2796\n",
            "Epoch 961/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 1.2533\n",
            "Epoch 962/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 1.2857\n",
            "Epoch 963/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 1.2649\n",
            "Epoch 964/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 1.2599\n",
            "Epoch 965/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 1.2780\n",
            "Epoch 966/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 1.2776\n",
            "Epoch 967/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 1.2914\n",
            "Epoch 968/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 1.2657\n",
            "Epoch 969/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 1.2603\n",
            "Epoch 970/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 1.2877\n",
            "Epoch 971/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 1.2572\n",
            "Epoch 972/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 1.2890\n",
            "Epoch 973/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 1.3130\n",
            "Epoch 974/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2579\n",
            "Epoch 975/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2888\n",
            "Epoch 976/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2746\n",
            "Epoch 977/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 1.2820\n",
            "Epoch 978/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 1.2790\n",
            "Epoch 979/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 1.2572\n",
            "Epoch 980/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 1.2565\n",
            "Epoch 981/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 1.2895\n",
            "Epoch 982/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 1.2914\n",
            "Epoch 983/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 1.2777\n",
            "Epoch 984/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 1.2865\n",
            "Epoch 985/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 1.2991\n",
            "Epoch 986/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 1.2601\n",
            "Epoch 987/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 1.2801\n",
            "Epoch 988/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 1.2371\n",
            "Epoch 989/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 1.2840\n",
            "Epoch 990/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 1.2671\n",
            "Epoch 991/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 1.2771\n",
            "Epoch 992/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 1.2512\n",
            "Epoch 993/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 1.2410\n",
            "Epoch 994/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 1.2633\n",
            "Epoch 995/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 1.2601\n",
            "Epoch 996/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 1.2215\n",
            "Epoch 997/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 1.2740\n",
            "Epoch 998/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 1.2758\n",
            "Epoch 999/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 1.3019\n",
            "Epoch 1000/1000\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 1.2558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1IV0hlRCeh3"
      },
      "source": [
        "Nilai terbaik yang didapat adalah menggunakan optimizer SGD dengan val_loss sebesar 0.29 dan loss 0.22 pada epoch ke 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_nmcDu1txND"
      },
      "source": [
        "#Nomor 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaaL4yIBt_ey"
      },
      "source": [
        "3. Lakukan prediksi terhadap dataset `titanic_train.csv` dan `titanic_eval.csv`. Gunakan file `titanic_train.csv` untuk training dan `titanic_eval.csv` sebagai validation set!\n",
        "\n",
        "  - Hasil prediksi dapat ditemui di kolom *survived*.\n",
        "  - Penjelasan dataset: https://www.kaggle.com/c/titanic/data?select=train.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHQCEKKBJ9ji"
      },
      "source": [
        "##Data Cleaning and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4waI3TDJ8d2"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntV0eHlGKDZP",
        "outputId": "b8dcf428-812c-414a-a2ba-8f603196b31f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "dataset3_train = pd.read_csv('/content/drive/My Drive/dataset_quiz/titanic_train.csv')\n",
        "dataset3_test = pd.read_csv('/content/drive/My Drive/dataset_quiz/titanic_eval.csv')\n",
        "dataset3_train.head()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>class</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Queenstown</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived     sex   age  ...     deck  embark_town  alone\n",
              "0         0    male  22.0  ...  unknown  Southampton      n\n",
              "1         1  female  38.0  ...        C    Cherbourg      n\n",
              "2         1  female  26.0  ...  unknown  Southampton      y\n",
              "3         1  female  35.0  ...        C  Southampton      n\n",
              "4         0    male  28.0  ...  unknown   Queenstown      y\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVY_xVemKSvT",
        "outputId": "3921c37b-0d0b-40df-8dc0-7e531aadd7d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "dataset3_train.replace(\"?\", np.nan, inplace=True)\n",
        "dataset3_train.head()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>class</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Queenstown</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived     sex   age  ...     deck  embark_town  alone\n",
              "0         0    male  22.0  ...  unknown  Southampton      n\n",
              "1         1  female  38.0  ...        C    Cherbourg      n\n",
              "2         1  female  26.0  ...  unknown  Southampton      y\n",
              "3         1  female  35.0  ...        C  Southampton      n\n",
              "4         0    male  28.0  ...  unknown   Queenstown      y\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3lxKpvLKmR2",
        "outputId": "c67ea59b-ffdc-48c6-d4d8-bfe6acb4841a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "dataset3_train.head()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>class</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Queenstown</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived     sex   age  ...     deck  embark_town  alone\n",
              "0         0    male  22.0  ...  unknown  Southampton      n\n",
              "1         1  female  38.0  ...        C    Cherbourg      n\n",
              "2         1  female  26.0  ...  unknown  Southampton      y\n",
              "3         1  female  35.0  ...        C  Southampton      n\n",
              "4         0    male  28.0  ...  unknown   Queenstown      y\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwNVzoX0LM_i",
        "outputId": "6a5bf75d-c09d-4414-da28-e85ca128b879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "dataset3_train.info()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 627 entries, 0 to 626\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   survived            627 non-null    int64  \n",
            " 1   sex                 627 non-null    object \n",
            " 2   age                 627 non-null    float64\n",
            " 3   n_siblings_spouses  627 non-null    int64  \n",
            " 4   parch               627 non-null    int64  \n",
            " 5   fare                627 non-null    float64\n",
            " 6   class               627 non-null    object \n",
            " 7   deck                627 non-null    object \n",
            " 8   embark_town         627 non-null    object \n",
            " 9   alone               627 non-null    object \n",
            "dtypes: float64(2), int64(3), object(5)\n",
            "memory usage: 49.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLZlYcX5McQ6"
      },
      "source": [
        "cleanup_data = {'sex':{'male': 1,'female' : 0},'alone':{'y':1,'n':0}}\n",
        "\n",
        "dataset3_train.replace(cleanup_data, inplace=True)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dcsut8laNUmO"
      },
      "source": [
        "dataset3_test.replace(cleanup_data, inplace=True)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxzNDzAuNhKN",
        "outputId": "d544e441-6f89-4d07-e2c7-632ff55c35e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "dataset3_train.head()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>class</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Cherbourg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Queenstown</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived  sex   age  n_siblings_spouses  ...  class     deck  embark_town alone\n",
              "0         0    1  22.0                   1  ...  Third  unknown  Southampton     0\n",
              "1         1    0  38.0                   1  ...  First        C    Cherbourg     0\n",
              "2         1    0  26.0                   0  ...  Third  unknown  Southampton     1\n",
              "3         1    0  35.0                   1  ...  First        C  Southampton     0\n",
              "4         0    1  28.0                   0  ...  Third  unknown   Queenstown     1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjc2mzuOMMVG",
        "outputId": "7e39f91a-23ae-480d-9a31-dc8d8288a383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "dataset3_test.head()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>class</th>\n",
              "      <th>deck</th>\n",
              "      <th>embark_town</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>Third</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>First</td>\n",
              "      <td>E</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>First</td>\n",
              "      <td>C</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0000</td>\n",
              "      <td>Second</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>Second</td>\n",
              "      <td>D</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived  sex   age  n_siblings_spouses  ...   class     deck  embark_town alone\n",
              "0         0    1  35.0                   0  ...   Third  unknown  Southampton     1\n",
              "1         0    1  54.0                   0  ...   First        E  Southampton     1\n",
              "2         1    0  58.0                   0  ...   First        C  Southampton     1\n",
              "3         1    0  55.0                   0  ...  Second  unknown  Southampton     1\n",
              "4         1    1  34.0                   0  ...  Second        D  Southampton     1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY803NqmOZyw",
        "outputId": "3fecf822-d37f-4159-d147-b36cb35e19bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "dataset3_train.drop(['deck','embark_town'], axis=1, inplace=True)\n",
        "dataset3_test.drop(['deck','embark_town'], axis=1, inplace=True)\n",
        "dataset3_train.head()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>class</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>Third</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>First</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>Third</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>First</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>Third</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived  sex   age  n_siblings_spouses  parch     fare  class  alone\n",
              "0         0    1  22.0                   1      0   7.2500  Third      0\n",
              "1         1    0  38.0                   1      0  71.2833  First      0\n",
              "2         1    0  26.0                   0      0   7.9250  Third      1\n",
              "3         1    0  35.0                   1      0  53.1000  First      0\n",
              "4         0    1  28.0                   0      0   8.4583  Third      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c-FxIyqO2jc",
        "outputId": "c507a5c9-d26c-48a6-bc30-6d51660481b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "dataset3_test.head()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>class</th>\n",
              "      <th>alone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>Third</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>First</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>First</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0000</td>\n",
              "      <td>Second</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>Second</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived  sex   age  n_siblings_spouses  parch     fare   class  alone\n",
              "0         0    1  35.0                   0      0   8.0500   Third      1\n",
              "1         0    1  54.0                   0      0  51.8625   First      1\n",
              "2         1    0  58.0                   0      0  26.5500   First      1\n",
              "3         1    0  55.0                   0      0  16.0000  Second      1\n",
              "4         1    1  34.0                   0      0  13.0000  Second      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3JXUrhOO76c",
        "outputId": "10ffa7ab-1975-4dbb-ef9b-2e47cf318c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "dataset3_train.info()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 627 entries, 0 to 626\n",
            "Data columns (total 8 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   survived            627 non-null    int64  \n",
            " 1   sex                 627 non-null    int64  \n",
            " 2   age                 627 non-null    float64\n",
            " 3   n_siblings_spouses  627 non-null    int64  \n",
            " 4   parch               627 non-null    int64  \n",
            " 5   fare                627 non-null    float64\n",
            " 6   class               627 non-null    object \n",
            " 7   alone               627 non-null    int64  \n",
            "dtypes: float64(2), int64(5), object(1)\n",
            "memory usage: 39.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTEk0_g2Pl9L",
        "outputId": "7579feb1-3176-4f69-b356-e1a257b35839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "class_categorized_train = pd.get_dummies(dataset3_train['class'])\n",
        "class_categorized_train"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>First</th>\n",
              "      <th>Second</th>\n",
              "      <th>Third</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>627 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     First  Second  Third\n",
              "0        0       0      1\n",
              "1        1       0      0\n",
              "2        0       0      1\n",
              "3        1       0      0\n",
              "4        0       0      1\n",
              "..     ...     ...    ...\n",
              "622      0       1      0\n",
              "623      0       0      1\n",
              "624      1       0      0\n",
              "625      0       0      1\n",
              "626      0       0      1\n",
              "\n",
              "[627 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3QG65vPNQT",
        "outputId": "0e66b39e-5cf5-485c-9e1b-16f0edc12840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "class_categorized_test = pd.get_dummies(dataset3_test['class'])\n",
        "class_categorized_test"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>First</th>\n",
              "      <th>Second</th>\n",
              "      <th>Third</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>264 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     First  Second  Third\n",
              "0        0       0      1\n",
              "1        1       0      0\n",
              "2        1       0      0\n",
              "3        0       1      0\n",
              "4        0       1      0\n",
              "..     ...     ...    ...\n",
              "259      0       1      0\n",
              "260      0       0      1\n",
              "261      0       0      1\n",
              "262      0       1      0\n",
              "263      1       0      0\n",
              "\n",
              "[264 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khR8w0cTPam_",
        "outputId": "487b5344-1743-48c5-ce4d-25caeaffc6dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "dataset3_train = pd.concat([dataset3_train, class_categorized_train], axis=1)\n",
        "\n",
        "dataset3_train.head()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>class</th>\n",
              "      <th>alone</th>\n",
              "      <th>First</th>\n",
              "      <th>Second</th>\n",
              "      <th>Third</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>Third</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>First</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>Third</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>First</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>Third</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived  sex   age  n_siblings_spouses  ...  alone  First Second  Third\n",
              "0         0    1  22.0                   1  ...      0      0      0      1\n",
              "1         1    0  38.0                   1  ...      0      1      0      0\n",
              "2         1    0  26.0                   0  ...      1      0      0      1\n",
              "3         1    0  35.0                   1  ...      0      1      0      0\n",
              "4         0    1  28.0                   0  ...      1      0      0      1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-FZTC7TQBzs",
        "outputId": "f704b74a-bc42-4b05-91e9-3242559c470e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "dataset3_test = pd.concat([dataset3_test, class_categorized_test], axis=1)\n",
        "\n",
        "dataset3_test.head()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>class</th>\n",
              "      <th>alone</th>\n",
              "      <th>First</th>\n",
              "      <th>Second</th>\n",
              "      <th>Third</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>Third</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>First</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>First</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0000</td>\n",
              "      <td>Second</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>Second</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived  sex   age  n_siblings_spouses  ...  alone  First Second  Third\n",
              "0         0    1  35.0                   0  ...      1      0      0      1\n",
              "1         0    1  54.0                   0  ...      1      1      0      0\n",
              "2         1    0  58.0                   0  ...      1      1      0      0\n",
              "3         1    0  55.0                   0  ...      1      0      1      0\n",
              "4         1    1  34.0                   0  ...      1      0      1      0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6Scq0hcQMVh"
      },
      "source": [
        "dataset3_train.drop(['class'], axis=1, inplace=True)\n",
        "dataset3_test.drop(['class'], axis=1, inplace=True)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vizuL56RQUPq",
        "outputId": "3c08f12c-d5e4-43e8-fda8-389c73b51604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "dataset3_test.head()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>alone</th>\n",
              "      <th>First</th>\n",
              "      <th>Second</th>\n",
              "      <th>Third</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived  sex   age  n_siblings_spouses  ...  alone  First  Second  Third\n",
              "0         0    1  35.0                   0  ...      1      0       0      1\n",
              "1         0    1  54.0                   0  ...      1      1       0      0\n",
              "2         1    0  58.0                   0  ...      1      1       0      0\n",
              "3         1    0  55.0                   0  ...      1      0       1      0\n",
              "4         1    1  34.0                   0  ...      1      0       1      0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsLggOc8QYAa",
        "outputId": "efb2080c-724a-47d9-adb6-cec26702ac4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "dataset3_train.head()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>alone</th>\n",
              "      <th>First</th>\n",
              "      <th>Second</th>\n",
              "      <th>Third</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived  sex   age  n_siblings_spouses  ...  alone  First  Second  Third\n",
              "0         0    1  22.0                   1  ...      0      0       0      1\n",
              "1         1    0  38.0                   1  ...      0      1       0      0\n",
              "2         1    0  26.0                   0  ...      1      0       0      1\n",
              "3         1    0  35.0                   1  ...      0      1       0      0\n",
              "4         0    1  28.0                   0  ...      1      0       0      1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6NLQNg-Q1k_",
        "outputId": "534f1688-24e8-4af3-ec66-b4b17a14cd8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "dataset3_train.info()\n",
        "# dataset3_test.info()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 627 entries, 0 to 626\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   survived            627 non-null    int64  \n",
            " 1   sex                 627 non-null    int64  \n",
            " 2   age                 627 non-null    float64\n",
            " 3   n_siblings_spouses  627 non-null    int64  \n",
            " 4   parch               627 non-null    int64  \n",
            " 5   fare                627 non-null    float64\n",
            " 6   alone               627 non-null    int64  \n",
            " 7   First               627 non-null    uint8  \n",
            " 8   Second              627 non-null    uint8  \n",
            " 9   Third               627 non-null    uint8  \n",
            "dtypes: float64(2), int64(5), uint8(3)\n",
            "memory usage: 36.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRV0Sp5IcPAm"
      },
      "source": [
        "label_train3 = dataset3_train['survived']\n",
        "feature_train3 = dataset3_train.drop(['survived'], axis=1)\n",
        "label_test3 = dataset3_test['survived']\n",
        "feature_test3 = dataset3_test.drop(['survived'], axis=1)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3RMYFv_ch5J"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "scaler3 = preprocessing.StandardScaler()\n",
        "\n",
        "feature_train3 = scaler3.fit_transform(feature_train3.values)\n",
        "feature_test3 = scaler3.fit_transform(feature_test3.values)\n",
        "label_train3 = scaler3.fit_transform(label_train3.values.reshape(-1,1)).flatten()\n",
        "label_test3 = scaler3.fit_transform(label_test3.values.reshape(-1,1)).flatten()"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viEiAG2Gc275"
      },
      "source": [
        "##Wider Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7acIOsNvcstn",
        "outputId": "4e42e348-65cb-49ad-8f08-149b7ae3acbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(40, input_dim=9, kernel_initializer='normal', activation='relu')) # 13 neuron input_dim=feature=9\n",
        "model.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='SGD')\n",
        "\n",
        "history2w=model.fit(x=feature_train3, y=label_train3, validation_data=(feature_test3, label_test3), epochs=100, batch_size=8)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.9413 - val_loss: 0.8782\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7910 - val_loss: 0.7384\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6425 - val_loss: 0.6619\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5821 - val_loss: 0.6423\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5622 - val_loss: 0.6379\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5556 - val_loss: 0.6354\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5530 - val_loss: 0.6314\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5491 - val_loss: 0.6272\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5484 - val_loss: 0.6309\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5479 - val_loss: 0.6291\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5477 - val_loss: 0.6251\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5414 - val_loss: 0.6189\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5449 - val_loss: 0.6245\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5421 - val_loss: 0.6311\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5412 - val_loss: 0.6251\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5427 - val_loss: 0.6195\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5409 - val_loss: 0.6210\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5396 - val_loss: 0.6185\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5379 - val_loss: 0.6160\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5363 - val_loss: 0.6246\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5359 - val_loss: 0.6149\n",
            "Epoch 22/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5317 - val_loss: 0.6164\n",
            "Epoch 23/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5356 - val_loss: 0.6067\n",
            "Epoch 24/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5342 - val_loss: 0.6150\n",
            "Epoch 25/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5341 - val_loss: 0.6111\n",
            "Epoch 26/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5321 - val_loss: 0.6093\n",
            "Epoch 27/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5310 - val_loss: 0.6100\n",
            "Epoch 28/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5291 - val_loss: 0.6130\n",
            "Epoch 29/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5290 - val_loss: 0.6047\n",
            "Epoch 30/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5294 - val_loss: 0.6023\n",
            "Epoch 31/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 0.6098\n",
            "Epoch 32/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5282 - val_loss: 0.6094\n",
            "Epoch 33/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 0.6114\n",
            "Epoch 34/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 0.6108\n",
            "Epoch 35/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 0.6016\n",
            "Epoch 36/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 0.6057\n",
            "Epoch 37/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5261 - val_loss: 0.6039\n",
            "Epoch 38/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 0.6055\n",
            "Epoch 39/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 0.6016\n",
            "Epoch 40/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 0.6023\n",
            "Epoch 41/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.6029\n",
            "Epoch 42/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.5970\n",
            "Epoch 43/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5214 - val_loss: 0.5987\n",
            "Epoch 44/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5224 - val_loss: 0.5958\n",
            "Epoch 45/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5200 - val_loss: 0.6009\n",
            "Epoch 46/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5189 - val_loss: 0.5949\n",
            "Epoch 47/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5191 - val_loss: 0.6066\n",
            "Epoch 48/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5188 - val_loss: 0.5999\n",
            "Epoch 49/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5202 - val_loss: 0.5954\n",
            "Epoch 50/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5188 - val_loss: 0.5940\n",
            "Epoch 51/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5181 - val_loss: 0.6017\n",
            "Epoch 52/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5178 - val_loss: 0.5901\n",
            "Epoch 53/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5151 - val_loss: 0.5919\n",
            "Epoch 54/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5163 - val_loss: 0.5925\n",
            "Epoch 55/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5154 - val_loss: 0.5925\n",
            "Epoch 56/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5164 - val_loss: 0.5913\n",
            "Epoch 57/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5165 - val_loss: 0.5882\n",
            "Epoch 58/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5160 - val_loss: 0.5884\n",
            "Epoch 59/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5149 - val_loss: 0.5862\n",
            "Epoch 60/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5143 - val_loss: 0.5840\n",
            "Epoch 61/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5141 - val_loss: 0.5855\n",
            "Epoch 62/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5128 - val_loss: 0.5937\n",
            "Epoch 63/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5133 - val_loss: 0.5930\n",
            "Epoch 64/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5128 - val_loss: 0.5939\n",
            "Epoch 65/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5130 - val_loss: 0.5924\n",
            "Epoch 66/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5124 - val_loss: 0.5891\n",
            "Epoch 67/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5092 - val_loss: 0.6011\n",
            "Epoch 68/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5138 - val_loss: 0.5878\n",
            "Epoch 69/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5112 - val_loss: 0.5841\n",
            "Epoch 70/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5111 - val_loss: 0.5854\n",
            "Epoch 71/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5077 - val_loss: 0.5898\n",
            "Epoch 72/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5107 - val_loss: 0.5824\n",
            "Epoch 73/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5095 - val_loss: 0.5839\n",
            "Epoch 74/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5077 - val_loss: 0.5867\n",
            "Epoch 75/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5086 - val_loss: 0.5855\n",
            "Epoch 76/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5086 - val_loss: 0.5836\n",
            "Epoch 77/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5102 - val_loss: 0.5815\n",
            "Epoch 78/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5072 - val_loss: 0.5943\n",
            "Epoch 79/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5061 - val_loss: 0.5825\n",
            "Epoch 80/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5068 - val_loss: 0.5847\n",
            "Epoch 81/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5062 - val_loss: 0.5833\n",
            "Epoch 82/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5063 - val_loss: 0.5834\n",
            "Epoch 83/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5057 - val_loss: 0.5891\n",
            "Epoch 84/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5062 - val_loss: 0.5829\n",
            "Epoch 85/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5058 - val_loss: 0.5777\n",
            "Epoch 86/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5059 - val_loss: 0.5850\n",
            "Epoch 87/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5021 - val_loss: 0.5848\n",
            "Epoch 88/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5042 - val_loss: 0.5842\n",
            "Epoch 89/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5040 - val_loss: 0.5932\n",
            "Epoch 90/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5019 - val_loss: 0.5881\n",
            "Epoch 91/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5054 - val_loss: 0.5860\n",
            "Epoch 92/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5016 - val_loss: 0.5896\n",
            "Epoch 93/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5003 - val_loss: 0.5794\n",
            "Epoch 94/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5023 - val_loss: 0.5800\n",
            "Epoch 95/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4995 - val_loss: 0.5770\n",
            "Epoch 96/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5014 - val_loss: 0.5730\n",
            "Epoch 97/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5021 - val_loss: 0.5759\n",
            "Epoch 98/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5027 - val_loss: 0.5837\n",
            "Epoch 99/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5017 - val_loss: 0.5786\n",
            "Epoch 100/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5005 - val_loss: 0.5758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp8ekmR5eMGR"
      },
      "source": [
        "Nilai val_loss terbaik yg didapat berada pada epoch 93 dengan loss: 0.49 dan val_loss: 0.57"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-tMR-jOdtkz",
        "outputId": "ac352f2c-e99c-4831-c2be-6cadb26c5da4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(history2w)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4sno84becUh"
      },
      "source": [
        "##Deeper Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTRoqmZYeYlk",
        "outputId": "3438970d-ef93-47a6-f9b9-3f874cc82dee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "deeper_model3 = Sequential()\n",
        "deeper_model3.add(Dense(9, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
        "deeper_model3.add(Dense(5, kernel_initializer='normal', activation='relu'))\n",
        "deeper_model3.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "deeper_model3.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "historyd3 = deeper_model3.fit(x=feature_train3, y=label_train3, validation_data=(feature_test3, label_test3), epochs=100, batch_size=8)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.9939 - val_loss: 0.9789\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9206 - val_loss: 0.8487\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7495 - val_loss: 0.7161\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6230 - val_loss: 0.6541\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5720 - val_loss: 0.6293\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5566 - val_loss: 0.6234\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5507 - val_loss: 0.6218\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5467 - val_loss: 0.6197\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5449 - val_loss: 0.6196\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5439 - val_loss: 0.6178\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5414 - val_loss: 0.6157\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5404 - val_loss: 0.6149\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5395 - val_loss: 0.6111\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 0.6104\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5363 - val_loss: 0.6085\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5341 - val_loss: 0.6100\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5356 - val_loss: 0.6081\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5337 - val_loss: 0.6045\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5352 - val_loss: 0.6048\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5312 - val_loss: 0.6037\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5298 - val_loss: 0.6037\n",
            "Epoch 22/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5291 - val_loss: 0.6011\n",
            "Epoch 23/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5295 - val_loss: 0.6011\n",
            "Epoch 24/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5282 - val_loss: 0.6001\n",
            "Epoch 25/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5271 - val_loss: 0.5977\n",
            "Epoch 26/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 0.5960\n",
            "Epoch 27/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 0.5951\n",
            "Epoch 28/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 0.5948\n",
            "Epoch 29/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5241 - val_loss: 0.5930\n",
            "Epoch 30/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 0.5929\n",
            "Epoch 31/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5221 - val_loss: 0.5912\n",
            "Epoch 32/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5895\n",
            "Epoch 33/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5221 - val_loss: 0.5894\n",
            "Epoch 34/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 0.5877\n",
            "Epoch 35/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5206 - val_loss: 0.5878\n",
            "Epoch 36/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5226 - val_loss: 0.5876\n",
            "Epoch 37/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5205 - val_loss: 0.5886\n",
            "Epoch 38/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5213 - val_loss: 0.5857\n",
            "Epoch 39/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5218 - val_loss: 0.5860\n",
            "Epoch 40/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5207 - val_loss: 0.5858\n",
            "Epoch 41/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5202 - val_loss: 0.5837\n",
            "Epoch 42/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5209 - val_loss: 0.5831\n",
            "Epoch 43/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5190 - val_loss: 0.5836\n",
            "Epoch 44/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5190 - val_loss: 0.5830\n",
            "Epoch 45/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5190 - val_loss: 0.5839\n",
            "Epoch 46/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5178 - val_loss: 0.5823\n",
            "Epoch 47/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5169 - val_loss: 0.5811\n",
            "Epoch 48/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5182 - val_loss: 0.5805\n",
            "Epoch 49/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5173 - val_loss: 0.5802\n",
            "Epoch 50/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5162 - val_loss: 0.5792\n",
            "Epoch 51/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5169 - val_loss: 0.5800\n",
            "Epoch 52/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5152 - val_loss: 0.5800\n",
            "Epoch 53/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5157 - val_loss: 0.5793\n",
            "Epoch 54/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5161 - val_loss: 0.5788\n",
            "Epoch 55/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5154 - val_loss: 0.5777\n",
            "Epoch 56/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5139 - val_loss: 0.5768\n",
            "Epoch 57/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5149 - val_loss: 0.5776\n",
            "Epoch 58/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5136 - val_loss: 0.5758\n",
            "Epoch 59/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5137 - val_loss: 0.5783\n",
            "Epoch 60/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5137 - val_loss: 0.5781\n",
            "Epoch 61/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5145 - val_loss: 0.5767\n",
            "Epoch 62/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5116 - val_loss: 0.5759\n",
            "Epoch 63/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5126 - val_loss: 0.5746\n",
            "Epoch 64/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5137 - val_loss: 0.5757\n",
            "Epoch 65/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5118 - val_loss: 0.5755\n",
            "Epoch 66/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5108 - val_loss: 0.5739\n",
            "Epoch 67/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5109 - val_loss: 0.5749\n",
            "Epoch 68/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5131 - val_loss: 0.5741\n",
            "Epoch 69/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5108 - val_loss: 0.5728\n",
            "Epoch 70/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5106 - val_loss: 0.5729\n",
            "Epoch 71/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5092 - val_loss: 0.5731\n",
            "Epoch 72/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5103 - val_loss: 0.5745\n",
            "Epoch 73/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5092 - val_loss: 0.5742\n",
            "Epoch 74/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5081 - val_loss: 0.5727\n",
            "Epoch 75/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5091 - val_loss: 0.5726\n",
            "Epoch 76/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5086 - val_loss: 0.5718\n",
            "Epoch 77/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5081 - val_loss: 0.5721\n",
            "Epoch 78/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5085 - val_loss: 0.5733\n",
            "Epoch 79/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5076 - val_loss: 0.5743\n",
            "Epoch 80/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5059 - val_loss: 0.5747\n",
            "Epoch 81/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5076 - val_loss: 0.5733\n",
            "Epoch 82/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5069 - val_loss: 0.5743\n",
            "Epoch 83/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5052 - val_loss: 0.5753\n",
            "Epoch 84/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5061 - val_loss: 0.5755\n",
            "Epoch 85/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5057 - val_loss: 0.5739\n",
            "Epoch 86/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5056 - val_loss: 0.5725\n",
            "Epoch 87/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5064 - val_loss: 0.5732\n",
            "Epoch 88/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5066 - val_loss: 0.5755\n",
            "Epoch 89/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5054 - val_loss: 0.5749\n",
            "Epoch 90/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5042 - val_loss: 0.5748\n",
            "Epoch 91/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5044 - val_loss: 0.5727\n",
            "Epoch 92/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5058 - val_loss: 0.5733\n",
            "Epoch 93/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5049 - val_loss: 0.5721\n",
            "Epoch 94/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5036 - val_loss: 0.5729\n",
            "Epoch 95/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5061 - val_loss: 0.5717\n",
            "Epoch 96/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5042 - val_loss: 0.5714\n",
            "Epoch 97/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5037 - val_loss: 0.5711\n",
            "Epoch 98/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5029 - val_loss: 0.5725\n",
            "Epoch 99/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5028 - val_loss: 0.5727\n",
            "Epoch 100/100\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5042 - val_loss: 0.5696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31YGnW_lgGi1",
        "outputId": "b7a59c8b-3c81-45ab-c973-fdecf1d1b340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(historyd3)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU20QWaDgPOV"
      },
      "source": [
        "berdasarkan grafik, val_loss mulai stabil mada epoch ke 70 hingga seratus, dengan rata rata nilai val_loss=0.57 dan loss=0.50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3Cm9P3VusTP"
      },
      "source": [
        "##Mencari nilai terbaik berdasarkan optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12tiieQzu_v-"
      },
      "source": [
        "###Wider Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofh-2zITvFQ_"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "opt_sgd=SGD(lr=0.01, momentum=0.9)\n",
        "opt_Adadelta=Adadelta(lr=0.001, rho=0.95, epsilon=1e-07)\n",
        "opt_Adamax=Adamax(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
        "opt_RMSprop=RMSprop(lr=0.001,rho=0.9, momentum=0.0, epsilon=1e-07, centered=False)\n",
        "\n",
        "def wide_opt3(optim):\n",
        "  wider_model3 = Sequential()\n",
        "  wider_model3.add(Dense(40, input_dim=9, kernel_initializer='normal', activation='relu')) #menggunakan neuron 40, input_dim=features=9\n",
        "  wider_model3.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "  opt=optim\n",
        "  wider_model3.compile(loss='mean_squared_error', optimizer=opt)\n",
        "\n",
        "  historyw3 = wider_model3.fit(x=feature_train3, y=label_train3, validation_data=(feature_test3, label_test3), epochs=1000, batch_size=8)\n",
        "\n",
        "  plot_loss(historyw3)\n"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thfdXZ0FvwQQ"
      },
      "source": [
        "####SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVj7SmkxvzWp",
        "outputId": "887d8903-15b2-4672-da6c-5ed557a99780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wide_opt3(opt_sgd)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.7516 - val_loss: 0.6904\n",
            "Epoch 2/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5958 - val_loss: 0.6299\n",
            "Epoch 3/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5696 - val_loss: 0.6320\n",
            "Epoch 4/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5733 - val_loss: 0.6297\n",
            "Epoch 5/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5675 - val_loss: 0.6238\n",
            "Epoch 6/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5755 - val_loss: 0.6108\n",
            "Epoch 7/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5767 - val_loss: 0.6281\n",
            "Epoch 8/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5680 - val_loss: 0.6025\n",
            "Epoch 9/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5814 - val_loss: 0.6072\n",
            "Epoch 10/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5513 - val_loss: 0.5731\n",
            "Epoch 11/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5534 - val_loss: 0.5800\n",
            "Epoch 12/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5521 - val_loss: 0.5847\n",
            "Epoch 13/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5527 - val_loss: 0.6473\n",
            "Epoch 14/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5543 - val_loss: 0.6362\n",
            "Epoch 15/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5571 - val_loss: 0.6435\n",
            "Epoch 16/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5717 - val_loss: 0.6342\n",
            "Epoch 17/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5536 - val_loss: 0.5772\n",
            "Epoch 18/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5482 - val_loss: 0.5752\n",
            "Epoch 19/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5584 - val_loss: 0.5806\n",
            "Epoch 20/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5464 - val_loss: 0.5660\n",
            "Epoch 21/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5468 - val_loss: 0.6174\n",
            "Epoch 22/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5381 - val_loss: 0.6685\n",
            "Epoch 23/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5460 - val_loss: 0.5904\n",
            "Epoch 24/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5308 - val_loss: 0.6118\n",
            "Epoch 25/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5347 - val_loss: 0.5654\n",
            "Epoch 26/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5368 - val_loss: 0.6304\n",
            "Epoch 27/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5382 - val_loss: 0.5690\n",
            "Epoch 28/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5533 - val_loss: 0.6292\n",
            "Epoch 29/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5455 - val_loss: 0.6167\n",
            "Epoch 30/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5369 - val_loss: 0.5935\n",
            "Epoch 31/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5463 - val_loss: 0.5713\n",
            "Epoch 32/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5414 - val_loss: 0.5742\n",
            "Epoch 33/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5332 - val_loss: 0.6031\n",
            "Epoch 34/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5277 - val_loss: 0.5715\n",
            "Epoch 35/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5198 - val_loss: 0.6165\n",
            "Epoch 36/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5559 - val_loss: 0.5714\n",
            "Epoch 37/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5395 - val_loss: 0.5583\n",
            "Epoch 38/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5168 - val_loss: 0.5823\n",
            "Epoch 39/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5344 - val_loss: 0.5769\n",
            "Epoch 40/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5282 - val_loss: 0.5729\n",
            "Epoch 41/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5314 - val_loss: 0.5753\n",
            "Epoch 42/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5100 - val_loss: 0.5591\n",
            "Epoch 43/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5307 - val_loss: 0.5879\n",
            "Epoch 44/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 0.5783\n",
            "Epoch 45/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5188 - val_loss: 0.6339\n",
            "Epoch 46/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5285 - val_loss: 0.5733\n",
            "Epoch 47/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5185 - val_loss: 0.5640\n",
            "Epoch 48/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5303 - val_loss: 0.6217\n",
            "Epoch 49/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5277 - val_loss: 0.5956\n",
            "Epoch 50/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 0.5824\n",
            "Epoch 51/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5322 - val_loss: 0.5790\n",
            "Epoch 52/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5214 - val_loss: 0.5677\n",
            "Epoch 53/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 0.5508\n",
            "Epoch 54/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5199 - val_loss: 0.6698\n",
            "Epoch 55/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5305 - val_loss: 0.6156\n",
            "Epoch 56/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 0.5611\n",
            "Epoch 57/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5236 - val_loss: 0.5796\n",
            "Epoch 58/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5203 - val_loss: 0.5827\n",
            "Epoch 59/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5157 - val_loss: 0.5658\n",
            "Epoch 60/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5071 - val_loss: 0.5726\n",
            "Epoch 61/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4967 - val_loss: 0.5959\n",
            "Epoch 62/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5239 - val_loss: 0.5641\n",
            "Epoch 63/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 0.6011\n",
            "Epoch 64/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5035 - val_loss: 0.5732\n",
            "Epoch 65/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 0.5622\n",
            "Epoch 66/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5163 - val_loss: 0.6018\n",
            "Epoch 67/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5192 - val_loss: 0.5714\n",
            "Epoch 68/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 0.5786\n",
            "Epoch 69/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5134 - val_loss: 0.5943\n",
            "Epoch 70/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5130 - val_loss: 0.5902\n",
            "Epoch 71/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5135 - val_loss: 0.5538\n",
            "Epoch 72/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5032 - val_loss: 0.6217\n",
            "Epoch 73/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 0.5736\n",
            "Epoch 74/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.6113\n",
            "Epoch 75/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5216 - val_loss: 0.5875\n",
            "Epoch 76/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5069 - val_loss: 0.5541\n",
            "Epoch 77/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5304 - val_loss: 0.6031\n",
            "Epoch 78/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5158 - val_loss: 0.5838\n",
            "Epoch 79/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.6226\n",
            "Epoch 80/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 0.6405\n",
            "Epoch 81/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5369 - val_loss: 0.6218\n",
            "Epoch 82/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5113 - val_loss: 0.6199\n",
            "Epoch 83/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 0.5931\n",
            "Epoch 84/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4983 - val_loss: 0.6049\n",
            "Epoch 85/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5226 - val_loss: 0.5819\n",
            "Epoch 86/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.5799\n",
            "Epoch 87/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5148 - val_loss: 0.6154\n",
            "Epoch 88/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5112 - val_loss: 0.5916\n",
            "Epoch 89/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5160 - val_loss: 0.5627\n",
            "Epoch 90/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5087 - val_loss: 0.5810\n",
            "Epoch 91/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5081 - val_loss: 0.5999\n",
            "Epoch 92/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5077 - val_loss: 0.5784\n",
            "Epoch 93/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5060 - val_loss: 0.5829\n",
            "Epoch 94/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5158 - val_loss: 0.5792\n",
            "Epoch 95/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5184 - val_loss: 0.5687\n",
            "Epoch 96/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4990 - val_loss: 0.6047\n",
            "Epoch 97/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5061 - val_loss: 0.6172\n",
            "Epoch 98/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5099 - val_loss: 0.5768\n",
            "Epoch 99/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5058 - val_loss: 0.6064\n",
            "Epoch 100/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 0.6457\n",
            "Epoch 101/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5155 - val_loss: 0.6560\n",
            "Epoch 102/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 0.6206\n",
            "Epoch 103/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5052 - val_loss: 0.5916\n",
            "Epoch 104/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5122 - val_loss: 0.6015\n",
            "Epoch 105/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5036 - val_loss: 0.5936\n",
            "Epoch 106/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5030 - val_loss: 0.5910\n",
            "Epoch 107/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5033 - val_loss: 0.6010\n",
            "Epoch 108/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5188 - val_loss: 0.5857\n",
            "Epoch 109/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5103 - val_loss: 0.5781\n",
            "Epoch 110/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4947 - val_loss: 0.5806\n",
            "Epoch 111/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5087 - val_loss: 0.6026\n",
            "Epoch 112/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5129 - val_loss: 0.6169\n",
            "Epoch 113/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5434 - val_loss: 0.5930\n",
            "Epoch 114/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5090 - val_loss: 0.5808\n",
            "Epoch 115/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5105 - val_loss: 0.6388\n",
            "Epoch 116/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5139 - val_loss: 0.5826\n",
            "Epoch 117/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5065 - val_loss: 0.5949\n",
            "Epoch 118/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5198 - val_loss: 0.6117\n",
            "Epoch 119/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4947 - val_loss: 0.6361\n",
            "Epoch 120/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5153 - val_loss: 0.6487\n",
            "Epoch 121/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5098 - val_loss: 0.5613\n",
            "Epoch 122/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5025 - val_loss: 0.6411\n",
            "Epoch 123/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5064 - val_loss: 0.5981\n",
            "Epoch 124/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5016 - val_loss: 0.6045\n",
            "Epoch 125/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4975 - val_loss: 0.5885\n",
            "Epoch 126/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5139 - val_loss: 0.5961\n",
            "Epoch 127/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5056 - val_loss: 0.5844\n",
            "Epoch 128/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5031 - val_loss: 0.6089\n",
            "Epoch 129/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5114 - val_loss: 0.6336\n",
            "Epoch 130/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5005 - val_loss: 0.6914\n",
            "Epoch 131/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5050 - val_loss: 0.6237\n",
            "Epoch 132/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5001 - val_loss: 0.5982\n",
            "Epoch 133/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5058 - val_loss: 0.5929\n",
            "Epoch 134/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5021 - val_loss: 0.5853\n",
            "Epoch 135/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5199 - val_loss: 0.5838\n",
            "Epoch 136/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4928 - val_loss: 0.6061\n",
            "Epoch 137/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5167 - val_loss: 0.6157\n",
            "Epoch 138/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5191 - val_loss: 0.5812\n",
            "Epoch 139/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5165 - val_loss: 0.5651\n",
            "Epoch 140/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5027 - val_loss: 0.5947\n",
            "Epoch 141/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5023 - val_loss: 0.5983\n",
            "Epoch 142/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5547 - val_loss: 0.5967\n",
            "Epoch 143/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 0.5914\n",
            "Epoch 144/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5181 - val_loss: 0.6140\n",
            "Epoch 145/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5155 - val_loss: 0.6301\n",
            "Epoch 146/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4935 - val_loss: 0.6133\n",
            "Epoch 147/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5024 - val_loss: 0.5968\n",
            "Epoch 148/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5150 - val_loss: 0.6169\n",
            "Epoch 149/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5078 - val_loss: 0.5829\n",
            "Epoch 150/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4967 - val_loss: 0.5838\n",
            "Epoch 151/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5001 - val_loss: 0.6177\n",
            "Epoch 152/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5133 - val_loss: 0.5805\n",
            "Epoch 153/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5027 - val_loss: 0.5949\n",
            "Epoch 154/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5073 - val_loss: 0.6047\n",
            "Epoch 155/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4923 - val_loss: 0.6134\n",
            "Epoch 156/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5069 - val_loss: 0.5927\n",
            "Epoch 157/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4923 - val_loss: 0.6121\n",
            "Epoch 158/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5075 - val_loss: 0.5879\n",
            "Epoch 159/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5013 - val_loss: 0.6002\n",
            "Epoch 160/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5002 - val_loss: 0.6362\n",
            "Epoch 161/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5217 - val_loss: 0.6406\n",
            "Epoch 162/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5131 - val_loss: 0.5888\n",
            "Epoch 163/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4994 - val_loss: 0.6136\n",
            "Epoch 164/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4959 - val_loss: 0.6074\n",
            "Epoch 165/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4915 - val_loss: 0.6370\n",
            "Epoch 166/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4953 - val_loss: 0.6421\n",
            "Epoch 167/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5069 - val_loss: 0.5963\n",
            "Epoch 168/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4870 - val_loss: 0.5931\n",
            "Epoch 169/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5142 - val_loss: 0.6345\n",
            "Epoch 170/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5006 - val_loss: 0.5827\n",
            "Epoch 171/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4998 - val_loss: 0.6085\n",
            "Epoch 172/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4914 - val_loss: 0.6157\n",
            "Epoch 173/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5012 - val_loss: 0.6210\n",
            "Epoch 174/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4931 - val_loss: 0.6342\n",
            "Epoch 175/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5138 - val_loss: 0.6525\n",
            "Epoch 176/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5110 - val_loss: 0.5960\n",
            "Epoch 177/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4991 - val_loss: 0.6066\n",
            "Epoch 178/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4931 - val_loss: 0.6209\n",
            "Epoch 179/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4985 - val_loss: 0.6357\n",
            "Epoch 180/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4965 - val_loss: 0.6505\n",
            "Epoch 181/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4949 - val_loss: 0.6194\n",
            "Epoch 182/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4857 - val_loss: 0.6214\n",
            "Epoch 183/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4833 - val_loss: 0.5892\n",
            "Epoch 184/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.6580\n",
            "Epoch 185/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4989 - val_loss: 0.5978\n",
            "Epoch 186/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5076 - val_loss: 0.5909\n",
            "Epoch 187/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5024 - val_loss: 0.6132\n",
            "Epoch 188/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5011 - val_loss: 0.5993\n",
            "Epoch 189/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4989 - val_loss: 0.6360\n",
            "Epoch 190/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 0.6104\n",
            "Epoch 191/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4880 - val_loss: 0.5892\n",
            "Epoch 192/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4941 - val_loss: 0.6239\n",
            "Epoch 193/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5086 - val_loss: 0.6045\n",
            "Epoch 194/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5191 - val_loss: 0.6091\n",
            "Epoch 195/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4941 - val_loss: 0.6025\n",
            "Epoch 196/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4906 - val_loss: 0.6121\n",
            "Epoch 197/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4922 - val_loss: 0.6056\n",
            "Epoch 198/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.6110\n",
            "Epoch 199/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4914 - val_loss: 0.6159\n",
            "Epoch 200/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4957 - val_loss: 0.6588\n",
            "Epoch 201/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4966 - val_loss: 0.6024\n",
            "Epoch 202/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4882 - val_loss: 0.5972\n",
            "Epoch 203/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4868 - val_loss: 0.5981\n",
            "Epoch 204/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5103 - val_loss: 0.6458\n",
            "Epoch 205/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4955 - val_loss: 0.6256\n",
            "Epoch 206/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4978 - val_loss: 0.6448\n",
            "Epoch 207/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 0.6656\n",
            "Epoch 208/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4923 - val_loss: 0.6013\n",
            "Epoch 209/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4805 - val_loss: 0.6181\n",
            "Epoch 210/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4914 - val_loss: 0.5877\n",
            "Epoch 211/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4960 - val_loss: 0.6141\n",
            "Epoch 212/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4982 - val_loss: 0.6260\n",
            "Epoch 213/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4825 - val_loss: 0.6247\n",
            "Epoch 214/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4835 - val_loss: 0.6100\n",
            "Epoch 215/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4883 - val_loss: 0.5883\n",
            "Epoch 216/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 0.6017\n",
            "Epoch 217/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5049 - val_loss: 0.6171\n",
            "Epoch 218/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5185 - val_loss: 0.5785\n",
            "Epoch 219/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5080 - val_loss: 0.6091\n",
            "Epoch 220/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5188 - val_loss: 0.5694\n",
            "Epoch 221/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4994 - val_loss: 0.5958\n",
            "Epoch 222/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.6150\n",
            "Epoch 223/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4902 - val_loss: 0.5970\n",
            "Epoch 224/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4911 - val_loss: 0.6552\n",
            "Epoch 225/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5188 - val_loss: 0.6416\n",
            "Epoch 226/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5048 - val_loss: 0.6319\n",
            "Epoch 227/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5156 - val_loss: 0.6172\n",
            "Epoch 228/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4872 - val_loss: 0.6105\n",
            "Epoch 229/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4900 - val_loss: 0.5730\n",
            "Epoch 230/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4855 - val_loss: 0.6006\n",
            "Epoch 231/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4954 - val_loss: 0.6261\n",
            "Epoch 232/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4947 - val_loss: 0.6784\n",
            "Epoch 233/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5154 - val_loss: 0.6023\n",
            "Epoch 234/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5024 - val_loss: 0.6277\n",
            "Epoch 235/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4923 - val_loss: 0.5923\n",
            "Epoch 236/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4955 - val_loss: 0.6543\n",
            "Epoch 237/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4981 - val_loss: 0.6038\n",
            "Epoch 238/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4700 - val_loss: 0.6338\n",
            "Epoch 239/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4855 - val_loss: 0.6566\n",
            "Epoch 240/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4916 - val_loss: 0.6305\n",
            "Epoch 241/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5047 - val_loss: 0.6104\n",
            "Epoch 242/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4966 - val_loss: 0.6411\n",
            "Epoch 243/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4899 - val_loss: 0.6056\n",
            "Epoch 244/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4902 - val_loss: 0.6501\n",
            "Epoch 245/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4905 - val_loss: 0.6635\n",
            "Epoch 246/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4938 - val_loss: 0.6051\n",
            "Epoch 247/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4791 - val_loss: 0.6318\n",
            "Epoch 248/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4933 - val_loss: 0.6031\n",
            "Epoch 249/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.6087\n",
            "Epoch 250/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4889 - val_loss: 0.5929\n",
            "Epoch 251/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4805 - val_loss: 0.5762\n",
            "Epoch 252/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4903 - val_loss: 0.6068\n",
            "Epoch 253/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5211 - val_loss: 0.6260\n",
            "Epoch 254/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4869 - val_loss: 0.6413\n",
            "Epoch 255/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5028 - val_loss: 0.6104\n",
            "Epoch 256/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 0.6689\n",
            "Epoch 257/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4967 - val_loss: 0.6272\n",
            "Epoch 258/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.6251\n",
            "Epoch 259/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5161 - val_loss: 0.5902\n",
            "Epoch 260/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4801 - val_loss: 0.6451\n",
            "Epoch 261/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4984 - val_loss: 0.6706\n",
            "Epoch 262/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4950 - val_loss: 0.5883\n",
            "Epoch 263/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 0.6072\n",
            "Epoch 264/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4921 - val_loss: 0.5907\n",
            "Epoch 265/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4846 - val_loss: 0.6193\n",
            "Epoch 266/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4788 - val_loss: 0.6150\n",
            "Epoch 267/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4975 - val_loss: 0.6014\n",
            "Epoch 268/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5092 - val_loss: 0.6189\n",
            "Epoch 269/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.6198\n",
            "Epoch 270/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5040 - val_loss: 0.6275\n",
            "Epoch 271/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5214 - val_loss: 0.6005\n",
            "Epoch 272/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4914 - val_loss: 0.5926\n",
            "Epoch 273/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 0.6510\n",
            "Epoch 274/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4931 - val_loss: 0.6022\n",
            "Epoch 275/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 0.6238\n",
            "Epoch 276/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4684 - val_loss: 0.5864\n",
            "Epoch 277/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4833 - val_loss: 0.6120\n",
            "Epoch 278/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.6227\n",
            "Epoch 279/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5037 - val_loss: 0.6359\n",
            "Epoch 280/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 0.6035\n",
            "Epoch 281/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5048 - val_loss: 0.6065\n",
            "Epoch 282/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5034 - val_loss: 0.6159\n",
            "Epoch 283/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5075 - val_loss: 0.6124\n",
            "Epoch 284/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4732 - val_loss: 0.6072\n",
            "Epoch 285/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.6791\n",
            "Epoch 286/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4821 - val_loss: 0.6059\n",
            "Epoch 287/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.6230\n",
            "Epoch 288/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4833 - val_loss: 0.6048\n",
            "Epoch 289/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 0.6077\n",
            "Epoch 290/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4858 - val_loss: 0.6242\n",
            "Epoch 291/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5057 - val_loss: 0.6243\n",
            "Epoch 292/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5189 - val_loss: 0.6127\n",
            "Epoch 293/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4921 - val_loss: 0.6229\n",
            "Epoch 294/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5157 - val_loss: 0.6122\n",
            "Epoch 295/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4698 - val_loss: 0.6212\n",
            "Epoch 296/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4870 - val_loss: 0.6011\n",
            "Epoch 297/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5045 - val_loss: 0.6288\n",
            "Epoch 298/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4907 - val_loss: 0.6138\n",
            "Epoch 299/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4918 - val_loss: 0.6899\n",
            "Epoch 300/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 0.5790\n",
            "Epoch 301/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4723 - val_loss: 0.6109\n",
            "Epoch 302/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4704 - val_loss: 0.5884\n",
            "Epoch 303/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4876 - val_loss: 0.6412\n",
            "Epoch 304/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.6165\n",
            "Epoch 305/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 0.6012\n",
            "Epoch 306/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4939 - val_loss: 0.5782\n",
            "Epoch 307/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4767 - val_loss: 0.5811\n",
            "Epoch 308/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4985 - val_loss: 0.6460\n",
            "Epoch 309/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4836 - val_loss: 0.6280\n",
            "Epoch 310/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4887 - val_loss: 0.6286\n",
            "Epoch 311/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4965 - val_loss: 0.6038\n",
            "Epoch 312/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4910 - val_loss: 0.6272\n",
            "Epoch 313/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4773 - val_loss: 0.5885\n",
            "Epoch 314/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4834 - val_loss: 0.6157\n",
            "Epoch 315/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4849 - val_loss: 0.5804\n",
            "Epoch 316/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5275 - val_loss: 0.6279\n",
            "Epoch 317/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.6224\n",
            "Epoch 318/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4800 - val_loss: 0.5995\n",
            "Epoch 319/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5005 - val_loss: 0.6629\n",
            "Epoch 320/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4920 - val_loss: 0.6754\n",
            "Epoch 321/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4994 - val_loss: 0.5916\n",
            "Epoch 322/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4722 - val_loss: 0.5812\n",
            "Epoch 323/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.6536\n",
            "Epoch 324/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4828 - val_loss: 0.6357\n",
            "Epoch 325/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4796 - val_loss: 0.6503\n",
            "Epoch 326/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 0.6466\n",
            "Epoch 327/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4948 - val_loss: 0.6162\n",
            "Epoch 328/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 0.6039\n",
            "Epoch 329/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5002 - val_loss: 0.6101\n",
            "Epoch 330/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4851 - val_loss: 0.6449\n",
            "Epoch 331/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5069 - val_loss: 0.6417\n",
            "Epoch 332/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5001 - val_loss: 0.6362\n",
            "Epoch 333/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4925 - val_loss: 0.5792\n",
            "Epoch 334/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 0.5976\n",
            "Epoch 335/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4969 - val_loss: 0.6395\n",
            "Epoch 336/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4929 - val_loss: 0.6369\n",
            "Epoch 337/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4933 - val_loss: 0.6506\n",
            "Epoch 338/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.6450\n",
            "Epoch 339/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4858 - val_loss: 0.6272\n",
            "Epoch 340/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5875\n",
            "Epoch 341/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4695 - val_loss: 0.6375\n",
            "Epoch 342/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4903 - val_loss: 0.6420\n",
            "Epoch 343/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5464 - val_loss: 0.6116\n",
            "Epoch 344/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.5905\n",
            "Epoch 345/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4920 - val_loss: 0.6601\n",
            "Epoch 346/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5118 - val_loss: 0.5980\n",
            "Epoch 347/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4866 - val_loss: 0.5919\n",
            "Epoch 348/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5110 - val_loss: 0.6470\n",
            "Epoch 349/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4952 - val_loss: 0.5822\n",
            "Epoch 350/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4792 - val_loss: 0.6279\n",
            "Epoch 351/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4719 - val_loss: 0.6283\n",
            "Epoch 352/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4742 - val_loss: 0.6263\n",
            "Epoch 353/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4830 - val_loss: 0.6045\n",
            "Epoch 354/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.6507\n",
            "Epoch 355/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4861 - val_loss: 0.6211\n",
            "Epoch 356/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.6250\n",
            "Epoch 357/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5002 - val_loss: 0.6127\n",
            "Epoch 358/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4876 - val_loss: 0.6026\n",
            "Epoch 359/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4775 - val_loss: 0.5839\n",
            "Epoch 360/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4819 - val_loss: 0.6218\n",
            "Epoch 361/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4859 - val_loss: 0.5981\n",
            "Epoch 362/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4852 - val_loss: 0.5979\n",
            "Epoch 363/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.5926\n",
            "Epoch 364/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.6372\n",
            "Epoch 365/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5053 - val_loss: 0.6628\n",
            "Epoch 366/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5155 - val_loss: 0.5933\n",
            "Epoch 367/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4900 - val_loss: 0.6031\n",
            "Epoch 368/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4864 - val_loss: 0.5857\n",
            "Epoch 369/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4792 - val_loss: 0.5872\n",
            "Epoch 370/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.6032\n",
            "Epoch 371/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.6027\n",
            "Epoch 372/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.6242\n",
            "Epoch 373/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 0.6266\n",
            "Epoch 374/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4908 - val_loss: 0.6146\n",
            "Epoch 375/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.6293\n",
            "Epoch 376/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4867 - val_loss: 0.5941\n",
            "Epoch 377/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5972\n",
            "Epoch 378/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.5873\n",
            "Epoch 379/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.5722\n",
            "Epoch 380/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.6227\n",
            "Epoch 381/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 0.6307\n",
            "Epoch 382/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.6797\n",
            "Epoch 383/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4886 - val_loss: 0.5979\n",
            "Epoch 384/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 0.5938\n",
            "Epoch 385/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.6154\n",
            "Epoch 386/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.6306\n",
            "Epoch 387/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 0.6044\n",
            "Epoch 388/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 0.6029\n",
            "Epoch 389/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.6256\n",
            "Epoch 390/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4627 - val_loss: 0.6522\n",
            "Epoch 391/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4691 - val_loss: 0.6287\n",
            "Epoch 392/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4819 - val_loss: 0.6077\n",
            "Epoch 393/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5998 - val_loss: 0.6196\n",
            "Epoch 394/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4965 - val_loss: 0.5844\n",
            "Epoch 395/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4825 - val_loss: 0.5792\n",
            "Epoch 396/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4847 - val_loss: 0.5890\n",
            "Epoch 397/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4795 - val_loss: 0.6052\n",
            "Epoch 398/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4939 - val_loss: 0.6054\n",
            "Epoch 399/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4832 - val_loss: 0.5958\n",
            "Epoch 400/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5078 - val_loss: 0.5886\n",
            "Epoch 401/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4821 - val_loss: 0.6193\n",
            "Epoch 402/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.6004\n",
            "Epoch 403/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4843 - val_loss: 0.6080\n",
            "Epoch 404/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4939 - val_loss: 0.6447\n",
            "Epoch 405/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4807 - val_loss: 0.6207\n",
            "Epoch 406/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5017 - val_loss: 0.6246\n",
            "Epoch 407/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4832 - val_loss: 0.5580\n",
            "Epoch 408/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4767 - val_loss: 0.6182\n",
            "Epoch 409/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4704 - val_loss: 0.6115\n",
            "Epoch 410/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4806 - val_loss: 0.5787\n",
            "Epoch 411/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4917 - val_loss: 0.6072\n",
            "Epoch 412/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4878 - val_loss: 0.5892\n",
            "Epoch 413/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5045 - val_loss: 0.6059\n",
            "Epoch 414/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4855 - val_loss: 0.6250\n",
            "Epoch 415/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4852 - val_loss: 0.5876\n",
            "Epoch 416/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.5863\n",
            "Epoch 417/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4699 - val_loss: 0.6015\n",
            "Epoch 418/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4804 - val_loss: 0.6075\n",
            "Epoch 419/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4793 - val_loss: 0.6479\n",
            "Epoch 420/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4829 - val_loss: 0.6066\n",
            "Epoch 421/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4796 - val_loss: 0.5942\n",
            "Epoch 422/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4722 - val_loss: 0.6141\n",
            "Epoch 423/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5112 - val_loss: 0.5954\n",
            "Epoch 424/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5006 - val_loss: 0.6572\n",
            "Epoch 425/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.6259\n",
            "Epoch 426/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.6083\n",
            "Epoch 427/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4665 - val_loss: 0.6051\n",
            "Epoch 428/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.6154\n",
            "Epoch 429/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4851 - val_loss: 0.6369\n",
            "Epoch 430/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4974 - val_loss: 0.6005\n",
            "Epoch 431/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4651 - val_loss: 0.5946\n",
            "Epoch 432/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5044 - val_loss: 0.5919\n",
            "Epoch 433/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.6192\n",
            "Epoch 434/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4750 - val_loss: 0.6099\n",
            "Epoch 435/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4906 - val_loss: 0.6293\n",
            "Epoch 436/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4661 - val_loss: 0.6357\n",
            "Epoch 437/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4809 - val_loss: 0.6076\n",
            "Epoch 438/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.6609\n",
            "Epoch 439/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4876 - val_loss: 0.6133\n",
            "Epoch 440/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4711 - val_loss: 0.6609\n",
            "Epoch 441/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 0.6070\n",
            "Epoch 442/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4686 - val_loss: 0.6024\n",
            "Epoch 443/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4807 - val_loss: 0.6006\n",
            "Epoch 444/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 0.6120\n",
            "Epoch 445/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.6655\n",
            "Epoch 446/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4656 - val_loss: 0.6254\n",
            "Epoch 447/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4990 - val_loss: 0.6711\n",
            "Epoch 448/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4807 - val_loss: 0.6239\n",
            "Epoch 449/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4830 - val_loss: 0.6006\n",
            "Epoch 450/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4603 - val_loss: 0.6086\n",
            "Epoch 451/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.6032\n",
            "Epoch 452/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.6083\n",
            "Epoch 453/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.5825\n",
            "Epoch 454/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4736 - val_loss: 0.6032\n",
            "Epoch 455/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5118 - val_loss: 0.6026\n",
            "Epoch 456/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4935 - val_loss: 0.6538\n",
            "Epoch 457/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4780 - val_loss: 0.6128\n",
            "Epoch 458/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4660 - val_loss: 0.5907\n",
            "Epoch 459/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5085 - val_loss: 0.6073\n",
            "Epoch 460/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.6212\n",
            "Epoch 461/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5011 - val_loss: 0.6716\n",
            "Epoch 462/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.6563\n",
            "Epoch 463/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.6147\n",
            "Epoch 464/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4779 - val_loss: 0.6101\n",
            "Epoch 465/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.5970\n",
            "Epoch 466/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.6018\n",
            "Epoch 467/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4706 - val_loss: 0.6118\n",
            "Epoch 468/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4834 - val_loss: 0.6059\n",
            "Epoch 469/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4757 - val_loss: 0.5971\n",
            "Epoch 470/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.6555\n",
            "Epoch 471/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4633 - val_loss: 0.6234\n",
            "Epoch 472/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4907 - val_loss: 0.5988\n",
            "Epoch 473/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4893 - val_loss: 0.6490\n",
            "Epoch 474/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4929 - val_loss: 0.6419\n",
            "Epoch 475/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4713 - val_loss: 0.5975\n",
            "Epoch 476/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 0.5921\n",
            "Epoch 477/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.6518\n",
            "Epoch 478/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4828 - val_loss: 0.6151\n",
            "Epoch 479/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.5970\n",
            "Epoch 480/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4802 - val_loss: 0.6240\n",
            "Epoch 481/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4714 - val_loss: 0.6798\n",
            "Epoch 482/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 0.6109\n",
            "Epoch 483/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 0.6109\n",
            "Epoch 484/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4885 - val_loss: 0.6268\n",
            "Epoch 485/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4985 - val_loss: 0.6088\n",
            "Epoch 486/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4828 - val_loss: 0.6110\n",
            "Epoch 487/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4487 - val_loss: 0.5940\n",
            "Epoch 488/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4621 - val_loss: 0.6109\n",
            "Epoch 489/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.7508\n",
            "Epoch 490/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4717 - val_loss: 0.6255\n",
            "Epoch 491/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.5914\n",
            "Epoch 492/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4669 - val_loss: 0.5877\n",
            "Epoch 493/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4704 - val_loss: 0.6185\n",
            "Epoch 494/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5162 - val_loss: 0.7049\n",
            "Epoch 495/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5357 - val_loss: 0.6268\n",
            "Epoch 496/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4976 - val_loss: 0.7585\n",
            "Epoch 497/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4963 - val_loss: 0.5789\n",
            "Epoch 498/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4706 - val_loss: 0.6028\n",
            "Epoch 499/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4914 - val_loss: 0.6399\n",
            "Epoch 500/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4726 - val_loss: 0.6117\n",
            "Epoch 501/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.6305\n",
            "Epoch 502/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.6071\n",
            "Epoch 503/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4586 - val_loss: 0.6206\n",
            "Epoch 504/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4855 - val_loss: 0.5975\n",
            "Epoch 505/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4697 - val_loss: 0.6339\n",
            "Epoch 506/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4951 - val_loss: 0.6643\n",
            "Epoch 507/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.5930\n",
            "Epoch 508/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4672 - val_loss: 0.5786\n",
            "Epoch 509/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4704 - val_loss: 0.6149\n",
            "Epoch 510/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.6520\n",
            "Epoch 511/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.6511\n",
            "Epoch 512/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5989\n",
            "Epoch 513/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.6512\n",
            "Epoch 514/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4987 - val_loss: 0.6233\n",
            "Epoch 515/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4648 - val_loss: 0.6424\n",
            "Epoch 516/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4869 - val_loss: 0.6228\n",
            "Epoch 517/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4852 - val_loss: 0.5858\n",
            "Epoch 518/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.6227\n",
            "Epoch 519/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.6074\n",
            "Epoch 520/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 0.5936\n",
            "Epoch 521/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4992 - val_loss: 0.6189\n",
            "Epoch 522/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.6181\n",
            "Epoch 523/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4878 - val_loss: 0.6186\n",
            "Epoch 524/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4906 - val_loss: 0.6115\n",
            "Epoch 525/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 0.6197\n",
            "Epoch 526/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4701 - val_loss: 0.5970\n",
            "Epoch 527/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4738 - val_loss: 0.5895\n",
            "Epoch 528/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.6245\n",
            "Epoch 529/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 0.5709\n",
            "Epoch 530/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.6184\n",
            "Epoch 531/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4733 - val_loss: 0.6066\n",
            "Epoch 532/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4870 - val_loss: 0.5925\n",
            "Epoch 533/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.6131\n",
            "Epoch 534/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5037 - val_loss: 0.6137\n",
            "Epoch 535/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4653 - val_loss: 0.6186\n",
            "Epoch 536/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4780 - val_loss: 0.6076\n",
            "Epoch 537/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4886 - val_loss: 0.5870\n",
            "Epoch 538/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 0.6129\n",
            "Epoch 539/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4676 - val_loss: 0.6228\n",
            "Epoch 540/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 0.6420\n",
            "Epoch 541/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4726 - val_loss: 0.6191\n",
            "Epoch 542/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4598 - val_loss: 0.6082\n",
            "Epoch 543/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4624 - val_loss: 0.5899\n",
            "Epoch 544/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4699 - val_loss: 0.6009\n",
            "Epoch 545/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 0.5906\n",
            "Epoch 546/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.6759\n",
            "Epoch 547/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4609 - val_loss: 0.6544\n",
            "Epoch 548/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4762 - val_loss: 0.5844\n",
            "Epoch 549/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5084 - val_loss: 0.6318\n",
            "Epoch 550/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4937 - val_loss: 0.5818\n",
            "Epoch 551/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.6164\n",
            "Epoch 552/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.6091\n",
            "Epoch 553/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5133 - val_loss: 0.6078\n",
            "Epoch 554/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4774 - val_loss: 0.5685\n",
            "Epoch 555/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4737 - val_loss: 0.5753\n",
            "Epoch 556/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4564 - val_loss: 0.6006\n",
            "Epoch 557/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4593 - val_loss: 0.5766\n",
            "Epoch 558/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.6058\n",
            "Epoch 559/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.5907\n",
            "Epoch 560/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4589 - val_loss: 0.6412\n",
            "Epoch 561/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.5961\n",
            "Epoch 562/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.6095\n",
            "Epoch 563/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4730 - val_loss: 0.6105\n",
            "Epoch 564/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4710 - val_loss: 0.6425\n",
            "Epoch 565/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.6412\n",
            "Epoch 566/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.6091\n",
            "Epoch 567/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.5997\n",
            "Epoch 568/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4561 - val_loss: 0.6169\n",
            "Epoch 569/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.6587\n",
            "Epoch 570/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4659 - val_loss: 0.6104\n",
            "Epoch 571/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5942\n",
            "Epoch 572/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4577 - val_loss: 0.6147\n",
            "Epoch 573/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4704 - val_loss: 0.6353\n",
            "Epoch 574/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 0.6603\n",
            "Epoch 575/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5093 - val_loss: 0.6001\n",
            "Epoch 576/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.6242\n",
            "Epoch 577/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.6555\n",
            "Epoch 578/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4762 - val_loss: 0.6359\n",
            "Epoch 579/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4663 - val_loss: 0.5991\n",
            "Epoch 580/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.6304\n",
            "Epoch 581/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4544 - val_loss: 0.6258\n",
            "Epoch 582/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.6078\n",
            "Epoch 583/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.6350\n",
            "Epoch 584/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4661 - val_loss: 0.6122\n",
            "Epoch 585/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.6920\n",
            "Epoch 586/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4726 - val_loss: 0.6248\n",
            "Epoch 587/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4858 - val_loss: 0.6014\n",
            "Epoch 588/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4839 - val_loss: 0.6163\n",
            "Epoch 589/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.6193\n",
            "Epoch 590/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4651 - val_loss: 0.6145\n",
            "Epoch 591/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.6291\n",
            "Epoch 592/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4985 - val_loss: 0.5956\n",
            "Epoch 593/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4656 - val_loss: 0.6085\n",
            "Epoch 594/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4603 - val_loss: 0.6031\n",
            "Epoch 595/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4715 - val_loss: 0.6629\n",
            "Epoch 596/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4710 - val_loss: 0.6152\n",
            "Epoch 597/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4790 - val_loss: 0.6098\n",
            "Epoch 598/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4701 - val_loss: 0.6373\n",
            "Epoch 599/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 0.6055\n",
            "Epoch 600/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4804 - val_loss: 0.5718\n",
            "Epoch 601/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4487 - val_loss: 0.6726\n",
            "Epoch 602/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.6281\n",
            "Epoch 603/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.6432\n",
            "Epoch 604/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.6133\n",
            "Epoch 605/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.5908\n",
            "Epoch 606/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.5900\n",
            "Epoch 607/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 0.6123\n",
            "Epoch 608/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.5963\n",
            "Epoch 609/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4748 - val_loss: 0.6136\n",
            "Epoch 610/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.6195\n",
            "Epoch 611/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.6375\n",
            "Epoch 612/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4734 - val_loss: 0.5935\n",
            "Epoch 613/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.5795\n",
            "Epoch 614/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4979 - val_loss: 0.6117\n",
            "Epoch 615/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.5879\n",
            "Epoch 616/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4942 - val_loss: 0.6099\n",
            "Epoch 617/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4683 - val_loss: 0.6508\n",
            "Epoch 618/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.6012\n",
            "Epoch 619/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4690 - val_loss: 0.6167\n",
            "Epoch 620/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4715 - val_loss: 0.6207\n",
            "Epoch 621/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.6153\n",
            "Epoch 622/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4646 - val_loss: 0.6571\n",
            "Epoch 623/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 0.6195\n",
            "Epoch 624/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.6349\n",
            "Epoch 625/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4621 - val_loss: 0.5949\n",
            "Epoch 626/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4683 - val_loss: 0.6127\n",
            "Epoch 627/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4674 - val_loss: 0.6324\n",
            "Epoch 628/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4835 - val_loss: 0.6305\n",
            "Epoch 629/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4794 - val_loss: 0.6686\n",
            "Epoch 630/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 0.6108\n",
            "Epoch 631/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4566 - val_loss: 0.6950\n",
            "Epoch 632/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.6579\n",
            "Epoch 633/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.6356\n",
            "Epoch 634/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4488 - val_loss: 0.6452\n",
            "Epoch 635/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.5954\n",
            "Epoch 636/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4550 - val_loss: 0.6091\n",
            "Epoch 637/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4694 - val_loss: 0.6257\n",
            "Epoch 638/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4704 - val_loss: 0.6086\n",
            "Epoch 639/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4647 - val_loss: 0.6034\n",
            "Epoch 640/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4707 - val_loss: 0.6038\n",
            "Epoch 641/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 0.5881\n",
            "Epoch 642/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4685 - val_loss: 0.6530\n",
            "Epoch 643/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 0.6318\n",
            "Epoch 644/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4739 - val_loss: 0.6369\n",
            "Epoch 645/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4720 - val_loss: 0.6178\n",
            "Epoch 646/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4729 - val_loss: 0.6304\n",
            "Epoch 647/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4523 - val_loss: 0.6130\n",
            "Epoch 648/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.6067\n",
            "Epoch 649/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 0.6194\n",
            "Epoch 650/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4619 - val_loss: 0.5983\n",
            "Epoch 651/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4946 - val_loss: 0.5935\n",
            "Epoch 652/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4719 - val_loss: 0.6049\n",
            "Epoch 653/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4503 - val_loss: 0.5896\n",
            "Epoch 654/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4529 - val_loss: 0.6148\n",
            "Epoch 655/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4455 - val_loss: 0.6483\n",
            "Epoch 656/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.6187\n",
            "Epoch 657/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.6408\n",
            "Epoch 658/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4533 - val_loss: 0.6526\n",
            "Epoch 659/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.6027\n",
            "Epoch 660/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4663 - val_loss: 0.6942\n",
            "Epoch 661/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4945 - val_loss: 0.6063\n",
            "Epoch 662/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.6048\n",
            "Epoch 663/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4421 - val_loss: 0.6135\n",
            "Epoch 664/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 0.6333\n",
            "Epoch 665/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4878 - val_loss: 0.6641\n",
            "Epoch 666/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4848 - val_loss: 0.6446\n",
            "Epoch 667/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.6186\n",
            "Epoch 668/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.6264\n",
            "Epoch 669/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4541 - val_loss: 0.6356\n",
            "Epoch 670/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4556 - val_loss: 0.5801\n",
            "Epoch 671/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4537 - val_loss: 0.6436\n",
            "Epoch 672/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4722 - val_loss: 0.6062\n",
            "Epoch 673/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 0.6473\n",
            "Epoch 674/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4926 - val_loss: 0.6938\n",
            "Epoch 675/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.6190\n",
            "Epoch 676/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4537 - val_loss: 0.6234\n",
            "Epoch 677/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4543 - val_loss: 0.6178\n",
            "Epoch 678/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4509 - val_loss: 0.5970\n",
            "Epoch 679/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.6271\n",
            "Epoch 680/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4618 - val_loss: 0.6285\n",
            "Epoch 681/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4665 - val_loss: 0.6347\n",
            "Epoch 682/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4902 - val_loss: 0.6506\n",
            "Epoch 683/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4688 - val_loss: 0.6355\n",
            "Epoch 684/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4671 - val_loss: 0.6633\n",
            "Epoch 685/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.6640\n",
            "Epoch 686/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4493 - val_loss: 0.6506\n",
            "Epoch 687/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 0.6243\n",
            "Epoch 688/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4515 - val_loss: 0.6119\n",
            "Epoch 689/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.6408\n",
            "Epoch 690/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4730 - val_loss: 0.6110\n",
            "Epoch 691/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4837 - val_loss: 0.6072\n",
            "Epoch 692/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.6188\n",
            "Epoch 693/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4523 - val_loss: 0.6122\n",
            "Epoch 694/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.6056\n",
            "Epoch 695/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4410 - val_loss: 0.6193\n",
            "Epoch 696/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.6532\n",
            "Epoch 697/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.5922\n",
            "Epoch 698/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4488 - val_loss: 0.6378\n",
            "Epoch 699/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4638 - val_loss: 0.6412\n",
            "Epoch 700/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4773 - val_loss: 0.6360\n",
            "Epoch 701/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.6686\n",
            "Epoch 702/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4515 - val_loss: 0.6126\n",
            "Epoch 703/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.6585\n",
            "Epoch 704/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 0.5986\n",
            "Epoch 705/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.6224\n",
            "Epoch 706/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4672 - val_loss: 0.6230\n",
            "Epoch 707/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 0.5920\n",
            "Epoch 708/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4466 - val_loss: 0.6319\n",
            "Epoch 709/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.6378\n",
            "Epoch 710/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4735 - val_loss: 0.6591\n",
            "Epoch 711/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 0.6338\n",
            "Epoch 712/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.6004\n",
            "Epoch 713/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4491 - val_loss: 0.6350\n",
            "Epoch 714/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.6280\n",
            "Epoch 715/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4686 - val_loss: 0.6023\n",
            "Epoch 716/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.6122\n",
            "Epoch 717/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4544 - val_loss: 0.6083\n",
            "Epoch 718/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.6686\n",
            "Epoch 719/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4605 - val_loss: 0.6496\n",
            "Epoch 720/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4621 - val_loss: 0.6271\n",
            "Epoch 721/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4833 - val_loss: 0.6537\n",
            "Epoch 722/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4658 - val_loss: 0.6500\n",
            "Epoch 723/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4639 - val_loss: 0.6387\n",
            "Epoch 724/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4633 - val_loss: 0.6306\n",
            "Epoch 725/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.6304\n",
            "Epoch 726/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.6861\n",
            "Epoch 727/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4796 - val_loss: 0.6559\n",
            "Epoch 728/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.6237\n",
            "Epoch 729/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4515 - val_loss: 0.6443\n",
            "Epoch 730/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.6271\n",
            "Epoch 731/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4564 - val_loss: 0.6113\n",
            "Epoch 732/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 0.5989\n",
            "Epoch 733/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.6905\n",
            "Epoch 734/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.6324\n",
            "Epoch 735/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.6291\n",
            "Epoch 736/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.6495\n",
            "Epoch 737/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4618 - val_loss: 0.6391\n",
            "Epoch 738/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.6087\n",
            "Epoch 739/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4659 - val_loss: 0.6090\n",
            "Epoch 740/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.6013\n",
            "Epoch 741/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.6062\n",
            "Epoch 742/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4535 - val_loss: 0.6573\n",
            "Epoch 743/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4750 - val_loss: 0.6353\n",
            "Epoch 744/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.6218\n",
            "Epoch 745/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.6268\n",
            "Epoch 746/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4767 - val_loss: 0.6221\n",
            "Epoch 747/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4656 - val_loss: 0.6336\n",
            "Epoch 748/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.6287\n",
            "Epoch 749/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4456 - val_loss: 0.6168\n",
            "Epoch 750/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.6024\n",
            "Epoch 751/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4603 - val_loss: 0.6074\n",
            "Epoch 752/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.6134\n",
            "Epoch 753/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4530 - val_loss: 0.6282\n",
            "Epoch 754/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.6004\n",
            "Epoch 755/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4459 - val_loss: 0.6714\n",
            "Epoch 756/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4767 - val_loss: 0.6091\n",
            "Epoch 757/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.6120\n",
            "Epoch 758/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4441 - val_loss: 0.6455\n",
            "Epoch 759/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4618 - val_loss: 0.6334\n",
            "Epoch 760/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4636 - val_loss: 0.6310\n",
            "Epoch 761/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4556 - val_loss: 0.6308\n",
            "Epoch 762/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4566 - val_loss: 0.6108\n",
            "Epoch 763/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.6262\n",
            "Epoch 764/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4719 - val_loss: 0.6399\n",
            "Epoch 765/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 0.6279\n",
            "Epoch 766/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4447 - val_loss: 0.6021\n",
            "Epoch 767/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4533 - val_loss: 0.6198\n",
            "Epoch 768/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4481 - val_loss: 0.6851\n",
            "Epoch 769/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4619 - val_loss: 0.6620\n",
            "Epoch 770/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.6799\n",
            "Epoch 771/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5161 - val_loss: 0.7043\n",
            "Epoch 772/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.6181\n",
            "Epoch 773/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4587 - val_loss: 0.6253\n",
            "Epoch 774/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4518 - val_loss: 0.6270\n",
            "Epoch 775/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.5992\n",
            "Epoch 776/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4675 - val_loss: 0.6697\n",
            "Epoch 777/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.6736\n",
            "Epoch 778/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.6685\n",
            "Epoch 779/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4831 - val_loss: 0.6105\n",
            "Epoch 780/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.6026\n",
            "Epoch 781/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4461 - val_loss: 0.6358\n",
            "Epoch 782/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4503 - val_loss: 0.6545\n",
            "Epoch 783/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4691 - val_loss: 0.6245\n",
            "Epoch 784/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.6232\n",
            "Epoch 785/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.6656\n",
            "Epoch 786/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4814 - val_loss: 0.6186\n",
            "Epoch 787/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4514 - val_loss: 0.6392\n",
            "Epoch 788/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4492 - val_loss: 0.6396\n",
            "Epoch 789/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.6670\n",
            "Epoch 790/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4647 - val_loss: 0.5936\n",
            "Epoch 791/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4523 - val_loss: 0.5976\n",
            "Epoch 792/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4514 - val_loss: 0.5972\n",
            "Epoch 793/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.6228\n",
            "Epoch 794/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4545 - val_loss: 0.6436\n",
            "Epoch 795/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.5933\n",
            "Epoch 796/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4541 - val_loss: 0.6145\n",
            "Epoch 797/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4638 - val_loss: 0.6490\n",
            "Epoch 798/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4519 - val_loss: 0.6237\n",
            "Epoch 799/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4532 - val_loss: 0.6198\n",
            "Epoch 800/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.6254\n",
            "Epoch 801/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4605 - val_loss: 0.6250\n",
            "Epoch 802/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.6292\n",
            "Epoch 803/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.6205\n",
            "Epoch 804/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4494 - val_loss: 0.6147\n",
            "Epoch 805/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4457 - val_loss: 0.6559\n",
            "Epoch 806/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4533 - val_loss: 0.6104\n",
            "Epoch 807/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4537 - val_loss: 0.6033\n",
            "Epoch 808/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.6419\n",
            "Epoch 809/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4683 - val_loss: 0.6563\n",
            "Epoch 810/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 0.6295\n",
            "Epoch 811/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 0.6286\n",
            "Epoch 812/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4508 - val_loss: 0.6725\n",
            "Epoch 813/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4791 - val_loss: 0.6401\n",
            "Epoch 814/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.6068\n",
            "Epoch 815/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.6492\n",
            "Epoch 816/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.6519\n",
            "Epoch 817/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4691 - val_loss: 0.6517\n",
            "Epoch 818/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 0.6233\n",
            "Epoch 819/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4620 - val_loss: 0.6310\n",
            "Epoch 820/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.6168\n",
            "Epoch 821/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.6689\n",
            "Epoch 822/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.6445\n",
            "Epoch 823/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 0.5976\n",
            "Epoch 824/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.6031\n",
            "Epoch 825/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.6208\n",
            "Epoch 826/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4500 - val_loss: 0.6195\n",
            "Epoch 827/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4459 - val_loss: 0.6160\n",
            "Epoch 828/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.6154\n",
            "Epoch 829/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4545 - val_loss: 0.6020\n",
            "Epoch 830/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4604 - val_loss: 0.6083\n",
            "Epoch 831/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.6242\n",
            "Epoch 832/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4720 - val_loss: 0.6200\n",
            "Epoch 833/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4612 - val_loss: 0.6223\n",
            "Epoch 834/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4706 - val_loss: 0.6288\n",
            "Epoch 835/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4419 - val_loss: 0.6278\n",
            "Epoch 836/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.6007\n",
            "Epoch 837/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4469 - val_loss: 0.6789\n",
            "Epoch 838/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4427 - val_loss: 0.6171\n",
            "Epoch 839/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4460 - val_loss: 0.6228\n",
            "Epoch 840/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5064 - val_loss: 0.6157\n",
            "Epoch 841/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.6256\n",
            "Epoch 842/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4525 - val_loss: 0.6182\n",
            "Epoch 843/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.6403\n",
            "Epoch 844/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.6527\n",
            "Epoch 845/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5033 - val_loss: 0.6121\n",
            "Epoch 846/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.6057\n",
            "Epoch 847/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4492 - val_loss: 0.5959\n",
            "Epoch 848/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4575 - val_loss: 0.6201\n",
            "Epoch 849/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4502 - val_loss: 0.6052\n",
            "Epoch 850/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4521 - val_loss: 0.6569\n",
            "Epoch 851/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4442 - val_loss: 0.6357\n",
            "Epoch 852/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4485 - val_loss: 0.6480\n",
            "Epoch 853/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.6164\n",
            "Epoch 854/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.7311\n",
            "Epoch 855/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5334 - val_loss: 0.6291\n",
            "Epoch 856/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4944 - val_loss: 0.6275\n",
            "Epoch 857/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.6341\n",
            "Epoch 858/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4598 - val_loss: 0.5939\n",
            "Epoch 859/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4723 - val_loss: 0.6090\n",
            "Epoch 860/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.6507\n",
            "Epoch 861/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.6117\n",
            "Epoch 862/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 0.6072\n",
            "Epoch 863/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.6197\n",
            "Epoch 864/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.6178\n",
            "Epoch 865/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.6054\n",
            "Epoch 866/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4492 - val_loss: 0.6035\n",
            "Epoch 867/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.6243\n",
            "Epoch 868/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4441 - val_loss: 0.6071\n",
            "Epoch 869/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4497 - val_loss: 0.6376\n",
            "Epoch 870/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4627 - val_loss: 0.6271\n",
            "Epoch 871/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4467 - val_loss: 0.6678\n",
            "Epoch 872/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4488 - val_loss: 0.6128\n",
            "Epoch 873/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4455 - val_loss: 0.6148\n",
            "Epoch 874/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4345 - val_loss: 0.6027\n",
            "Epoch 875/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.6525\n",
            "Epoch 876/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4672 - val_loss: 0.6390\n",
            "Epoch 877/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.6240\n",
            "Epoch 878/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.6212\n",
            "Epoch 879/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4523 - val_loss: 0.6035\n",
            "Epoch 880/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4564 - val_loss: 0.6357\n",
            "Epoch 881/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4929 - val_loss: 0.5988\n",
            "Epoch 882/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.6112\n",
            "Epoch 883/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.5836\n",
            "Epoch 884/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4546 - val_loss: 0.6592\n",
            "Epoch 885/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4482 - val_loss: 0.6346\n",
            "Epoch 886/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4501 - val_loss: 0.6107\n",
            "Epoch 887/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4440 - val_loss: 0.6302\n",
            "Epoch 888/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4507 - val_loss: 0.6393\n",
            "Epoch 889/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4804 - val_loss: 0.6109\n",
            "Epoch 890/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4434 - val_loss: 0.6223\n",
            "Epoch 891/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.6375\n",
            "Epoch 892/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4534 - val_loss: 0.5859\n",
            "Epoch 893/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.6255\n",
            "Epoch 894/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4451 - val_loss: 0.5840\n",
            "Epoch 895/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4544 - val_loss: 0.6046\n",
            "Epoch 896/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4474 - val_loss: 0.6272\n",
            "Epoch 897/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.6263\n",
            "Epoch 898/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 0.6545\n",
            "Epoch 899/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4633 - val_loss: 0.5890\n",
            "Epoch 900/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4726 - val_loss: 0.6421\n",
            "Epoch 901/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4637 - val_loss: 0.6343\n",
            "Epoch 902/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4580 - val_loss: 0.6239\n",
            "Epoch 903/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4513 - val_loss: 0.6658\n",
            "Epoch 904/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.6222\n",
            "Epoch 905/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4498 - val_loss: 0.6299\n",
            "Epoch 906/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.6560\n",
            "Epoch 907/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4605 - val_loss: 0.6103\n",
            "Epoch 908/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.6257\n",
            "Epoch 909/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4495 - val_loss: 0.6114\n",
            "Epoch 910/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4490 - val_loss: 0.6526\n",
            "Epoch 911/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.6129\n",
            "Epoch 912/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.6352\n",
            "Epoch 913/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4447 - val_loss: 0.6492\n",
            "Epoch 914/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4522 - val_loss: 0.5961\n",
            "Epoch 915/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4592 - val_loss: 0.6057\n",
            "Epoch 916/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4467 - val_loss: 0.6895\n",
            "Epoch 917/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.6207\n",
            "Epoch 918/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4449 - val_loss: 0.6483\n",
            "Epoch 919/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4474 - val_loss: 0.6378\n",
            "Epoch 920/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4720 - val_loss: 0.6171\n",
            "Epoch 921/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.6377\n",
            "Epoch 922/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.6095\n",
            "Epoch 923/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4465 - val_loss: 0.6286\n",
            "Epoch 924/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4469 - val_loss: 0.6632\n",
            "Epoch 925/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4686 - val_loss: 0.6193\n",
            "Epoch 926/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4446 - val_loss: 0.5980\n",
            "Epoch 927/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4422 - val_loss: 0.6050\n",
            "Epoch 928/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4748 - val_loss: 0.6078\n",
            "Epoch 929/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4311 - val_loss: 0.5963\n",
            "Epoch 930/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4345 - val_loss: 0.6246\n",
            "Epoch 931/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4685 - val_loss: 0.6142\n",
            "Epoch 932/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4689 - val_loss: 0.6349\n",
            "Epoch 933/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4687 - val_loss: 0.6257\n",
            "Epoch 934/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.6241\n",
            "Epoch 935/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4390 - val_loss: 0.6023\n",
            "Epoch 936/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4513 - val_loss: 0.6545\n",
            "Epoch 937/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.6054\n",
            "Epoch 938/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 0.6489\n",
            "Epoch 939/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4545 - val_loss: 0.6283\n",
            "Epoch 940/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4248 - val_loss: 0.6056\n",
            "Epoch 941/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4445 - val_loss: 0.6228\n",
            "Epoch 942/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4630 - val_loss: 0.6185\n",
            "Epoch 943/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4504 - val_loss: 0.6259\n",
            "Epoch 944/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.6185\n",
            "Epoch 945/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4449 - val_loss: 0.6257\n",
            "Epoch 946/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4508 - val_loss: 0.6253\n",
            "Epoch 947/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4525 - val_loss: 0.6061\n",
            "Epoch 948/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4701 - val_loss: 0.6144\n",
            "Epoch 949/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.6313\n",
            "Epoch 950/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4544 - val_loss: 0.6588\n",
            "Epoch 951/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.6217\n",
            "Epoch 952/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4750 - val_loss: 0.6034\n",
            "Epoch 953/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4579 - val_loss: 0.5936\n",
            "Epoch 954/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4521 - val_loss: 0.6321\n",
            "Epoch 955/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4416 - val_loss: 0.6335\n",
            "Epoch 956/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4432 - val_loss: 0.6742\n",
            "Epoch 957/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4525 - val_loss: 0.6133\n",
            "Epoch 958/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.6743\n",
            "Epoch 959/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4407 - val_loss: 0.5754\n",
            "Epoch 960/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4791 - val_loss: 0.6889\n",
            "Epoch 961/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4489 - val_loss: 0.6271\n",
            "Epoch 962/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4493 - val_loss: 0.6243\n",
            "Epoch 963/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4522 - val_loss: 0.6483\n",
            "Epoch 964/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4467 - val_loss: 0.6288\n",
            "Epoch 965/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4485 - val_loss: 0.6434\n",
            "Epoch 966/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4609 - val_loss: 0.5993\n",
            "Epoch 967/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.5925\n",
            "Epoch 968/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4618 - val_loss: 0.6033\n",
            "Epoch 969/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4483 - val_loss: 0.6223\n",
            "Epoch 970/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4438 - val_loss: 0.6009\n",
            "Epoch 971/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.6163\n",
            "Epoch 972/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4669 - val_loss: 0.5932\n",
            "Epoch 973/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4625 - val_loss: 0.6103\n",
            "Epoch 974/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.6129\n",
            "Epoch 975/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4459 - val_loss: 0.6333\n",
            "Epoch 976/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.6212\n",
            "Epoch 977/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 0.5905\n",
            "Epoch 978/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.6365\n",
            "Epoch 979/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4488 - val_loss: 0.6579\n",
            "Epoch 980/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4462 - val_loss: 0.6188\n",
            "Epoch 981/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4533 - val_loss: 0.6926\n",
            "Epoch 982/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 0.6195\n",
            "Epoch 983/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4474 - val_loss: 0.6200\n",
            "Epoch 984/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.6113\n",
            "Epoch 985/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4453 - val_loss: 0.6437\n",
            "Epoch 986/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4486 - val_loss: 0.5948\n",
            "Epoch 987/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.6461\n",
            "Epoch 988/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.7177\n",
            "Epoch 989/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4877 - val_loss: 0.6302\n",
            "Epoch 990/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.6184\n",
            "Epoch 991/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4346 - val_loss: 0.6254\n",
            "Epoch 992/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.6090\n",
            "Epoch 993/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4762 - val_loss: 0.5972\n",
            "Epoch 994/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4566 - val_loss: 0.6070\n",
            "Epoch 995/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.6349\n",
            "Epoch 996/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 0.6056\n",
            "Epoch 997/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.6264\n",
            "Epoch 998/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4451 - val_loss: 0.6209\n",
            "Epoch 999/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4851 - val_loss: 0.6079\n",
            "Epoch 1000/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4390 - val_loss: 0.5859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lolMZG14vz8R"
      },
      "source": [
        "####Adamax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZxq2_Dwv2Pl",
        "outputId": "0bc5f0bd-5abb-43b1-d50e-f38d8bb44e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wide_opt3(opt_Adamax)"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.9389 - val_loss: 0.8971\n",
            "Epoch 2/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8419 - val_loss: 0.8056\n",
            "Epoch 3/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7377 - val_loss: 0.7243\n",
            "Epoch 4/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6544 - val_loss: 0.6779\n",
            "Epoch 5/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6058 - val_loss: 0.6574\n",
            "Epoch 6/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5810 - val_loss: 0.6476\n",
            "Epoch 7/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5684 - val_loss: 0.6429\n",
            "Epoch 8/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5611 - val_loss: 0.6402\n",
            "Epoch 9/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5578 - val_loss: 0.6389\n",
            "Epoch 10/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5544 - val_loss: 0.6380\n",
            "Epoch 11/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5528 - val_loss: 0.6368\n",
            "Epoch 12/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5502 - val_loss: 0.6343\n",
            "Epoch 13/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5496 - val_loss: 0.6336\n",
            "Epoch 14/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5481 - val_loss: 0.6322\n",
            "Epoch 15/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5472 - val_loss: 0.6321\n",
            "Epoch 16/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5463 - val_loss: 0.6307\n",
            "Epoch 17/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5457 - val_loss: 0.6293\n",
            "Epoch 18/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5452 - val_loss: 0.6271\n",
            "Epoch 19/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5446 - val_loss: 0.6262\n",
            "Epoch 20/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5434 - val_loss: 0.6245\n",
            "Epoch 21/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5427 - val_loss: 0.6233\n",
            "Epoch 22/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5431 - val_loss: 0.6228\n",
            "Epoch 23/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5413 - val_loss: 0.6226\n",
            "Epoch 24/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5411 - val_loss: 0.6215\n",
            "Epoch 25/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5411 - val_loss: 0.6215\n",
            "Epoch 26/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5404 - val_loss: 0.6201\n",
            "Epoch 27/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5394 - val_loss: 0.6210\n",
            "Epoch 28/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5395 - val_loss: 0.6187\n",
            "Epoch 29/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5384 - val_loss: 0.6179\n",
            "Epoch 30/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5372 - val_loss: 0.6159\n",
            "Epoch 31/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5373 - val_loss: 0.6153\n",
            "Epoch 32/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5366 - val_loss: 0.6154\n",
            "Epoch 33/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5366 - val_loss: 0.6156\n",
            "Epoch 34/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5363 - val_loss: 0.6135\n",
            "Epoch 35/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5357 - val_loss: 0.6128\n",
            "Epoch 36/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5352 - val_loss: 0.6123\n",
            "Epoch 37/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5354 - val_loss: 0.6119\n",
            "Epoch 38/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5344 - val_loss: 0.6112\n",
            "Epoch 39/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5333 - val_loss: 0.6113\n",
            "Epoch 40/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5329 - val_loss: 0.6099\n",
            "Epoch 41/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5329 - val_loss: 0.6103\n",
            "Epoch 42/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5326 - val_loss: 0.6083\n",
            "Epoch 43/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5321 - val_loss: 0.6088\n",
            "Epoch 44/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5316 - val_loss: 0.6090\n",
            "Epoch 45/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5311 - val_loss: 0.6084\n",
            "Epoch 46/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5306 - val_loss: 0.6095\n",
            "Epoch 47/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5303 - val_loss: 0.6068\n",
            "Epoch 48/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5303 - val_loss: 0.6069\n",
            "Epoch 49/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5294 - val_loss: 0.6068\n",
            "Epoch 50/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5298 - val_loss: 0.6067\n",
            "Epoch 51/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 0.6051\n",
            "Epoch 52/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 0.6053\n",
            "Epoch 53/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5283 - val_loss: 0.6040\n",
            "Epoch 54/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5278 - val_loss: 0.6051\n",
            "Epoch 55/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5277 - val_loss: 0.6037\n",
            "Epoch 56/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 0.6045\n",
            "Epoch 57/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5270 - val_loss: 0.6034\n",
            "Epoch 58/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 0.6012\n",
            "Epoch 59/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 0.6020\n",
            "Epoch 60/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 0.6024\n",
            "Epoch 61/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 0.6020\n",
            "Epoch 62/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 0.6026\n",
            "Epoch 63/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 0.6016\n",
            "Epoch 64/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 0.6007\n",
            "Epoch 65/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 0.6002\n",
            "Epoch 66/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 0.5999\n",
            "Epoch 67/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5247 - val_loss: 0.6002\n",
            "Epoch 68/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 0.5987\n",
            "Epoch 69/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 0.5992\n",
            "Epoch 70/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5235 - val_loss: 0.5989\n",
            "Epoch 71/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.5992\n",
            "Epoch 72/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.5989\n",
            "Epoch 73/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5221 - val_loss: 0.5982\n",
            "Epoch 74/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5222 - val_loss: 0.5975\n",
            "Epoch 75/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5225 - val_loss: 0.6006\n",
            "Epoch 76/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5215 - val_loss: 0.5984\n",
            "Epoch 77/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5213 - val_loss: 0.5984\n",
            "Epoch 78/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5220 - val_loss: 0.5979\n",
            "Epoch 79/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5210 - val_loss: 0.5982\n",
            "Epoch 80/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5204 - val_loss: 0.5972\n",
            "Epoch 81/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5209 - val_loss: 0.5963\n",
            "Epoch 82/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5201 - val_loss: 0.5969\n",
            "Epoch 83/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5210 - val_loss: 0.5956\n",
            "Epoch 84/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5198 - val_loss: 0.5956\n",
            "Epoch 85/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5198 - val_loss: 0.5962\n",
            "Epoch 86/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5207 - val_loss: 0.5965\n",
            "Epoch 87/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5195 - val_loss: 0.5948\n",
            "Epoch 88/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5191 - val_loss: 0.5951\n",
            "Epoch 89/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5186 - val_loss: 0.5944\n",
            "Epoch 90/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5183 - val_loss: 0.5935\n",
            "Epoch 91/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5186 - val_loss: 0.5949\n",
            "Epoch 92/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5177 - val_loss: 0.5941\n",
            "Epoch 93/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5179 - val_loss: 0.5947\n",
            "Epoch 94/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5179 - val_loss: 0.5950\n",
            "Epoch 95/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5174 - val_loss: 0.5947\n",
            "Epoch 96/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5168 - val_loss: 0.5947\n",
            "Epoch 97/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5163 - val_loss: 0.5930\n",
            "Epoch 98/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5164 - val_loss: 0.5936\n",
            "Epoch 99/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5172 - val_loss: 0.5934\n",
            "Epoch 100/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5162 - val_loss: 0.5935\n",
            "Epoch 101/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5167 - val_loss: 0.5932\n",
            "Epoch 102/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5156 - val_loss: 0.5946\n",
            "Epoch 103/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5151 - val_loss: 0.5926\n",
            "Epoch 104/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5149 - val_loss: 0.5918\n",
            "Epoch 105/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5148 - val_loss: 0.5920\n",
            "Epoch 106/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5147 - val_loss: 0.5926\n",
            "Epoch 107/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5144 - val_loss: 0.5912\n",
            "Epoch 108/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5147 - val_loss: 0.5926\n",
            "Epoch 109/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5144 - val_loss: 0.5927\n",
            "Epoch 110/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5142 - val_loss: 0.5913\n",
            "Epoch 111/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5143 - val_loss: 0.5922\n",
            "Epoch 112/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5141 - val_loss: 0.5909\n",
            "Epoch 113/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5130 - val_loss: 0.5905\n",
            "Epoch 114/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5128 - val_loss: 0.5916\n",
            "Epoch 115/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5127 - val_loss: 0.5900\n",
            "Epoch 116/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5127 - val_loss: 0.5905\n",
            "Epoch 117/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5123 - val_loss: 0.5904\n",
            "Epoch 118/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5126 - val_loss: 0.5904\n",
            "Epoch 119/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5124 - val_loss: 0.5887\n",
            "Epoch 120/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5117 - val_loss: 0.5898\n",
            "Epoch 121/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5121 - val_loss: 0.5890\n",
            "Epoch 122/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5116 - val_loss: 0.5903\n",
            "Epoch 123/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5116 - val_loss: 0.5895\n",
            "Epoch 124/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5114 - val_loss: 0.5894\n",
            "Epoch 125/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5111 - val_loss: 0.5898\n",
            "Epoch 126/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5113 - val_loss: 0.5899\n",
            "Epoch 127/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5112 - val_loss: 0.5878\n",
            "Epoch 128/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5101 - val_loss: 0.5888\n",
            "Epoch 129/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5101 - val_loss: 0.5881\n",
            "Epoch 130/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5103 - val_loss: 0.5886\n",
            "Epoch 131/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5099 - val_loss: 0.5895\n",
            "Epoch 132/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5103 - val_loss: 0.5884\n",
            "Epoch 133/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5093 - val_loss: 0.5886\n",
            "Epoch 134/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5096 - val_loss: 0.5884\n",
            "Epoch 135/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5085 - val_loss: 0.5883\n",
            "Epoch 136/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5083 - val_loss: 0.5890\n",
            "Epoch 137/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5084 - val_loss: 0.5883\n",
            "Epoch 138/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5082 - val_loss: 0.5877\n",
            "Epoch 139/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5085 - val_loss: 0.5871\n",
            "Epoch 140/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5075 - val_loss: 0.5877\n",
            "Epoch 141/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5088 - val_loss: 0.5870\n",
            "Epoch 142/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5075 - val_loss: 0.5868\n",
            "Epoch 143/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5077 - val_loss: 0.5862\n",
            "Epoch 144/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5075 - val_loss: 0.5880\n",
            "Epoch 145/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5079 - val_loss: 0.5872\n",
            "Epoch 146/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5082 - val_loss: 0.5869\n",
            "Epoch 147/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5077 - val_loss: 0.5877\n",
            "Epoch 148/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5075 - val_loss: 0.5880\n",
            "Epoch 149/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5069 - val_loss: 0.5860\n",
            "Epoch 150/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5068 - val_loss: 0.5880\n",
            "Epoch 151/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5066 - val_loss: 0.5870\n",
            "Epoch 152/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5058 - val_loss: 0.5864\n",
            "Epoch 153/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5062 - val_loss: 0.5855\n",
            "Epoch 154/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5060 - val_loss: 0.5872\n",
            "Epoch 155/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5053 - val_loss: 0.5852\n",
            "Epoch 156/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5056 - val_loss: 0.5850\n",
            "Epoch 157/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5052 - val_loss: 0.5850\n",
            "Epoch 158/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5051 - val_loss: 0.5851\n",
            "Epoch 159/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5052 - val_loss: 0.5852\n",
            "Epoch 160/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5057 - val_loss: 0.5866\n",
            "Epoch 161/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5046 - val_loss: 0.5837\n",
            "Epoch 162/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5051 - val_loss: 0.5837\n",
            "Epoch 163/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5042 - val_loss: 0.5847\n",
            "Epoch 164/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5043 - val_loss: 0.5862\n",
            "Epoch 165/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5041 - val_loss: 0.5842\n",
            "Epoch 166/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5036 - val_loss: 0.5832\n",
            "Epoch 167/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5035 - val_loss: 0.5841\n",
            "Epoch 168/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5035 - val_loss: 0.5825\n",
            "Epoch 169/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5040 - val_loss: 0.5836\n",
            "Epoch 170/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5030 - val_loss: 0.5833\n",
            "Epoch 171/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5025 - val_loss: 0.5827\n",
            "Epoch 172/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5028 - val_loss: 0.5827\n",
            "Epoch 173/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5027 - val_loss: 0.5829\n",
            "Epoch 174/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5026 - val_loss: 0.5827\n",
            "Epoch 175/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5022 - val_loss: 0.5843\n",
            "Epoch 176/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5022 - val_loss: 0.5831\n",
            "Epoch 177/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5017 - val_loss: 0.5836\n",
            "Epoch 178/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5019 - val_loss: 0.5834\n",
            "Epoch 179/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5012 - val_loss: 0.5836\n",
            "Epoch 180/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5016 - val_loss: 0.5831\n",
            "Epoch 181/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5014 - val_loss: 0.5825\n",
            "Epoch 182/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5015 - val_loss: 0.5816\n",
            "Epoch 183/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5009 - val_loss: 0.5823\n",
            "Epoch 184/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5010 - val_loss: 0.5819\n",
            "Epoch 185/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5006 - val_loss: 0.5818\n",
            "Epoch 186/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5010 - val_loss: 0.5813\n",
            "Epoch 187/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5005 - val_loss: 0.5829\n",
            "Epoch 188/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5003 - val_loss: 0.5823\n",
            "Epoch 189/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5006 - val_loss: 0.5828\n",
            "Epoch 190/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5004 - val_loss: 0.5820\n",
            "Epoch 191/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5000 - val_loss: 0.5806\n",
            "Epoch 192/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4992 - val_loss: 0.5818\n",
            "Epoch 193/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4995 - val_loss: 0.5802\n",
            "Epoch 194/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4995 - val_loss: 0.5797\n",
            "Epoch 195/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4989 - val_loss: 0.5812\n",
            "Epoch 196/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4993 - val_loss: 0.5804\n",
            "Epoch 197/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4991 - val_loss: 0.5807\n",
            "Epoch 198/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4984 - val_loss: 0.5816\n",
            "Epoch 199/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4985 - val_loss: 0.5808\n",
            "Epoch 200/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4980 - val_loss: 0.5798\n",
            "Epoch 201/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4984 - val_loss: 0.5800\n",
            "Epoch 202/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4981 - val_loss: 0.5790\n",
            "Epoch 203/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4988 - val_loss: 0.5791\n",
            "Epoch 204/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4982 - val_loss: 0.5790\n",
            "Epoch 205/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4984 - val_loss: 0.5788\n",
            "Epoch 206/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4982 - val_loss: 0.5810\n",
            "Epoch 207/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4977 - val_loss: 0.5803\n",
            "Epoch 208/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4974 - val_loss: 0.5798\n",
            "Epoch 209/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4973 - val_loss: 0.5807\n",
            "Epoch 210/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4970 - val_loss: 0.5793\n",
            "Epoch 211/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4968 - val_loss: 0.5789\n",
            "Epoch 212/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4971 - val_loss: 0.5794\n",
            "Epoch 213/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4974 - val_loss: 0.5799\n",
            "Epoch 214/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4965 - val_loss: 0.5794\n",
            "Epoch 215/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4968 - val_loss: 0.5793\n",
            "Epoch 216/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4966 - val_loss: 0.5795\n",
            "Epoch 217/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4956 - val_loss: 0.5798\n",
            "Epoch 218/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4950 - val_loss: 0.5808\n",
            "Epoch 219/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4960 - val_loss: 0.5791\n",
            "Epoch 220/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4956 - val_loss: 0.5794\n",
            "Epoch 221/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4955 - val_loss: 0.5778\n",
            "Epoch 222/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4957 - val_loss: 0.5786\n",
            "Epoch 223/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4959 - val_loss: 0.5786\n",
            "Epoch 224/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4957 - val_loss: 0.5800\n",
            "Epoch 225/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4950 - val_loss: 0.5795\n",
            "Epoch 226/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4964 - val_loss: 0.5784\n",
            "Epoch 227/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4953 - val_loss: 0.5813\n",
            "Epoch 228/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4946 - val_loss: 0.5792\n",
            "Epoch 229/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4947 - val_loss: 0.5790\n",
            "Epoch 230/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4948 - val_loss: 0.5787\n",
            "Epoch 231/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4944 - val_loss: 0.5777\n",
            "Epoch 232/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4947 - val_loss: 0.5795\n",
            "Epoch 233/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4943 - val_loss: 0.5777\n",
            "Epoch 234/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4949 - val_loss: 0.5791\n",
            "Epoch 235/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4946 - val_loss: 0.5794\n",
            "Epoch 236/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4938 - val_loss: 0.5786\n",
            "Epoch 237/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4938 - val_loss: 0.5774\n",
            "Epoch 238/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4936 - val_loss: 0.5772\n",
            "Epoch 239/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4938 - val_loss: 0.5764\n",
            "Epoch 240/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4931 - val_loss: 0.5769\n",
            "Epoch 241/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4939 - val_loss: 0.5779\n",
            "Epoch 242/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4929 - val_loss: 0.5773\n",
            "Epoch 243/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4936 - val_loss: 0.5780\n",
            "Epoch 244/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4931 - val_loss: 0.5776\n",
            "Epoch 245/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4926 - val_loss: 0.5769\n",
            "Epoch 246/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4929 - val_loss: 0.5768\n",
            "Epoch 247/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4925 - val_loss: 0.5765\n",
            "Epoch 248/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4924 - val_loss: 0.5770\n",
            "Epoch 249/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4926 - val_loss: 0.5772\n",
            "Epoch 250/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4918 - val_loss: 0.5763\n",
            "Epoch 251/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4926 - val_loss: 0.5760\n",
            "Epoch 252/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4917 - val_loss: 0.5757\n",
            "Epoch 253/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4917 - val_loss: 0.5773\n",
            "Epoch 254/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 0.5770\n",
            "Epoch 255/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4921 - val_loss: 0.5764\n",
            "Epoch 256/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4918 - val_loss: 0.5766\n",
            "Epoch 257/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4916 - val_loss: 0.5765\n",
            "Epoch 258/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4914 - val_loss: 0.5748\n",
            "Epoch 259/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4916 - val_loss: 0.5763\n",
            "Epoch 260/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4922 - val_loss: 0.5768\n",
            "Epoch 261/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4913 - val_loss: 0.5752\n",
            "Epoch 262/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4915 - val_loss: 0.5780\n",
            "Epoch 263/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4906 - val_loss: 0.5759\n",
            "Epoch 264/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4910 - val_loss: 0.5756\n",
            "Epoch 265/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4901 - val_loss: 0.5746\n",
            "Epoch 266/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4908 - val_loss: 0.5762\n",
            "Epoch 267/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4905 - val_loss: 0.5735\n",
            "Epoch 268/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4915 - val_loss: 0.5741\n",
            "Epoch 269/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4907 - val_loss: 0.5758\n",
            "Epoch 270/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4909 - val_loss: 0.5761\n",
            "Epoch 271/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4892 - val_loss: 0.5749\n",
            "Epoch 272/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4898 - val_loss: 0.5739\n",
            "Epoch 273/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4898 - val_loss: 0.5747\n",
            "Epoch 274/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.5750\n",
            "Epoch 275/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4893 - val_loss: 0.5748\n",
            "Epoch 276/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4892 - val_loss: 0.5756\n",
            "Epoch 277/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 0.5757\n",
            "Epoch 278/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4891 - val_loss: 0.5754\n",
            "Epoch 279/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4888 - val_loss: 0.5739\n",
            "Epoch 280/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4894 - val_loss: 0.5746\n",
            "Epoch 281/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5750\n",
            "Epoch 282/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4886 - val_loss: 0.5736\n",
            "Epoch 283/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4885 - val_loss: 0.5745\n",
            "Epoch 284/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4882 - val_loss: 0.5739\n",
            "Epoch 285/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 0.5738\n",
            "Epoch 286/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4885 - val_loss: 0.5750\n",
            "Epoch 287/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4887 - val_loss: 0.5745\n",
            "Epoch 288/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4882 - val_loss: 0.5749\n",
            "Epoch 289/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4873 - val_loss: 0.5752\n",
            "Epoch 290/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.5759\n",
            "Epoch 291/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4881 - val_loss: 0.5746\n",
            "Epoch 292/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4878 - val_loss: 0.5752\n",
            "Epoch 293/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5745\n",
            "Epoch 294/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.5740\n",
            "Epoch 295/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4868 - val_loss: 0.5743\n",
            "Epoch 296/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4869 - val_loss: 0.5737\n",
            "Epoch 297/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4870 - val_loss: 0.5757\n",
            "Epoch 298/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4872 - val_loss: 0.5719\n",
            "Epoch 299/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.5728\n",
            "Epoch 300/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4867 - val_loss: 0.5737\n",
            "Epoch 301/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.5753\n",
            "Epoch 302/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4859 - val_loss: 0.5726\n",
            "Epoch 303/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4878 - val_loss: 0.5730\n",
            "Epoch 304/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4860 - val_loss: 0.5734\n",
            "Epoch 305/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4861 - val_loss: 0.5726\n",
            "Epoch 306/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4855 - val_loss: 0.5742\n",
            "Epoch 307/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.5723\n",
            "Epoch 308/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.5726\n",
            "Epoch 309/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4852 - val_loss: 0.5727\n",
            "Epoch 310/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 0.5740\n",
            "Epoch 311/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.5733\n",
            "Epoch 312/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 0.5741\n",
            "Epoch 313/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4846 - val_loss: 0.5733\n",
            "Epoch 314/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4851 - val_loss: 0.5734\n",
            "Epoch 315/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.5728\n",
            "Epoch 316/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4849 - val_loss: 0.5727\n",
            "Epoch 317/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4848 - val_loss: 0.5743\n",
            "Epoch 318/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4847 - val_loss: 0.5736\n",
            "Epoch 319/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4847 - val_loss: 0.5737\n",
            "Epoch 320/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.5728\n",
            "Epoch 321/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 0.5738\n",
            "Epoch 322/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4847 - val_loss: 0.5717\n",
            "Epoch 323/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4836 - val_loss: 0.5713\n",
            "Epoch 324/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4834 - val_loss: 0.5720\n",
            "Epoch 325/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4841 - val_loss: 0.5744\n",
            "Epoch 326/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4839 - val_loss: 0.5708\n",
            "Epoch 327/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4842 - val_loss: 0.5727\n",
            "Epoch 328/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4843 - val_loss: 0.5729\n",
            "Epoch 329/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4841 - val_loss: 0.5731\n",
            "Epoch 330/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4843 - val_loss: 0.5718\n",
            "Epoch 331/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4826 - val_loss: 0.5723\n",
            "Epoch 332/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4832 - val_loss: 0.5724\n",
            "Epoch 333/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 0.5717\n",
            "Epoch 334/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4829 - val_loss: 0.5722\n",
            "Epoch 335/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4835 - val_loss: 0.5717\n",
            "Epoch 336/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.5720\n",
            "Epoch 337/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4832 - val_loss: 0.5710\n",
            "Epoch 338/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.5722\n",
            "Epoch 339/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.5713\n",
            "Epoch 340/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.5713\n",
            "Epoch 341/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4815 - val_loss: 0.5711\n",
            "Epoch 342/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4819 - val_loss: 0.5718\n",
            "Epoch 343/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4818 - val_loss: 0.5702\n",
            "Epoch 344/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.5713\n",
            "Epoch 345/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4826 - val_loss: 0.5730\n",
            "Epoch 346/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.5714\n",
            "Epoch 347/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 0.5708\n",
            "Epoch 348/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.5719\n",
            "Epoch 349/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4826 - val_loss: 0.5713\n",
            "Epoch 350/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 0.5718\n",
            "Epoch 351/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 0.5716\n",
            "Epoch 352/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.5712\n",
            "Epoch 353/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.5720\n",
            "Epoch 354/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.5720\n",
            "Epoch 355/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.5711\n",
            "Epoch 356/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 0.5712\n",
            "Epoch 357/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4814 - val_loss: 0.5713\n",
            "Epoch 358/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 0.5710\n",
            "Epoch 359/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.5730\n",
            "Epoch 360/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5736\n",
            "Epoch 361/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5713\n",
            "Epoch 362/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5715\n",
            "Epoch 363/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 0.5700\n",
            "Epoch 364/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4800 - val_loss: 0.5707\n",
            "Epoch 365/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4802 - val_loss: 0.5705\n",
            "Epoch 366/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4802 - val_loss: 0.5706\n",
            "Epoch 367/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 0.5705\n",
            "Epoch 368/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4806 - val_loss: 0.5713\n",
            "Epoch 369/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4805 - val_loss: 0.5713\n",
            "Epoch 370/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4798 - val_loss: 0.5710\n",
            "Epoch 371/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4799 - val_loss: 0.5710\n",
            "Epoch 372/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5706\n",
            "Epoch 373/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4798 - val_loss: 0.5715\n",
            "Epoch 374/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.5718\n",
            "Epoch 375/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4802 - val_loss: 0.5723\n",
            "Epoch 376/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4793 - val_loss: 0.5712\n",
            "Epoch 377/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5706\n",
            "Epoch 378/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5713\n",
            "Epoch 379/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4788 - val_loss: 0.5716\n",
            "Epoch 380/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4804 - val_loss: 0.5715\n",
            "Epoch 381/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4798 - val_loss: 0.5728\n",
            "Epoch 382/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5731\n",
            "Epoch 383/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4788 - val_loss: 0.5730\n",
            "Epoch 384/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.5718\n",
            "Epoch 385/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4791 - val_loss: 0.5710\n",
            "Epoch 386/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.5717\n",
            "Epoch 387/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4794 - val_loss: 0.5725\n",
            "Epoch 388/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.5719\n",
            "Epoch 389/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4788 - val_loss: 0.5710\n",
            "Epoch 390/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.5711\n",
            "Epoch 391/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.5712\n",
            "Epoch 392/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4780 - val_loss: 0.5714\n",
            "Epoch 393/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.5719\n",
            "Epoch 394/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.5713\n",
            "Epoch 395/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4779 - val_loss: 0.5710\n",
            "Epoch 396/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4778 - val_loss: 0.5713\n",
            "Epoch 397/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.5719\n",
            "Epoch 398/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.5709\n",
            "Epoch 399/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.5725\n",
            "Epoch 400/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.5733\n",
            "Epoch 401/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.5711\n",
            "Epoch 402/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.5703\n",
            "Epoch 403/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.5702\n",
            "Epoch 404/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.5710\n",
            "Epoch 405/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4780 - val_loss: 0.5699\n",
            "Epoch 406/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.5712\n",
            "Epoch 407/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.5707\n",
            "Epoch 408/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4780 - val_loss: 0.5726\n",
            "Epoch 409/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4775 - val_loss: 0.5693\n",
            "Epoch 410/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4791 - val_loss: 0.5715\n",
            "Epoch 411/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4767 - val_loss: 0.5689\n",
            "Epoch 412/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.5713\n",
            "Epoch 413/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.5707\n",
            "Epoch 414/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5703\n",
            "Epoch 415/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.5708\n",
            "Epoch 416/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 0.5720\n",
            "Epoch 417/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5714\n",
            "Epoch 418/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4762 - val_loss: 0.5712\n",
            "Epoch 419/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4769 - val_loss: 0.5724\n",
            "Epoch 420/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 0.5731\n",
            "Epoch 421/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 0.5709\n",
            "Epoch 422/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5693\n",
            "Epoch 423/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.5698\n",
            "Epoch 424/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5706\n",
            "Epoch 425/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 0.5707\n",
            "Epoch 426/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 0.5696\n",
            "Epoch 427/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5704\n",
            "Epoch 428/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 0.5702\n",
            "Epoch 429/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 0.5693\n",
            "Epoch 430/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.5700\n",
            "Epoch 431/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.5713\n",
            "Epoch 432/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4754 - val_loss: 0.5692\n",
            "Epoch 433/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.5701\n",
            "Epoch 434/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.5702\n",
            "Epoch 435/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.5710\n",
            "Epoch 436/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.5715\n",
            "Epoch 437/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5703\n",
            "Epoch 438/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4750 - val_loss: 0.5702\n",
            "Epoch 439/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4757 - val_loss: 0.5720\n",
            "Epoch 440/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5700\n",
            "Epoch 441/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.5696\n",
            "Epoch 442/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5689\n",
            "Epoch 443/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5704\n",
            "Epoch 444/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.5702\n",
            "Epoch 445/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.5711\n",
            "Epoch 446/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4757 - val_loss: 0.5710\n",
            "Epoch 447/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.5712\n",
            "Epoch 448/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 0.5698\n",
            "Epoch 449/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5717\n",
            "Epoch 450/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.5711\n",
            "Epoch 451/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.5705\n",
            "Epoch 452/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.5696\n",
            "Epoch 453/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.5719\n",
            "Epoch 454/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 0.5710\n",
            "Epoch 455/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5707\n",
            "Epoch 456/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.5716\n",
            "Epoch 457/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.5684\n",
            "Epoch 458/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4748 - val_loss: 0.5694\n",
            "Epoch 459/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.5682\n",
            "Epoch 460/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4743 - val_loss: 0.5684\n",
            "Epoch 461/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4748 - val_loss: 0.5702\n",
            "Epoch 462/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.5685\n",
            "Epoch 463/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.5690\n",
            "Epoch 464/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.5691\n",
            "Epoch 465/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 0.5710\n",
            "Epoch 466/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4737 - val_loss: 0.5694\n",
            "Epoch 467/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4734 - val_loss: 0.5700\n",
            "Epoch 468/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.5695\n",
            "Epoch 469/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 0.5691\n",
            "Epoch 470/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4730 - val_loss: 0.5697\n",
            "Epoch 471/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4735 - val_loss: 0.5700\n",
            "Epoch 472/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4734 - val_loss: 0.5711\n",
            "Epoch 473/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4738 - val_loss: 0.5710\n",
            "Epoch 474/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4736 - val_loss: 0.5717\n",
            "Epoch 475/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4725 - val_loss: 0.5706\n",
            "Epoch 476/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4736 - val_loss: 0.5692\n",
            "Epoch 477/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4733 - val_loss: 0.5699\n",
            "Epoch 478/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4733 - val_loss: 0.5700\n",
            "Epoch 479/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4724 - val_loss: 0.5684\n",
            "Epoch 480/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4729 - val_loss: 0.5681\n",
            "Epoch 481/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4733 - val_loss: 0.5688\n",
            "Epoch 482/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.5688\n",
            "Epoch 483/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4726 - val_loss: 0.5692\n",
            "Epoch 484/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4732 - val_loss: 0.5693\n",
            "Epoch 485/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4722 - val_loss: 0.5697\n",
            "Epoch 486/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4726 - val_loss: 0.5717\n",
            "Epoch 487/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4728 - val_loss: 0.5681\n",
            "Epoch 488/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.5689\n",
            "Epoch 489/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.5699\n",
            "Epoch 490/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4722 - val_loss: 0.5699\n",
            "Epoch 491/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4732 - val_loss: 0.5687\n",
            "Epoch 492/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4719 - val_loss: 0.5693\n",
            "Epoch 493/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4717 - val_loss: 0.5682\n",
            "Epoch 494/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4725 - val_loss: 0.5710\n",
            "Epoch 495/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4720 - val_loss: 0.5687\n",
            "Epoch 496/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4717 - val_loss: 0.5697\n",
            "Epoch 497/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4714 - val_loss: 0.5685\n",
            "Epoch 498/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4714 - val_loss: 0.5694\n",
            "Epoch 499/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4714 - val_loss: 0.5682\n",
            "Epoch 500/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4725 - val_loss: 0.5693\n",
            "Epoch 501/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4708 - val_loss: 0.5676\n",
            "Epoch 502/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 0.5672\n",
            "Epoch 503/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4719 - val_loss: 0.5690\n",
            "Epoch 504/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.5694\n",
            "Epoch 505/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4711 - val_loss: 0.5699\n",
            "Epoch 506/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4708 - val_loss: 0.5687\n",
            "Epoch 507/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4714 - val_loss: 0.5689\n",
            "Epoch 508/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4712 - val_loss: 0.5701\n",
            "Epoch 509/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.5684\n",
            "Epoch 510/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 0.5701\n",
            "Epoch 511/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4707 - val_loss: 0.5681\n",
            "Epoch 512/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.5685\n",
            "Epoch 513/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4717 - val_loss: 0.5675\n",
            "Epoch 514/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4721 - val_loss: 0.5687\n",
            "Epoch 515/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4705 - val_loss: 0.5691\n",
            "Epoch 516/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4713 - val_loss: 0.5693\n",
            "Epoch 517/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4713 - val_loss: 0.5687\n",
            "Epoch 518/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4710 - val_loss: 0.5692\n",
            "Epoch 519/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 0.5685\n",
            "Epoch 520/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4705 - val_loss: 0.5676\n",
            "Epoch 521/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4712 - val_loss: 0.5687\n",
            "Epoch 522/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.5694\n",
            "Epoch 523/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4704 - val_loss: 0.5684\n",
            "Epoch 524/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.5679\n",
            "Epoch 525/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.5678\n",
            "Epoch 526/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4707 - val_loss: 0.5682\n",
            "Epoch 527/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4705 - val_loss: 0.5684\n",
            "Epoch 528/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4713 - val_loss: 0.5697\n",
            "Epoch 529/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.5687\n",
            "Epoch 530/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4705 - val_loss: 0.5682\n",
            "Epoch 531/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.5659\n",
            "Epoch 532/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4701 - val_loss: 0.5687\n",
            "Epoch 533/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4707 - val_loss: 0.5671\n",
            "Epoch 534/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4694 - val_loss: 0.5673\n",
            "Epoch 535/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4702 - val_loss: 0.5675\n",
            "Epoch 536/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4699 - val_loss: 0.5675\n",
            "Epoch 537/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 0.5680\n",
            "Epoch 538/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4689 - val_loss: 0.5682\n",
            "Epoch 539/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4698 - val_loss: 0.5688\n",
            "Epoch 540/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4697 - val_loss: 0.5671\n",
            "Epoch 541/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 0.5680\n",
            "Epoch 542/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4689 - val_loss: 0.5691\n",
            "Epoch 543/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4700 - val_loss: 0.5678\n",
            "Epoch 544/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4691 - val_loss: 0.5689\n",
            "Epoch 545/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4697 - val_loss: 0.5677\n",
            "Epoch 546/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.5690\n",
            "Epoch 547/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4699 - val_loss: 0.5690\n",
            "Epoch 548/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4695 - val_loss: 0.5679\n",
            "Epoch 549/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4697 - val_loss: 0.5670\n",
            "Epoch 550/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.5671\n",
            "Epoch 551/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.5684\n",
            "Epoch 552/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.5680\n",
            "Epoch 553/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 0.5673\n",
            "Epoch 554/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4697 - val_loss: 0.5691\n",
            "Epoch 555/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4699 - val_loss: 0.5675\n",
            "Epoch 556/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.5669\n",
            "Epoch 557/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4697 - val_loss: 0.5699\n",
            "Epoch 558/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 0.5676\n",
            "Epoch 559/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4707 - val_loss: 0.5675\n",
            "Epoch 560/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.5691\n",
            "Epoch 561/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.5676\n",
            "Epoch 562/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4691 - val_loss: 0.5672\n",
            "Epoch 563/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4695 - val_loss: 0.5676\n",
            "Epoch 564/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4688 - val_loss: 0.5676\n",
            "Epoch 565/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4698 - val_loss: 0.5675\n",
            "Epoch 566/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 0.5675\n",
            "Epoch 567/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4688 - val_loss: 0.5658\n",
            "Epoch 568/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 0.5676\n",
            "Epoch 569/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4690 - val_loss: 0.5684\n",
            "Epoch 570/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.5678\n",
            "Epoch 571/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4683 - val_loss: 0.5671\n",
            "Epoch 572/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4684 - val_loss: 0.5678\n",
            "Epoch 573/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4699 - val_loss: 0.5673\n",
            "Epoch 574/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4678 - val_loss: 0.5656\n",
            "Epoch 575/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4687 - val_loss: 0.5676\n",
            "Epoch 576/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 0.5659\n",
            "Epoch 577/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4676 - val_loss: 0.5670\n",
            "Epoch 578/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 0.5667\n",
            "Epoch 579/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 0.5674\n",
            "Epoch 580/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4681 - val_loss: 0.5656\n",
            "Epoch 581/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4681 - val_loss: 0.5665\n",
            "Epoch 582/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4685 - val_loss: 0.5676\n",
            "Epoch 583/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.5661\n",
            "Epoch 584/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4678 - val_loss: 0.5675\n",
            "Epoch 585/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4690 - val_loss: 0.5649\n",
            "Epoch 586/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 0.5657\n",
            "Epoch 587/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4689 - val_loss: 0.5669\n",
            "Epoch 588/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4675 - val_loss: 0.5658\n",
            "Epoch 589/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4678 - val_loss: 0.5686\n",
            "Epoch 590/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4676 - val_loss: 0.5669\n",
            "Epoch 591/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.5671\n",
            "Epoch 592/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 0.5655\n",
            "Epoch 593/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 0.5666\n",
            "Epoch 594/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4684 - val_loss: 0.5674\n",
            "Epoch 595/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4680 - val_loss: 0.5679\n",
            "Epoch 596/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4678 - val_loss: 0.5667\n",
            "Epoch 597/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4674 - val_loss: 0.5674\n",
            "Epoch 598/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4680 - val_loss: 0.5675\n",
            "Epoch 599/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 0.5673\n",
            "Epoch 600/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.5674\n",
            "Epoch 601/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4678 - val_loss: 0.5671\n",
            "Epoch 602/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.5674\n",
            "Epoch 603/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4665 - val_loss: 0.5658\n",
            "Epoch 604/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4678 - val_loss: 0.5678\n",
            "Epoch 605/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4665 - val_loss: 0.5666\n",
            "Epoch 606/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4672 - val_loss: 0.5673\n",
            "Epoch 607/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4671 - val_loss: 0.5660\n",
            "Epoch 608/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 0.5671\n",
            "Epoch 609/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4674 - val_loss: 0.5652\n",
            "Epoch 610/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4667 - val_loss: 0.5654\n",
            "Epoch 611/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 0.5659\n",
            "Epoch 612/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4686 - val_loss: 0.5658\n",
            "Epoch 613/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.5652\n",
            "Epoch 614/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4667 - val_loss: 0.5655\n",
            "Epoch 615/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4665 - val_loss: 0.5649\n",
            "Epoch 616/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 0.5654\n",
            "Epoch 617/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4680 - val_loss: 0.5686\n",
            "Epoch 618/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.5672\n",
            "Epoch 619/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.5666\n",
            "Epoch 620/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 0.5666\n",
            "Epoch 621/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.5664\n",
            "Epoch 622/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.5670\n",
            "Epoch 623/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4667 - val_loss: 0.5654\n",
            "Epoch 624/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 0.5648\n",
            "Epoch 625/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.5653\n",
            "Epoch 626/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.5643\n",
            "Epoch 627/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 0.5655\n",
            "Epoch 628/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.5653\n",
            "Epoch 629/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 0.5666\n",
            "Epoch 630/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.5657\n",
            "Epoch 631/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4659 - val_loss: 0.5650\n",
            "Epoch 632/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.5655\n",
            "Epoch 633/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4659 - val_loss: 0.5665\n",
            "Epoch 634/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4670 - val_loss: 0.5672\n",
            "Epoch 635/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 0.5661\n",
            "Epoch 636/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4660 - val_loss: 0.5657\n",
            "Epoch 637/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4660 - val_loss: 0.5667\n",
            "Epoch 638/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 0.5676\n",
            "Epoch 639/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.5649\n",
            "Epoch 640/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4661 - val_loss: 0.5658\n",
            "Epoch 641/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4665 - val_loss: 0.5655\n",
            "Epoch 642/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.5661\n",
            "Epoch 643/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.5641\n",
            "Epoch 644/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4676 - val_loss: 0.5650\n",
            "Epoch 645/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4661 - val_loss: 0.5675\n",
            "Epoch 646/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.5658\n",
            "Epoch 647/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4667 - val_loss: 0.5652\n",
            "Epoch 648/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 0.5652\n",
            "Epoch 649/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.5667\n",
            "Epoch 650/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4656 - val_loss: 0.5646\n",
            "Epoch 651/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4661 - val_loss: 0.5649\n",
            "Epoch 652/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 0.5644\n",
            "Epoch 653/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 0.5654\n",
            "Epoch 654/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4656 - val_loss: 0.5640\n",
            "Epoch 655/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.5649\n",
            "Epoch 656/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.5646\n",
            "Epoch 657/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.5656\n",
            "Epoch 658/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.5653\n",
            "Epoch 659/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4644 - val_loss: 0.5666\n",
            "Epoch 660/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4661 - val_loss: 0.5672\n",
            "Epoch 661/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4654 - val_loss: 0.5653\n",
            "Epoch 662/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.5653\n",
            "Epoch 663/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4647 - val_loss: 0.5662\n",
            "Epoch 664/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4648 - val_loss: 0.5668\n",
            "Epoch 665/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4653 - val_loss: 0.5640\n",
            "Epoch 666/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4643 - val_loss: 0.5659\n",
            "Epoch 667/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.5653\n",
            "Epoch 668/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4647 - val_loss: 0.5641\n",
            "Epoch 669/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4644 - val_loss: 0.5659\n",
            "Epoch 670/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4651 - val_loss: 0.5649\n",
            "Epoch 671/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4654 - val_loss: 0.5672\n",
            "Epoch 672/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4639 - val_loss: 0.5652\n",
            "Epoch 673/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.5666\n",
            "Epoch 674/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.5642\n",
            "Epoch 675/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4647 - val_loss: 0.5650\n",
            "Epoch 676/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4658 - val_loss: 0.5683\n",
            "Epoch 677/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4643 - val_loss: 0.5653\n",
            "Epoch 678/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.5655\n",
            "Epoch 679/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4653 - val_loss: 0.5647\n",
            "Epoch 680/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4652 - val_loss: 0.5645\n",
            "Epoch 681/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.5662\n",
            "Epoch 682/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.5675\n",
            "Epoch 683/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.5662\n",
            "Epoch 684/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4654 - val_loss: 0.5656\n",
            "Epoch 685/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.5656\n",
            "Epoch 686/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.5664\n",
            "Epoch 687/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.5667\n",
            "Epoch 688/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4646 - val_loss: 0.5660\n",
            "Epoch 689/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4643 - val_loss: 0.5658\n",
            "Epoch 690/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4654 - val_loss: 0.5650\n",
            "Epoch 691/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4646 - val_loss: 0.5637\n",
            "Epoch 692/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.5656\n",
            "Epoch 693/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4639 - val_loss: 0.5642\n",
            "Epoch 694/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.5665\n",
            "Epoch 695/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4643 - val_loss: 0.5636\n",
            "Epoch 696/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4652 - val_loss: 0.5638\n",
            "Epoch 697/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4643 - val_loss: 0.5657\n",
            "Epoch 698/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4647 - val_loss: 0.5663\n",
            "Epoch 699/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.5644\n",
            "Epoch 700/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.5649\n",
            "Epoch 701/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4643 - val_loss: 0.5643\n",
            "Epoch 702/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4636 - val_loss: 0.5647\n",
            "Epoch 703/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4637 - val_loss: 0.5649\n",
            "Epoch 704/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.5664\n",
            "Epoch 705/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4644 - val_loss: 0.5651\n",
            "Epoch 706/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4636 - val_loss: 0.5645\n",
            "Epoch 707/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4635 - val_loss: 0.5648\n",
            "Epoch 708/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4635 - val_loss: 0.5628\n",
            "Epoch 709/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4635 - val_loss: 0.5646\n",
            "Epoch 710/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4635 - val_loss: 0.5637\n",
            "Epoch 711/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4635 - val_loss: 0.5647\n",
            "Epoch 712/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.5650\n",
            "Epoch 713/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.5643\n",
            "Epoch 714/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4633 - val_loss: 0.5654\n",
            "Epoch 715/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.5642\n",
            "Epoch 716/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4633 - val_loss: 0.5642\n",
            "Epoch 717/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.5635\n",
            "Epoch 718/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4627 - val_loss: 0.5641\n",
            "Epoch 719/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4630 - val_loss: 0.5636\n",
            "Epoch 720/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4637 - val_loss: 0.5623\n",
            "Epoch 721/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4630 - val_loss: 0.5642\n",
            "Epoch 722/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.5650\n",
            "Epoch 723/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.5639\n",
            "Epoch 724/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4635 - val_loss: 0.5656\n",
            "Epoch 725/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.5652\n",
            "Epoch 726/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.5641\n",
            "Epoch 727/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4637 - val_loss: 0.5639\n",
            "Epoch 728/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4646 - val_loss: 0.5643\n",
            "Epoch 729/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4625 - val_loss: 0.5644\n",
            "Epoch 730/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4635 - val_loss: 0.5659\n",
            "Epoch 731/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.5648\n",
            "Epoch 732/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4638 - val_loss: 0.5664\n",
            "Epoch 733/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.5658\n",
            "Epoch 734/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4635 - val_loss: 0.5656\n",
            "Epoch 735/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.5661\n",
            "Epoch 736/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.5645\n",
            "Epoch 737/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 0.5656\n",
            "Epoch 738/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4628 - val_loss: 0.5642\n",
            "Epoch 739/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.5649\n",
            "Epoch 740/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4635 - val_loss: 0.5654\n",
            "Epoch 741/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.5638\n",
            "Epoch 742/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.5629\n",
            "Epoch 743/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4621 - val_loss: 0.5635\n",
            "Epoch 744/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.5657\n",
            "Epoch 745/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4624 - val_loss: 0.5627\n",
            "Epoch 746/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4627 - val_loss: 0.5651\n",
            "Epoch 747/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.5650\n",
            "Epoch 748/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4617 - val_loss: 0.5641\n",
            "Epoch 749/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.5620\n",
            "Epoch 750/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4621 - val_loss: 0.5641\n",
            "Epoch 751/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4620 - val_loss: 0.5649\n",
            "Epoch 752/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.5648\n",
            "Epoch 753/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4630 - val_loss: 0.5657\n",
            "Epoch 754/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4619 - val_loss: 0.5636\n",
            "Epoch 755/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4620 - val_loss: 0.5640\n",
            "Epoch 756/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.5638\n",
            "Epoch 757/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4620 - val_loss: 0.5644\n",
            "Epoch 758/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.5638\n",
            "Epoch 759/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4624 - val_loss: 0.5640\n",
            "Epoch 760/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4609 - val_loss: 0.5633\n",
            "Epoch 761/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4624 - val_loss: 0.5678\n",
            "Epoch 762/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.5639\n",
            "Epoch 763/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4619 - val_loss: 0.5653\n",
            "Epoch 764/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4619 - val_loss: 0.5650\n",
            "Epoch 765/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4618 - val_loss: 0.5653\n",
            "Epoch 766/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.5638\n",
            "Epoch 767/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4620 - val_loss: 0.5638\n",
            "Epoch 768/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.5644\n",
            "Epoch 769/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4609 - val_loss: 0.5639\n",
            "Epoch 770/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.5649\n",
            "Epoch 771/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.5657\n",
            "Epoch 772/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4621 - val_loss: 0.5657\n",
            "Epoch 773/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.5644\n",
            "Epoch 774/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.5629\n",
            "Epoch 775/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.5645\n",
            "Epoch 776/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4612 - val_loss: 0.5642\n",
            "Epoch 777/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4609 - val_loss: 0.5636\n",
            "Epoch 778/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.5642\n",
            "Epoch 779/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4619 - val_loss: 0.5650\n",
            "Epoch 780/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4620 - val_loss: 0.5657\n",
            "Epoch 781/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4612 - val_loss: 0.5636\n",
            "Epoch 782/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 0.5644\n",
            "Epoch 783/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 0.5658\n",
            "Epoch 784/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.5661\n",
            "Epoch 785/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4609 - val_loss: 0.5634\n",
            "Epoch 786/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.5633\n",
            "Epoch 787/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.5641\n",
            "Epoch 788/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.5643\n",
            "Epoch 789/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.5667\n",
            "Epoch 790/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.5633\n",
            "Epoch 791/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.5652\n",
            "Epoch 792/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.5660\n",
            "Epoch 793/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4604 - val_loss: 0.5655\n",
            "Epoch 794/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4612 - val_loss: 0.5644\n",
            "Epoch 795/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.5654\n",
            "Epoch 796/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.5668\n",
            "Epoch 797/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.5643\n",
            "Epoch 798/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.5640\n",
            "Epoch 799/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4612 - val_loss: 0.5654\n",
            "Epoch 800/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4604 - val_loss: 0.5645\n",
            "Epoch 801/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.5655\n",
            "Epoch 802/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.5665\n",
            "Epoch 803/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.5648\n",
            "Epoch 804/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.5647\n",
            "Epoch 805/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4603 - val_loss: 0.5654\n",
            "Epoch 806/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 0.5639\n",
            "Epoch 807/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4604 - val_loss: 0.5632\n",
            "Epoch 808/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.5638\n",
            "Epoch 809/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4598 - val_loss: 0.5645\n",
            "Epoch 810/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.5629\n",
            "Epoch 811/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.5643\n",
            "Epoch 812/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.5637\n",
            "Epoch 813/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4598 - val_loss: 0.5636\n",
            "Epoch 814/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4602 - val_loss: 0.5636\n",
            "Epoch 815/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.5644\n",
            "Epoch 816/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4598 - val_loss: 0.5639\n",
            "Epoch 817/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4598 - val_loss: 0.5662\n",
            "Epoch 818/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.5638\n",
            "Epoch 819/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4605 - val_loss: 0.5662\n",
            "Epoch 820/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4605 - val_loss: 0.5660\n",
            "Epoch 821/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.5647\n",
            "Epoch 822/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4604 - val_loss: 0.5652\n",
            "Epoch 823/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4592 - val_loss: 0.5632\n",
            "Epoch 824/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.5647\n",
            "Epoch 825/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.5640\n",
            "Epoch 826/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.5655\n",
            "Epoch 827/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4592 - val_loss: 0.5655\n",
            "Epoch 828/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.5657\n",
            "Epoch 829/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4593 - val_loss: 0.5653\n",
            "Epoch 830/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.5637\n",
            "Epoch 831/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.5628\n",
            "Epoch 832/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.5621\n",
            "Epoch 833/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.5643\n",
            "Epoch 834/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.5641\n",
            "Epoch 835/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.5630\n",
            "Epoch 836/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.5623\n",
            "Epoch 837/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4587 - val_loss: 0.5634\n",
            "Epoch 838/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4593 - val_loss: 0.5643\n",
            "Epoch 839/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.5658\n",
            "Epoch 840/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.5644\n",
            "Epoch 841/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4592 - val_loss: 0.5634\n",
            "Epoch 842/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4579 - val_loss: 0.5640\n",
            "Epoch 843/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4598 - val_loss: 0.5661\n",
            "Epoch 844/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.5636\n",
            "Epoch 845/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.5651\n",
            "Epoch 846/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4587 - val_loss: 0.5633\n",
            "Epoch 847/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4586 - val_loss: 0.5633\n",
            "Epoch 848/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.5641\n",
            "Epoch 849/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4590 - val_loss: 0.5633\n",
            "Epoch 850/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.5631\n",
            "Epoch 851/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4590 - val_loss: 0.5632\n",
            "Epoch 852/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.5657\n",
            "Epoch 853/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.5637\n",
            "Epoch 854/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.5645\n",
            "Epoch 855/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4590 - val_loss: 0.5630\n",
            "Epoch 856/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4590 - val_loss: 0.5658\n",
            "Epoch 857/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.5654\n",
            "Epoch 858/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4579 - val_loss: 0.5645\n",
            "Epoch 859/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.5646\n",
            "Epoch 860/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.5637\n",
            "Epoch 861/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.5627\n",
            "Epoch 862/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.5634\n",
            "Epoch 863/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.5640\n",
            "Epoch 864/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.5638\n",
            "Epoch 865/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4586 - val_loss: 0.5639\n",
            "Epoch 866/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.5636\n",
            "Epoch 867/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4590 - val_loss: 0.5613\n",
            "Epoch 868/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.5642\n",
            "Epoch 869/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.5625\n",
            "Epoch 870/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4593 - val_loss: 0.5626\n",
            "Epoch 871/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4580 - val_loss: 0.5623\n",
            "Epoch 872/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4598 - val_loss: 0.5627\n",
            "Epoch 873/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.5641\n",
            "Epoch 874/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.5634\n",
            "Epoch 875/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.5639\n",
            "Epoch 876/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4587 - val_loss: 0.5636\n",
            "Epoch 877/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4580 - val_loss: 0.5639\n",
            "Epoch 878/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.5628\n",
            "Epoch 879/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4580 - val_loss: 0.5635\n",
            "Epoch 880/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4580 - val_loss: 0.5640\n",
            "Epoch 881/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.5633\n",
            "Epoch 882/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.5638\n",
            "Epoch 883/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.5631\n",
            "Epoch 884/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.5635\n",
            "Epoch 885/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.5626\n",
            "Epoch 886/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.5654\n",
            "Epoch 887/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4589 - val_loss: 0.5644\n",
            "Epoch 888/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.5638\n",
            "Epoch 889/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.5623\n",
            "Epoch 890/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.5634\n",
            "Epoch 891/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.5636\n",
            "Epoch 892/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4575 - val_loss: 0.5618\n",
            "Epoch 893/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4587 - val_loss: 0.5628\n",
            "Epoch 894/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.5660\n",
            "Epoch 895/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.5632\n",
            "Epoch 896/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.5646\n",
            "Epoch 897/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.5631\n",
            "Epoch 898/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.5624\n",
            "Epoch 899/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4577 - val_loss: 0.5624\n",
            "Epoch 900/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.5638\n",
            "Epoch 901/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.5629\n",
            "Epoch 902/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4587 - val_loss: 0.5627\n",
            "Epoch 903/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.5651\n",
            "Epoch 904/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4575 - val_loss: 0.5641\n",
            "Epoch 905/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4577 - val_loss: 0.5622\n",
            "Epoch 906/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.5645\n",
            "Epoch 907/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4569 - val_loss: 0.5627\n",
            "Epoch 908/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.5651\n",
            "Epoch 909/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.5652\n",
            "Epoch 910/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4571 - val_loss: 0.5647\n",
            "Epoch 911/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.5623\n",
            "Epoch 912/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.5643\n",
            "Epoch 913/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4569 - val_loss: 0.5637\n",
            "Epoch 914/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.5627\n",
            "Epoch 915/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.5646\n",
            "Epoch 916/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.5619\n",
            "Epoch 917/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.5677\n",
            "Epoch 918/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4577 - val_loss: 0.5641\n",
            "Epoch 919/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4571 - val_loss: 0.5626\n",
            "Epoch 920/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.5638\n",
            "Epoch 921/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.5622\n",
            "Epoch 922/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.5637\n",
            "Epoch 923/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.5631\n",
            "Epoch 924/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.5653\n",
            "Epoch 925/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.5646\n",
            "Epoch 926/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.5631\n",
            "Epoch 927/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.5639\n",
            "Epoch 928/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4569 - val_loss: 0.5643\n",
            "Epoch 929/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.5635\n",
            "Epoch 930/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.5659\n",
            "Epoch 931/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4564 - val_loss: 0.5641\n",
            "Epoch 932/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4559 - val_loss: 0.5622\n",
            "Epoch 933/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.5635\n",
            "Epoch 934/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.5636\n",
            "Epoch 935/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.5636\n",
            "Epoch 936/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.5650\n",
            "Epoch 937/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.5619\n",
            "Epoch 938/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.5641\n",
            "Epoch 939/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.5634\n",
            "Epoch 940/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.5654\n",
            "Epoch 941/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4566 - val_loss: 0.5641\n",
            "Epoch 942/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.5626\n",
            "Epoch 943/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.5623\n",
            "Epoch 944/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.5626\n",
            "Epoch 945/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.5638\n",
            "Epoch 946/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4553 - val_loss: 0.5629\n",
            "Epoch 947/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4569 - val_loss: 0.5627\n",
            "Epoch 948/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.5627\n",
            "Epoch 949/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4559 - val_loss: 0.5624\n",
            "Epoch 950/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4566 - val_loss: 0.5627\n",
            "Epoch 951/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4561 - val_loss: 0.5652\n",
            "Epoch 952/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.5652\n",
            "Epoch 953/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.5633\n",
            "Epoch 954/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.5612\n",
            "Epoch 955/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.5636\n",
            "Epoch 956/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.5642\n",
            "Epoch 957/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.5677\n",
            "Epoch 958/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4559 - val_loss: 0.5633\n",
            "Epoch 959/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4564 - val_loss: 0.5647\n",
            "Epoch 960/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4553 - val_loss: 0.5648\n",
            "Epoch 961/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.5633\n",
            "Epoch 962/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.5641\n",
            "Epoch 963/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.5617\n",
            "Epoch 964/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4563 - val_loss: 0.5645\n",
            "Epoch 965/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.5637\n",
            "Epoch 966/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.5628\n",
            "Epoch 967/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4551 - val_loss: 0.5647\n",
            "Epoch 968/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4551 - val_loss: 0.5633\n",
            "Epoch 969/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.5639\n",
            "Epoch 970/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 0.5635\n",
            "Epoch 971/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.5668\n",
            "Epoch 972/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4546 - val_loss: 0.5650\n",
            "Epoch 973/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.5640\n",
            "Epoch 974/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.5642\n",
            "Epoch 975/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.5639\n",
            "Epoch 976/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.5655\n",
            "Epoch 977/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4551 - val_loss: 0.5647\n",
            "Epoch 978/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4563 - val_loss: 0.5651\n",
            "Epoch 979/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4553 - val_loss: 0.5664\n",
            "Epoch 980/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.5665\n",
            "Epoch 981/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.5653\n",
            "Epoch 982/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 0.5636\n",
            "Epoch 983/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.5647\n",
            "Epoch 984/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4556 - val_loss: 0.5646\n",
            "Epoch 985/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.5653\n",
            "Epoch 986/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4553 - val_loss: 0.5642\n",
            "Epoch 987/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.5643\n",
            "Epoch 988/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4553 - val_loss: 0.5652\n",
            "Epoch 989/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4556 - val_loss: 0.5656\n",
            "Epoch 990/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4545 - val_loss: 0.5658\n",
            "Epoch 991/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4543 - val_loss: 0.5652\n",
            "Epoch 992/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4546 - val_loss: 0.5643\n",
            "Epoch 993/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.5631\n",
            "Epoch 994/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.5652\n",
            "Epoch 995/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4546 - val_loss: 0.5635\n",
            "Epoch 996/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4556 - val_loss: 0.5623\n",
            "Epoch 997/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4554 - val_loss: 0.5650\n",
            "Epoch 998/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.5631\n",
            "Epoch 999/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.5645\n",
            "Epoch 1000/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.5631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orkthF3wv3Bx"
      },
      "source": [
        "####Adadelta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wCV9VjHv6lE",
        "outputId": "dfe4a860-ce79-4d6e-aa29-a74e177aa76f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wide_opt3(opt_Adadelta)"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 1.0141 - val_loss: 1.0126\n",
            "Epoch 2/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0139 - val_loss: 1.0125\n",
            "Epoch 3/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0137 - val_loss: 1.0123\n",
            "Epoch 4/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0136 - val_loss: 1.0121\n",
            "Epoch 5/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0134 - val_loss: 1.0119\n",
            "Epoch 6/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0132 - val_loss: 1.0118\n",
            "Epoch 7/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0130 - val_loss: 1.0116\n",
            "Epoch 8/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0128 - val_loss: 1.0114\n",
            "Epoch 9/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0126 - val_loss: 1.0113\n",
            "Epoch 10/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0125 - val_loss: 1.0111\n",
            "Epoch 11/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0123 - val_loss: 1.0110\n",
            "Epoch 12/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0121 - val_loss: 1.0108\n",
            "Epoch 13/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0119 - val_loss: 1.0106\n",
            "Epoch 14/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0118 - val_loss: 1.0105\n",
            "Epoch 15/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0116 - val_loss: 1.0103\n",
            "Epoch 16/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0114 - val_loss: 1.0102\n",
            "Epoch 17/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0112 - val_loss: 1.0100\n",
            "Epoch 18/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0110 - val_loss: 1.0098\n",
            "Epoch 19/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0109 - val_loss: 1.0097\n",
            "Epoch 20/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0107 - val_loss: 1.0095\n",
            "Epoch 21/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0105 - val_loss: 1.0093\n",
            "Epoch 22/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0103 - val_loss: 1.0092\n",
            "Epoch 23/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0102 - val_loss: 1.0090\n",
            "Epoch 24/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0100 - val_loss: 1.0089\n",
            "Epoch 25/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0098 - val_loss: 1.0087\n",
            "Epoch 26/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 1.0085\n",
            "Epoch 27/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0094 - val_loss: 1.0084\n",
            "Epoch 28/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0093 - val_loss: 1.0082\n",
            "Epoch 29/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0091 - val_loss: 1.0080\n",
            "Epoch 30/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0089 - val_loss: 1.0079\n",
            "Epoch 31/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0087 - val_loss: 1.0077\n",
            "Epoch 32/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0086 - val_loss: 1.0076\n",
            "Epoch 33/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0084 - val_loss: 1.0074\n",
            "Epoch 34/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0082 - val_loss: 1.0072\n",
            "Epoch 35/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0080 - val_loss: 1.0071\n",
            "Epoch 36/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0079 - val_loss: 1.0069\n",
            "Epoch 37/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0077 - val_loss: 1.0068\n",
            "Epoch 38/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0075 - val_loss: 1.0066\n",
            "Epoch 39/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0073 - val_loss: 1.0064\n",
            "Epoch 40/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0072 - val_loss: 1.0063\n",
            "Epoch 41/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0070 - val_loss: 1.0061\n",
            "Epoch 42/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0068 - val_loss: 1.0060\n",
            "Epoch 43/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0066 - val_loss: 1.0058\n",
            "Epoch 44/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0065 - val_loss: 1.0056\n",
            "Epoch 45/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0063 - val_loss: 1.0055\n",
            "Epoch 46/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0061 - val_loss: 1.0053\n",
            "Epoch 47/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0059 - val_loss: 1.0052\n",
            "Epoch 48/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0057 - val_loss: 1.0050\n",
            "Epoch 49/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0056 - val_loss: 1.0048\n",
            "Epoch 50/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0054 - val_loss: 1.0047\n",
            "Epoch 51/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0052 - val_loss: 1.0045\n",
            "Epoch 52/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0050 - val_loss: 1.0044\n",
            "Epoch 53/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0049 - val_loss: 1.0042\n",
            "Epoch 54/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0047 - val_loss: 1.0040\n",
            "Epoch 55/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0045 - val_loss: 1.0039\n",
            "Epoch 56/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0043 - val_loss: 1.0037\n",
            "Epoch 57/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0042 - val_loss: 1.0036\n",
            "Epoch 58/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0040 - val_loss: 1.0034\n",
            "Epoch 59/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0038 - val_loss: 1.0033\n",
            "Epoch 60/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0036 - val_loss: 1.0031\n",
            "Epoch 61/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0035 - val_loss: 1.0029\n",
            "Epoch 62/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0033 - val_loss: 1.0028\n",
            "Epoch 63/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 1.0026\n",
            "Epoch 64/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0030 - val_loss: 1.0025\n",
            "Epoch 65/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0028 - val_loss: 1.0023\n",
            "Epoch 66/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0026 - val_loss: 1.0022\n",
            "Epoch 67/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0024 - val_loss: 1.0020\n",
            "Epoch 68/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0023 - val_loss: 1.0018\n",
            "Epoch 69/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0021 - val_loss: 1.0017\n",
            "Epoch 70/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0019 - val_loss: 1.0015\n",
            "Epoch 71/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0018 - val_loss: 1.0014\n",
            "Epoch 72/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0016 - val_loss: 1.0012\n",
            "Epoch 73/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0014 - val_loss: 1.0011\n",
            "Epoch 74/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0012 - val_loss: 1.0009\n",
            "Epoch 75/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 1.0008\n",
            "Epoch 76/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0009 - val_loss: 1.0006\n",
            "Epoch 77/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0007 - val_loss: 1.0005\n",
            "Epoch 78/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0006 - val_loss: 1.0003\n",
            "Epoch 79/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0004 - val_loss: 1.0002\n",
            "Epoch 80/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0002 - val_loss: 1.0000\n",
            "Epoch 81/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 0.9999\n",
            "Epoch 82/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9997\n",
            "Epoch 83/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9995\n",
            "Epoch 84/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9994\n",
            "Epoch 85/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9992\n",
            "Epoch 86/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9991\n",
            "Epoch 87/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9989\n",
            "Epoch 88/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9988\n",
            "Epoch 89/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9986\n",
            "Epoch 90/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9985\n",
            "Epoch 91/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 0.9983\n",
            "Epoch 92/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 0.9982\n",
            "Epoch 93/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9980\n",
            "Epoch 94/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 0.9979\n",
            "Epoch 95/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 0.9977\n",
            "Epoch 96/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 0.9975\n",
            "Epoch 97/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 0.9974\n",
            "Epoch 98/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 0.9972\n",
            "Epoch 99/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 0.9971\n",
            "Epoch 100/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 0.9969\n",
            "Epoch 101/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9967 - val_loss: 0.9968\n",
            "Epoch 102/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9965 - val_loss: 0.9966\n",
            "Epoch 103/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9963 - val_loss: 0.9964\n",
            "Epoch 104/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9962 - val_loss: 0.9963\n",
            "Epoch 105/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9960 - val_loss: 0.9961\n",
            "Epoch 106/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9958 - val_loss: 0.9960\n",
            "Epoch 107/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9956 - val_loss: 0.9958\n",
            "Epoch 108/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9955 - val_loss: 0.9956\n",
            "Epoch 109/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9953 - val_loss: 0.9955\n",
            "Epoch 110/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9951 - val_loss: 0.9953\n",
            "Epoch 111/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9950 - val_loss: 0.9952\n",
            "Epoch 112/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9948 - val_loss: 0.9950\n",
            "Epoch 113/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9946 - val_loss: 0.9949\n",
            "Epoch 114/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 0.9947\n",
            "Epoch 115/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9943 - val_loss: 0.9946\n",
            "Epoch 116/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9941 - val_loss: 0.9944\n",
            "Epoch 117/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 0.9942\n",
            "Epoch 118/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 0.9941\n",
            "Epoch 119/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9936 - val_loss: 0.9939\n",
            "Epoch 120/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 0.9938\n",
            "Epoch 121/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 0.9936\n",
            "Epoch 122/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 0.9935\n",
            "Epoch 123/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 0.9933\n",
            "Epoch 124/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 0.9932\n",
            "Epoch 125/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9926 - val_loss: 0.9930\n",
            "Epoch 126/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 0.9929\n",
            "Epoch 127/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9922 - val_loss: 0.9927\n",
            "Epoch 128/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9921 - val_loss: 0.9926\n",
            "Epoch 129/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9919 - val_loss: 0.9924\n",
            "Epoch 130/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9917 - val_loss: 0.9923\n",
            "Epoch 131/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9916 - val_loss: 0.9921\n",
            "Epoch 132/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9914 - val_loss: 0.9920\n",
            "Epoch 133/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9912 - val_loss: 0.9918\n",
            "Epoch 134/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9911 - val_loss: 0.9916\n",
            "Epoch 135/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 0.9915\n",
            "Epoch 136/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9907 - val_loss: 0.9913\n",
            "Epoch 137/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9906 - val_loss: 0.9912\n",
            "Epoch 138/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9904 - val_loss: 0.9910\n",
            "Epoch 139/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9902 - val_loss: 0.9909\n",
            "Epoch 140/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9900 - val_loss: 0.9907\n",
            "Epoch 141/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9899 - val_loss: 0.9906\n",
            "Epoch 142/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9897 - val_loss: 0.9904\n",
            "Epoch 143/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9895 - val_loss: 0.9903\n",
            "Epoch 144/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9894 - val_loss: 0.9901\n",
            "Epoch 145/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9892 - val_loss: 0.9900\n",
            "Epoch 146/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9890 - val_loss: 0.9898\n",
            "Epoch 147/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9889 - val_loss: 0.9897\n",
            "Epoch 148/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9887 - val_loss: 0.9895\n",
            "Epoch 149/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9885 - val_loss: 0.9894\n",
            "Epoch 150/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9884 - val_loss: 0.9892\n",
            "Epoch 151/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9882 - val_loss: 0.9891\n",
            "Epoch 152/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9880 - val_loss: 0.9889\n",
            "Epoch 153/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9879 - val_loss: 0.9888\n",
            "Epoch 154/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9877 - val_loss: 0.9886\n",
            "Epoch 155/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9875 - val_loss: 0.9885\n",
            "Epoch 156/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9873 - val_loss: 0.9883\n",
            "Epoch 157/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9872 - val_loss: 0.9882\n",
            "Epoch 158/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9870 - val_loss: 0.9880\n",
            "Epoch 159/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9868 - val_loss: 0.9878\n",
            "Epoch 160/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9867 - val_loss: 0.9877\n",
            "Epoch 161/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9865 - val_loss: 0.9875\n",
            "Epoch 162/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9863 - val_loss: 0.9874\n",
            "Epoch 163/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9862 - val_loss: 0.9872\n",
            "Epoch 164/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9860 - val_loss: 0.9871\n",
            "Epoch 165/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9858 - val_loss: 0.9869\n",
            "Epoch 166/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9857 - val_loss: 0.9868\n",
            "Epoch 167/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9855 - val_loss: 0.9867\n",
            "Epoch 168/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9853 - val_loss: 0.9865\n",
            "Epoch 169/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9851 - val_loss: 0.9863\n",
            "Epoch 170/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9850 - val_loss: 0.9862\n",
            "Epoch 171/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9848 - val_loss: 0.9860\n",
            "Epoch 172/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9846 - val_loss: 0.9859\n",
            "Epoch 173/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9845 - val_loss: 0.9857\n",
            "Epoch 174/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9843 - val_loss: 0.9856\n",
            "Epoch 175/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9841 - val_loss: 0.9854\n",
            "Epoch 176/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9839 - val_loss: 0.9853\n",
            "Epoch 177/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9838 - val_loss: 0.9851\n",
            "Epoch 178/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9836 - val_loss: 0.9850\n",
            "Epoch 179/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9834 - val_loss: 0.9848\n",
            "Epoch 180/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9832 - val_loss: 0.9847\n",
            "Epoch 181/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9831 - val_loss: 0.9845\n",
            "Epoch 182/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9829 - val_loss: 0.9844\n",
            "Epoch 183/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9827 - val_loss: 0.9842\n",
            "Epoch 184/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9826 - val_loss: 0.9840\n",
            "Epoch 185/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9824 - val_loss: 0.9839\n",
            "Epoch 186/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9822 - val_loss: 0.9837\n",
            "Epoch 187/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9820 - val_loss: 0.9836\n",
            "Epoch 188/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9818 - val_loss: 0.9834\n",
            "Epoch 189/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9817 - val_loss: 0.9833\n",
            "Epoch 190/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9815 - val_loss: 0.9831\n",
            "Epoch 191/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9813 - val_loss: 0.9829\n",
            "Epoch 192/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9811 - val_loss: 0.9828\n",
            "Epoch 193/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9810 - val_loss: 0.9826\n",
            "Epoch 194/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9808 - val_loss: 0.9825\n",
            "Epoch 195/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9806 - val_loss: 0.9823\n",
            "Epoch 196/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9804 - val_loss: 0.9822\n",
            "Epoch 197/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9803 - val_loss: 0.9820\n",
            "Epoch 198/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9801 - val_loss: 0.9819\n",
            "Epoch 199/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9799 - val_loss: 0.9817\n",
            "Epoch 200/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9798 - val_loss: 0.9815\n",
            "Epoch 201/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9796 - val_loss: 0.9814\n",
            "Epoch 202/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9794 - val_loss: 0.9812\n",
            "Epoch 203/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9792 - val_loss: 0.9811\n",
            "Epoch 204/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9791 - val_loss: 0.9809\n",
            "Epoch 205/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9789 - val_loss: 0.9808\n",
            "Epoch 206/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9787 - val_loss: 0.9806\n",
            "Epoch 207/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9785 - val_loss: 0.9804\n",
            "Epoch 208/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9784 - val_loss: 0.9803\n",
            "Epoch 209/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9782 - val_loss: 0.9801\n",
            "Epoch 210/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9780 - val_loss: 0.9800\n",
            "Epoch 211/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9778 - val_loss: 0.9798\n",
            "Epoch 212/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9777 - val_loss: 0.9796\n",
            "Epoch 213/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9775 - val_loss: 0.9795\n",
            "Epoch 214/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9773 - val_loss: 0.9793\n",
            "Epoch 215/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9771 - val_loss: 0.9792\n",
            "Epoch 216/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9769 - val_loss: 0.9790\n",
            "Epoch 217/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9768 - val_loss: 0.9788\n",
            "Epoch 218/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9766 - val_loss: 0.9787\n",
            "Epoch 219/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9764 - val_loss: 0.9785\n",
            "Epoch 220/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9762 - val_loss: 0.9784\n",
            "Epoch 221/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9761 - val_loss: 0.9782\n",
            "Epoch 222/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9759 - val_loss: 0.9780\n",
            "Epoch 223/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9757 - val_loss: 0.9779\n",
            "Epoch 224/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9755 - val_loss: 0.9777\n",
            "Epoch 225/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9753 - val_loss: 0.9776\n",
            "Epoch 226/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9752 - val_loss: 0.9774\n",
            "Epoch 227/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9750 - val_loss: 0.9773\n",
            "Epoch 228/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9748 - val_loss: 0.9771\n",
            "Epoch 229/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9746 - val_loss: 0.9769\n",
            "Epoch 230/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9745 - val_loss: 0.9768\n",
            "Epoch 231/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9743 - val_loss: 0.9766\n",
            "Epoch 232/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9741 - val_loss: 0.9764\n",
            "Epoch 233/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9739 - val_loss: 0.9763\n",
            "Epoch 234/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9737 - val_loss: 0.9761\n",
            "Epoch 235/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9735 - val_loss: 0.9759\n",
            "Epoch 236/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9734 - val_loss: 0.9758\n",
            "Epoch 237/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9732 - val_loss: 0.9756\n",
            "Epoch 238/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9730 - val_loss: 0.9754\n",
            "Epoch 239/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9728 - val_loss: 0.9753\n",
            "Epoch 240/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9726 - val_loss: 0.9751\n",
            "Epoch 241/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9724 - val_loss: 0.9749\n",
            "Epoch 242/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9723 - val_loss: 0.9748\n",
            "Epoch 243/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9721 - val_loss: 0.9746\n",
            "Epoch 244/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9719 - val_loss: 0.9745\n",
            "Epoch 245/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9717 - val_loss: 0.9743\n",
            "Epoch 246/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9715 - val_loss: 0.9741\n",
            "Epoch 247/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9714 - val_loss: 0.9740\n",
            "Epoch 248/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9712 - val_loss: 0.9738\n",
            "Epoch 249/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9710 - val_loss: 0.9736\n",
            "Epoch 250/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9708 - val_loss: 0.9735\n",
            "Epoch 251/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9706 - val_loss: 0.9733\n",
            "Epoch 252/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9704 - val_loss: 0.9731\n",
            "Epoch 253/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9703 - val_loss: 0.9730\n",
            "Epoch 254/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9701 - val_loss: 0.9728\n",
            "Epoch 255/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9699 - val_loss: 0.9726\n",
            "Epoch 256/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9697 - val_loss: 0.9725\n",
            "Epoch 257/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9695 - val_loss: 0.9723\n",
            "Epoch 258/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9693 - val_loss: 0.9721\n",
            "Epoch 259/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9691 - val_loss: 0.9720\n",
            "Epoch 260/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9689 - val_loss: 0.9718\n",
            "Epoch 261/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9688 - val_loss: 0.9716\n",
            "Epoch 262/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9686 - val_loss: 0.9715\n",
            "Epoch 263/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9684 - val_loss: 0.9713\n",
            "Epoch 264/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9682 - val_loss: 0.9711\n",
            "Epoch 265/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9680 - val_loss: 0.9710\n",
            "Epoch 266/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9678 - val_loss: 0.9708\n",
            "Epoch 267/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9676 - val_loss: 0.9706\n",
            "Epoch 268/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9675 - val_loss: 0.9705\n",
            "Epoch 269/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9673 - val_loss: 0.9703\n",
            "Epoch 270/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9671 - val_loss: 0.9701\n",
            "Epoch 271/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9669 - val_loss: 0.9699\n",
            "Epoch 272/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9667 - val_loss: 0.9698\n",
            "Epoch 273/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9665 - val_loss: 0.9696\n",
            "Epoch 274/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9663 - val_loss: 0.9694\n",
            "Epoch 275/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9661 - val_loss: 0.9693\n",
            "Epoch 276/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9660 - val_loss: 0.9691\n",
            "Epoch 277/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9658 - val_loss: 0.9689\n",
            "Epoch 278/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9656 - val_loss: 0.9688\n",
            "Epoch 279/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9654 - val_loss: 0.9686\n",
            "Epoch 280/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9652 - val_loss: 0.9684\n",
            "Epoch 281/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9650 - val_loss: 0.9683\n",
            "Epoch 282/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9648 - val_loss: 0.9681\n",
            "Epoch 283/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9646 - val_loss: 0.9679\n",
            "Epoch 284/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9645 - val_loss: 0.9678\n",
            "Epoch 285/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9643 - val_loss: 0.9676\n",
            "Epoch 286/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9641 - val_loss: 0.9674\n",
            "Epoch 287/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9639 - val_loss: 0.9673\n",
            "Epoch 288/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9637 - val_loss: 0.9671\n",
            "Epoch 289/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9635 - val_loss: 0.9669\n",
            "Epoch 290/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9633 - val_loss: 0.9668\n",
            "Epoch 291/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9632 - val_loss: 0.9666\n",
            "Epoch 292/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9630 - val_loss: 0.9664\n",
            "Epoch 293/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9628 - val_loss: 0.9662\n",
            "Epoch 294/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9626 - val_loss: 0.9661\n",
            "Epoch 295/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9624 - val_loss: 0.9659\n",
            "Epoch 296/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9622 - val_loss: 0.9657\n",
            "Epoch 297/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9620 - val_loss: 0.9655\n",
            "Epoch 298/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9618 - val_loss: 0.9654\n",
            "Epoch 299/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9616 - val_loss: 0.9652\n",
            "Epoch 300/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9614 - val_loss: 0.9650\n",
            "Epoch 301/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9613 - val_loss: 0.9649\n",
            "Epoch 302/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9611 - val_loss: 0.9647\n",
            "Epoch 303/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9609 - val_loss: 0.9645\n",
            "Epoch 304/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9607 - val_loss: 0.9644\n",
            "Epoch 305/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9605 - val_loss: 0.9642\n",
            "Epoch 306/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9603 - val_loss: 0.9640\n",
            "Epoch 307/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9601 - val_loss: 0.9639\n",
            "Epoch 308/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9599 - val_loss: 0.9637\n",
            "Epoch 309/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9597 - val_loss: 0.9635\n",
            "Epoch 310/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9596 - val_loss: 0.9633\n",
            "Epoch 311/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9594 - val_loss: 0.9632\n",
            "Epoch 312/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9592 - val_loss: 0.9630\n",
            "Epoch 313/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9590 - val_loss: 0.9628\n",
            "Epoch 314/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9588 - val_loss: 0.9627\n",
            "Epoch 315/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9586 - val_loss: 0.9625\n",
            "Epoch 316/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9584 - val_loss: 0.9623\n",
            "Epoch 317/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9582 - val_loss: 0.9622\n",
            "Epoch 318/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9580 - val_loss: 0.9620\n",
            "Epoch 319/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9578 - val_loss: 0.9618\n",
            "Epoch 320/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9577 - val_loss: 0.9616\n",
            "Epoch 321/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9575 - val_loss: 0.9615\n",
            "Epoch 322/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9573 - val_loss: 0.9613\n",
            "Epoch 323/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9571 - val_loss: 0.9611\n",
            "Epoch 324/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9569 - val_loss: 0.9610\n",
            "Epoch 325/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9567 - val_loss: 0.9608\n",
            "Epoch 326/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9565 - val_loss: 0.9606\n",
            "Epoch 327/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9563 - val_loss: 0.9604\n",
            "Epoch 328/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9561 - val_loss: 0.9603\n",
            "Epoch 329/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9559 - val_loss: 0.9601\n",
            "Epoch 330/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9557 - val_loss: 0.9599\n",
            "Epoch 331/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9555 - val_loss: 0.9597\n",
            "Epoch 332/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9553 - val_loss: 0.9595\n",
            "Epoch 333/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9551 - val_loss: 0.9594\n",
            "Epoch 334/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9549 - val_loss: 0.9592\n",
            "Epoch 335/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9547 - val_loss: 0.9590\n",
            "Epoch 336/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9545 - val_loss: 0.9588\n",
            "Epoch 337/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9543 - val_loss: 0.9587\n",
            "Epoch 338/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9542 - val_loss: 0.9585\n",
            "Epoch 339/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9540 - val_loss: 0.9583\n",
            "Epoch 340/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9538 - val_loss: 0.9582\n",
            "Epoch 341/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9536 - val_loss: 0.9580\n",
            "Epoch 342/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9534 - val_loss: 0.9578\n",
            "Epoch 343/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9532 - val_loss: 0.9576\n",
            "Epoch 344/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9530 - val_loss: 0.9575\n",
            "Epoch 345/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9528 - val_loss: 0.9573\n",
            "Epoch 346/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9526 - val_loss: 0.9571\n",
            "Epoch 347/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9524 - val_loss: 0.9569\n",
            "Epoch 348/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9522 - val_loss: 0.9567\n",
            "Epoch 349/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9520 - val_loss: 0.9566\n",
            "Epoch 350/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9518 - val_loss: 0.9564\n",
            "Epoch 351/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9516 - val_loss: 0.9562\n",
            "Epoch 352/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9514 - val_loss: 0.9560\n",
            "Epoch 353/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9512 - val_loss: 0.9559\n",
            "Epoch 354/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9510 - val_loss: 0.9557\n",
            "Epoch 355/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9508 - val_loss: 0.9555\n",
            "Epoch 356/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9506 - val_loss: 0.9553\n",
            "Epoch 357/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9504 - val_loss: 0.9552\n",
            "Epoch 358/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9502 - val_loss: 0.9550\n",
            "Epoch 359/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9500 - val_loss: 0.9548\n",
            "Epoch 360/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9498 - val_loss: 0.9546\n",
            "Epoch 361/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9496 - val_loss: 0.9545\n",
            "Epoch 362/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9494 - val_loss: 0.9543\n",
            "Epoch 363/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9492 - val_loss: 0.9541\n",
            "Epoch 364/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9490 - val_loss: 0.9539\n",
            "Epoch 365/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9488 - val_loss: 0.9538\n",
            "Epoch 366/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9486 - val_loss: 0.9536\n",
            "Epoch 367/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9484 - val_loss: 0.9534\n",
            "Epoch 368/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9482 - val_loss: 0.9532\n",
            "Epoch 369/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9480 - val_loss: 0.9530\n",
            "Epoch 370/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9478 - val_loss: 0.9529\n",
            "Epoch 371/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9476 - val_loss: 0.9527\n",
            "Epoch 372/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9474 - val_loss: 0.9525\n",
            "Epoch 373/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9472 - val_loss: 0.9523\n",
            "Epoch 374/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9470 - val_loss: 0.9521\n",
            "Epoch 375/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9468 - val_loss: 0.9520\n",
            "Epoch 376/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9466 - val_loss: 0.9518\n",
            "Epoch 377/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9464 - val_loss: 0.9516\n",
            "Epoch 378/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9462 - val_loss: 0.9514\n",
            "Epoch 379/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9460 - val_loss: 0.9512\n",
            "Epoch 380/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9458 - val_loss: 0.9510\n",
            "Epoch 381/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9456 - val_loss: 0.9509\n",
            "Epoch 382/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9454 - val_loss: 0.9507\n",
            "Epoch 383/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9452 - val_loss: 0.9505\n",
            "Epoch 384/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9450 - val_loss: 0.9503\n",
            "Epoch 385/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9448 - val_loss: 0.9501\n",
            "Epoch 386/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9446 - val_loss: 0.9500\n",
            "Epoch 387/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9444 - val_loss: 0.9498\n",
            "Epoch 388/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9441 - val_loss: 0.9496\n",
            "Epoch 389/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9439 - val_loss: 0.9494\n",
            "Epoch 390/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9437 - val_loss: 0.9492\n",
            "Epoch 391/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9435 - val_loss: 0.9490\n",
            "Epoch 392/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9433 - val_loss: 0.9489\n",
            "Epoch 393/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9431 - val_loss: 0.9487\n",
            "Epoch 394/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9429 - val_loss: 0.9485\n",
            "Epoch 395/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9427 - val_loss: 0.9483\n",
            "Epoch 396/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9425 - val_loss: 0.9481\n",
            "Epoch 397/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9423 - val_loss: 0.9479\n",
            "Epoch 398/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.9478\n",
            "Epoch 399/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9419 - val_loss: 0.9476\n",
            "Epoch 400/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9417 - val_loss: 0.9474\n",
            "Epoch 401/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9414 - val_loss: 0.9472\n",
            "Epoch 402/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9412 - val_loss: 0.9470\n",
            "Epoch 403/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9410 - val_loss: 0.9468\n",
            "Epoch 404/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9408 - val_loss: 0.9466\n",
            "Epoch 405/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9406 - val_loss: 0.9465\n",
            "Epoch 406/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9404 - val_loss: 0.9463\n",
            "Epoch 407/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9402 - val_loss: 0.9461\n",
            "Epoch 408/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9400 - val_loss: 0.9459\n",
            "Epoch 409/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 0.9457\n",
            "Epoch 410/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9396 - val_loss: 0.9455\n",
            "Epoch 411/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9393 - val_loss: 0.9453\n",
            "Epoch 412/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9391 - val_loss: 0.9452\n",
            "Epoch 413/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9389 - val_loss: 0.9450\n",
            "Epoch 414/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9387 - val_loss: 0.9448\n",
            "Epoch 415/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9385 - val_loss: 0.9446\n",
            "Epoch 416/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9383 - val_loss: 0.9444\n",
            "Epoch 417/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9381 - val_loss: 0.9442\n",
            "Epoch 418/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9379 - val_loss: 0.9440\n",
            "Epoch 419/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9377 - val_loss: 0.9439\n",
            "Epoch 420/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9375 - val_loss: 0.9437\n",
            "Epoch 421/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9373 - val_loss: 0.9435\n",
            "Epoch 422/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9371 - val_loss: 0.9433\n",
            "Epoch 423/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9368 - val_loss: 0.9431\n",
            "Epoch 424/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9366 - val_loss: 0.9429\n",
            "Epoch 425/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9364 - val_loss: 0.9427\n",
            "Epoch 426/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9362 - val_loss: 0.9426\n",
            "Epoch 427/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9360 - val_loss: 0.9424\n",
            "Epoch 428/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9358 - val_loss: 0.9422\n",
            "Epoch 429/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9356 - val_loss: 0.9420\n",
            "Epoch 430/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9354 - val_loss: 0.9418\n",
            "Epoch 431/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9351 - val_loss: 0.9416\n",
            "Epoch 432/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9349 - val_loss: 0.9414\n",
            "Epoch 433/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9347 - val_loss: 0.9412\n",
            "Epoch 434/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9345 - val_loss: 0.9410\n",
            "Epoch 435/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9343 - val_loss: 0.9409\n",
            "Epoch 436/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9341 - val_loss: 0.9407\n",
            "Epoch 437/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9339 - val_loss: 0.9405\n",
            "Epoch 438/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9337 - val_loss: 0.9403\n",
            "Epoch 439/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9334 - val_loss: 0.9401\n",
            "Epoch 440/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9332 - val_loss: 0.9399\n",
            "Epoch 441/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9330 - val_loss: 0.9397\n",
            "Epoch 442/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9328 - val_loss: 0.9395\n",
            "Epoch 443/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9326 - val_loss: 0.9394\n",
            "Epoch 444/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9324 - val_loss: 0.9392\n",
            "Epoch 445/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9322 - val_loss: 0.9390\n",
            "Epoch 446/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9319 - val_loss: 0.9388\n",
            "Epoch 447/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9317 - val_loss: 0.9386\n",
            "Epoch 448/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9315 - val_loss: 0.9384\n",
            "Epoch 449/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9313 - val_loss: 0.9382\n",
            "Epoch 450/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9311 - val_loss: 0.9380\n",
            "Epoch 451/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9308 - val_loss: 0.9378\n",
            "Epoch 452/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9306 - val_loss: 0.9376\n",
            "Epoch 453/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9304 - val_loss: 0.9374\n",
            "Epoch 454/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9302 - val_loss: 0.9372\n",
            "Epoch 455/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9300 - val_loss: 0.9370\n",
            "Epoch 456/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9297 - val_loss: 0.9368\n",
            "Epoch 457/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9295 - val_loss: 0.9366\n",
            "Epoch 458/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9293 - val_loss: 0.9364\n",
            "Epoch 459/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9362\n",
            "Epoch 460/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9288 - val_loss: 0.9360\n",
            "Epoch 461/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9286 - val_loss: 0.9358\n",
            "Epoch 462/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9284 - val_loss: 0.9356\n",
            "Epoch 463/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9282 - val_loss: 0.9354\n",
            "Epoch 464/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9279 - val_loss: 0.9352\n",
            "Epoch 465/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9277 - val_loss: 0.9350\n",
            "Epoch 466/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9275 - val_loss: 0.9348\n",
            "Epoch 467/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9273 - val_loss: 0.9346\n",
            "Epoch 468/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9270 - val_loss: 0.9344\n",
            "Epoch 469/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9268 - val_loss: 0.9342\n",
            "Epoch 470/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9266 - val_loss: 0.9340\n",
            "Epoch 471/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9263 - val_loss: 0.9338\n",
            "Epoch 472/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9261 - val_loss: 0.9336\n",
            "Epoch 473/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9259 - val_loss: 0.9334\n",
            "Epoch 474/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9257 - val_loss: 0.9332\n",
            "Epoch 475/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9254 - val_loss: 0.9330\n",
            "Epoch 476/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9252 - val_loss: 0.9328\n",
            "Epoch 477/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9250 - val_loss: 0.9326\n",
            "Epoch 478/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9248 - val_loss: 0.9325\n",
            "Epoch 479/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9245 - val_loss: 0.9323\n",
            "Epoch 480/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9243 - val_loss: 0.9321\n",
            "Epoch 481/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9241 - val_loss: 0.9319\n",
            "Epoch 482/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9239 - val_loss: 0.9317\n",
            "Epoch 483/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9236 - val_loss: 0.9315\n",
            "Epoch 484/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9234 - val_loss: 0.9313\n",
            "Epoch 485/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9232 - val_loss: 0.9311\n",
            "Epoch 486/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9229 - val_loss: 0.9309\n",
            "Epoch 487/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9227 - val_loss: 0.9307\n",
            "Epoch 488/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9225 - val_loss: 0.9305\n",
            "Epoch 489/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9223 - val_loss: 0.9303\n",
            "Epoch 490/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9220 - val_loss: 0.9301\n",
            "Epoch 491/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9218 - val_loss: 0.9299\n",
            "Epoch 492/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9216 - val_loss: 0.9297\n",
            "Epoch 493/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9213 - val_loss: 0.9295\n",
            "Epoch 494/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9211 - val_loss: 0.9293\n",
            "Epoch 495/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9209 - val_loss: 0.9291\n",
            "Epoch 496/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9207 - val_loss: 0.9289\n",
            "Epoch 497/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9204 - val_loss: 0.9287\n",
            "Epoch 498/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9202 - val_loss: 0.9285\n",
            "Epoch 499/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 0.9283\n",
            "Epoch 500/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9197 - val_loss: 0.9281\n",
            "Epoch 501/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9195 - val_loss: 0.9279\n",
            "Epoch 502/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9193 - val_loss: 0.9276\n",
            "Epoch 503/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9190 - val_loss: 0.9274\n",
            "Epoch 504/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9188 - val_loss: 0.9272\n",
            "Epoch 505/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9186 - val_loss: 0.9270\n",
            "Epoch 506/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9183 - val_loss: 0.9268\n",
            "Epoch 507/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9181 - val_loss: 0.9266\n",
            "Epoch 508/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9179 - val_loss: 0.9264\n",
            "Epoch 509/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9176 - val_loss: 0.9262\n",
            "Epoch 510/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9174 - val_loss: 0.9260\n",
            "Epoch 511/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9172 - val_loss: 0.9258\n",
            "Epoch 512/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9169 - val_loss: 0.9256\n",
            "Epoch 513/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9167 - val_loss: 0.9254\n",
            "Epoch 514/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9165 - val_loss: 0.9252\n",
            "Epoch 515/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9162 - val_loss: 0.9250\n",
            "Epoch 516/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9160 - val_loss: 0.9248\n",
            "Epoch 517/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9157 - val_loss: 0.9246\n",
            "Epoch 518/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9155 - val_loss: 0.9244\n",
            "Epoch 519/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9153 - val_loss: 0.9241\n",
            "Epoch 520/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9150 - val_loss: 0.9239\n",
            "Epoch 521/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9148 - val_loss: 0.9237\n",
            "Epoch 522/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9146 - val_loss: 0.9235\n",
            "Epoch 523/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9143 - val_loss: 0.9233\n",
            "Epoch 524/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9141 - val_loss: 0.9231\n",
            "Epoch 525/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9139 - val_loss: 0.9229\n",
            "Epoch 526/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9136 - val_loss: 0.9227\n",
            "Epoch 527/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9134 - val_loss: 0.9225\n",
            "Epoch 528/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9132 - val_loss: 0.9223\n",
            "Epoch 529/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9129 - val_loss: 0.9221\n",
            "Epoch 530/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9127 - val_loss: 0.9219\n",
            "Epoch 531/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9124 - val_loss: 0.9217\n",
            "Epoch 532/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9122 - val_loss: 0.9215\n",
            "Epoch 533/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9120 - val_loss: 0.9213\n",
            "Epoch 534/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9117 - val_loss: 0.9210\n",
            "Epoch 535/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9115 - val_loss: 0.9208\n",
            "Epoch 536/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9113 - val_loss: 0.9206\n",
            "Epoch 537/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9110 - val_loss: 0.9204\n",
            "Epoch 538/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9108 - val_loss: 0.9202\n",
            "Epoch 539/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9105 - val_loss: 0.9200\n",
            "Epoch 540/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9103 - val_loss: 0.9198\n",
            "Epoch 541/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9101 - val_loss: 0.9196\n",
            "Epoch 542/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9098 - val_loss: 0.9193\n",
            "Epoch 543/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9096 - val_loss: 0.9191\n",
            "Epoch 544/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9093 - val_loss: 0.9189\n",
            "Epoch 545/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9091 - val_loss: 0.9187\n",
            "Epoch 546/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9088 - val_loss: 0.9185\n",
            "Epoch 547/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9086 - val_loss: 0.9183\n",
            "Epoch 548/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9084 - val_loss: 0.9181\n",
            "Epoch 549/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9081 - val_loss: 0.9179\n",
            "Epoch 550/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9079 - val_loss: 0.9177\n",
            "Epoch 551/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9077 - val_loss: 0.9175\n",
            "Epoch 552/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9074 - val_loss: 0.9172\n",
            "Epoch 553/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9072 - val_loss: 0.9170\n",
            "Epoch 554/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9070 - val_loss: 0.9168\n",
            "Epoch 555/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9067 - val_loss: 0.9166\n",
            "Epoch 556/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9065 - val_loss: 0.9164\n",
            "Epoch 557/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9062 - val_loss: 0.9162\n",
            "Epoch 558/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9060 - val_loss: 0.9160\n",
            "Epoch 559/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9058 - val_loss: 0.9158\n",
            "Epoch 560/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9055 - val_loss: 0.9156\n",
            "Epoch 561/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9053 - val_loss: 0.9154\n",
            "Epoch 562/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9050 - val_loss: 0.9151\n",
            "Epoch 563/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9048 - val_loss: 0.9149\n",
            "Epoch 564/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9046 - val_loss: 0.9147\n",
            "Epoch 565/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9043 - val_loss: 0.9145\n",
            "Epoch 566/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9041 - val_loss: 0.9143\n",
            "Epoch 567/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9038 - val_loss: 0.9141\n",
            "Epoch 568/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9036 - val_loss: 0.9139\n",
            "Epoch 569/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9033 - val_loss: 0.9137\n",
            "Epoch 570/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9031 - val_loss: 0.9134\n",
            "Epoch 571/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9028 - val_loss: 0.9132\n",
            "Epoch 572/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9026 - val_loss: 0.9130\n",
            "Epoch 573/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9024 - val_loss: 0.9128\n",
            "Epoch 574/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9021 - val_loss: 0.9126\n",
            "Epoch 575/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9019 - val_loss: 0.9124\n",
            "Epoch 576/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9016 - val_loss: 0.9122\n",
            "Epoch 577/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9014 - val_loss: 0.9120\n",
            "Epoch 578/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9012 - val_loss: 0.9118\n",
            "Epoch 579/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9009 - val_loss: 0.9115\n",
            "Epoch 580/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9007 - val_loss: 0.9113\n",
            "Epoch 581/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9004 - val_loss: 0.9111\n",
            "Epoch 582/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9002 - val_loss: 0.9109\n",
            "Epoch 583/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9000 - val_loss: 0.9107\n",
            "Epoch 584/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8997 - val_loss: 0.9105\n",
            "Epoch 585/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8995 - val_loss: 0.9103\n",
            "Epoch 586/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8992 - val_loss: 0.9100\n",
            "Epoch 587/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8990 - val_loss: 0.9098\n",
            "Epoch 588/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8987 - val_loss: 0.9096\n",
            "Epoch 589/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8985 - val_loss: 0.9094\n",
            "Epoch 590/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8982 - val_loss: 0.9092\n",
            "Epoch 591/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8980 - val_loss: 0.9089\n",
            "Epoch 592/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8977 - val_loss: 0.9087\n",
            "Epoch 593/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8974 - val_loss: 0.9085\n",
            "Epoch 594/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8972 - val_loss: 0.9083\n",
            "Epoch 595/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8969 - val_loss: 0.9081\n",
            "Epoch 596/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8967 - val_loss: 0.9078\n",
            "Epoch 597/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8964 - val_loss: 0.9076\n",
            "Epoch 598/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8962 - val_loss: 0.9074\n",
            "Epoch 599/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8959 - val_loss: 0.9072\n",
            "Epoch 600/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8957 - val_loss: 0.9070\n",
            "Epoch 601/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8954 - val_loss: 0.9067\n",
            "Epoch 602/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8952 - val_loss: 0.9065\n",
            "Epoch 603/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8949 - val_loss: 0.9063\n",
            "Epoch 604/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8947 - val_loss: 0.9061\n",
            "Epoch 605/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8944 - val_loss: 0.9059\n",
            "Epoch 606/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8942 - val_loss: 0.9056\n",
            "Epoch 607/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8939 - val_loss: 0.9054\n",
            "Epoch 608/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8937 - val_loss: 0.9052\n",
            "Epoch 609/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8934 - val_loss: 0.9050\n",
            "Epoch 610/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8932 - val_loss: 0.9047\n",
            "Epoch 611/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8929 - val_loss: 0.9045\n",
            "Epoch 612/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8926 - val_loss: 0.9043\n",
            "Epoch 613/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8924 - val_loss: 0.9041\n",
            "Epoch 614/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8921 - val_loss: 0.9038\n",
            "Epoch 615/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8919 - val_loss: 0.9036\n",
            "Epoch 616/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8916 - val_loss: 0.9034\n",
            "Epoch 617/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8914 - val_loss: 0.9032\n",
            "Epoch 618/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8911 - val_loss: 0.9029\n",
            "Epoch 619/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8908 - val_loss: 0.9027\n",
            "Epoch 620/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8906 - val_loss: 0.9025\n",
            "Epoch 621/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8903 - val_loss: 0.9023\n",
            "Epoch 622/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8901 - val_loss: 0.9020\n",
            "Epoch 623/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8898 - val_loss: 0.9018\n",
            "Epoch 624/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8895 - val_loss: 0.9016\n",
            "Epoch 625/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8893 - val_loss: 0.9014\n",
            "Epoch 626/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8890 - val_loss: 0.9011\n",
            "Epoch 627/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8888 - val_loss: 0.9009\n",
            "Epoch 628/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8885 - val_loss: 0.9007\n",
            "Epoch 629/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8883 - val_loss: 0.9005\n",
            "Epoch 630/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8880 - val_loss: 0.9003\n",
            "Epoch 631/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8878 - val_loss: 0.9000\n",
            "Epoch 632/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8875 - val_loss: 0.8998\n",
            "Epoch 633/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8872 - val_loss: 0.8996\n",
            "Epoch 634/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8870 - val_loss: 0.8993\n",
            "Epoch 635/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8867 - val_loss: 0.8991\n",
            "Epoch 636/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8865 - val_loss: 0.8989\n",
            "Epoch 637/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8862 - val_loss: 0.8987\n",
            "Epoch 638/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8860 - val_loss: 0.8984\n",
            "Epoch 639/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8857 - val_loss: 0.8982\n",
            "Epoch 640/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8854 - val_loss: 0.8980\n",
            "Epoch 641/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8852 - val_loss: 0.8977\n",
            "Epoch 642/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8849 - val_loss: 0.8975\n",
            "Epoch 643/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8846 - val_loss: 0.8973\n",
            "Epoch 644/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8843 - val_loss: 0.8970\n",
            "Epoch 645/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8841 - val_loss: 0.8968\n",
            "Epoch 646/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8838 - val_loss: 0.8966\n",
            "Epoch 647/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8835 - val_loss: 0.8963\n",
            "Epoch 648/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8833 - val_loss: 0.8961\n",
            "Epoch 649/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8830 - val_loss: 0.8959\n",
            "Epoch 650/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8827 - val_loss: 0.8956\n",
            "Epoch 651/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8825 - val_loss: 0.8954\n",
            "Epoch 652/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8822 - val_loss: 0.8952\n",
            "Epoch 653/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8819 - val_loss: 0.8949\n",
            "Epoch 654/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8817 - val_loss: 0.8947\n",
            "Epoch 655/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8814 - val_loss: 0.8944\n",
            "Epoch 656/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8811 - val_loss: 0.8942\n",
            "Epoch 657/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8808 - val_loss: 0.8940\n",
            "Epoch 658/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8806 - val_loss: 0.8937\n",
            "Epoch 659/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8803 - val_loss: 0.8935\n",
            "Epoch 660/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8800 - val_loss: 0.8933\n",
            "Epoch 661/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8798 - val_loss: 0.8931\n",
            "Epoch 662/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8795 - val_loss: 0.8928\n",
            "Epoch 663/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8793 - val_loss: 0.8926\n",
            "Epoch 664/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8790 - val_loss: 0.8924\n",
            "Epoch 665/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8787 - val_loss: 0.8921\n",
            "Epoch 666/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8785 - val_loss: 0.8919\n",
            "Epoch 667/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8782 - val_loss: 0.8917\n",
            "Epoch 668/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8779 - val_loss: 0.8915\n",
            "Epoch 669/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8777 - val_loss: 0.8912\n",
            "Epoch 670/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8774 - val_loss: 0.8910\n",
            "Epoch 671/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8771 - val_loss: 0.8908\n",
            "Epoch 672/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8769 - val_loss: 0.8905\n",
            "Epoch 673/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8766 - val_loss: 0.8903\n",
            "Epoch 674/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8763 - val_loss: 0.8901\n",
            "Epoch 675/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8761 - val_loss: 0.8898\n",
            "Epoch 676/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8758 - val_loss: 0.8896\n",
            "Epoch 677/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8756 - val_loss: 0.8894\n",
            "Epoch 678/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8753 - val_loss: 0.8891\n",
            "Epoch 679/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8750 - val_loss: 0.8889\n",
            "Epoch 680/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8748 - val_loss: 0.8887\n",
            "Epoch 681/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8745 - val_loss: 0.8884\n",
            "Epoch 682/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8742 - val_loss: 0.8882\n",
            "Epoch 683/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8739 - val_loss: 0.8880\n",
            "Epoch 684/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8737 - val_loss: 0.8877\n",
            "Epoch 685/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8734 - val_loss: 0.8875\n",
            "Epoch 686/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8731 - val_loss: 0.8873\n",
            "Epoch 687/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8729 - val_loss: 0.8870\n",
            "Epoch 688/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8726 - val_loss: 0.8868\n",
            "Epoch 689/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8723 - val_loss: 0.8865\n",
            "Epoch 690/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8720 - val_loss: 0.8863\n",
            "Epoch 691/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8718 - val_loss: 0.8861\n",
            "Epoch 692/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8715 - val_loss: 0.8858\n",
            "Epoch 693/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8712 - val_loss: 0.8856\n",
            "Epoch 694/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8709 - val_loss: 0.8854\n",
            "Epoch 695/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8707 - val_loss: 0.8851\n",
            "Epoch 696/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8704 - val_loss: 0.8849\n",
            "Epoch 697/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8701 - val_loss: 0.8847\n",
            "Epoch 698/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8699 - val_loss: 0.8844\n",
            "Epoch 699/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8696 - val_loss: 0.8842\n",
            "Epoch 700/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8693 - val_loss: 0.8839\n",
            "Epoch 701/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8690 - val_loss: 0.8837\n",
            "Epoch 702/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8688 - val_loss: 0.8835\n",
            "Epoch 703/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8685 - val_loss: 0.8832\n",
            "Epoch 704/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8682 - val_loss: 0.8830\n",
            "Epoch 705/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8679 - val_loss: 0.8827\n",
            "Epoch 706/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8677 - val_loss: 0.8825\n",
            "Epoch 707/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8674 - val_loss: 0.8823\n",
            "Epoch 708/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8671 - val_loss: 0.8820\n",
            "Epoch 709/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8669 - val_loss: 0.8818\n",
            "Epoch 710/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8666 - val_loss: 0.8816\n",
            "Epoch 711/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8663 - val_loss: 0.8813\n",
            "Epoch 712/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8660 - val_loss: 0.8811\n",
            "Epoch 713/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8658 - val_loss: 0.8809\n",
            "Epoch 714/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8655 - val_loss: 0.8806\n",
            "Epoch 715/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8652 - val_loss: 0.8804\n",
            "Epoch 716/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8650 - val_loss: 0.8802\n",
            "Epoch 717/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8647 - val_loss: 0.8799\n",
            "Epoch 718/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8644 - val_loss: 0.8797\n",
            "Epoch 719/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8641 - val_loss: 0.8794\n",
            "Epoch 720/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8639 - val_loss: 0.8792\n",
            "Epoch 721/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8636 - val_loss: 0.8789\n",
            "Epoch 722/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8633 - val_loss: 0.8787\n",
            "Epoch 723/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8630 - val_loss: 0.8785\n",
            "Epoch 724/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8627 - val_loss: 0.8782\n",
            "Epoch 725/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8625 - val_loss: 0.8780\n",
            "Epoch 726/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8622 - val_loss: 0.8777\n",
            "Epoch 727/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8619 - val_loss: 0.8775\n",
            "Epoch 728/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8616 - val_loss: 0.8773\n",
            "Epoch 729/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8614 - val_loss: 0.8770\n",
            "Epoch 730/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8611 - val_loss: 0.8768\n",
            "Epoch 731/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8608 - val_loss: 0.8765\n",
            "Epoch 732/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8605 - val_loss: 0.8763\n",
            "Epoch 733/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8603 - val_loss: 0.8761\n",
            "Epoch 734/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8600 - val_loss: 0.8758\n",
            "Epoch 735/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8597 - val_loss: 0.8756\n",
            "Epoch 736/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8594 - val_loss: 0.8753\n",
            "Epoch 737/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8591 - val_loss: 0.8751\n",
            "Epoch 738/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8589 - val_loss: 0.8749\n",
            "Epoch 739/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8586 - val_loss: 0.8746\n",
            "Epoch 740/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8583 - val_loss: 0.8744\n",
            "Epoch 741/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8580 - val_loss: 0.8741\n",
            "Epoch 742/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8578 - val_loss: 0.8739\n",
            "Epoch 743/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8575 - val_loss: 0.8737\n",
            "Epoch 744/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8572 - val_loss: 0.8734\n",
            "Epoch 745/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8569 - val_loss: 0.8732\n",
            "Epoch 746/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8566 - val_loss: 0.8729\n",
            "Epoch 747/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8564 - val_loss: 0.8727\n",
            "Epoch 748/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8561 - val_loss: 0.8724\n",
            "Epoch 749/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8558 - val_loss: 0.8722\n",
            "Epoch 750/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8555 - val_loss: 0.8719\n",
            "Epoch 751/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8552 - val_loss: 0.8717\n",
            "Epoch 752/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8550 - val_loss: 0.8715\n",
            "Epoch 753/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8547 - val_loss: 0.8712\n",
            "Epoch 754/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8544 - val_loss: 0.8710\n",
            "Epoch 755/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8541 - val_loss: 0.8707\n",
            "Epoch 756/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8539 - val_loss: 0.8705\n",
            "Epoch 757/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8536 - val_loss: 0.8703\n",
            "Epoch 758/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8533 - val_loss: 0.8700\n",
            "Epoch 759/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8530 - val_loss: 0.8698\n",
            "Epoch 760/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8528 - val_loss: 0.8696\n",
            "Epoch 761/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8525 - val_loss: 0.8693\n",
            "Epoch 762/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8522 - val_loss: 0.8691\n",
            "Epoch 763/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8519 - val_loss: 0.8688\n",
            "Epoch 764/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8517 - val_loss: 0.8686\n",
            "Epoch 765/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8514 - val_loss: 0.8684\n",
            "Epoch 766/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8511 - val_loss: 0.8681\n",
            "Epoch 767/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8508 - val_loss: 0.8679\n",
            "Epoch 768/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8506 - val_loss: 0.8676\n",
            "Epoch 769/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8503 - val_loss: 0.8674\n",
            "Epoch 770/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8500 - val_loss: 0.8671\n",
            "Epoch 771/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8497 - val_loss: 0.8669\n",
            "Epoch 772/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8494 - val_loss: 0.8667\n",
            "Epoch 773/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8491 - val_loss: 0.8664\n",
            "Epoch 774/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8489 - val_loss: 0.8662\n",
            "Epoch 775/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8486 - val_loss: 0.8659\n",
            "Epoch 776/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8483 - val_loss: 0.8657\n",
            "Epoch 777/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8480 - val_loss: 0.8654\n",
            "Epoch 778/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8477 - val_loss: 0.8652\n",
            "Epoch 779/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8474 - val_loss: 0.8649\n",
            "Epoch 780/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8472 - val_loss: 0.8647\n",
            "Epoch 781/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8469 - val_loss: 0.8644\n",
            "Epoch 782/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8466 - val_loss: 0.8642\n",
            "Epoch 783/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8463 - val_loss: 0.8639\n",
            "Epoch 784/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8460 - val_loss: 0.8637\n",
            "Epoch 785/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8457 - val_loss: 0.8634\n",
            "Epoch 786/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8454 - val_loss: 0.8632\n",
            "Epoch 787/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8452 - val_loss: 0.8630\n",
            "Epoch 788/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8449 - val_loss: 0.8627\n",
            "Epoch 789/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8446 - val_loss: 0.8625\n",
            "Epoch 790/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8443 - val_loss: 0.8622\n",
            "Epoch 791/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8440 - val_loss: 0.8619\n",
            "Epoch 792/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8437 - val_loss: 0.8617\n",
            "Epoch 793/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8434 - val_loss: 0.8615\n",
            "Epoch 794/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8431 - val_loss: 0.8612\n",
            "Epoch 795/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8428 - val_loss: 0.8609\n",
            "Epoch 796/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8425 - val_loss: 0.8607\n",
            "Epoch 797/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8423 - val_loss: 0.8605\n",
            "Epoch 798/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8420 - val_loss: 0.8602\n",
            "Epoch 799/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8417 - val_loss: 0.8600\n",
            "Epoch 800/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8414 - val_loss: 0.8597\n",
            "Epoch 801/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8411 - val_loss: 0.8595\n",
            "Epoch 802/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8408 - val_loss: 0.8592\n",
            "Epoch 803/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8405 - val_loss: 0.8590\n",
            "Epoch 804/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8403 - val_loss: 0.8587\n",
            "Epoch 805/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8400 - val_loss: 0.8585\n",
            "Epoch 806/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8397 - val_loss: 0.8582\n",
            "Epoch 807/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8394 - val_loss: 0.8580\n",
            "Epoch 808/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8391 - val_loss: 0.8577\n",
            "Epoch 809/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8388 - val_loss: 0.8575\n",
            "Epoch 810/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8385 - val_loss: 0.8572\n",
            "Epoch 811/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8382 - val_loss: 0.8570\n",
            "Epoch 812/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8379 - val_loss: 0.8567\n",
            "Epoch 813/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8377 - val_loss: 0.8565\n",
            "Epoch 814/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8374 - val_loss: 0.8562\n",
            "Epoch 815/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8371 - val_loss: 0.8560\n",
            "Epoch 816/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8368 - val_loss: 0.8557\n",
            "Epoch 817/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8365 - val_loss: 0.8555\n",
            "Epoch 818/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8362 - val_loss: 0.8552\n",
            "Epoch 819/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8359 - val_loss: 0.8550\n",
            "Epoch 820/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8356 - val_loss: 0.8547\n",
            "Epoch 821/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8353 - val_loss: 0.8545\n",
            "Epoch 822/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8351 - val_loss: 0.8542\n",
            "Epoch 823/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8348 - val_loss: 0.8540\n",
            "Epoch 824/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8345 - val_loss: 0.8537\n",
            "Epoch 825/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8342 - val_loss: 0.8535\n",
            "Epoch 826/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8339 - val_loss: 0.8532\n",
            "Epoch 827/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8336 - val_loss: 0.8530\n",
            "Epoch 828/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8334 - val_loss: 0.8527\n",
            "Epoch 829/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8331 - val_loss: 0.8525\n",
            "Epoch 830/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8328 - val_loss: 0.8523\n",
            "Epoch 831/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8325 - val_loss: 0.8520\n",
            "Epoch 832/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8322 - val_loss: 0.8518\n",
            "Epoch 833/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8319 - val_loss: 0.8515\n",
            "Epoch 834/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8316 - val_loss: 0.8513\n",
            "Epoch 835/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8313 - val_loss: 0.8510\n",
            "Epoch 836/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8311 - val_loss: 0.8508\n",
            "Epoch 837/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8308 - val_loss: 0.8505\n",
            "Epoch 838/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8305 - val_loss: 0.8502\n",
            "Epoch 839/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8302 - val_loss: 0.8500\n",
            "Epoch 840/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8299 - val_loss: 0.8497\n",
            "Epoch 841/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8296 - val_loss: 0.8495\n",
            "Epoch 842/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8293 - val_loss: 0.8492\n",
            "Epoch 843/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8290 - val_loss: 0.8490\n",
            "Epoch 844/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8287 - val_loss: 0.8487\n",
            "Epoch 845/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8284 - val_loss: 0.8485\n",
            "Epoch 846/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8281 - val_loss: 0.8482\n",
            "Epoch 847/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8278 - val_loss: 0.8480\n",
            "Epoch 848/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8275 - val_loss: 0.8477\n",
            "Epoch 849/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8272 - val_loss: 0.8475\n",
            "Epoch 850/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8269 - val_loss: 0.8472\n",
            "Epoch 851/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8266 - val_loss: 0.8470\n",
            "Epoch 852/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8263 - val_loss: 0.8467\n",
            "Epoch 853/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8260 - val_loss: 0.8464\n",
            "Epoch 854/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8257 - val_loss: 0.8462\n",
            "Epoch 855/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8255 - val_loss: 0.8460\n",
            "Epoch 856/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8252 - val_loss: 0.8457\n",
            "Epoch 857/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8249 - val_loss: 0.8455\n",
            "Epoch 858/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8246 - val_loss: 0.8452\n",
            "Epoch 859/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8243 - val_loss: 0.8450\n",
            "Epoch 860/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8240 - val_loss: 0.8447\n",
            "Epoch 861/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8237 - val_loss: 0.8445\n",
            "Epoch 862/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8235 - val_loss: 0.8442\n",
            "Epoch 863/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8232 - val_loss: 0.8440\n",
            "Epoch 864/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8229 - val_loss: 0.8437\n",
            "Epoch 865/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8226 - val_loss: 0.8435\n",
            "Epoch 866/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8223 - val_loss: 0.8432\n",
            "Epoch 867/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8220 - val_loss: 0.8430\n",
            "Epoch 868/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8217 - val_loss: 0.8427\n",
            "Epoch 869/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8214 - val_loss: 0.8425\n",
            "Epoch 870/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8211 - val_loss: 0.8422\n",
            "Epoch 871/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8208 - val_loss: 0.8420\n",
            "Epoch 872/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8205 - val_loss: 0.8417\n",
            "Epoch 873/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8202 - val_loss: 0.8414\n",
            "Epoch 874/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8199 - val_loss: 0.8412\n",
            "Epoch 875/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8196 - val_loss: 0.8409\n",
            "Epoch 876/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8193 - val_loss: 0.8407\n",
            "Epoch 877/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8190 - val_loss: 0.8404\n",
            "Epoch 878/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8187 - val_loss: 0.8402\n",
            "Epoch 879/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8184 - val_loss: 0.8399\n",
            "Epoch 880/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8182 - val_loss: 0.8397\n",
            "Epoch 881/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8179 - val_loss: 0.8394\n",
            "Epoch 882/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8176 - val_loss: 0.8392\n",
            "Epoch 883/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8173 - val_loss: 0.8389\n",
            "Epoch 884/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8170 - val_loss: 0.8387\n",
            "Epoch 885/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8167 - val_loss: 0.8384\n",
            "Epoch 886/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8164 - val_loss: 0.8382\n",
            "Epoch 887/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8161 - val_loss: 0.8379\n",
            "Epoch 888/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8158 - val_loss: 0.8377\n",
            "Epoch 889/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8155 - val_loss: 0.8374\n",
            "Epoch 890/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8152 - val_loss: 0.8372\n",
            "Epoch 891/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8149 - val_loss: 0.8369\n",
            "Epoch 892/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8146 - val_loss: 0.8367\n",
            "Epoch 893/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8143 - val_loss: 0.8364\n",
            "Epoch 894/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8140 - val_loss: 0.8362\n",
            "Epoch 895/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8138 - val_loss: 0.8359\n",
            "Epoch 896/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8135 - val_loss: 0.8357\n",
            "Epoch 897/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8132 - val_loss: 0.8354\n",
            "Epoch 898/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8129 - val_loss: 0.8352\n",
            "Epoch 899/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8126 - val_loss: 0.8349\n",
            "Epoch 900/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8123 - val_loss: 0.8347\n",
            "Epoch 901/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8120 - val_loss: 0.8344\n",
            "Epoch 902/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8117 - val_loss: 0.8341\n",
            "Epoch 903/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8114 - val_loss: 0.8339\n",
            "Epoch 904/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8111 - val_loss: 0.8336\n",
            "Epoch 905/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8108 - val_loss: 0.8334\n",
            "Epoch 906/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8105 - val_loss: 0.8331\n",
            "Epoch 907/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8102 - val_loss: 0.8329\n",
            "Epoch 908/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8099 - val_loss: 0.8326\n",
            "Epoch 909/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8096 - val_loss: 0.8324\n",
            "Epoch 910/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8093 - val_loss: 0.8321\n",
            "Epoch 911/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8090 - val_loss: 0.8318\n",
            "Epoch 912/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8087 - val_loss: 0.8316\n",
            "Epoch 913/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8084 - val_loss: 0.8313\n",
            "Epoch 914/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8081 - val_loss: 0.8311\n",
            "Epoch 915/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8078 - val_loss: 0.8308\n",
            "Epoch 916/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8075 - val_loss: 0.8306\n",
            "Epoch 917/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8072 - val_loss: 0.8303\n",
            "Epoch 918/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8069 - val_loss: 0.8301\n",
            "Epoch 919/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8066 - val_loss: 0.8298\n",
            "Epoch 920/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8063 - val_loss: 0.8296\n",
            "Epoch 921/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8060 - val_loss: 0.8293\n",
            "Epoch 922/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8057 - val_loss: 0.8290\n",
            "Epoch 923/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8054 - val_loss: 0.8288\n",
            "Epoch 924/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8051 - val_loss: 0.8285\n",
            "Epoch 925/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8048 - val_loss: 0.8283\n",
            "Epoch 926/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8045 - val_loss: 0.8280\n",
            "Epoch 927/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8042 - val_loss: 0.8278\n",
            "Epoch 928/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8039 - val_loss: 0.8275\n",
            "Epoch 929/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8036 - val_loss: 0.8273\n",
            "Epoch 930/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8033 - val_loss: 0.8270\n",
            "Epoch 931/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8030 - val_loss: 0.8268\n",
            "Epoch 932/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8027 - val_loss: 0.8265\n",
            "Epoch 933/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8024 - val_loss: 0.8263\n",
            "Epoch 934/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8021 - val_loss: 0.8260\n",
            "Epoch 935/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8018 - val_loss: 0.8258\n",
            "Epoch 936/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8015 - val_loss: 0.8255\n",
            "Epoch 937/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8012 - val_loss: 0.8253\n",
            "Epoch 938/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8009 - val_loss: 0.8250\n",
            "Epoch 939/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8006 - val_loss: 0.8248\n",
            "Epoch 940/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8004 - val_loss: 0.8245\n",
            "Epoch 941/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8001 - val_loss: 0.8243\n",
            "Epoch 942/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7998 - val_loss: 0.8240\n",
            "Epoch 943/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7995 - val_loss: 0.8238\n",
            "Epoch 944/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7992 - val_loss: 0.8235\n",
            "Epoch 945/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7989 - val_loss: 0.8233\n",
            "Epoch 946/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7986 - val_loss: 0.8230\n",
            "Epoch 947/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7983 - val_loss: 0.8228\n",
            "Epoch 948/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7980 - val_loss: 0.8225\n",
            "Epoch 949/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7977 - val_loss: 0.8222\n",
            "Epoch 950/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7974 - val_loss: 0.8220\n",
            "Epoch 951/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7971 - val_loss: 0.8217\n",
            "Epoch 952/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7968 - val_loss: 0.8215\n",
            "Epoch 953/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7965 - val_loss: 0.8212\n",
            "Epoch 954/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7962 - val_loss: 0.8210\n",
            "Epoch 955/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7959 - val_loss: 0.8207\n",
            "Epoch 956/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7956 - val_loss: 0.8205\n",
            "Epoch 957/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7953 - val_loss: 0.8202\n",
            "Epoch 958/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7950 - val_loss: 0.8200\n",
            "Epoch 959/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7947 - val_loss: 0.8197\n",
            "Epoch 960/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7944 - val_loss: 0.8195\n",
            "Epoch 961/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7941 - val_loss: 0.8192\n",
            "Epoch 962/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7938 - val_loss: 0.8190\n",
            "Epoch 963/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7935 - val_loss: 0.8187\n",
            "Epoch 964/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7932 - val_loss: 0.8185\n",
            "Epoch 965/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7930 - val_loss: 0.8182\n",
            "Epoch 966/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7927 - val_loss: 0.8180\n",
            "Epoch 967/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7924 - val_loss: 0.8177\n",
            "Epoch 968/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7921 - val_loss: 0.8175\n",
            "Epoch 969/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7918 - val_loss: 0.8172\n",
            "Epoch 970/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7915 - val_loss: 0.8170\n",
            "Epoch 971/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7912 - val_loss: 0.8167\n",
            "Epoch 972/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7909 - val_loss: 0.8165\n",
            "Epoch 973/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7906 - val_loss: 0.8162\n",
            "Epoch 974/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7903 - val_loss: 0.8160\n",
            "Epoch 975/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7900 - val_loss: 0.8157\n",
            "Epoch 976/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7897 - val_loss: 0.8155\n",
            "Epoch 977/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7894 - val_loss: 0.8152\n",
            "Epoch 978/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7891 - val_loss: 0.8150\n",
            "Epoch 979/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7888 - val_loss: 0.8147\n",
            "Epoch 980/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7885 - val_loss: 0.8145\n",
            "Epoch 981/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7882 - val_loss: 0.8142\n",
            "Epoch 982/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7879 - val_loss: 0.8140\n",
            "Epoch 983/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7876 - val_loss: 0.8137\n",
            "Epoch 984/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7873 - val_loss: 0.8135\n",
            "Epoch 985/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7870 - val_loss: 0.8132\n",
            "Epoch 986/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7867 - val_loss: 0.8130\n",
            "Epoch 987/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7864 - val_loss: 0.8128\n",
            "Epoch 988/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7862 - val_loss: 0.8125\n",
            "Epoch 989/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7859 - val_loss: 0.8123\n",
            "Epoch 990/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7856 - val_loss: 0.8120\n",
            "Epoch 991/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7853 - val_loss: 0.8118\n",
            "Epoch 992/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7850 - val_loss: 0.8115\n",
            "Epoch 993/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7847 - val_loss: 0.8113\n",
            "Epoch 994/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7844 - val_loss: 0.8110\n",
            "Epoch 995/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7841 - val_loss: 0.8107\n",
            "Epoch 996/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7838 - val_loss: 0.8105\n",
            "Epoch 997/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7835 - val_loss: 0.8102\n",
            "Epoch 998/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7832 - val_loss: 0.8100\n",
            "Epoch 999/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7829 - val_loss: 0.8097\n",
            "Epoch 1000/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7826 - val_loss: 0.8095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lU4JNXfv8NR"
      },
      "source": [
        "####RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P0w5OGtv-VK",
        "outputId": "d6bed639-3f51-4d36-8c07-a16362c6f588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wide_opt3(opt_RMSprop)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.8797 - val_loss: 0.7852\n",
            "Epoch 2/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6769 - val_loss: 0.6737\n",
            "Epoch 3/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5879 - val_loss: 0.6417\n",
            "Epoch 4/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5613 - val_loss: 0.6392\n",
            "Epoch 5/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5514 - val_loss: 0.6345\n",
            "Epoch 6/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5484 - val_loss: 0.6256\n",
            "Epoch 7/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5463 - val_loss: 0.6208\n",
            "Epoch 8/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5428 - val_loss: 0.6237\n",
            "Epoch 9/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5434 - val_loss: 0.6194\n",
            "Epoch 10/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5388 - val_loss: 0.6230\n",
            "Epoch 11/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5399 - val_loss: 0.6118\n",
            "Epoch 12/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5380 - val_loss: 0.6116\n",
            "Epoch 13/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5368 - val_loss: 0.6080\n",
            "Epoch 14/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5346 - val_loss: 0.6091\n",
            "Epoch 15/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5331 - val_loss: 0.6119\n",
            "Epoch 16/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5313 - val_loss: 0.6123\n",
            "Epoch 17/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5321 - val_loss: 0.6065\n",
            "Epoch 18/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5289 - val_loss: 0.6087\n",
            "Epoch 19/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5285 - val_loss: 0.6082\n",
            "Epoch 20/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 0.6015\n",
            "Epoch 21/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 0.5961\n",
            "Epoch 22/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 0.6005\n",
            "Epoch 23/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 0.5998\n",
            "Epoch 24/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 0.6051\n",
            "Epoch 25/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.6002\n",
            "Epoch 26/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 0.5949\n",
            "Epoch 27/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5212 - val_loss: 0.5976\n",
            "Epoch 28/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5218 - val_loss: 0.5961\n",
            "Epoch 29/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5201 - val_loss: 0.5912\n",
            "Epoch 30/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5190 - val_loss: 0.5925\n",
            "Epoch 31/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5191 - val_loss: 0.5920\n",
            "Epoch 32/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5172 - val_loss: 0.5920\n",
            "Epoch 33/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5176 - val_loss: 0.5948\n",
            "Epoch 34/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5182 - val_loss: 0.5951\n",
            "Epoch 35/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5159 - val_loss: 0.5941\n",
            "Epoch 36/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5166 - val_loss: 0.5905\n",
            "Epoch 37/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5148 - val_loss: 0.5902\n",
            "Epoch 38/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5141 - val_loss: 0.5978\n",
            "Epoch 39/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5145 - val_loss: 0.5944\n",
            "Epoch 40/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5129 - val_loss: 0.5909\n",
            "Epoch 41/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5124 - val_loss: 0.5980\n",
            "Epoch 42/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5109 - val_loss: 0.5843\n",
            "Epoch 43/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5122 - val_loss: 0.5883\n",
            "Epoch 44/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5115 - val_loss: 0.5893\n",
            "Epoch 45/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5105 - val_loss: 0.5844\n",
            "Epoch 46/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5100 - val_loss: 0.5882\n",
            "Epoch 47/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5090 - val_loss: 0.5932\n",
            "Epoch 48/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5078 - val_loss: 0.5844\n",
            "Epoch 49/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5077 - val_loss: 0.5948\n",
            "Epoch 50/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5088 - val_loss: 0.5814\n",
            "Epoch 51/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5068 - val_loss: 0.5870\n",
            "Epoch 52/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5092 - val_loss: 0.5844\n",
            "Epoch 53/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5068 - val_loss: 0.5930\n",
            "Epoch 54/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5055 - val_loss: 0.5885\n",
            "Epoch 55/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5075 - val_loss: 0.5922\n",
            "Epoch 56/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5072 - val_loss: 0.5853\n",
            "Epoch 57/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5051 - val_loss: 0.5902\n",
            "Epoch 58/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5063 - val_loss: 0.5838\n",
            "Epoch 59/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5061 - val_loss: 0.5854\n",
            "Epoch 60/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5040 - val_loss: 0.5838\n",
            "Epoch 61/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5054 - val_loss: 0.5909\n",
            "Epoch 62/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5033 - val_loss: 0.5856\n",
            "Epoch 63/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5032 - val_loss: 0.5905\n",
            "Epoch 64/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5015 - val_loss: 0.5872\n",
            "Epoch 65/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5027 - val_loss: 0.5873\n",
            "Epoch 66/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5043 - val_loss: 0.5881\n",
            "Epoch 67/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5014 - val_loss: 0.5865\n",
            "Epoch 68/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5030 - val_loss: 0.5906\n",
            "Epoch 69/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5012 - val_loss: 0.5827\n",
            "Epoch 70/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5002 - val_loss: 0.5907\n",
            "Epoch 71/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5003 - val_loss: 0.5931\n",
            "Epoch 72/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5027 - val_loss: 0.5842\n",
            "Epoch 73/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5016 - val_loss: 0.5853\n",
            "Epoch 74/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4994 - val_loss: 0.5847\n",
            "Epoch 75/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4995 - val_loss: 0.5897\n",
            "Epoch 76/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4997 - val_loss: 0.5897\n",
            "Epoch 77/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4980 - val_loss: 0.6008\n",
            "Epoch 78/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5002 - val_loss: 0.5812\n",
            "Epoch 79/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4976 - val_loss: 0.5860\n",
            "Epoch 80/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4960 - val_loss: 0.5876\n",
            "Epoch 81/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5000 - val_loss: 0.5789\n",
            "Epoch 82/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4953 - val_loss: 0.5853\n",
            "Epoch 83/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4979 - val_loss: 0.5850\n",
            "Epoch 84/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4955 - val_loss: 0.5801\n",
            "Epoch 85/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4952 - val_loss: 0.5832\n",
            "Epoch 86/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4973 - val_loss: 0.5849\n",
            "Epoch 87/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4978 - val_loss: 0.5825\n",
            "Epoch 88/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4941 - val_loss: 0.5906\n",
            "Epoch 89/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4965 - val_loss: 0.5874\n",
            "Epoch 90/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4959 - val_loss: 0.5854\n",
            "Epoch 91/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4957 - val_loss: 0.5757\n",
            "Epoch 92/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4957 - val_loss: 0.5800\n",
            "Epoch 93/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4949 - val_loss: 0.5843\n",
            "Epoch 94/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4953 - val_loss: 0.5816\n",
            "Epoch 95/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4939 - val_loss: 0.5861\n",
            "Epoch 96/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4943 - val_loss: 0.5969\n",
            "Epoch 97/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4929 - val_loss: 0.5854\n",
            "Epoch 98/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4942 - val_loss: 0.5891\n",
            "Epoch 99/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4924 - val_loss: 0.5877\n",
            "Epoch 100/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4921 - val_loss: 0.5939\n",
            "Epoch 101/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4946 - val_loss: 0.5967\n",
            "Epoch 102/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4944 - val_loss: 0.5873\n",
            "Epoch 103/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4934 - val_loss: 0.5761\n",
            "Epoch 104/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4923 - val_loss: 0.5876\n",
            "Epoch 105/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4903 - val_loss: 0.5819\n",
            "Epoch 106/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4918 - val_loss: 0.5795\n",
            "Epoch 107/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4936 - val_loss: 0.5863\n",
            "Epoch 108/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4917 - val_loss: 0.5842\n",
            "Epoch 109/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4907 - val_loss: 0.5934\n",
            "Epoch 110/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4934 - val_loss: 0.5792\n",
            "Epoch 111/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 0.5808\n",
            "Epoch 112/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4892 - val_loss: 0.5823\n",
            "Epoch 113/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4910 - val_loss: 0.5801\n",
            "Epoch 114/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4884 - val_loss: 0.5803\n",
            "Epoch 115/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4913 - val_loss: 0.5892\n",
            "Epoch 116/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4877 - val_loss: 0.5938\n",
            "Epoch 117/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4909 - val_loss: 0.5858\n",
            "Epoch 118/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4900 - val_loss: 0.5820\n",
            "Epoch 119/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4881 - val_loss: 0.5856\n",
            "Epoch 120/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4898 - val_loss: 0.5860\n",
            "Epoch 121/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4880 - val_loss: 0.5795\n",
            "Epoch 122/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4877 - val_loss: 0.5847\n",
            "Epoch 123/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5853\n",
            "Epoch 124/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4869 - val_loss: 0.5881\n",
            "Epoch 125/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4870 - val_loss: 0.5830\n",
            "Epoch 126/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4877 - val_loss: 0.5799\n",
            "Epoch 127/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4875 - val_loss: 0.5811\n",
            "Epoch 128/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.5745\n",
            "Epoch 129/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4830 - val_loss: 0.5825\n",
            "Epoch 130/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4882 - val_loss: 0.5851\n",
            "Epoch 131/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.5812\n",
            "Epoch 132/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4876 - val_loss: 0.5850\n",
            "Epoch 133/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4851 - val_loss: 0.5828\n",
            "Epoch 134/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4841 - val_loss: 0.5853\n",
            "Epoch 135/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5767\n",
            "Epoch 136/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4843 - val_loss: 0.5798\n",
            "Epoch 137/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4847 - val_loss: 0.5834\n",
            "Epoch 138/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4832 - val_loss: 0.5784\n",
            "Epoch 139/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4859 - val_loss: 0.5816\n",
            "Epoch 140/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4818 - val_loss: 0.5992\n",
            "Epoch 141/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4846 - val_loss: 0.5885\n",
            "Epoch 142/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4838 - val_loss: 0.5849\n",
            "Epoch 143/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4855 - val_loss: 0.5889\n",
            "Epoch 144/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5848\n",
            "Epoch 145/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.5828\n",
            "Epoch 146/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4814 - val_loss: 0.5799\n",
            "Epoch 147/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4831 - val_loss: 0.5834\n",
            "Epoch 148/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 0.5865\n",
            "Epoch 149/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4819 - val_loss: 0.5902\n",
            "Epoch 150/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.5849\n",
            "Epoch 151/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.5865\n",
            "Epoch 152/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5814\n",
            "Epoch 153/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.5922\n",
            "Epoch 154/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4826 - val_loss: 0.5814\n",
            "Epoch 155/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5833\n",
            "Epoch 156/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5848\n",
            "Epoch 157/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5756\n",
            "Epoch 158/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4801 - val_loss: 0.5821\n",
            "Epoch 159/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.5788\n",
            "Epoch 160/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.5966\n",
            "Epoch 161/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4818 - val_loss: 0.5847\n",
            "Epoch 162/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4769 - val_loss: 0.5916\n",
            "Epoch 163/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.5823\n",
            "Epoch 164/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.5933\n",
            "Epoch 165/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.5941\n",
            "Epoch 166/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4805 - val_loss: 0.5825\n",
            "Epoch 167/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.5858\n",
            "Epoch 168/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.5798\n",
            "Epoch 169/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.5779\n",
            "Epoch 170/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.5841\n",
            "Epoch 171/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4791 - val_loss: 0.5853\n",
            "Epoch 172/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.5810\n",
            "Epoch 173/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4778 - val_loss: 0.5867\n",
            "Epoch 174/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4774 - val_loss: 0.5797\n",
            "Epoch 175/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.5763\n",
            "Epoch 176/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5802\n",
            "Epoch 177/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.5882\n",
            "Epoch 178/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5850\n",
            "Epoch 179/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4762 - val_loss: 0.5846\n",
            "Epoch 180/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5787\n",
            "Epoch 181/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.5889\n",
            "Epoch 182/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.5827\n",
            "Epoch 183/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.5940\n",
            "Epoch 184/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.5819\n",
            "Epoch 185/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.5796\n",
            "Epoch 186/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.5880\n",
            "Epoch 187/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.5810\n",
            "Epoch 188/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 0.5950\n",
            "Epoch 189/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4773 - val_loss: 0.5817\n",
            "Epoch 190/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4729 - val_loss: 0.5968\n",
            "Epoch 191/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4696 - val_loss: 0.5923\n",
            "Epoch 192/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.5824\n",
            "Epoch 193/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4739 - val_loss: 0.5801\n",
            "Epoch 194/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.5880\n",
            "Epoch 195/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4724 - val_loss: 0.5891\n",
            "Epoch 196/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4712 - val_loss: 0.5839\n",
            "Epoch 197/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.5884\n",
            "Epoch 198/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.5818\n",
            "Epoch 199/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4706 - val_loss: 0.5812\n",
            "Epoch 200/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4738 - val_loss: 0.5889\n",
            "Epoch 201/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4724 - val_loss: 0.5910\n",
            "Epoch 202/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4717 - val_loss: 0.5884\n",
            "Epoch 203/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4722 - val_loss: 0.5898\n",
            "Epoch 204/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.5841\n",
            "Epoch 205/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4711 - val_loss: 0.5834\n",
            "Epoch 206/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4717 - val_loss: 0.5878\n",
            "Epoch 207/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4715 - val_loss: 0.5790\n",
            "Epoch 208/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 0.5819\n",
            "Epoch 209/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4688 - val_loss: 0.5848\n",
            "Epoch 210/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4721 - val_loss: 0.5744\n",
            "Epoch 211/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4700 - val_loss: 0.5786\n",
            "Epoch 212/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4690 - val_loss: 0.5947\n",
            "Epoch 213/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4712 - val_loss: 0.5785\n",
            "Epoch 214/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4725 - val_loss: 0.5796\n",
            "Epoch 215/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4701 - val_loss: 0.5911\n",
            "Epoch 216/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4728 - val_loss: 0.5953\n",
            "Epoch 217/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.5778\n",
            "Epoch 218/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4735 - val_loss: 0.5777\n",
            "Epoch 219/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 0.6020\n",
            "Epoch 220/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4706 - val_loss: 0.5778\n",
            "Epoch 221/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4709 - val_loss: 0.5766\n",
            "Epoch 222/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4688 - val_loss: 0.5822\n",
            "Epoch 223/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4714 - val_loss: 0.5782\n",
            "Epoch 224/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4683 - val_loss: 0.5844\n",
            "Epoch 225/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4689 - val_loss: 0.5762\n",
            "Epoch 226/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.5791\n",
            "Epoch 227/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4706 - val_loss: 0.5844\n",
            "Epoch 228/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4694 - val_loss: 0.5806\n",
            "Epoch 229/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4701 - val_loss: 0.5937\n",
            "Epoch 230/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.5982\n",
            "Epoch 231/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4723 - val_loss: 0.5818\n",
            "Epoch 232/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 0.5887\n",
            "Epoch 233/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4670 - val_loss: 0.5872\n",
            "Epoch 234/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4699 - val_loss: 0.5874\n",
            "Epoch 235/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4686 - val_loss: 0.5838\n",
            "Epoch 236/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4691 - val_loss: 0.6048\n",
            "Epoch 237/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4717 - val_loss: 0.5901\n",
            "Epoch 238/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.5867\n",
            "Epoch 239/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4698 - val_loss: 0.5963\n",
            "Epoch 240/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4698 - val_loss: 0.5803\n",
            "Epoch 241/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4660 - val_loss: 0.5883\n",
            "Epoch 242/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4660 - val_loss: 0.5851\n",
            "Epoch 243/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.5775\n",
            "Epoch 244/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4640 - val_loss: 0.5816\n",
            "Epoch 245/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4665 - val_loss: 0.5756\n",
            "Epoch 246/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4687 - val_loss: 0.5843\n",
            "Epoch 247/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4665 - val_loss: 0.5875\n",
            "Epoch 248/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4667 - val_loss: 0.5738\n",
            "Epoch 249/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4671 - val_loss: 0.5777\n",
            "Epoch 250/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4640 - val_loss: 0.5758\n",
            "Epoch 251/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4639 - val_loss: 0.5739\n",
            "Epoch 252/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.5859\n",
            "Epoch 253/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4625 - val_loss: 0.6018\n",
            "Epoch 254/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.5903\n",
            "Epoch 255/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4656 - val_loss: 0.5906\n",
            "Epoch 256/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.5818\n",
            "Epoch 257/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4636 - val_loss: 0.5788\n",
            "Epoch 258/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4638 - val_loss: 0.5771\n",
            "Epoch 259/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.5925\n",
            "Epoch 260/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4648 - val_loss: 0.5827\n",
            "Epoch 261/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.5764\n",
            "Epoch 262/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4638 - val_loss: 0.5930\n",
            "Epoch 263/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 0.5856\n",
            "Epoch 264/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4653 - val_loss: 0.5899\n",
            "Epoch 265/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4646 - val_loss: 0.5793\n",
            "Epoch 266/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4639 - val_loss: 0.5784\n",
            "Epoch 267/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.5833\n",
            "Epoch 268/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.5782\n",
            "Epoch 269/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.5771\n",
            "Epoch 270/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.5842\n",
            "Epoch 271/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4624 - val_loss: 0.5896\n",
            "Epoch 272/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.5862\n",
            "Epoch 273/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.5880\n",
            "Epoch 274/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4630 - val_loss: 0.5911\n",
            "Epoch 275/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.5922\n",
            "Epoch 276/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.5935\n",
            "Epoch 277/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4618 - val_loss: 0.5705\n",
            "Epoch 278/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.5802\n",
            "Epoch 279/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.6109\n",
            "Epoch 280/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4593 - val_loss: 0.5889\n",
            "Epoch 281/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4639 - val_loss: 0.5854\n",
            "Epoch 282/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.5813\n",
            "Epoch 283/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4589 - val_loss: 0.5828\n",
            "Epoch 284/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.5925\n",
            "Epoch 285/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.5850\n",
            "Epoch 286/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4592 - val_loss: 0.5759\n",
            "Epoch 287/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.5791\n",
            "Epoch 288/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.5830\n",
            "Epoch 289/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4602 - val_loss: 0.5802\n",
            "Epoch 290/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.5797\n",
            "Epoch 291/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.5989\n",
            "Epoch 292/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.5807\n",
            "Epoch 293/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4554 - val_loss: 0.5842\n",
            "Epoch 294/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.5865\n",
            "Epoch 295/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4587 - val_loss: 0.5861\n",
            "Epoch 296/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4564 - val_loss: 0.5830\n",
            "Epoch 297/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4590 - val_loss: 0.5790\n",
            "Epoch 298/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4571 - val_loss: 0.5916\n",
            "Epoch 299/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.5798\n",
            "Epoch 300/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4554 - val_loss: 0.5839\n",
            "Epoch 301/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4592 - val_loss: 0.5731\n",
            "Epoch 302/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.5821\n",
            "Epoch 303/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.5860\n",
            "Epoch 304/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4590 - val_loss: 0.5897\n",
            "Epoch 305/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4571 - val_loss: 0.5787\n",
            "Epoch 306/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4498 - val_loss: 0.5949\n",
            "Epoch 307/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.5877\n",
            "Epoch 308/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4554 - val_loss: 0.5923\n",
            "Epoch 309/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4530 - val_loss: 0.6060\n",
            "Epoch 310/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.5840\n",
            "Epoch 311/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.5797\n",
            "Epoch 312/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 0.5911\n",
            "Epoch 313/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4566 - val_loss: 0.5866\n",
            "Epoch 314/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.5927\n",
            "Epoch 315/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4530 - val_loss: 0.6058\n",
            "Epoch 316/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.5873\n",
            "Epoch 317/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4546 - val_loss: 0.5821\n",
            "Epoch 318/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4554 - val_loss: 0.5905\n",
            "Epoch 319/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.5770\n",
            "Epoch 320/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 0.5766\n",
            "Epoch 321/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4533 - val_loss: 0.5829\n",
            "Epoch 322/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4545 - val_loss: 0.5920\n",
            "Epoch 323/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4537 - val_loss: 0.5828\n",
            "Epoch 324/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.5937\n",
            "Epoch 325/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.5765\n",
            "Epoch 326/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4517 - val_loss: 0.5764\n",
            "Epoch 327/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4535 - val_loss: 0.5888\n",
            "Epoch 328/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 0.5822\n",
            "Epoch 329/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4530 - val_loss: 0.5834\n",
            "Epoch 330/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4546 - val_loss: 0.5806\n",
            "Epoch 331/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 0.5804\n",
            "Epoch 332/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4526 - val_loss: 0.5805\n",
            "Epoch 333/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4516 - val_loss: 0.5869\n",
            "Epoch 334/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4526 - val_loss: 0.5952\n",
            "Epoch 335/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4482 - val_loss: 0.5824\n",
            "Epoch 336/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4521 - val_loss: 0.5797\n",
            "Epoch 337/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 0.5798\n",
            "Epoch 338/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4490 - val_loss: 0.5967\n",
            "Epoch 339/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4516 - val_loss: 0.5764\n",
            "Epoch 340/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.5955\n",
            "Epoch 341/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4543 - val_loss: 0.5891\n",
            "Epoch 342/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4537 - val_loss: 0.5912\n",
            "Epoch 343/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4502 - val_loss: 0.6002\n",
            "Epoch 344/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4507 - val_loss: 0.5877\n",
            "Epoch 345/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4521 - val_loss: 0.5909\n",
            "Epoch 346/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4519 - val_loss: 0.5795\n",
            "Epoch 347/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4482 - val_loss: 0.5880\n",
            "Epoch 348/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4521 - val_loss: 0.5764\n",
            "Epoch 349/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4470 - val_loss: 0.6004\n",
            "Epoch 350/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4508 - val_loss: 0.5780\n",
            "Epoch 351/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4529 - val_loss: 0.5817\n",
            "Epoch 352/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4493 - val_loss: 0.5894\n",
            "Epoch 353/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4483 - val_loss: 0.5826\n",
            "Epoch 354/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4510 - val_loss: 0.5956\n",
            "Epoch 355/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4491 - val_loss: 0.6041\n",
            "Epoch 356/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4504 - val_loss: 0.5846\n",
            "Epoch 357/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4486 - val_loss: 0.5802\n",
            "Epoch 358/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.5910\n",
            "Epoch 359/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4511 - val_loss: 0.5776\n",
            "Epoch 360/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4494 - val_loss: 0.5903\n",
            "Epoch 361/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.6076\n",
            "Epoch 362/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.5881\n",
            "Epoch 363/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4466 - val_loss: 0.5927\n",
            "Epoch 364/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4477 - val_loss: 0.5810\n",
            "Epoch 365/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4486 - val_loss: 0.5816\n",
            "Epoch 366/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4465 - val_loss: 0.5873\n",
            "Epoch 367/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4463 - val_loss: 0.5992\n",
            "Epoch 368/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4472 - val_loss: 0.5749\n",
            "Epoch 369/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4500 - val_loss: 0.5805\n",
            "Epoch 370/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4501 - val_loss: 0.5808\n",
            "Epoch 371/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4445 - val_loss: 0.5789\n",
            "Epoch 372/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4442 - val_loss: 0.5841\n",
            "Epoch 373/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4446 - val_loss: 0.5814\n",
            "Epoch 374/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4443 - val_loss: 0.5876\n",
            "Epoch 375/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4487 - val_loss: 0.5947\n",
            "Epoch 376/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4465 - val_loss: 0.5819\n",
            "Epoch 377/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4479 - val_loss: 0.5872\n",
            "Epoch 378/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4466 - val_loss: 0.5728\n",
            "Epoch 379/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4445 - val_loss: 0.5730\n",
            "Epoch 380/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4481 - val_loss: 0.6028\n",
            "Epoch 381/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4496 - val_loss: 0.5762\n",
            "Epoch 382/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4467 - val_loss: 0.5923\n",
            "Epoch 383/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4477 - val_loss: 0.5775\n",
            "Epoch 384/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4448 - val_loss: 0.5870\n",
            "Epoch 385/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4459 - val_loss: 0.5948\n",
            "Epoch 386/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4469 - val_loss: 0.5817\n",
            "Epoch 387/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4465 - val_loss: 0.5903\n",
            "Epoch 388/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.5828\n",
            "Epoch 389/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4416 - val_loss: 0.6130\n",
            "Epoch 390/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4496 - val_loss: 0.5858\n",
            "Epoch 391/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4448 - val_loss: 0.5798\n",
            "Epoch 392/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4452 - val_loss: 0.5881\n",
            "Epoch 393/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4467 - val_loss: 0.5897\n",
            "Epoch 394/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4454 - val_loss: 0.5828\n",
            "Epoch 395/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4453 - val_loss: 0.5884\n",
            "Epoch 396/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.5822\n",
            "Epoch 397/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4450 - val_loss: 0.5888\n",
            "Epoch 398/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4452 - val_loss: 0.5807\n",
            "Epoch 399/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4463 - val_loss: 0.5904\n",
            "Epoch 400/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4437 - val_loss: 0.5791\n",
            "Epoch 401/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4432 - val_loss: 0.5786\n",
            "Epoch 402/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4429 - val_loss: 0.5841\n",
            "Epoch 403/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4445 - val_loss: 0.5827\n",
            "Epoch 404/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4420 - val_loss: 0.5920\n",
            "Epoch 405/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4413 - val_loss: 0.5886\n",
            "Epoch 406/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4434 - val_loss: 0.5822\n",
            "Epoch 407/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4437 - val_loss: 0.5992\n",
            "Epoch 408/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4456 - val_loss: 0.6049\n",
            "Epoch 409/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4409 - val_loss: 0.6120\n",
            "Epoch 410/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4412 - val_loss: 0.5920\n",
            "Epoch 411/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4422 - val_loss: 0.5910\n",
            "Epoch 412/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4401 - val_loss: 0.5825\n",
            "Epoch 413/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4393 - val_loss: 0.5857\n",
            "Epoch 414/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.6033\n",
            "Epoch 415/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4402 - val_loss: 0.5710\n",
            "Epoch 416/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4437 - val_loss: 0.5839\n",
            "Epoch 417/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4404 - val_loss: 0.5888\n",
            "Epoch 418/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4427 - val_loss: 0.5743\n",
            "Epoch 419/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4357 - val_loss: 0.6251\n",
            "Epoch 420/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4416 - val_loss: 0.5821\n",
            "Epoch 421/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 0.5897\n",
            "Epoch 422/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4402 - val_loss: 0.5955\n",
            "Epoch 423/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4439 - val_loss: 0.5823\n",
            "Epoch 424/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4394 - val_loss: 0.5817\n",
            "Epoch 425/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4400 - val_loss: 0.5940\n",
            "Epoch 426/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4438 - val_loss: 0.5846\n",
            "Epoch 427/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4397 - val_loss: 0.5730\n",
            "Epoch 428/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4411 - val_loss: 0.5788\n",
            "Epoch 429/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4392 - val_loss: 0.6011\n",
            "Epoch 430/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4398 - val_loss: 0.5765\n",
            "Epoch 431/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4380 - val_loss: 0.5915\n",
            "Epoch 432/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4409 - val_loss: 0.5869\n",
            "Epoch 433/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4398 - val_loss: 0.5984\n",
            "Epoch 434/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 0.5799\n",
            "Epoch 435/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 0.5728\n",
            "Epoch 436/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4407 - val_loss: 0.5876\n",
            "Epoch 437/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 0.5794\n",
            "Epoch 438/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4410 - val_loss: 0.5926\n",
            "Epoch 439/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4371 - val_loss: 0.5845\n",
            "Epoch 440/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4391 - val_loss: 0.5869\n",
            "Epoch 441/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4382 - val_loss: 0.5899\n",
            "Epoch 442/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4360 - val_loss: 0.5869\n",
            "Epoch 443/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 0.5784\n",
            "Epoch 444/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4382 - val_loss: 0.5808\n",
            "Epoch 445/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4396 - val_loss: 0.5988\n",
            "Epoch 446/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4350 - val_loss: 0.5865\n",
            "Epoch 447/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 0.5848\n",
            "Epoch 448/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4382 - val_loss: 0.5780\n",
            "Epoch 449/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4390 - val_loss: 0.5872\n",
            "Epoch 450/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4360 - val_loss: 0.5923\n",
            "Epoch 451/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4385 - val_loss: 0.5837\n",
            "Epoch 452/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4342 - val_loss: 0.5830\n",
            "Epoch 453/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4357 - val_loss: 0.5829\n",
            "Epoch 454/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 0.5890\n",
            "Epoch 455/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4365 - val_loss: 0.5831\n",
            "Epoch 456/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4365 - val_loss: 0.5815\n",
            "Epoch 457/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4303 - val_loss: 0.5830\n",
            "Epoch 458/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.6061\n",
            "Epoch 459/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4379 - val_loss: 0.5902\n",
            "Epoch 460/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4348 - val_loss: 0.5860\n",
            "Epoch 461/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.5802\n",
            "Epoch 462/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4331 - val_loss: 0.6135\n",
            "Epoch 463/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4364 - val_loss: 0.5772\n",
            "Epoch 464/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 0.5937\n",
            "Epoch 465/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.5876\n",
            "Epoch 466/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4365 - val_loss: 0.5912\n",
            "Epoch 467/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4365 - val_loss: 0.5760\n",
            "Epoch 468/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4370 - val_loss: 0.5842\n",
            "Epoch 469/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4359 - val_loss: 0.5926\n",
            "Epoch 470/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4340 - val_loss: 0.5958\n",
            "Epoch 471/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.5822\n",
            "Epoch 472/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4354 - val_loss: 0.5904\n",
            "Epoch 473/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4336 - val_loss: 0.5838\n",
            "Epoch 474/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4361 - val_loss: 0.5892\n",
            "Epoch 475/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4326 - val_loss: 0.5984\n",
            "Epoch 476/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.5886\n",
            "Epoch 477/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4339 - val_loss: 0.5888\n",
            "Epoch 478/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4305 - val_loss: 0.6164\n",
            "Epoch 479/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4344 - val_loss: 0.5899\n",
            "Epoch 480/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4349 - val_loss: 0.5885\n",
            "Epoch 481/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4361 - val_loss: 0.5877\n",
            "Epoch 482/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4340 - val_loss: 0.5815\n",
            "Epoch 483/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4380 - val_loss: 0.5926\n",
            "Epoch 484/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4350 - val_loss: 0.6024\n",
            "Epoch 485/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4350 - val_loss: 0.5983\n",
            "Epoch 486/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4326 - val_loss: 0.5865\n",
            "Epoch 487/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4361 - val_loss: 0.5888\n",
            "Epoch 488/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4330 - val_loss: 0.5924\n",
            "Epoch 489/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4367 - val_loss: 0.5869\n",
            "Epoch 490/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4340 - val_loss: 0.5882\n",
            "Epoch 491/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4308 - val_loss: 0.5848\n",
            "Epoch 492/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4334 - val_loss: 0.5861\n",
            "Epoch 493/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4318 - val_loss: 0.6099\n",
            "Epoch 494/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4361 - val_loss: 0.6025\n",
            "Epoch 495/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4323 - val_loss: 0.5949\n",
            "Epoch 496/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4333 - val_loss: 0.5775\n",
            "Epoch 497/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4300 - val_loss: 0.5824\n",
            "Epoch 498/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 0.5777\n",
            "Epoch 499/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4343 - val_loss: 0.5823\n",
            "Epoch 500/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 0.5873\n",
            "Epoch 501/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4330 - val_loss: 0.6043\n",
            "Epoch 502/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4309 - val_loss: 0.5828\n",
            "Epoch 503/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4306 - val_loss: 0.5959\n",
            "Epoch 504/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4298 - val_loss: 0.5952\n",
            "Epoch 505/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4326 - val_loss: 0.6002\n",
            "Epoch 506/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4339 - val_loss: 0.5787\n",
            "Epoch 507/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 0.5877\n",
            "Epoch 508/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4333 - val_loss: 0.6039\n",
            "Epoch 509/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 0.5903\n",
            "Epoch 510/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4319 - val_loss: 0.5787\n",
            "Epoch 511/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4301 - val_loss: 0.5937\n",
            "Epoch 512/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4323 - val_loss: 0.6113\n",
            "Epoch 513/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4308 - val_loss: 0.5873\n",
            "Epoch 514/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4295 - val_loss: 0.6035\n",
            "Epoch 515/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4307 - val_loss: 0.5959\n",
            "Epoch 516/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4290 - val_loss: 0.5894\n",
            "Epoch 517/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4308 - val_loss: 0.5959\n",
            "Epoch 518/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4318 - val_loss: 0.5920\n",
            "Epoch 519/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4295 - val_loss: 0.5949\n",
            "Epoch 520/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4332 - val_loss: 0.5895\n",
            "Epoch 521/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 0.6228\n",
            "Epoch 522/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.6047\n",
            "Epoch 523/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 0.5926\n",
            "Epoch 524/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4345 - val_loss: 0.5890\n",
            "Epoch 525/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4288 - val_loss: 0.6053\n",
            "Epoch 526/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4326 - val_loss: 0.5927\n",
            "Epoch 527/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 0.5943\n",
            "Epoch 528/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4332 - val_loss: 0.5924\n",
            "Epoch 529/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4288 - val_loss: 0.5886\n",
            "Epoch 530/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4314 - val_loss: 0.6081\n",
            "Epoch 531/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4297 - val_loss: 0.5930\n",
            "Epoch 532/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4306 - val_loss: 0.6191\n",
            "Epoch 533/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4295 - val_loss: 0.6039\n",
            "Epoch 534/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4317 - val_loss: 0.5933\n",
            "Epoch 535/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4293 - val_loss: 0.6052\n",
            "Epoch 536/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4307 - val_loss: 0.5995\n",
            "Epoch 537/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4244 - val_loss: 0.5894\n",
            "Epoch 538/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4325 - val_loss: 0.5894\n",
            "Epoch 539/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4281 - val_loss: 0.5963\n",
            "Epoch 540/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4304 - val_loss: 0.5931\n",
            "Epoch 541/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4262 - val_loss: 0.5877\n",
            "Epoch 542/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4319 - val_loss: 0.5995\n",
            "Epoch 543/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4275 - val_loss: 0.5885\n",
            "Epoch 544/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4290 - val_loss: 0.5997\n",
            "Epoch 545/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4280 - val_loss: 0.5903\n",
            "Epoch 546/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4281 - val_loss: 0.5855\n",
            "Epoch 547/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4323 - val_loss: 0.5997\n",
            "Epoch 548/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4305 - val_loss: 0.5925\n",
            "Epoch 549/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4292 - val_loss: 0.6006\n",
            "Epoch 550/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4288 - val_loss: 0.6230\n",
            "Epoch 551/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4300 - val_loss: 0.6101\n",
            "Epoch 552/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4288 - val_loss: 0.6114\n",
            "Epoch 553/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4301 - val_loss: 0.6034\n",
            "Epoch 554/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4311 - val_loss: 0.5953\n",
            "Epoch 555/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4282 - val_loss: 0.5982\n",
            "Epoch 556/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4273 - val_loss: 0.5952\n",
            "Epoch 557/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4289 - val_loss: 0.6078\n",
            "Epoch 558/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4323 - val_loss: 0.6032\n",
            "Epoch 559/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 0.5911\n",
            "Epoch 560/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 0.6114\n",
            "Epoch 561/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4275 - val_loss: 0.5996\n",
            "Epoch 562/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4283 - val_loss: 0.6219\n",
            "Epoch 563/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4301 - val_loss: 0.6025\n",
            "Epoch 564/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4282 - val_loss: 0.5917\n",
            "Epoch 565/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4306 - val_loss: 0.5992\n",
            "Epoch 566/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4293 - val_loss: 0.6006\n",
            "Epoch 567/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 0.5964\n",
            "Epoch 568/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4262 - val_loss: 0.5923\n",
            "Epoch 569/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4255 - val_loss: 0.6061\n",
            "Epoch 570/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4300 - val_loss: 0.6015\n",
            "Epoch 571/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4295 - val_loss: 0.6077\n",
            "Epoch 572/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4260 - val_loss: 0.6215\n",
            "Epoch 573/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4292 - val_loss: 0.6115\n",
            "Epoch 574/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.6567\n",
            "Epoch 575/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4239 - val_loss: 0.6098\n",
            "Epoch 576/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4290 - val_loss: 0.6054\n",
            "Epoch 577/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4281 - val_loss: 0.6067\n",
            "Epoch 578/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4246 - val_loss: 0.6153\n",
            "Epoch 579/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.5967\n",
            "Epoch 580/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4276 - val_loss: 0.6051\n",
            "Epoch 581/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4248 - val_loss: 0.6075\n",
            "Epoch 582/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4280 - val_loss: 0.6156\n",
            "Epoch 583/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.6138\n",
            "Epoch 584/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4259 - val_loss: 0.6336\n",
            "Epoch 585/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4292 - val_loss: 0.6195\n",
            "Epoch 586/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4242 - val_loss: 0.6251\n",
            "Epoch 587/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4299 - val_loss: 0.6166\n",
            "Epoch 588/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4286 - val_loss: 0.6132\n",
            "Epoch 589/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4279 - val_loss: 0.5975\n",
            "Epoch 590/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4275 - val_loss: 0.6074\n",
            "Epoch 591/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 0.6064\n",
            "Epoch 592/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4237 - val_loss: 0.6222\n",
            "Epoch 593/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4266 - val_loss: 0.6255\n",
            "Epoch 594/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 0.6024\n",
            "Epoch 595/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.5983\n",
            "Epoch 596/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4262 - val_loss: 0.5953\n",
            "Epoch 597/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.6169\n",
            "Epoch 598/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4283 - val_loss: 0.6069\n",
            "Epoch 599/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4253 - val_loss: 0.6085\n",
            "Epoch 600/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4231 - val_loss: 0.6030\n",
            "Epoch 601/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4291 - val_loss: 0.6069\n",
            "Epoch 602/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4283 - val_loss: 0.6220\n",
            "Epoch 603/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4226 - val_loss: 0.6027\n",
            "Epoch 604/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4250 - val_loss: 0.6143\n",
            "Epoch 605/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4235 - val_loss: 0.6149\n",
            "Epoch 606/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4231 - val_loss: 0.6105\n",
            "Epoch 607/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4207 - val_loss: 0.6059\n",
            "Epoch 608/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4201 - val_loss: 0.6274\n",
            "Epoch 609/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4261 - val_loss: 0.5995\n",
            "Epoch 610/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4250 - val_loss: 0.6070\n",
            "Epoch 611/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4249 - val_loss: 0.6340\n",
            "Epoch 612/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4280 - val_loss: 0.6108\n",
            "Epoch 613/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4275 - val_loss: 0.5992\n",
            "Epoch 614/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4246 - val_loss: 0.6048\n",
            "Epoch 615/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4280 - val_loss: 0.5955\n",
            "Epoch 616/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4208 - val_loss: 0.5981\n",
            "Epoch 617/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.6209\n",
            "Epoch 618/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4267 - val_loss: 0.6130\n",
            "Epoch 619/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4245 - val_loss: 0.5974\n",
            "Epoch 620/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 0.6024\n",
            "Epoch 621/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4282 - val_loss: 0.6050\n",
            "Epoch 622/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4234 - val_loss: 0.6119\n",
            "Epoch 623/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4214 - val_loss: 0.6075\n",
            "Epoch 624/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.5915\n",
            "Epoch 625/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4196 - val_loss: 0.6342\n",
            "Epoch 626/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.6149\n",
            "Epoch 627/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4259 - val_loss: 0.6090\n",
            "Epoch 628/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4241 - val_loss: 0.5984\n",
            "Epoch 629/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4238 - val_loss: 0.6014\n",
            "Epoch 630/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4236 - val_loss: 0.6013\n",
            "Epoch 631/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4222 - val_loss: 0.6036\n",
            "Epoch 632/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4174 - val_loss: 0.6345\n",
            "Epoch 633/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4210 - val_loss: 0.6029\n",
            "Epoch 634/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4242 - val_loss: 0.6169\n",
            "Epoch 635/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4229 - val_loss: 0.5954\n",
            "Epoch 636/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4214 - val_loss: 0.5974\n",
            "Epoch 637/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4263 - val_loss: 0.6088\n",
            "Epoch 638/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4248 - val_loss: 0.6215\n",
            "Epoch 639/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4228 - val_loss: 0.6032\n",
            "Epoch 640/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4182 - val_loss: 0.6166\n",
            "Epoch 641/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4255 - val_loss: 0.6230\n",
            "Epoch 642/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4218 - val_loss: 0.6084\n",
            "Epoch 643/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4210 - val_loss: 0.6059\n",
            "Epoch 644/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4238 - val_loss: 0.6100\n",
            "Epoch 645/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4263 - val_loss: 0.6198\n",
            "Epoch 646/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4203 - val_loss: 0.6109\n",
            "Epoch 647/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4239 - val_loss: 0.6153\n",
            "Epoch 648/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4236 - val_loss: 0.6215\n",
            "Epoch 649/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4193 - val_loss: 0.6200\n",
            "Epoch 650/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4122 - val_loss: 0.6518\n",
            "Epoch 651/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4256 - val_loss: 0.6081\n",
            "Epoch 652/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4226 - val_loss: 0.6081\n",
            "Epoch 653/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4238 - val_loss: 0.6046\n",
            "Epoch 654/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4190 - val_loss: 0.6041\n",
            "Epoch 655/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4210 - val_loss: 0.5998\n",
            "Epoch 656/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4151 - val_loss: 0.6247\n",
            "Epoch 657/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4189 - val_loss: 0.6244\n",
            "Epoch 658/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4184 - val_loss: 0.6202\n",
            "Epoch 659/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4209 - val_loss: 0.6098\n",
            "Epoch 660/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4240 - val_loss: 0.6040\n",
            "Epoch 661/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4234 - val_loss: 0.6050\n",
            "Epoch 662/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4238 - val_loss: 0.6028\n",
            "Epoch 663/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4221 - val_loss: 0.6011\n",
            "Epoch 664/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4189 - val_loss: 0.5987\n",
            "Epoch 665/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4235 - val_loss: 0.6101\n",
            "Epoch 666/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4171 - val_loss: 0.6140\n",
            "Epoch 667/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4247 - val_loss: 0.6283\n",
            "Epoch 668/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4207 - val_loss: 0.6070\n",
            "Epoch 669/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4196 - val_loss: 0.6222\n",
            "Epoch 670/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4207 - val_loss: 0.6049\n",
            "Epoch 671/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4214 - val_loss: 0.6074\n",
            "Epoch 672/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4186 - val_loss: 0.6292\n",
            "Epoch 673/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4190 - val_loss: 0.6263\n",
            "Epoch 674/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4247 - val_loss: 0.6061\n",
            "Epoch 675/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4181 - val_loss: 0.6084\n",
            "Epoch 676/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4180 - val_loss: 0.6226\n",
            "Epoch 677/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4197 - val_loss: 0.6418\n",
            "Epoch 678/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4205 - val_loss: 0.6136\n",
            "Epoch 679/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4181 - val_loss: 0.6398\n",
            "Epoch 680/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4179 - val_loss: 0.6280\n",
            "Epoch 681/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4233 - val_loss: 0.6102\n",
            "Epoch 682/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4126 - val_loss: 0.6545\n",
            "Epoch 683/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4211 - val_loss: 0.6164\n",
            "Epoch 684/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4212 - val_loss: 0.6117\n",
            "Epoch 685/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4203 - val_loss: 0.6242\n",
            "Epoch 686/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4202 - val_loss: 0.6172\n",
            "Epoch 687/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4127 - val_loss: 0.6479\n",
            "Epoch 688/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4219 - val_loss: 0.6147\n",
            "Epoch 689/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4207 - val_loss: 0.6182\n",
            "Epoch 690/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4189 - val_loss: 0.6249\n",
            "Epoch 691/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4173 - val_loss: 0.6361\n",
            "Epoch 692/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4207 - val_loss: 0.6169\n",
            "Epoch 693/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4185 - val_loss: 0.6097\n",
            "Epoch 694/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4147 - val_loss: 0.6366\n",
            "Epoch 695/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4203 - val_loss: 0.6092\n",
            "Epoch 696/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4172 - val_loss: 0.6509\n",
            "Epoch 697/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4165 - val_loss: 0.6408\n",
            "Epoch 698/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4209 - val_loss: 0.6148\n",
            "Epoch 699/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4177 - val_loss: 0.6254\n",
            "Epoch 700/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4185 - val_loss: 0.6256\n",
            "Epoch 701/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4205 - val_loss: 0.6325\n",
            "Epoch 702/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 0.6196\n",
            "Epoch 703/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4187 - val_loss: 0.6054\n",
            "Epoch 704/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4171 - val_loss: 0.6196\n",
            "Epoch 705/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4146 - val_loss: 0.6133\n",
            "Epoch 706/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4194 - val_loss: 0.6139\n",
            "Epoch 707/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4173 - val_loss: 0.6033\n",
            "Epoch 708/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4164 - val_loss: 0.6424\n",
            "Epoch 709/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4134 - val_loss: 0.6267\n",
            "Epoch 710/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4218 - val_loss: 0.6121\n",
            "Epoch 711/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4122 - val_loss: 0.6374\n",
            "Epoch 712/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4159 - val_loss: 0.6069\n",
            "Epoch 713/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4200 - val_loss: 0.6224\n",
            "Epoch 714/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4201 - val_loss: 0.6229\n",
            "Epoch 715/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4135 - val_loss: 0.6206\n",
            "Epoch 716/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4160 - val_loss: 0.6288\n",
            "Epoch 717/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4188 - val_loss: 0.6314\n",
            "Epoch 718/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4149 - val_loss: 0.6196\n",
            "Epoch 719/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 0.6274\n",
            "Epoch 720/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4174 - val_loss: 0.6367\n",
            "Epoch 721/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4154 - val_loss: 0.6396\n",
            "Epoch 722/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4180 - val_loss: 0.6294\n",
            "Epoch 723/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4202 - val_loss: 0.6214\n",
            "Epoch 724/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4163 - val_loss: 0.6246\n",
            "Epoch 725/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4201 - val_loss: 0.6305\n",
            "Epoch 726/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4195 - val_loss: 0.6225\n",
            "Epoch 727/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4177 - val_loss: 0.6208\n",
            "Epoch 728/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4164 - val_loss: 0.6634\n",
            "Epoch 729/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4190 - val_loss: 0.6208\n",
            "Epoch 730/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4162 - val_loss: 0.6168\n",
            "Epoch 731/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4152 - val_loss: 0.6210\n",
            "Epoch 732/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 0.6303\n",
            "Epoch 733/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4157 - val_loss: 0.6392\n",
            "Epoch 734/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4189 - val_loss: 0.6300\n",
            "Epoch 735/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4179 - val_loss: 0.6194\n",
            "Epoch 736/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4193 - val_loss: 0.6374\n",
            "Epoch 737/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4131 - val_loss: 0.6346\n",
            "Epoch 738/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4197 - val_loss: 0.6159\n",
            "Epoch 739/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4162 - val_loss: 0.6306\n",
            "Epoch 740/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4184 - val_loss: 0.6218\n",
            "Epoch 741/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4205 - val_loss: 0.6162\n",
            "Epoch 742/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4181 - val_loss: 0.6185\n",
            "Epoch 743/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4154 - val_loss: 0.6254\n",
            "Epoch 744/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.6228\n",
            "Epoch 745/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4202 - val_loss: 0.6280\n",
            "Epoch 746/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.6275\n",
            "Epoch 747/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4159 - val_loss: 0.6483\n",
            "Epoch 748/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4154 - val_loss: 0.6427\n",
            "Epoch 749/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4153 - val_loss: 0.6187\n",
            "Epoch 750/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4146 - val_loss: 0.6182\n",
            "Epoch 751/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4179 - val_loss: 0.6256\n",
            "Epoch 752/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4156 - val_loss: 0.6447\n",
            "Epoch 753/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4128 - val_loss: 0.6288\n",
            "Epoch 754/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4173 - val_loss: 0.6416\n",
            "Epoch 755/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4149 - val_loss: 0.6447\n",
            "Epoch 756/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4156 - val_loss: 0.6305\n",
            "Epoch 757/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4147 - val_loss: 0.6312\n",
            "Epoch 758/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4123 - val_loss: 0.6362\n",
            "Epoch 759/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4132 - val_loss: 0.6316\n",
            "Epoch 760/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.6371\n",
            "Epoch 761/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 0.6206\n",
            "Epoch 762/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4162 - val_loss: 0.6202\n",
            "Epoch 763/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 0.6425\n",
            "Epoch 764/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4127 - val_loss: 0.6292\n",
            "Epoch 765/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4181 - val_loss: 0.6297\n",
            "Epoch 766/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4126 - val_loss: 0.6158\n",
            "Epoch 767/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4136 - val_loss: 0.6327\n",
            "Epoch 768/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4131 - val_loss: 0.6488\n",
            "Epoch 769/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4183 - val_loss: 0.6293\n",
            "Epoch 770/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4155 - val_loss: 0.6229\n",
            "Epoch 771/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4187 - val_loss: 0.6174\n",
            "Epoch 772/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.6311\n",
            "Epoch 773/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4103 - val_loss: 0.6222\n",
            "Epoch 774/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4156 - val_loss: 0.6518\n",
            "Epoch 775/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4163 - val_loss: 0.6147\n",
            "Epoch 776/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4157 - val_loss: 0.6250\n",
            "Epoch 777/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 0.6366\n",
            "Epoch 778/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4144 - val_loss: 0.6241\n",
            "Epoch 779/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.6219\n",
            "Epoch 780/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.6451\n",
            "Epoch 781/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4175 - val_loss: 0.6348\n",
            "Epoch 782/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4135 - val_loss: 0.6397\n",
            "Epoch 783/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4147 - val_loss: 0.6447\n",
            "Epoch 784/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4155 - val_loss: 0.6367\n",
            "Epoch 785/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4146 - val_loss: 0.6346\n",
            "Epoch 786/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4156 - val_loss: 0.6214\n",
            "Epoch 787/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4158 - val_loss: 0.6294\n",
            "Epoch 788/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4133 - val_loss: 0.6387\n",
            "Epoch 789/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4125 - val_loss: 0.6574\n",
            "Epoch 790/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4175 - val_loss: 0.6321\n",
            "Epoch 791/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4116 - val_loss: 0.6435\n",
            "Epoch 792/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4139 - val_loss: 0.6174\n",
            "Epoch 793/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 0.6358\n",
            "Epoch 794/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4094 - val_loss: 0.6372\n",
            "Epoch 795/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4154 - val_loss: 0.6571\n",
            "Epoch 796/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4152 - val_loss: 0.6504\n",
            "Epoch 797/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4122 - val_loss: 0.6530\n",
            "Epoch 798/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4159 - val_loss: 0.6340\n",
            "Epoch 799/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4162 - val_loss: 0.6322\n",
            "Epoch 800/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4125 - val_loss: 0.6460\n",
            "Epoch 801/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4109 - val_loss: 0.6225\n",
            "Epoch 802/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4152 - val_loss: 0.6397\n",
            "Epoch 803/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4142 - val_loss: 0.6434\n",
            "Epoch 804/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4156 - val_loss: 0.6241\n",
            "Epoch 805/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4129 - val_loss: 0.6253\n",
            "Epoch 806/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4155 - val_loss: 0.6223\n",
            "Epoch 807/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4160 - val_loss: 0.6452\n",
            "Epoch 808/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4147 - val_loss: 0.6690\n",
            "Epoch 809/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4157 - val_loss: 0.6398\n",
            "Epoch 810/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4148 - val_loss: 0.6352\n",
            "Epoch 811/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.6601\n",
            "Epoch 812/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4127 - val_loss: 0.6318\n",
            "Epoch 813/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4155 - val_loss: 0.6372\n",
            "Epoch 814/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4149 - val_loss: 0.6404\n",
            "Epoch 815/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4095 - val_loss: 0.6338\n",
            "Epoch 816/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4096 - val_loss: 0.6688\n",
            "Epoch 817/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4166 - val_loss: 0.6492\n",
            "Epoch 818/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.6329\n",
            "Epoch 819/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4095 - val_loss: 0.6311\n",
            "Epoch 820/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4110 - val_loss: 0.6263\n",
            "Epoch 821/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4145 - val_loss: 0.6348\n",
            "Epoch 822/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4151 - val_loss: 0.6438\n",
            "Epoch 823/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4108 - val_loss: 0.6510\n",
            "Epoch 824/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4126 - val_loss: 0.6628\n",
            "Epoch 825/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4141 - val_loss: 0.6551\n",
            "Epoch 826/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4133 - val_loss: 0.6319\n",
            "Epoch 827/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4133 - val_loss: 0.6282\n",
            "Epoch 828/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4119 - val_loss: 0.6540\n",
            "Epoch 829/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4126 - val_loss: 0.6279\n",
            "Epoch 830/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4140 - val_loss: 0.6451\n",
            "Epoch 831/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4155 - val_loss: 0.6521\n",
            "Epoch 832/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4122 - val_loss: 0.6456\n",
            "Epoch 833/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4101 - val_loss: 0.6453\n",
            "Epoch 834/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.6418\n",
            "Epoch 835/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.6433\n",
            "Epoch 836/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4114 - val_loss: 0.6476\n",
            "Epoch 837/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 0.6386\n",
            "Epoch 838/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4122 - val_loss: 0.6426\n",
            "Epoch 839/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4088 - val_loss: 0.6575\n",
            "Epoch 840/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4142 - val_loss: 0.6390\n",
            "Epoch 841/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4142 - val_loss: 0.6499\n",
            "Epoch 842/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.6400\n",
            "Epoch 843/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4107 - val_loss: 0.6505\n",
            "Epoch 844/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4142 - val_loss: 0.6247\n",
            "Epoch 845/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.6490\n",
            "Epoch 846/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4123 - val_loss: 0.6385\n",
            "Epoch 847/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4096 - val_loss: 0.6460\n",
            "Epoch 848/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4140 - val_loss: 0.6304\n",
            "Epoch 849/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4071 - val_loss: 0.6831\n",
            "Epoch 850/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4163 - val_loss: 0.6528\n",
            "Epoch 851/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4139 - val_loss: 0.6373\n",
            "Epoch 852/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4106 - val_loss: 0.6396\n",
            "Epoch 853/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.6296\n",
            "Epoch 854/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4109 - val_loss: 0.6388\n",
            "Epoch 855/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4127 - val_loss: 0.6400\n",
            "Epoch 856/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4093 - val_loss: 0.6652\n",
            "Epoch 857/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4137 - val_loss: 0.6509\n",
            "Epoch 858/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4130 - val_loss: 0.6527\n",
            "Epoch 859/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4107 - val_loss: 0.6412\n",
            "Epoch 860/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.6493\n",
            "Epoch 861/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4136 - val_loss: 0.6364\n",
            "Epoch 862/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4151 - val_loss: 0.6690\n",
            "Epoch 863/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4060 - val_loss: 0.6371\n",
            "Epoch 864/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4117 - val_loss: 0.6531\n",
            "Epoch 865/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4059 - val_loss: 0.6468\n",
            "Epoch 866/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4097 - val_loss: 0.6389\n",
            "Epoch 867/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4047 - val_loss: 0.6963\n",
            "Epoch 868/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4155 - val_loss: 0.6514\n",
            "Epoch 869/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4117 - val_loss: 0.6503\n",
            "Epoch 870/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4147 - val_loss: 0.6588\n",
            "Epoch 871/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4125 - val_loss: 0.6554\n",
            "Epoch 872/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.6554\n",
            "Epoch 873/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.6798\n",
            "Epoch 874/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4113 - val_loss: 0.6610\n",
            "Epoch 875/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4122 - val_loss: 0.6460\n",
            "Epoch 876/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4148 - val_loss: 0.6347\n",
            "Epoch 877/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4086 - val_loss: 0.6468\n",
            "Epoch 878/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 0.6415\n",
            "Epoch 879/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4109 - val_loss: 0.6752\n",
            "Epoch 880/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 0.6862\n",
            "Epoch 881/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4144 - val_loss: 0.6376\n",
            "Epoch 882/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4097 - val_loss: 0.6579\n",
            "Epoch 883/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4088 - val_loss: 0.6661\n",
            "Epoch 884/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4097 - val_loss: 0.6565\n",
            "Epoch 885/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4116 - val_loss: 0.6673\n",
            "Epoch 886/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4090 - val_loss: 0.6453\n",
            "Epoch 887/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4073 - val_loss: 0.6706\n",
            "Epoch 888/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4126 - val_loss: 0.6849\n",
            "Epoch 889/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4116 - val_loss: 0.6586\n",
            "Epoch 890/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4097 - val_loss: 0.6616\n",
            "Epoch 891/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4128 - val_loss: 0.6536\n",
            "Epoch 892/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4115 - val_loss: 0.6427\n",
            "Epoch 893/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4110 - val_loss: 0.6367\n",
            "Epoch 894/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4138 - val_loss: 0.6521\n",
            "Epoch 895/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4051 - val_loss: 0.6565\n",
            "Epoch 896/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4123 - val_loss: 0.6477\n",
            "Epoch 897/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4095 - val_loss: 0.6679\n",
            "Epoch 898/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.6443\n",
            "Epoch 899/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4093 - val_loss: 0.6718\n",
            "Epoch 900/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4071 - val_loss: 0.6508\n",
            "Epoch 901/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 0.6625\n",
            "Epoch 902/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4050 - val_loss: 0.6426\n",
            "Epoch 903/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4089 - val_loss: 0.6472\n",
            "Epoch 904/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4122 - val_loss: 0.6452\n",
            "Epoch 905/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4098 - val_loss: 0.6608\n",
            "Epoch 906/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4043 - val_loss: 0.6769\n",
            "Epoch 907/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 0.6472\n",
            "Epoch 908/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4084 - val_loss: 0.6494\n",
            "Epoch 909/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4111 - val_loss: 0.6490\n",
            "Epoch 910/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4113 - val_loss: 0.6520\n",
            "Epoch 911/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.6639\n",
            "Epoch 912/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4109 - val_loss: 0.6738\n",
            "Epoch 913/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4082 - val_loss: 0.6768\n",
            "Epoch 914/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4065 - val_loss: 0.6722\n",
            "Epoch 915/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4093 - val_loss: 0.6471\n",
            "Epoch 916/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 0.6913\n",
            "Epoch 917/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4101 - val_loss: 0.6515\n",
            "Epoch 918/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4095 - val_loss: 0.6631\n",
            "Epoch 919/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.6769\n",
            "Epoch 920/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4069 - val_loss: 0.6712\n",
            "Epoch 921/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4054 - val_loss: 0.6674\n",
            "Epoch 922/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.6414\n",
            "Epoch 923/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4135 - val_loss: 0.6532\n",
            "Epoch 924/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4063 - val_loss: 0.6691\n",
            "Epoch 925/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4090 - val_loss: 0.6798\n",
            "Epoch 926/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4066 - val_loss: 0.6784\n",
            "Epoch 927/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4117 - val_loss: 0.6762\n",
            "Epoch 928/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4089 - val_loss: 0.6811\n",
            "Epoch 929/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4086 - val_loss: 0.6539\n",
            "Epoch 930/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4029 - val_loss: 0.6503\n",
            "Epoch 931/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4036 - val_loss: 0.6804\n",
            "Epoch 932/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4072 - val_loss: 0.6592\n",
            "Epoch 933/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4093 - val_loss: 0.6752\n",
            "Epoch 934/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4059 - val_loss: 0.6721\n",
            "Epoch 935/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4082 - val_loss: 0.6582\n",
            "Epoch 936/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4094 - val_loss: 0.6597\n",
            "Epoch 937/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.6532\n",
            "Epoch 938/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4070 - val_loss: 0.6752\n",
            "Epoch 939/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4083 - val_loss: 0.6605\n",
            "Epoch 940/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4093 - val_loss: 0.6534\n",
            "Epoch 941/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.6984\n",
            "Epoch 942/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4092 - val_loss: 0.6631\n",
            "Epoch 943/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4081 - val_loss: 0.6427\n",
            "Epoch 944/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4007 - val_loss: 0.6450\n",
            "Epoch 945/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4108 - val_loss: 0.6480\n",
            "Epoch 946/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4065 - val_loss: 0.6706\n",
            "Epoch 947/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4088 - val_loss: 0.6759\n",
            "Epoch 948/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.6881\n",
            "Epoch 949/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4053 - val_loss: 0.6792\n",
            "Epoch 950/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4078 - val_loss: 0.6857\n",
            "Epoch 951/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4037 - val_loss: 0.6632\n",
            "Epoch 952/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4104 - val_loss: 0.6584\n",
            "Epoch 953/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4062 - val_loss: 0.6707\n",
            "Epoch 954/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4072 - val_loss: 0.6557\n",
            "Epoch 955/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4099 - val_loss: 0.6687\n",
            "Epoch 956/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4079 - val_loss: 0.6671\n",
            "Epoch 957/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3999 - val_loss: 0.7149\n",
            "Epoch 958/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4105 - val_loss: 0.6516\n",
            "Epoch 959/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3998 - val_loss: 0.6836\n",
            "Epoch 960/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 0.6762\n",
            "Epoch 961/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4066 - val_loss: 0.6716\n",
            "Epoch 962/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4045 - val_loss: 0.6815\n",
            "Epoch 963/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4057 - val_loss: 0.6832\n",
            "Epoch 964/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4086 - val_loss: 0.6721\n",
            "Epoch 965/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4084 - val_loss: 0.6772\n",
            "Epoch 966/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4069 - val_loss: 0.6704\n",
            "Epoch 967/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4021 - val_loss: 0.6599\n",
            "Epoch 968/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4047 - val_loss: 0.6738\n",
            "Epoch 969/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4079 - val_loss: 0.6771\n",
            "Epoch 970/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4032 - val_loss: 0.6521\n",
            "Epoch 971/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4054 - val_loss: 0.6816\n",
            "Epoch 972/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4049 - val_loss: 0.6734\n",
            "Epoch 973/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4055 - val_loss: 0.6760\n",
            "Epoch 974/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4068 - val_loss: 0.6585\n",
            "Epoch 975/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4013 - val_loss: 0.6574\n",
            "Epoch 976/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4035 - val_loss: 0.6717\n",
            "Epoch 977/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4066 - val_loss: 0.6680\n",
            "Epoch 978/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4083 - val_loss: 0.6728\n",
            "Epoch 979/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4042 - val_loss: 0.6745\n",
            "Epoch 980/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4061 - val_loss: 0.6451\n",
            "Epoch 981/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4034 - val_loss: 0.6671\n",
            "Epoch 982/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4053 - val_loss: 0.6867\n",
            "Epoch 983/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4029 - val_loss: 0.6703\n",
            "Epoch 984/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4082 - val_loss: 0.6631\n",
            "Epoch 985/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4084 - val_loss: 0.6680\n",
            "Epoch 986/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4018 - val_loss: 0.6692\n",
            "Epoch 987/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4060 - val_loss: 0.6599\n",
            "Epoch 988/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4037 - val_loss: 0.6943\n",
            "Epoch 989/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4084 - val_loss: 0.6817\n",
            "Epoch 990/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4042 - val_loss: 0.6767\n",
            "Epoch 991/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3997 - val_loss: 0.6947\n",
            "Epoch 992/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 0.6716\n",
            "Epoch 993/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4059 - val_loss: 0.6685\n",
            "Epoch 994/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4050 - val_loss: 0.6719\n",
            "Epoch 995/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4042 - val_loss: 0.6852\n",
            "Epoch 996/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3928 - val_loss: 0.6977\n",
            "Epoch 997/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 0.6709\n",
            "Epoch 998/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4033 - val_loss: 0.6842\n",
            "Epoch 999/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4023 - val_loss: 0.6457\n",
            "Epoch 1000/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 0.6780\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEJCAYAAACZjSCSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVfrA8e/JpJFCKIFQQgi9GHpXSkAQ1BVXxYIVV8UGdlfs6OLad9WVtaw/y7pKsYKIIgqhCCJFeicQCDWhJyH9/P64d2pmkknIkHLfz/Pkmbn3nrlz7gzcd05XWmuEEEJYV1BVZ0AIIUTVkkAghBAWJ4FACCEsTgKBEEJYnAQCIYSwOAkEQghhcQENBEqpUUqpbUqpnUqpSV6Ot1RK/aKUWq+USlFKxQcyP0IIIUpSgRpHoJSyAduBEUA6sBIYq7Xe7JLmC2CO1voTpdQw4Fat9U0ByZAQQgivggN47r7ATq11KoBSajpwObDZJU1n4CHz+ULg27JOGhsbqxMTEyuUoezsbCIjIyv02ppKrtka5Jqt4WyuefXq1Zla60bejgUyEDQH9rlspwP9PNKsA64E3gSuAKKVUg211kd9nTQxMZFVq1ZVKEMpKSkkJydX6LU1lVyzNcg1W8PZXLNSKs3nsQBWDY0BRmmtbze3bwL6aa0nuKRpBrwNtAIWA1cBSVrrEx7nGg+MB4iLi+s1ffr0CuUpKyuLqKioCr22ppJrtga5Zms4m2seOnToaq11b2/HAlki2A+0cNmON/c5aK0PYJQIUEpFAVd5BgEz3fvA+wC9e/fWFY2I8gvCGuSarUGuufIEstfQSqCdUqqVUioUuA6Y7ZpAKRWrlLLn4XHgwwDmRwghhBcBKxForQuVUhOAeYAN+FBrvUkp9TywSms9G0gGXlRKaYyqoXsDlR8hRM1WUFBAeno6ubm5AMTExLBly5YqztW55c81h4eHEx8fT0hIiN/nDWTVEFrrucBcj33PuDz/EvgykHkQQtQO6enpREdHk5iYiFKK06dPEx0dXdXZOqfKumatNUePHiU9PZ1WrVr5fV4ZWSyEqBFyc3Np2LAhSqmqzkq1pZSiYcOGjlKTvyQQCCFqDAkCZavIZ2SZQLByzzG+3pFPfmFxVWdFCCGqFcsEgtVpx5m9q4DCYgkEQoiKqa3jFiwTCOyFJVmiWQgh3FknEJiRQOKAEOJsaa159NFHSUpKokuXLsyYMQOAgwcPMnjwYLp3705SUhJLliyhqKiIcePGOdL+85//rOLclxTQ7qPViTLLBIGaUkMIce48990mNuw7js1mq7Rzdm5Wl2cvO8+vtF9//TVr165l3bp1ZGZm0qdPHwYPHsznn3/OyJEjefLJJykqKiInJ4e1a9eyf/9+Nm7cCMCJEyUmT6hyUiIQQohyWrp0KWPHjsVmsxEXF8eQIUNYuXIlffr04aOPPmLy5Mls2LCB6OhoWrduTWpqKhMnTuTHH3+kbt26VZ39EixTIrCTAoEQNd+zl51XLQeUDR48mMWLF/P9998zbtw4HnroIW6++WbWrVvHvHnzePfdd5k5cyYffli9ZtOxUIlAigRCiMoxaNAgZsyYQVFRERkZGSxevJi+ffuSlpZGXFwcd9xxB7fffjtr1qwhMzOT4uJirrrqKqZMmcKaNWuqOvslWKZE4Og1JJFACHGWrrjiCpYvX063bt1QSvHKK6/QpEkTPvnkE1599VVCQkKIioriv//9L/v37+fWW2+l2Oy6/uKLL1Zx7kuyTiCwFwgkDgghKigrKwswahheffVVXn31Vbfjt9xyC7fcckuJ11XHUoAr61QNVXUGhBCimrJMILCTAoEQQrizTCCwNxbLOAIhhHBnoUBgPEoYEEIId9YJBOajFAiEEMKdZQKBvUgg3UeFEMKdZQKBo9eQxAEhxDlQ2pTVe/bsISkp6RzmpnTWCQTSRiCEEF5ZJxA4Zh+t4owIIWqkSZMmMXXqVMf25MmTmTJlChdeeCE9e/akS5cuzJo1q9znzc3N5dZbb6VLly706NGDhQsXArBp0yb69u1L9+7d6dq1Kzt27CA7O5tLL72Ubt26kZSU5Jj++mxZb2SxlAmEqPl+mESd/X+ArRJvYU26wMUv+Tx87bXX8sADD3DvvfcCMHPmTObNm8d9991H3bp1yczMpH///owePbpc6wZPnToVpRQbNmxg69atXHTRRWzfvp13332X+++/nxtuuIH8/HyKior46quvaNasGd9//z0AJ0+ePLtrNlmoRGCQEoEQoiJ69OjBkSNHOHDgAOvWraN+/fo0adKEJ554gq5duzJ8+HD279/P4cOHy3XepUuXcuONNwLQsWNHWrZsyfbt2xkwYAB///vfefnll0lLS6NOnTp07tyZ+fPn89hjj7FkyRJiYmIq5dosWCIQQtR4F7/EmSqYhvrqq6/myy+/5NChQ1x77bV89tlnZGRksHr1akJCQkhMTCQ3N7dS3uv666+nX79+fP/991xyySW899579OnThzVr1jB37lyeeuopLrzwQp555pmzfi/rBAJZoUwIcZauvfZa7rjjDjIzM1m0aBEzZ86kcePGhISEsHDhQtLS0sp9zkGDBvHZZ58xbNgwtm/fzt69e+nQoQOpqam0bt2a++67j71797J+/Xri4+NJSEjgxhtvpF69enzwwQeVcl2WCQTI7KNCiLN03nnGgjjNmzenadOm3HDDDVx22WV06dKF3r1707Fjx3Kf85577uHuu++mS5cuBAcH8/HHHxMWFsbMmTP59NNPCQkJcVRBLVq0iDFjxhAUFERISAjvvPNOpVyXZQKBzD4qhKgMGzZscDyPjY1l+fLlXtPZp6z2JjEx0bGGcXh4OB999FGJNJMmTWLSpElu+4YPH84VV1xRkWyXyjqNxUq6jwohhDeWKxFI91EhxLmyYcMGbrrpJrd9YWFhrFixoopy5J11AoG0EQghzrEuXbqwdu3aqs5GmSxUNWQ8ShwQouaSXn9lq8hnZJ1AIN1HhajRwsPDOXr0qPwfLoXWmqNHjxIeHl6u1wW0akgpNQp4E7ABH2itX/I4ngB8AtQz00zSWs8NTF6MR/knJETNFB8fT3p6OhkZGYAxR095b3g1nT/XHB4eTnx8fLnOG7BAoJSyAVOBEUA6sFIpNVtrvdkl2VPATK31O0qpzsBcIDFQeRJC1FwhISG0atXKsZ2SkkKPHj2qMEfnXqCuOZBVQ32BnVrrVK11PjAduNwjjQbqms9jgAMBzI/xhlIkEEIIN4GsGmoO7HPZTgf6eaSZDPyklJoIRALDA5UZ52yAEgmEEMJVVXcfHQt8rLV+XSk1APhUKZWktS52TaSUGg+MB4iLiyMlJaXcb7TlYCEAK35fSXqUZdrIycrKqtDnVZPJNVuDXHPlCWQg2A+0cNmON/e5ug0YBaC1Xq6UCgdigSOuibTW7wPvA/Tu3VsnJyeXOzNZ6w/Auj/o06cP7ePO7YyFVSklJYWKfF41mVyzNcg1V55A/jReCbRTSrVSSoUC1wGzPdLsBS4EUEp1AsKBjEBkRlYoE0II7wIWCLTWhcAEYB6wBaN30Cal1PNKqdFmsoeBO5RS64BpwDgdoE7CskKZEEJ4F9A2AnNMwFyPfc+4PN8MXBDIPNiF5J+ipTqELi4uO7EQQliIZVpNE/bMZFHYQ1BQOasHCSFEbWGZQKAdlyolAiGEcGWZQECQcalSNSSEEO6sEwgca1VKIBBCCFfWCQTKvNRi6TUkhBCuLBMIHEtVShuBEEK4sUwgsJcIpI1ACCHcWSgQ2Cedk0AghBCuLBQIpEQghBDeWCYQaHtjsUwxIYQQbiwTCJSUCIQQwivLBALnrHNFVZsPIYSoZqwTCMxLVVI1JIQQbqwTCBxVQxIIhBDClYUCgUwxIYQQ3lgoEJglAlmiTAgh3FguEEhjsRBCuLNQILCvWSwlAiGEcGW5QICMIxBCCDcWCgQ2QGYfFUIIT5YJBPZpqJV0HxVCCDeWCQT2FcqkRCCEEO6sEwiCjKohaSMQQgh3lgkEskKZEEJ4Z5lAIGsWCyGEdxYKBDLFhBBCeGOhQGCfYkICgRBCuLJcIJAVyoQQwp1lAoFzHIGUCIQQVaioEBa9AnlZVZ0TB8sEAsfIYpl0TghRlTZ+CQtfgAVTqjonDpYJBMrRWFy1+RBCWFxBjvtjNRDQQKCUGqWU2qaU2qmUmuTl+D+VUmvNv+1KqROBy4x9GmqpGhJCVCH7DMj2H6fVQHCgTqyUsgFTgRFAOrBSKTVba73ZnkZr/aBL+olAj8DlR3oNCSGqA3u1RPUJBIEsEfQFdmqtU7XW+cB04PJS0o8FpgUsN/bGYqkbEkJUpWpYIghkIGgO7HPZTjf3laCUagm0AhYELDdSIhBCVCvVJxAErGqonK4DvtQ+uvQopcYD4wHi4uJISUkp9xvkHNhOa2DP7lSyKvD6miorK6tCn1dNJtdsDTXhmlVxAf1W3M329ndxrGFvAJqnb6cdsP/AAXb4kX9bYQ7x6XNIa3kVWdlnAnLNgQwE+4EWLtvx5j5vrgPu9XUirfX7wPsAvXv31snJyeXOTOofGrZDYkICvSvw+poqJSWFinxeNZlcszVU6jV/cSts+homn6yc89kd3QWLM+ia/j+46hFj34ptsBOaN4+neWn5P3MCjmyGJW/Dnvm06nMRKRn1AvI9BzIQrATaKaVaYQSA64DrPRMppToC9YHlAcyLjCwWQvi26evAnNfRDuBy3/G3jeDllh47AnfvClgbgda6EJgAzAO2ADO11puUUs8rpUa7JL0OmK4DvKq8CpLuo0KIAJh+A7zd18dB+/gl19tbBXsNBYeXM2PlOHXAzgxorecCcz32PeOxPTmQeXBQ3r4QIYQ4S1vnlHLQvN9oDUteh4QBZZcIigqhuKDk/qDA3a4tNLLYXKFMAoEQoizfPwz/N9K4X2yZA8UVnJrG8ToNvzwPH10Mhbmlv2b69fBCk5L787Mrlgc/WCYQOEcWy1xDQlhWcTHMfxZO7C093coPYN9vsPErmHEDrHivgu9XaDwWnHHuS00xHle8C7PuhcJ8I+DYf6TumOf9XF/cUrE8+MEygUBJ1ZAQ4vBG+PUN+GKc9+PHUuGEy/Cnk+bz0wf9O/++lfDPJPhkNGRnOgNBrsvsOWHRzud//A+O7oDn6sE3d/l9GZXNcoFA1iwWQlCY533/Wz3gjSTndpFZV28LdU9XcMb4c60yKsiF/xtuBI/di+Dbu52BwP7oek67QxuNx/XTy8x2vePry0xTEdVlQFnAaUcbgQQCISwryLwP+FvnX5RvPHoGglfbGbOHdrjYue/1Du5pdvwEzXuVPGfhGfftb8Y7n+eWPo6hzhk/SyblZJlAEGTvPioL0whhXY4fhOUNBCHu+/NPG4+uPYZyvUyenPJiyX35pUw//Vr7UrOjVWBu2dYJBDbzUiva+i+EqAXMNkK/SwT2qiEzEEyOgTbDzi4L+1f5PlZGj6LiAHUhtU4bQbBRtFPe+ucKIWqmBVPgX73gzHGjuia9lJssOAOAvYo455hxc/clc4fzdacPGc93VeLcmB0uLVfyQJUILBMI7HV8qji/ijMihKg0i1+Fozth7wrIPgKLXi49vb1KSBdB2jLY7qOrpt3O+cZjYR58euXZ5VV5ud12uqz018T3gZ43Q8O2gJQIzpqjRODZYi+ECJxf34IDfwT+fexVv0UFkLEdDm3wns7Ri6fYGNz1rZ9dNovy4Pjus8tjeL2S+4LDyn7d6H9BnQYAaBVSRuKKsVAbgfGBS9WQEOfQ/KeNx8qe1dOTve9/cSFM7eP7Pe2dRVy7c/pjyetnP9dPRAM4c8x9n2cjtKfcU+YTo21DSgRnSQWbH3iRVA0JUeMUF8Ox3cZjoZf/w3MeMB59lfgzthmvtQcAzy6c/jjbruchdUrua9jOe9qWFxiP9oZpcyBslbYRKKUilbnor1KqvVJqtFIBKqMESJBZNRQkJQJR00ztB/OerOpclF9ldtVOeRHe6g6fXAZTGvlO5/pDr8i86R/aCFP7wtJ/OANBaV04/Tl3RQTXgaSr3Pc17gi9xpVMG9EAHtoKF00xd9gDge3s8uCDvyWCxUC4Uqo58BNwE/BxQHIUIEFBQeRrm1QNiZonYyssf7tq8zA5Bn54rHyvKW/1S2ns8/OkLTUeD2/yns61RPCvnkYj74k0Yzt9pbOx+FzcBxLOd98ODoPL3oKoOPf9MfHGY+/b4JLXjOfKBnWbOts+HCWCwGTV30CgtNY5wJXAv7XWVwPnBSZLgRGkoIBgKREI4Wra9ca8OP5Y8a7zeWoKbPuh9PRn83/t5Vaw6FXntucAsPcGe39dzlHn8xNpMKWxs0pn+49wfE/F81Regx923w6pA2FR8Mh29/31Eo3HJl2cDcolehhVcA0DP/kdCJRSA4AbgO/NfYEpowSIUooCgqVEIISrbd8b8+KUxnXwVZq5kOB/L4dp15XxOh8lguJiWPY25J0ueey3d2HNf41G1YVTXF7jEQhiWuDV6QMl9x10mZ/nu/tLz3PHP5V+3FOkl2qq5MeNxxb9jAbrvnca2649hK75FO4ySzddxsBN3xhVRPagFeRxe9XVIxA8ADwOfGOuMtYaWBiQHAWIs0QgjcVClIvrDf2jUcZauv4o8hEIdqfAT0/C3L8aVTeubQk/PgazJzq3j6UaQcB+gwwzB38d302dHC83fW8Wv+JfupgWMPAh/9LanW/mNa6Lc9+Qx+DJQ85ZRu09gyIaOtN0Hm2UAMBYoKbNMOPRXvIp0RYQ2FmT/WqC1lovAhYBmI3GmVrr+wKZscoWpBT5BMs4AiHKy/OXvbdG05xjEB7j/kvWV4nAPoHbus+Nv8bnwT3LnCN3Xb3Vw307z9kltN/vd/uR+XLIO+U+RbRdo06QsaXk/jEfGo2/LfpBbHt4pZWxXyn3HkJHzNcmDio7D7HmXEMtB7jvH/QwzLyZnIhmZZ+jAvztNfS5UqquUioS2AhsVko9GpAcBUiQUhToYGzFPqafFUKUtObTkhOhuXajzM8xqnheaQXzn3FP56sa1jNAHNkEG74sOXvnuZZ7Eup4DPr687vOKhyAUS8Zj406OXsAJfQ3evn4Et/beGydXHYe4nvDAxugp8ciNJ0vh8knKQqOLPscFeBv1VBnrfUp4M/AD0ArjJ5DNUZQEOzQ8cSd8jHiUIjqqKoXUpo9AfKz3Pe5lqpzTzpX31r9sfGYdcToZbTxa2e6/xsJeeZ5CrxMrLZ3eaVl2Y23OvzSeI7+DY1w9twB6H83PLwNxnupGb/kNbjhy5L7B/8VHtkJkbH+5aFegu/1jAPE30AQYo4b+DMwW2tdQKArrSpZkFKsLG5P3dwDxgRVQtQE1XG23C9vdT4vynOWEPKzjIZee1fPNf91ptv3G7zY3Agi3gZzrfwgMHlN6A/Dn4P6id6PRzZ2Pr95NgR7rDvQoHXJ10Q38T44rO8d0G5Eyf22YIgqZ0A6x/wNBO8Be4BIYLFSqiVwqtRXVDNBSrFTNzc27DMKClHdeVajbPkO9v7mO/3On2HpG87tw5vh3YHG3DuTY+DgurPPU/pK5/Mzx93zuOU7OGU24ro2jtod+MN7iSBQgoJh4ANwv4/rvnkWNOsJ9/4OrYe4H5u4xtmge/Mso6dPLeVvY/FbwFsuu9KUUkMDk6XACFJwUJv/MP1df1SIquYZCGbcaDz6mrvnf2a99UBzyoWFLxhB4IdJxvYf/4Om3Sovf+8nw8i/O7ezjsDPzxrPD28smX7PEu+Tr5Umuqn7/9ng8NLn7Q8KcbZPlDU3T1znktU8f5kHUY3dSwOtk8uT4xrH38biGKXUP5RSq8y/1zFKBzWGUoqjuq6xkZ1RtZkRwl9nOzrXVoE5tk4fgj2/wtfjy04LsGO+8/nBtc7nnm0LAL88X/4SeTOPnkPXfua+PfRJuPAZ+MtPxrZrI3VFJmlL6O+9SqgW8/dT+hCjt9A15vZNwEcYI41rjBOYXcOyj5aeUNQ++dkQEnHOG+HOWmmB4NBGiG3nHKjkbT6ioAoEgveGQJaXrpy+eKsvL82Kd9y3713pnDHUG88ZOiPqu2/HxEP3652N0a5ae6m4eGQHHFrve1CaBfnbRtBGa/2s1jrV/HsOqHEhs0gFU6RskPJ3OCXVQ5Zx+hD8vVnVzdeTleF7cJXd4c3eewj5CgTL/w3vXmAszOLY53J99kFa9j77rj19Cs7Aka3u5/v8Ome1U3mCAFTsV7fdBQ84Fl3xyXO6hZAI923HYLMoY2TwlR/AM8fg0V3Q7dqS54tqDG2HQ6Mq7q5ajfgbCM4opQbaN5RSFwAVmMe1aikFNvvIvX90rNrMiHPnZLrx6Nqd8VwpzIPX2sL3D/pOk7YM3hng7DmzdS58dYfx3HWBFdcRuEvMyclOpsP+NfT77U73cx78w6iCcazVbQaC0wfhhSbw737GqF277T8YDb0VmZUz9yzWGohuYvTtLg/PQFDgciu67jPoerUxsM2zu+aE1XDLHERJ/n4DdwFTlVJ7lFJ7gLeBO0t/SfUTBOyp27uqsyHOuSqsDio0BzCun2k8bvvRvVslwHH77JjmervTx8KGmUYJ4bMxLudyueHZSxiRjWDhC9TJ9fgV/59h8HZvlxKBWTW05TtnGs9RuwBHK9CjztdcRUGlzFTfrKfxGN2k9HMPfAhGPA8t+jv3hdSBiWv4vc+/jAFfPW/2L5+xbaGVH6N7LcivQKC1Xqe17gZ0BbpqrXsAwwKaswBQCj5r/1bZCUXt4ogDZzn0RWtY8o/ytTHZq3bsN+Jp17rPpQMuDboeo949p0PJOuJ8bp9qYdlbRpdRXxxtBH42OldGR4o//dPorvlMJrS/2NjX1WOCOvuo3EadjMeHt3nvbjr8WWOA1W3zIL6vsS84DBq2IScyAbqP9W+5R1GqcpXJtNanzBHGAOWcnanqKaAYZczboYIqd+EMUXVO7C0jgRkJyjtKNzUFsjOd23uXwy/PwXflmGbLHgBKW93KWz0+lBx49VZ3/9/XcW4fQcYXfyeUK03vvzgHcF36mrE92uUH2Oi34fwJ8MQBY2EWMEoGw8xlLcd85P28Y6fD2BnGnEaiUp3NUpU1rPuFUSIoKtZGP2ZdDH9rCCveq+ps1VzHdp/b+d292fYjvNHFqFd3lZcF08a614OXp0RQXGRMtfzfPzv32W/q/tSJpy2DfSv9661jb7faOsf9x0mBj2Y4X8sbevOrObjM31/6OWWUdrp6aXwtTUy8UUIIDjPGPkw+CT3N2WlCPXqg9xpnNPImXQl3Lik5XUNkQ+gwqnzvL/xyNoGgRk0xAcagMq21s55QF8MPf/U+L7oo21vd4c1KHJxUEfZ+6wf+cN+/dQ5smwsLXqjYee038CM+VsKyW/Y2vOnll/pHF8P/Dfe9hq7ruruuI21TF7jsz4G4JPfX1WvpXMc2EA6sLbmvrjkiXwUZK2zZBZez22hZlHLOXtq0q/fpGkRAlBoIlFKnlVKnvPydBsqcD1UpNUoptU0ptVMpNclHmmuUUpuVUpuUUp9X8Dr8EgQUa4wBKnVcZgtMeSmQb2ttpw8Z/d1PH3KvZvHXuwPh49IWC7EXTD1+l9h/2UY0cFYJ+Vs1pLX/PYx+ehKO7/a+oDq4BwJ7gzEYUx7buY6S/Z/LmrbZmSVH50bFlb/ffmn+9Ib79kEvgWDgg3DjV8av9ZBwuGMBhETCTVXQC0sERKkdgLXWXibn9o9SygZMBUYA6cBKpdRsrfVmlzTtMBa8uUBrfVwp1dj72SqHUlBsvxnctRQ2z4J5jxv9r5e/bSwmUZn/yWqSmbcYUw8MquSmn38muY/09DU1gqcDf0DmTvfuk67s36OvAWL2QBAUAif32V/k33tv/Apm3WNu+FkDevqg0f2z/93uc/EUuHTH/PoO5/N/JsFTZk8fX9MlzPHyXcT3Kb29oTzajoAeN8GcB5z7jmwuma7TZe69e5r3gifN+YQatIFju4znXa+F866onLyJc+psqobK0hfYaQ5AywemA5d7pLkDmKq1Pg6gtT5CACmljBIBQExzGHCP+xwix3ZX7MRaGzetmkBr+P7hkpOPbf7WaAh1teNnWDf97N6vvEuDam3Uk7+fDF/f7jvdc/Xgx8fdX+fKXvr4bSp8Yc7tbk+ye3Hp1YGu9emugcbe8+bwJngxwej2GWZOW7J5ltGDZ9YEmOnSnfHnyd7fw7Uh2FcgOGwGwcbnQaw5+Klh6/KNEval1zi47nNjnEHLC0oev/I/xiRrz54ovYvnHb9AHzPADX0COlx89nkT51wgA0FzYJ/Ldrq5z1V7oL1S6lel1G9KqYC2BCnMNgJXdVyGq9t/2dgV+tnTYvXH8HYv53quZ0NrWPI6nD589ufyJjvT+OVqbwTNPWWsLuXNZ1fBN+UYLrJ+ZsUHF+1fY8yO+c2d8Hz9ksdXfegsHdinZl7xDj6rhrJ8/KbIyoBPLoMPRzm7gWoNm751VuP4GilrX6XqzDGj++b6Gc4J1Oyljl2/uL8mbZn3cwFsmWNcs69gYXfxy85ZMEOjSv67PH8imzo/CsPLOI9do45wyevOKZftN+9hTznTtBpiLKdY1pQcderDJa/CX3f7nupZVHtnMTa80t6/HZAMxGNMcd1Fa+3Wh00pNR4YDxAXF0dKSkrF3k0Xs//AQVJSnDe+Lgf34ui9PONGFg/6gtD84/RfYUy4tbrna5yuW3ovjU6bvyEO2LL8Bw7vdv4njTqdSoNjayiyhXO8fjdyIsue2yTqdCq9Vz/PsTWzWN/tebdjTQ7+zIl6XcitE+fz9XGHFpAbHsfJeucBkJWV5fZ5heYd53ygoKCAX1NSGLT4WmzFzl+ky+Z9RX6Y8Ykkm/t8fd6uxyOy99J35UQyYgewKWlSiTS4pPXUMPN3Wqd+YsxiuH6G9wubY4zMTUmeRVBRHoPN3al7dtMaSEtLY7d57qysLE4d3EVdj1PknDrK+iUL6A9weCNFr3diyeCZNDi6mq4bnict4Wp2t76Rpgd2YZ98oFhrlv7yI+G5R+i78im386VvX0tMUTDRQEbqOrzOOF9aiWjGDb6PuUhJK44UBhgAACAASURBVCLpYBqxwMbte6h76jgJQKEtguCiHHYezmZ3/f4cy7XRLm4oTQ57X058V+txtEn9mMziaDYuca66pYo7kpgwhr355xGfOJZWe6axaOUGdJCX5RmrEc9/21YQqGsOZCDYD7je+eLNfa7SgRXmQje7lVLbMQLDStdEWuv3gfcBevfurZOTkyuUIVvKXBrHNSE52aWnS70D8O1qx+bgfW8ZU+WaesUVw/5p0Ky7UQS2eXxkZ47D4bpwBDoldadTkkvenr/KOaAoLglu+8m5tuuepdDxkpKZPFgfVkODkELcrrPgDLxg1qxd8pqxCIarTd/AiX2w9U1j26yLT0lJMc6Tn2382jZHloaEhBj7U9yrJc7f+CQ8bM5Dk2I8JA8Z4qx6sU8HcPqQ83hyMuxfDSuhUWieM9+bvi1xecnJyUa3ysadjKkCvP36L0VyArB6mmO79W5jJsqWCS1oab5vSkoKdesEg0ftT8SZA/Tf9Zpj21Zs5nV9BmyAltFFxjlWp8F283J1EYO3T3FW07iIb9YMgk9AViqNQgK3BGpycjJ0qA/f3EXSZXcbJZZVvQmOioOv76Btmzak50cxKDkZhl9szPC55HVoPwq2/2ic5NFU2uz6BVI/JrbvNST3S/Z4lxG0BOASKP43Q8o77UMVcPzbtpBAXXMgv+2VQDulVCulVChwHTDbI823mD8alVKxGFVFqQSIo/uoq25j4YmDxs0V3IIAYPyHWj8dfpxkjDvYsxSO7jKqEfb9Di8nOoft26sUCvONem7XCcNUkFEd80aS0Wg4fSyc9IyLOKsn7AOACs4YDbmHXRrx5j7i3uWwIBe+GAfzn3Y/V95pIrLNwVbbfnCfXgC8r37lba2G6dcbN+xv73Zen+v6si+1ND4TAMxqluN7nHXzrtZOM7pVfntX2X3Wvfnv5UbQ8+TyvTbMXOG90RMgc7v79gvNnG0Cm76GhX8v2RjrJQgAsPI/kPar8dzbwuvlNdZHaQiMhvx7lhs/IkIj4fyJ0OVquOa/JX8UDH4Uxs2F613OF9kQzrsSbviqZHpPNSAIiMoVsBKB1rpQKTUBmAfYgA+11puUUs8Dq7TWs81jFymlNgNFwKNa64DNEe3Wa8h1Z2iE8Z/jx8dLFuWzPOrqP77U9xvY626nNDICjKvwGGeQ2WPePLIzjLlibCHOutj8bOPx6E5jsNQ0cwCP5w0s9wSENDEGTnn2oQejS+zmWfQ9shma2ZyjV135O35imzlYa/10GPEcvNWzZF7sE6ZpbQSAEB/LVXx7l/G45Ts4/37/3t9B4bPnz69vGCOMN31Nl/KcsiDb6Dlmt+hlaDnQd3pfssvRz+HyqTDrXvd9o142Bkudf5/R6Nyki9H+4LmIuSuljEXNPYXUgUSzAbjb9c5eTLZgaDfc/3wKywhoG4HWei4w12PfMy7PNcZUFedkugoFFJXWg/DxfcYN88hmSF1k9BEvj69vhzbm/Ofrprkfcy1p5Js34J3z4f0hMOgRuND8Ne/a3XCayyhOe4CwO33ImGPG84Zil/Ki8/mse4wuf57yfKw2+tPTRiDy5ufnjJtniXOZc8Hb+6F7S+Ppi3Flp3EVUsf98/G0qZL6tactLTuNJ19dOuOSjAZV1++/85+Nief2rXDua2veoIc/B0P+CmEV7rnt7op3yk4jLK+qG4vPqeAgKCgspQ+2fQxBky7QuHP5AwHAq238T7tgivG45DXntMK+el6cSHPffn+I93S+7F/tvn3mGHxxq/e0y0qZmO/kPu/7KzI6+1R6+dJXh4Xc//ITfHiRf2nj+xrtQvbSXlGBUV0YUsfYv3mWMQFd7knndAtBQZUXBITwk6UqA4ODFPlFfg7GCbKVXCKvvUvv1gd81Bt7E1eOyopzOXfP/lXlf439l22Pm9z3nyxr4jc/NC1jUjV/J04LpGYueXziIPS40XfakX93735pC3EfsNj5cnhoq7Ewet2mlZ9XIfxkqUAQEgT5pZUIPI1PMXrfDJhgbI+dDk8dMW4A9RJg3Pdw82xj0I0vN33j7K9dHt3NG4zncnqx7ct1mg1JT5WdCIzVnMrDc3GQsoRGlZ3mbFa68tS0G9xWyvTMvjTvDcpWcn9MAjyy0znlce/bjLaly6eWcjI/RjKHRtT6hdFF9WepQBBc3kBgd9EUY54VpYwbQah5E0wcCK2HGPvvM+vG69Q35mKxazOs5FJ7zXvB/euNX9UDfTSPjHjOaCi8e5kxXa/d2OnOkZyu6jY3Fu94ZKfRA+quX2HSPo7G9oEOXrqpunr2hLGa011e6sajfUwpZf91Pupl577Q6JJz1zTqaCwccsOXzsVI7IZMggufdW6PdJkgrtNo5/NrPnU+r5/oPtlZo05w/UwY+SJMMkoleaH14c7F0KKPM4iDf6W4fnfC05nwuEePrlvnQpQ5UmDySfjTP0q+tklXSHRZ+CRafuWLmsFSbQQhQYq8wgrUMyvl/VeiqwatnCWDfLPh1N77pO0Io+fG/evc2wAuN9eYXWreVPrfY4xSnrjGuDGP9qyrV9CwDVz0N2O91ewMo5fLg5uNdVjtc897dg8cO80YwQpGCWbGjc6G4ived1ZfNOkCQx4zzmk3fLIx/35hrpF2y2zjF6y9oTM8xpgW+egOo7FdKeNm+HYvoxRw52Lnr+he4yBjq1GaOpYKAx8wqkrOHINl/zICZEwLox3iivfg0tfhj0+NuW7sJq6BV1o5p2gY+zk0cFk++/H9rFr0M45JE1yncvY2UvzCZ40eXirIqPY670qznj7KvXdPpNfhYoabvoH5zxjLJEY1MfJWVFByqUQhqilLBYLgIDhTkRKBv+w31LBoo9qoSVdje/Cj0O06qN/S++sGPgjB4ZA8CUa96D3NLXOMYAPGzbPvHUZXzfPvM25aZel6rREoWg8xbthaG4EkymOev6FPAAoWmTOyNu8FTx02ei2FRjoXA99ljl4NjTQaPvNOOa/fvnBIfG/31aN63WL8FRcZN2V7ffmIv8GwZ4z83b/OeP+gIKPkNehhI831M43gEWQzSgH7fjM+Y9cgABAWRUFoPee26zw+dV1KNxe9YHQGUEHO+vkuLstCglH/n3QVnDpgzLrpS5th7lNDV6QqUIgqZKlAEBIEJ/1tLD5biS590YOCfAcB8G+OGG9rrSrlXxAAuPL9kq/1DAJ2Qx83Ak1olPMG6LmISIQ5jXdkI+N5hMu03lGNjMFRCf28nz/I5qxes+fFfvMM8lHyaj/S+fzS12HXAmjh4/yuGpkrYI2ba1zDXb8a4x7i+xq/3PuVMZdSSB2jFCZELWapQBAcpMjPk+Up/VJWtcaoF6Hl+ZDQ3/vxQK4k1STJ+PPHgAlGUG7e0/lau8GPVn7ehKiBLBYIIC+QVUNWEhYN3a+v6lyULSjIGQSEEF5ZqtdQubuPCiGEBVgqEITaFLkF1WB0qhBCVCOWCgSRwUbVkAQDIYRwslQgiAo1ujcez6mEpf6EEKKWsFYgCDECwbFsCQRCCGFnqUBQN8wIBIdO+lgsXAghLMhSgaBldBChtiBW7PaxWLsQQliQpQJBWLCiR0I9ft2ZWdVZEUKIasNSgQDggraxbDpwillrvawXLIQQFmS5QDCmVzwA909fS3GxH/PFCyFELWe5QNCsXh3HJJmLdmRUbWaEEKIasFwgAJj/oLHe74dLd1dxToQQoupZMhC0bRzFoyM7sGRHJt+tO1D2C4QQohazZCAAGNs3AYCJ0/6g4FytUSCEENWQZQNBg8hQbh9orPh15b+XVXFuhBCi6lg2EAA8fkknWjaMYMP+k8xYubeqsyOEEFXC0oHAFqT49p4L6N6iHo99tYHJszdVdZaEEOKcs3QgAKgfGcont/YF4ONle/h8hZQMhBDWYvlAABATEULKI8kAPPHNBi6f+itn8mXNAiGENUggMCXGRjJ7wgUArNt3gv4v/kJ2XmEV50oIIQJPAoGLrvH1+OPpEQCcPFPA1e8uZ09mdhXnSgghAksCgYf6kaHsfOFi+rVqwOaDp0h+LYXVaccoKCqWuYmEELWSBAIvgm1BTB/fn9HdmgFw1TvLaffkD1z85hIOnDhTxbkTQojKFdBAoJQapZTappTaqZSa5OX4OKVUhlJqrfl3eyDzUx5KKd4a28PRiAyw7fBpzn9pAQNfXsDJMwUUSQlBCFELBCwQKKVswFTgYqAzMFYp1dlL0hla6+7m3weByk9FJcZGsvvFS3hoRHvHvvTjZ+j23E+0eWIu3607wPbDp6swh0IIcXaCA3juvsBOrXUqgFJqOnA5sDmA7xkQSinuu7Ad913Yjn3Hchj0ykLHsYnT/gDg1TFdqR8RysB2sYSH2Koqq0IIUW5K68BUbyilxgCjtNa3m9s3Af201hNc0owDXgQygO3Ag1rrfV7ONR4YDxAXF9dr+vTpFcpTVlYWUVFRFXqtq7wizZxdBfy8t4AzHj1MgxXc3jWMvk1sBNkXPqhClXXNNYlcszXINZfP0KFDV2ute3s7VtWBoCGQpbXOU0rdCVyrtR5W2nl79+6tV61aVaE8paSkkJycXKHX+lJQVMybP+/g7YU7Sxy7ZUBL/jqqI4XFmvCQIMKCz31JIRDXXN3JNVuDXHP5KKV8BoJAVg3tB1q4bMeb+xy01kddNj8AXglgfgIixBbEIyM7cFm3Zox8Y7HbsU+Wp/HJ8jQAmtQNp23jKGxBin9d34O64SFVkV0hhCghkIFgJdBOKdUKIwBcB1zvmkAp1VRrfdDcHA1sCWB+AqpDk2j2vHQphUXF/LT5MB2bRPPeolRmrDJqug6dyuXQqVwAuk7+CYCPbu3D0A6NqyzPQggBAQwEWutCpdQEYB5gAz7UWm9SSj0PrNJazwbuU0qNBgqBY8C4QOXnXAm2BXFJl6YAvDymK8+O7syG9JO8tWAHv+486pb21o9Wcnn3ZlzevRlr950koUEErWIj6dWyflVkXQhhUYEsEaC1ngvM9dj3jMvzx4HHA5mHqhYRGky/1g35NLEBAJ+tSOPpWc7prmetPcCste7LZY4f3JrEhpFc2bO59EASQgRcQAOBcAoKMnoQ3TQgkRv7t+R0XiF1Qmx8vSadx77a4Jb2/cWpgDET6o8PDKJenVDqhNqIqSPtCkKIyieBoAoopRyNxdf2SeB0biFTvt/Cg8Pb88+ft7ulHfXGEsfzjk2iOZ1byKSLOzLyvCaEBssMIUKIsyeBoBq4fVBrbh/UGoD7LmzLF6vS+W79AZbsyHRLt/WQMYLZPoitYWQot5yfyMRhbVHmmIWsvEKiwuRrFUL4T+4Y1YxSimv6tOCaPkbP28ysPG74zwpuvSCRSV+7VyEdzc7nH/O389WadA6eyCW+fh1SM7N5/vLz6BAXTV2pShJC+EECQTUXGxXGvAcHo7Vm77EcUjOymTCsLX/611KSmtdl84FTpB3NASDVXDvhGZfG6Gvah9CxRy5NYsLJLyxm2a5MVu45xkMjOmAz2y0Ki4oJtkk1kxBWJYGghlBK8ddRHR3b26aMItS8eR/LzufXXUe5z6wycjVzewEzX/ylxP6pC3fx9J868/36A2w7dJp7hrZl88FT/OOablUyAloIUXUkENRQrjfrhlFhjO7WjLaNorjkLaNxuVPTumw5eKrUc/xtjnP+v1fnbQNg8bYM7hzSms7N6jKsY1wAci6EqG4kENQinZvVZclfh5J2NIeB7WIpLCpm6ZLFtOnal3s+W0OITbFm7wm31wzt0IiF2zIc26fzCnntJ6Pn0gPD29EqNpLhneKICLWRmplN69hIR8O0EKJ2kEBQy7RoEEGLBhEAjnr/Fg0i+G7iQAByC4q49aOV3Du0LQPbxQKwbFcma9KOOwKA3Rs/7yhx/rF9E3j2ss5sOXiKPUezSdmWwWOjOtKsXp1AXpYQIoAkEFhMeIiNaeP7u+07v00s57eJ5cb+LTl4MpePf93D4PaNuPfzNSVeP+33vUz7fa/bvtSMbL6+53zyC4upE2Jj4bYjHD6Vx/X9EgJ6LUKIyiGBQDjUiwilXkQoL4/pCkD3hGGcyS/i73O3sGDrEab8OYmnvt1Y4nUb9p+k3ZM/lNj/8bLdJDWL4U/dmjK0Q2OpUhKimpJAIHxqblb3fDiuj2PfgDYNueXD38nJL+KxUR146YetHM8p8Pr67Yez2H44i6//MGYf//6+gRw5lcfQjjLjqhDViQQCUS5tGkWx9DHn2kHX9kng7v+tZnD7Rvy48RCLtmf4fO2lby0FoE9ifdo2jmba73t55aqubD98mrRjOfRr1YDbB7XmZE4BwTZFpIyQFuKckP9p4qy9c2MvAK7s2Zzj2QU0jg4jNTOb4f9Y5DX9yj3HWbnnOAB//Wq9Y//8zYeZ8r1zSYp/39CTrLxCxvSMJyhIkZNvTNQnVUxCVC4JBKLShAXbaBJjjG9o2ziKmDohnDxTwOqnhhMcFITNpgixKZbtPMqc9QcZ0yuesf/5zef57vnMaKxeu+8ECvhsxV7uHdqGxtHhHM/J59DJXF68sgt3/W81wzvF0SexAQlmjykhhP8kEIiA+W7CQDbsP0nDqDC3/UM7Nna0E3SIi2bb4dM8cUlHWjaM5M5PV5c4z+crnL2Upi7c5XZs+kpjBbh5mw4DEBlq47XBYRQUFXPgxBlaNoys1GsSojaSQCACJqFhBAkNS/+FPmvCBWgNdUKNksSciQOZv/kwdwxuTbHW3PvZmhKzsJYmO7+Iu3/OgZ+NXkzfTRjIrLX7GT+kNb+lHmPLwVNc3zfBMdZCCCGBQFQxzxXYkprHkNQ8xrH96W39HM+/XJ3O5yvSuDipKWnHshncrhFv/rKDTQdOERUWzB2DWpdYz+Gyt40G6g+W7nbseydlF9PH96dOiI3042e4pEsT8ouKOZNfRL2I0EBcphDVmgQCUWOM6RXPmF7xbvu6J9Tj4Znr+Mc13WkUHcadQ1pzz/s/szIDTucW+jzXde872yaGtG/k6O00YWhbkprHEF+/Du3jotly8BSdmtZlV0YWnZrWBYzR2XmFxbJinKg1JBCIGq1xdLhbqSE8xMbN54XxYXIymVl5TJmzmV+2HOF0nhEUEhpEsPdYjts5XLu8vr1wp+N5kIJi7Ux3da94XryyCx2f/tGxfWGnxoSH2BjSvpHP3kz5hcUUay3rT4tqSwKBqLVio8J447oepB/PYeDLC5kwtC2PjOxAXmERF7+5hNSM7FJf7xoEAL5Ync4Xq9O9brdpFMltA1vTq2V9Zqzcx/ltGjK8cxxaa7o99xNnCoqYMb4/XePrOdpDhKguJBCIWi++fgQpjyQ7GojDgm38eP9gTucW0DAqjI37T7Jm73F6tKjP377fzO+7jzle2zAylPuHt3Nb7MebXRnZPPGNcwW5D3/dzZhe8azdd4IzBUUAXGtWR/3lglZ8sXofjaPDuKJHc5btOsqDI9oDMGvtfiLDgnloRHvyC4uJDvdd/TR14U6iw4O5eUBihT4XIewkEAhLSIx170YaGhzk6Nbq2kA9884BDHplAfuOneHnhwbTvF4EdUJt3NCvJX+bs5mPl+3hriFtGJXUhA+WpDJn/UGf7/mlS+nB1Ye/Gg3Xp3OdU34v27XcLc17i1IBaB0bScbpPMYPbs1tg1qx43AWl0/9lWcv6+xYQ6JhZBjrDxSSbL62oKgYrUGjyckron6kNICL0kkgEMLDV3edz44jWbRtHO3YZwtSTB59HqOSmtAzoT6hwUG8fX1PHr/kDJGhNqb9vo/LujXl8xV7uXNwG/63Is1xo759YCsWbc9gx5GscufFvvzo6/O38/p8Z4+o575zLipknyX2xlE5fLf+AK/8uM3tHOMHt+b2Qa1oHB3OnsxssvIKaR8XzYKtRxjROY68wiIiQuVWYGXy7QvhoXHdcBrXDfd6rH/rhm7b9on57k5uA+BYTvTeoW25d2hbR7qnzEetNXPWH2Siy7KiH43rw5D2jdh9NJuv16ST0CCC/MJini6jOsrToFcWet3//uJU4++mXoz3MmAP4Iu7BhAdHsz8TYex2RQncgq4qmc8/1mSyktXduHI6TxZc6IWk0AgxDmklCK5QyP6tmrAlD8n0a5xlKO3UZtGUTw60rku9ehuzfl9zzG++SOduRsO0S0+hgFtYpn2+17G9Irn/5buZt4Dgxn5xmK/3ttXEAC4+t3lJXpUvb/YqJ5qFB3GOym7eGB4O/IKi7myR3MSYyM5cjqPxtFhhNiC2H/iDPM3HWLcBa1KzUNBUTHBQUrmi6pmJBAIcY5Fh4cw884BZaaLiQhhROc4hndyX8th0sUd0Vrz8EXtiQgNZu59g/jwh9/4cocxHfjiR4cy+NWFXNu7BTNW7fM7X57dau3eSTGm9bCvWGffthvROY75m40pPl6dt41JF3ekbp0Q7p++loFtY7l/eDt+3ZnptuLdHYNa8eSlnd3OU1ysKdKaDftPEl+/Do2jvZfKROWTQCBENeft17NSylGv37lZXf7UJpSbLurL7sxsEhpG8PNDQ2jZMIJr+rTgqneWOV5384CW/Hd5GgBvXted+6evdTvvyPPiHPM2+cseBMCY4sO1SmvpzkyW7iw5Rch/luzmqzX7OZadz5d3DWDrodMlFj36bsJAfth4kMbRYYxMasKT32xk4rC2dGxSl62HTlFYrNl3LIeosGDqR4ayas8x6keG0qZRFGBUw3n77HZlZBFqC5JpRlxIIBCilujWoh7dWtQDjNlfAXom1OOVMV3p3bI+/12exv0XtuOOQa2xBSma1atTIhC8e2Mv3l6wk1aNIhnYNpZlu46SdjSHl3/cWun5PZadD8CYd5d7PW6fHgRgstk4vmDrEfdEP5VsF+kWH8OVPePZlZHFqj3HeerSTizYegRbkKJHQj3u+p/RuP7H0yPYdzyHv8/dwqVdmvL0rE3cPKAl9SNCaRITTsbpPO4d2hZbkKKgqJhNB07R3fx8vcktKOJ0biGNosN8pqmuJBAIUYsppbimdwsAJo8+D8Brd9I3r+tO61ijvWLihe0c+y/p0pTComK3QPDdhIG8vySVF65IIjosmMe+Ws/MVe5dZSNCbaQ8mkyDiFAe/3oD8zYd4lRuIXcOaU2nJnUpLNY88sW6QFwy69JPsi79pGP7+g9WeE3X42/zHc9/SzXGjthLS3Yr9xxzm/TwkYvaM6ZXC/6dspObByRyLDufHgn1+GTZHsdaGq+O6cpV5hoadgVFxSgg2BZ01tcXCBIIhLCwF6/sQn5hMZd3b+4zTbAtiMmXdaZlw0jSj+fQJT6Gf43t4Tj+yphuTBzWjgdnrOWhi9rTvUU9t+6or17djVfGdGXepsOM6ByHzbxBXnReHN/+sZ8FW4+Qsi2DTk3rkpVXQNO6dfh9zzHuu7AdGadzuWtIG3LyjdHgnv59Q0/AuXaFq7i6YRw+lVfhzwYoMfPtaz9t56fNh1mffrJE0LB79Mv1HDyZS2GxpllMOEez8x1diW/ol8Bn5rTqY/u24K4hbWgUHeb4vHILihwlEIWisLj0QYWVRWmty05V0ZMrNQp4E7ABH2itX/KR7irgS6CP1npVaefs3bu3XrWq1CQ+paSkkJycXKHX1lRyzdZQ0685MyuPWHOAX05+If/7LY1bzk8kLNh9Oo57P1tDUvMYrurZnKXLlnHlKGPZ1CU7Mrjz09XkFRbzt8uTuKxbU6LDQ3h30S4iw4J5+tuNXN8vgZ2Hs/h9j/HrP0jBpV2b8d26A47zR4UFk5VXcrJC+yJLgdK5aV1uG9iKh79YR+PoMM7kFznmx7JPtPjl6nTu6RbGX8cOr9B7KKVWa617ezsWsBKBUsoGTAVGAOnASqXUbK31Zo900cD9gPfymxCi1ot1WbwoIjSY8YPbeE031SwBADQId1azDGrXiM3PjyqR/q4hxnku7dKU+hEh5BUWc+enq3l0ZAfHaHLXQLD66eEczy7gpR+2cHdyW/Ydy2HJjgxuGpDodenV927q5XUxJVc9E+qxZu+JUtNsPniKh82qsiOn3UsxbiPUA9TrNpBVQ32BnVrrVACl1HTgcmCzR7q/AS8DjwYwL0IIC2tgtouEh9j45C993Y4tf3wYL/+wlbiYcMdyq29cZ1R9dWgS7Zg88L4L23F1r3hmrtrHtN/3kdS8LiPPa8LWv40iSCk+/HU3I89rwjd/7OetX3ZwRY/mvH51N2avO8CavWt9ljbKIy4iMJEgkIGgOeDaiTkd6OeaQCnVE2ihtf5eKSWBQAhxzjWNqeO48fuilOIhc2LAhy/qwMMXdXAcs08vbi99XN83geiwYG45P5GgIEXjukZp54Z+Cdw2sBVzNxx09IJa9+xF3PjBCga1i2X2ugOkHz/DN/ecz9OzNrJx/6kS+WgWFZjG5oC1ESilxgCjtNa3m9s3Af201hPM7SBgATBOa71HKZUCPOKtjUApNR4YDxAXF9dr+vTpFcpTVlYWUVFRFXptTSXXbA1yzdWX1prVh4vo2shGqE1xplBz9885dI218VBv56C5nAJNsYaoUOev/hnb8vlht9E2cVe3MJKicyt8zUOHDvXZRoDWOiB/wABgnsv248DjLtsxQCawx/zLBQ4AvUs7b69evXRFLVy4sMKvrankmq1Brrn2mvD5Gt3ysTn6mzXpZ3XNwCrt474ayE6tK4F2SqlWSqlQ4DpgtksAOqm1jtVaJ2qtE4HfgNG6jF5DQghhJVFhRg1+IKdnClgg0FoXAhOAecAWYKbWepNS6nml1OhAva8QQtQmk0Z15M7BrbmkS9OAvUdAB5RprecCcz32PeMjbXIg8yKEEDVRTEQIj1/SKaDvUT3HOwshhDhnJBAIIYTFSSAQQgiLk0AghBAWJ4FACCEsTgKBEEJYnAQCIYSwOAkEQghhcQFdmCYQlFIZgPelgcoWizG/kZXINVuDXLM1nM01t9RaN/J2oMYFgrOh6RuNHQAABc1JREFUlFqlfc2+V0vJNVuDXLM1BOqapWpICCEsTgKBEEJYnNUCwftVnYEqINdsDXLN1hCQa7ZUG4EQQoiSrFYiEEII4cEygUApNUoptU0ptVMpNamq81NZlFItlFILlVKblVKblFL3m/sbKKXmK6V2mI/1zf1KKfWW+TmsV0r1rNorqBillE0p9YdSao653UoptcK8rhnmqngopcLM7Z3m8cSqzHdFKaXqKaW+VEptVUptUUoNsMB3/KD5b3qjUmqaUiq8Nn7PSqkPlVJHlFIbXfaV+7tVSt1ipt+hlLqlPHmwRCBQStmAqcDFQGdgrFKqc9XmqtIUAg9rrTsD/YF7zWubBPyitW4H/GJug/EZtDP/xgPvnPssV4r7MVa+s3sZ+KfWui1wHLjN3H8bcNzc/08zXU30JvCj1roj0A3j2mvtd6yUag7ch7GGeRJgw1jutjZ+zx8Dozz2leu7VUo1AJ4F+gF9gWftwcMvvhYzrk1/wABgnsv248DjVZ2vAF3rLGAEsA1oau5rCmwzn78HjHVJ70hXU/6AePM/xzBgDqAwBtkEe37fGEulDjCfB5vpVFVfQzmvNwbY7ZnvWv4dNwf2AQ3M720OMLK2fs9AIrCxot8tMBZ4z2W/W7qy/ixRIsD5j8ou3dxXq5jF4R7ACiBOa33QPHQIiDOf14bP4g3gr0Cxud0QOKGNdbLB/Zoc12seP2mmr0laARnAR2Z12AdKqUhq8Xestd4PvAbsBQ5ifG+rqd3fs6vyfrdn9Z1bJRDUekqpKOAr4AGt9SnXY9r4iVAruocppf4EHNFar67qvJxDwUBP4B2tdQ8gG2dVAVC7vmMAs1rjcowg2AyIpGT1iSWci+/WKoFgP9DCZTve3FcrKKVCMILAZ1rrr83dh5VSTc3jTYEj5v6a/llcAIxWSu0BpmNUD70J1FNKBZtpXK/Jcb3m8Rjg6LnMcCVIB9K11ivM7S8xAkNt/Y4BhgO7tdYZWusC4GuM7742f8+uyvvdntV3bpVAsBJoZ/Y4CMVodJpdxXmqFEopBfwfsEVr/Q+XQ7MBe8+BWzDaDuz7bzZ7H/QHTroUQas9rfXjWut4rXUixve4QGt9A7AQGGMm87xe++cwxkxfo345a60PAfuUUh3MXRcCm6ml37FpL9BfKRVh/hu3X3Ot/Z49lPe7nQdcpJSqb5amLjL3+aeqG0nOYWPMJcB2YBfwZFXnpxKvayBGsXE9sNb8uwSjfvQXYAfwM9DATK8welDtAjZg9Mqo8uuo4LUnA3PM562B34GdwBdAmLk/3NzeaR5vXdX5ruC1dgdWmd/zt0D92v4dA88BW4GNwKdAWG38noFpGO0gBRilv9sq8t0CfzGvfydwa3nyICOLhRDC4qxSNSSEEMIHCQRCCGFxEgiEEMLiJBAIIYTFSSAQQgiLk0AghAelVJFSaq3LX6XNVquUSnSdZVKI6iC47CRCWM4ZrXX3qs6EEOeKlAiE8JNSao9S6hWl1Aal1O9Kqbbm/kSl1AJzfvhflFIJ5v44pdQ3Sql15t/55qlsSqn/mHPt/6SUqlNlFyUEEgiE8KaOR9XQtS7HTmqtuwBvY8yCCvAv4BOtdVfgM+Atc/9bwCKtdTeMuYE2mfvbAVO11ucBJ4CrAnw9QpRKRhYL4UEplaW1jvKyfw8wTGudak70d0hr3VAplYkxd3yBuf+g1jpWKZUBxGut81zOkQjM18aCIyilHgNCtNZTAn9lQngnJQIhykf7eF4eeS7Pi5C2OlHFJBAIUT7XujwuN58vw5gJFeAGYIn5/BfgbnCssRxzrjIpRHnILxEhSqqjlFrrsv2j1trehbS+Umo9xq/6sea+iRirhz2KsZLYreb++4H3lVK3YfzyvxtjlkkhqhVpIxDCT2YbQW+tdWZV50WIyiRVQ0IIYXFSIhBCCIuTEoEQQlicBAIhhLA4CQRCCGFxEgiEEMLiJBAIIYTFSSAQQgiL+3+XAIVyaBxxlAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B9YmFARDAFv"
      },
      "source": [
        "untuk wide model hasil val_loss dan loss sudah mulai stabil dari epoch ke 600 menggunakan optimizer adamax dengan val_loss 0.56 dan loss 0.45"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7P8oPfKwh7M"
      },
      "source": [
        "###Deeper Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaHiJ5GnwlAl"
      },
      "source": [
        "def deep_mode3(optim): \n",
        "  deeper_model3 = Sequential()\n",
        "  deeper_model3.add(Dense(9, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
        "  deeper_model3.add(Dense(5, kernel_initializer='normal', activation='relu'))\n",
        "  deeper_model3.add(Dense(1, kernel_initializer='normal'))\n",
        "  opt=optim\n",
        "  deeper_model3.compile(loss='mean_squared_error', optimizer=opt)\n",
        "  historyd3 = deeper_model3.fit(x=feature_train3, y=label_train3, validation_data=(feature_test3, label_test3), epochs=1000, batch_size=8)\n",
        "  plot_loss(historyd3)"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDObTn6FxAeP"
      },
      "source": [
        "####SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1ogvvRwxD-Y",
        "outputId": "1e5dd11b-1778-4113-f6b6-7084ae7e48b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "deep_mode3(opt_sgd)"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 1.0145 - val_loss: 0.9925\n",
            "Epoch 2/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8982 - val_loss: 0.6875\n",
            "Epoch 3/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6169 - val_loss: 0.6458\n",
            "Epoch 4/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5899 - val_loss: 0.6322\n",
            "Epoch 5/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5809 - val_loss: 0.6256\n",
            "Epoch 6/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5647 - val_loss: 0.6411\n",
            "Epoch 7/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5715 - val_loss: 0.6554\n",
            "Epoch 8/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5816 - val_loss: 0.6203\n",
            "Epoch 9/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5964 - val_loss: 0.6326\n",
            "Epoch 10/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5509 - val_loss: 0.6007\n",
            "Epoch 11/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5684 - val_loss: 0.6216\n",
            "Epoch 12/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5556 - val_loss: 0.6486\n",
            "Epoch 13/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5494 - val_loss: 0.6147\n",
            "Epoch 14/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5525 - val_loss: 0.6209\n",
            "Epoch 15/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5424 - val_loss: 0.6473\n",
            "Epoch 16/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5676 - val_loss: 0.6314\n",
            "Epoch 17/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 0.6040\n",
            "Epoch 18/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5591 - val_loss: 0.5934\n",
            "Epoch 19/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5350 - val_loss: 0.6123\n",
            "Epoch 20/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5383 - val_loss: 0.6183\n",
            "Epoch 21/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 0.5920\n",
            "Epoch 22/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 0.6194\n",
            "Epoch 23/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5437 - val_loss: 0.5980\n",
            "Epoch 24/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5389 - val_loss: 0.6387\n",
            "Epoch 25/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 0.6214\n",
            "Epoch 26/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5465 - val_loss: 0.6133\n",
            "Epoch 27/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5275 - val_loss: 0.6603\n",
            "Epoch 28/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5402 - val_loss: 0.6085\n",
            "Epoch 29/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5225 - val_loss: 0.6267\n",
            "Epoch 30/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5196 - val_loss: 0.5948\n",
            "Epoch 31/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5368 - val_loss: 0.6234\n",
            "Epoch 32/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 0.6065\n",
            "Epoch 33/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5313 - val_loss: 0.5954\n",
            "Epoch 34/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5310 - val_loss: 0.6574\n",
            "Epoch 35/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5347 - val_loss: 0.6471\n",
            "Epoch 36/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5360 - val_loss: 0.6387\n",
            "Epoch 37/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 0.6051\n",
            "Epoch 38/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5282 - val_loss: 0.6114\n",
            "Epoch 39/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5354 - val_loss: 0.6557\n",
            "Epoch 40/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5336 - val_loss: 0.5907\n",
            "Epoch 41/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 0.6153\n",
            "Epoch 42/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5209 - val_loss: 0.6044\n",
            "Epoch 43/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 0.6209\n",
            "Epoch 44/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 0.6004\n",
            "Epoch 45/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5312 - val_loss: 0.5944\n",
            "Epoch 46/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5154 - val_loss: 0.7089\n",
            "Epoch 47/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 0.5963\n",
            "Epoch 48/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5114 - val_loss: 0.6448\n",
            "Epoch 49/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5363 - val_loss: 0.6090\n",
            "Epoch 50/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5284 - val_loss: 0.5962\n",
            "Epoch 51/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5208 - val_loss: 0.6364\n",
            "Epoch 52/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5795\n",
            "Epoch 53/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5050 - val_loss: 0.5998\n",
            "Epoch 54/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5202 - val_loss: 0.6090\n",
            "Epoch 55/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5213 - val_loss: 0.5954\n",
            "Epoch 56/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5127 - val_loss: 0.6009\n",
            "Epoch 57/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5225 - val_loss: 0.6069\n",
            "Epoch 58/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5307 - val_loss: 0.6107\n",
            "Epoch 59/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5222 - val_loss: 0.5925\n",
            "Epoch 60/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5061 - val_loss: 0.6016\n",
            "Epoch 61/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5299 - val_loss: 0.5854\n",
            "Epoch 62/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5155 - val_loss: 0.6409\n",
            "Epoch 63/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5080 - val_loss: 0.5989\n",
            "Epoch 64/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5144 - val_loss: 0.6360\n",
            "Epoch 65/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5138 - val_loss: 0.5999\n",
            "Epoch 66/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5219 - val_loss: 0.6290\n",
            "Epoch 67/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5035 - val_loss: 0.6022\n",
            "Epoch 68/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5158 - val_loss: 0.5942\n",
            "Epoch 69/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5044 - val_loss: 0.6093\n",
            "Epoch 70/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5165 - val_loss: 0.6329\n",
            "Epoch 71/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5112 - val_loss: 0.5960\n",
            "Epoch 72/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5024 - val_loss: 0.5883\n",
            "Epoch 73/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5111 - val_loss: 0.6038\n",
            "Epoch 74/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.6349\n",
            "Epoch 75/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5151 - val_loss: 0.5999\n",
            "Epoch 76/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5088 - val_loss: 0.6591\n",
            "Epoch 77/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4946 - val_loss: 0.6229\n",
            "Epoch 78/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4996 - val_loss: 0.6114\n",
            "Epoch 79/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5299 - val_loss: 0.5931\n",
            "Epoch 80/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5056 - val_loss: 0.6219\n",
            "Epoch 81/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4931 - val_loss: 0.5988\n",
            "Epoch 82/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 0.6014\n",
            "Epoch 83/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 0.6248\n",
            "Epoch 84/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4939 - val_loss: 0.5845\n",
            "Epoch 85/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4916 - val_loss: 0.6156\n",
            "Epoch 86/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4952 - val_loss: 0.6246\n",
            "Epoch 87/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4981 - val_loss: 0.6123\n",
            "Epoch 88/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4959 - val_loss: 0.6006\n",
            "Epoch 89/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4900 - val_loss: 0.5784\n",
            "Epoch 90/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4944 - val_loss: 0.6142\n",
            "Epoch 91/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4956 - val_loss: 0.5854\n",
            "Epoch 92/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4902 - val_loss: 0.5972\n",
            "Epoch 93/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4882 - val_loss: 0.5856\n",
            "Epoch 94/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5040 - val_loss: 0.6051\n",
            "Epoch 95/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5283 - val_loss: 0.6705\n",
            "Epoch 96/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4953 - val_loss: 0.6041\n",
            "Epoch 97/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5007 - val_loss: 0.6287\n",
            "Epoch 98/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4967 - val_loss: 0.6047\n",
            "Epoch 99/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4834 - val_loss: 0.6166\n",
            "Epoch 100/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4953 - val_loss: 0.6202\n",
            "Epoch 101/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5060 - val_loss: 0.6516\n",
            "Epoch 102/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5154 - val_loss: 0.6062\n",
            "Epoch 103/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5165 - val_loss: 0.5966\n",
            "Epoch 104/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4857 - val_loss: 0.5776\n",
            "Epoch 105/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4920 - val_loss: 0.6086\n",
            "Epoch 106/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.5822\n",
            "Epoch 107/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4836 - val_loss: 0.5765\n",
            "Epoch 108/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5039 - val_loss: 0.5803\n",
            "Epoch 109/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4793 - val_loss: 0.5956\n",
            "Epoch 110/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4932 - val_loss: 0.6729\n",
            "Epoch 111/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4891 - val_loss: 0.6020\n",
            "Epoch 112/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4937 - val_loss: 0.5822\n",
            "Epoch 113/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4969 - val_loss: 0.5648\n",
            "Epoch 114/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.6115\n",
            "Epoch 115/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4875 - val_loss: 0.5816\n",
            "Epoch 116/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.5821\n",
            "Epoch 117/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4880 - val_loss: 0.6383\n",
            "Epoch 118/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5093 - val_loss: 0.5706\n",
            "Epoch 119/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4883 - val_loss: 0.5785\n",
            "Epoch 120/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4954 - val_loss: 0.5933\n",
            "Epoch 121/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4838 - val_loss: 0.5735\n",
            "Epoch 122/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4898 - val_loss: 0.6889\n",
            "Epoch 123/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4877 - val_loss: 0.5853\n",
            "Epoch 124/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4999 - val_loss: 0.5983\n",
            "Epoch 125/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4944 - val_loss: 0.5886\n",
            "Epoch 126/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4835 - val_loss: 0.6386\n",
            "Epoch 127/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4921 - val_loss: 0.5962\n",
            "Epoch 128/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5893\n",
            "Epoch 129/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4801 - val_loss: 0.6242\n",
            "Epoch 130/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4885 - val_loss: 0.6131\n",
            "Epoch 131/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4964 - val_loss: 0.6013\n",
            "Epoch 132/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.5717\n",
            "Epoch 133/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.5927\n",
            "Epoch 134/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4809 - val_loss: 0.5811\n",
            "Epoch 135/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4689 - val_loss: 0.6074\n",
            "Epoch 136/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4887 - val_loss: 0.5851\n",
            "Epoch 137/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 0.6441\n",
            "Epoch 138/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4911 - val_loss: 0.5977\n",
            "Epoch 139/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4762 - val_loss: 0.6332\n",
            "Epoch 140/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.6289\n",
            "Epoch 141/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4875 - val_loss: 0.5919\n",
            "Epoch 142/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4829 - val_loss: 0.5847\n",
            "Epoch 143/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4709 - val_loss: 0.5850\n",
            "Epoch 144/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4932 - val_loss: 0.6026\n",
            "Epoch 145/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.5892\n",
            "Epoch 146/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5082 - val_loss: 0.5858\n",
            "Epoch 147/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4780 - val_loss: 0.5810\n",
            "Epoch 148/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4886 - val_loss: 0.5863\n",
            "Epoch 149/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4742 - val_loss: 0.5844\n",
            "Epoch 150/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.6243\n",
            "Epoch 151/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4762 - val_loss: 0.5997\n",
            "Epoch 152/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4734 - val_loss: 0.5892\n",
            "Epoch 153/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4680 - val_loss: 0.5864\n",
            "Epoch 154/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4899 - val_loss: 0.6011\n",
            "Epoch 155/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4969 - val_loss: 0.5782\n",
            "Epoch 156/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4685 - val_loss: 0.6114\n",
            "Epoch 157/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4717 - val_loss: 0.5930\n",
            "Epoch 158/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.6004\n",
            "Epoch 159/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4775 - val_loss: 0.5909\n",
            "Epoch 160/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4696 - val_loss: 0.6099\n",
            "Epoch 161/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.5907\n",
            "Epoch 162/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4636 - val_loss: 0.5693\n",
            "Epoch 163/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4845 - val_loss: 0.5955\n",
            "Epoch 164/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5029 - val_loss: 0.5936\n",
            "Epoch 165/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4781 - val_loss: 0.6135\n",
            "Epoch 166/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4671 - val_loss: 0.5854\n",
            "Epoch 167/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4701 - val_loss: 0.5901\n",
            "Epoch 168/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.7028\n",
            "Epoch 169/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.6141\n",
            "Epoch 170/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4708 - val_loss: 0.5731\n",
            "Epoch 171/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4799 - val_loss: 0.6065\n",
            "Epoch 172/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.6389\n",
            "Epoch 173/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4715 - val_loss: 0.6567\n",
            "Epoch 174/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4769 - val_loss: 0.5924\n",
            "Epoch 175/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4651 - val_loss: 0.5827\n",
            "Epoch 176/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5669\n",
            "Epoch 177/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4685 - val_loss: 0.5899\n",
            "Epoch 178/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 0.5803\n",
            "Epoch 179/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4864 - val_loss: 0.6326\n",
            "Epoch 180/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 0.5784\n",
            "Epoch 181/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4604 - val_loss: 0.5898\n",
            "Epoch 182/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.6073\n",
            "Epoch 183/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4484 - val_loss: 0.5968\n",
            "Epoch 184/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4732 - val_loss: 0.5995\n",
            "Epoch 185/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.5853\n",
            "Epoch 186/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.6122\n",
            "Epoch 187/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4927 - val_loss: 0.6329\n",
            "Epoch 188/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4736 - val_loss: 0.5995\n",
            "Epoch 189/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.5876\n",
            "Epoch 190/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.5800\n",
            "Epoch 191/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.5828\n",
            "Epoch 192/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4725 - val_loss: 0.5863\n",
            "Epoch 193/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.6429\n",
            "Epoch 194/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4602 - val_loss: 0.5970\n",
            "Epoch 195/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.5750\n",
            "Epoch 196/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4529 - val_loss: 0.5930\n",
            "Epoch 197/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4485 - val_loss: 0.6143\n",
            "Epoch 198/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4828 - val_loss: 0.6029\n",
            "Epoch 199/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4619 - val_loss: 0.6151\n",
            "Epoch 200/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 0.5994\n",
            "Epoch 201/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4680 - val_loss: 0.6045\n",
            "Epoch 202/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.5778\n",
            "Epoch 203/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.5945\n",
            "Epoch 204/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4590 - val_loss: 0.6126\n",
            "Epoch 205/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.6260\n",
            "Epoch 206/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.5915\n",
            "Epoch 207/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4778 - val_loss: 0.5957\n",
            "Epoch 208/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.5937\n",
            "Epoch 209/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.5836\n",
            "Epoch 210/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4473 - val_loss: 0.5859\n",
            "Epoch 211/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4719 - val_loss: 0.5956\n",
            "Epoch 212/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4547 - val_loss: 0.6351\n",
            "Epoch 213/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4836 - val_loss: 0.5833\n",
            "Epoch 214/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.6028\n",
            "Epoch 215/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.6041\n",
            "Epoch 216/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4754 - val_loss: 0.5844\n",
            "Epoch 217/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.6001\n",
            "Epoch 218/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4720 - val_loss: 0.5925\n",
            "Epoch 219/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4653 - val_loss: 0.5808\n",
            "Epoch 220/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.5887\n",
            "Epoch 221/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.6230\n",
            "Epoch 222/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4802 - val_loss: 0.6406\n",
            "Epoch 223/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4914 - val_loss: 0.5885\n",
            "Epoch 224/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4719 - val_loss: 0.5994\n",
            "Epoch 225/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4754 - val_loss: 0.5982\n",
            "Epoch 226/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4509 - val_loss: 0.6058\n",
            "Epoch 227/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4598 - val_loss: 0.5999\n",
            "Epoch 228/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4646 - val_loss: 0.6048\n",
            "Epoch 229/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4705 - val_loss: 0.6149\n",
            "Epoch 230/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4674 - val_loss: 0.5934\n",
            "Epoch 231/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4458 - val_loss: 0.5888\n",
            "Epoch 232/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4804 - val_loss: 0.5965\n",
            "Epoch 233/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4513 - val_loss: 0.5831\n",
            "Epoch 234/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4647 - val_loss: 0.5908\n",
            "Epoch 235/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.5999\n",
            "Epoch 236/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4525 - val_loss: 0.6008\n",
            "Epoch 237/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4771 - val_loss: 0.6331\n",
            "Epoch 238/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4479 - val_loss: 0.6095\n",
            "Epoch 239/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.6060\n",
            "Epoch 240/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4488 - val_loss: 0.6059\n",
            "Epoch 241/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4553 - val_loss: 0.6208\n",
            "Epoch 242/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.6680\n",
            "Epoch 243/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4905 - val_loss: 0.6065\n",
            "Epoch 244/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4571 - val_loss: 0.6487\n",
            "Epoch 245/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.6110\n",
            "Epoch 246/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4507 - val_loss: 0.5934\n",
            "Epoch 247/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.5977\n",
            "Epoch 248/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4486 - val_loss: 0.6039\n",
            "Epoch 249/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.5940\n",
            "Epoch 250/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4470 - val_loss: 0.5924\n",
            "Epoch 251/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4511 - val_loss: 0.6164\n",
            "Epoch 252/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4471 - val_loss: 0.6234\n",
            "Epoch 253/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.6015\n",
            "Epoch 254/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4509 - val_loss: 0.6207\n",
            "Epoch 255/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4696 - val_loss: 0.6270\n",
            "Epoch 256/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.5841\n",
            "Epoch 257/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4652 - val_loss: 0.6262\n",
            "Epoch 258/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4477 - val_loss: 0.6048\n",
            "Epoch 259/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.6314\n",
            "Epoch 260/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.6067\n",
            "Epoch 261/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.6017\n",
            "Epoch 262/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.6090\n",
            "Epoch 263/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4709 - val_loss: 0.6216\n",
            "Epoch 264/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4454 - val_loss: 0.6220\n",
            "Epoch 265/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4815 - val_loss: 0.5996\n",
            "Epoch 266/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.6246\n",
            "Epoch 267/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4725 - val_loss: 0.6145\n",
            "Epoch 268/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.6007\n",
            "Epoch 269/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4521 - val_loss: 0.6266\n",
            "Epoch 270/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4503 - val_loss: 0.6130\n",
            "Epoch 271/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4695 - val_loss: 0.6801\n",
            "Epoch 272/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4522 - val_loss: 0.6633\n",
            "Epoch 273/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.6180\n",
            "Epoch 274/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 0.6101\n",
            "Epoch 275/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.6239\n",
            "Epoch 276/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4559 - val_loss: 0.6026\n",
            "Epoch 277/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4473 - val_loss: 0.6040\n",
            "Epoch 278/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 0.7042\n",
            "Epoch 279/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 0.6105\n",
            "Epoch 280/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4507 - val_loss: 0.6174\n",
            "Epoch 281/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 0.6166\n",
            "Epoch 282/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4511 - val_loss: 0.6154\n",
            "Epoch 283/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4502 - val_loss: 0.6323\n",
            "Epoch 284/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.6097\n",
            "Epoch 285/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4579 - val_loss: 0.6073\n",
            "Epoch 286/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.6001\n",
            "Epoch 287/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.6567\n",
            "Epoch 288/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4779 - val_loss: 0.6522\n",
            "Epoch 289/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.6124\n",
            "Epoch 290/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4647 - val_loss: 0.6189\n",
            "Epoch 291/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.7978\n",
            "Epoch 292/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.6063\n",
            "Epoch 293/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4619 - val_loss: 0.6283\n",
            "Epoch 294/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4633 - val_loss: 0.6528\n",
            "Epoch 295/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4609 - val_loss: 0.6181\n",
            "Epoch 296/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4514 - val_loss: 0.6007\n",
            "Epoch 297/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4502 - val_loss: 0.6799\n",
            "Epoch 298/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4412 - val_loss: 0.6278\n",
            "Epoch 299/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4440 - val_loss: 0.6165\n",
            "Epoch 300/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4423 - val_loss: 0.6351\n",
            "Epoch 301/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.6064\n",
            "Epoch 302/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4711 - val_loss: 0.6257\n",
            "Epoch 303/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.7042\n",
            "Epoch 304/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4491 - val_loss: 0.6226\n",
            "Epoch 305/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4367 - val_loss: 0.7281\n",
            "Epoch 306/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4518 - val_loss: 0.6213\n",
            "Epoch 307/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4501 - val_loss: 0.6258\n",
            "Epoch 308/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4434 - val_loss: 0.6388\n",
            "Epoch 309/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.6111\n",
            "Epoch 310/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.6281\n",
            "Epoch 311/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.6089\n",
            "Epoch 312/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4484 - val_loss: 0.6790\n",
            "Epoch 313/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4647 - val_loss: 0.6246\n",
            "Epoch 314/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4807 - val_loss: 0.6251\n",
            "Epoch 315/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4654 - val_loss: 0.5902\n",
            "Epoch 316/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4395 - val_loss: 0.6049\n",
            "Epoch 317/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.6818\n",
            "Epoch 318/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4826 - val_loss: 0.6082\n",
            "Epoch 319/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4715 - val_loss: 0.6332\n",
            "Epoch 320/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.6499\n",
            "Epoch 321/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4511 - val_loss: 0.6150\n",
            "Epoch 322/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.6304\n",
            "Epoch 323/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4461 - val_loss: 0.6246\n",
            "Epoch 324/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 0.6346\n",
            "Epoch 325/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4402 - val_loss: 0.6138\n",
            "Epoch 326/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4561 - val_loss: 0.6242\n",
            "Epoch 327/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4695 - val_loss: 0.6538\n",
            "Epoch 328/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4454 - val_loss: 0.6385\n",
            "Epoch 329/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.6534\n",
            "Epoch 330/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.6327\n",
            "Epoch 331/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4427 - val_loss: 0.7018\n",
            "Epoch 332/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4602 - val_loss: 0.6108\n",
            "Epoch 333/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4330 - val_loss: 0.6136\n",
            "Epoch 334/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4630 - val_loss: 0.5926\n",
            "Epoch 335/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.6217\n",
            "Epoch 336/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 0.6250\n",
            "Epoch 337/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.6404\n",
            "Epoch 338/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4492 - val_loss: 0.6236\n",
            "Epoch 339/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4684 - val_loss: 0.6149\n",
            "Epoch 340/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5210 - val_loss: 0.6544\n",
            "Epoch 341/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4892 - val_loss: 0.6138\n",
            "Epoch 342/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4637 - val_loss: 0.6314\n",
            "Epoch 343/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4505 - val_loss: 0.6220\n",
            "Epoch 344/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4501 - val_loss: 0.6121\n",
            "Epoch 345/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4450 - val_loss: 0.6234\n",
            "Epoch 346/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4435 - val_loss: 0.6213\n",
            "Epoch 347/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 0.6779\n",
            "Epoch 348/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4482 - val_loss: 0.6000\n",
            "Epoch 349/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4378 - val_loss: 0.6034\n",
            "Epoch 350/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4426 - val_loss: 0.6233\n",
            "Epoch 351/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 0.6349\n",
            "Epoch 352/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4516 - val_loss: 0.6036\n",
            "Epoch 353/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.6227\n",
            "Epoch 354/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4685 - val_loss: 0.5959\n",
            "Epoch 355/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.6588\n",
            "Epoch 356/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4628 - val_loss: 0.6155\n",
            "Epoch 357/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4493 - val_loss: 0.6351\n",
            "Epoch 358/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.6293\n",
            "Epoch 359/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.6460\n",
            "Epoch 360/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4455 - val_loss: 0.6146\n",
            "Epoch 361/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.6455\n",
            "Epoch 362/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4680 - val_loss: 0.6244\n",
            "Epoch 363/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4523 - val_loss: 0.6573\n",
            "Epoch 364/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4473 - val_loss: 0.6049\n",
            "Epoch 365/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4546 - val_loss: 0.6365\n",
            "Epoch 366/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.6346\n",
            "Epoch 367/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4563 - val_loss: 0.6244\n",
            "Epoch 368/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4504 - val_loss: 0.6397\n",
            "Epoch 369/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4489 - val_loss: 0.6134\n",
            "Epoch 370/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4515 - val_loss: 0.6255\n",
            "Epoch 371/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4676 - val_loss: 0.6553\n",
            "Epoch 372/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4653 - val_loss: 0.6321\n",
            "Epoch 373/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4730 - val_loss: 0.6393\n",
            "Epoch 374/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.6367\n",
            "Epoch 375/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5128 - val_loss: 0.6346\n",
            "Epoch 376/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.6302\n",
            "Epoch 377/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4380 - val_loss: 0.6332\n",
            "Epoch 378/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4473 - val_loss: 0.6463\n",
            "Epoch 379/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.6500\n",
            "Epoch 380/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4495 - val_loss: 0.6290\n",
            "Epoch 381/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4526 - val_loss: 0.6741\n",
            "Epoch 382/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4446 - val_loss: 0.6350\n",
            "Epoch 383/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4561 - val_loss: 0.6679\n",
            "Epoch 384/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.6483\n",
            "Epoch 385/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4734 - val_loss: 0.6405\n",
            "Epoch 386/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.6234\n",
            "Epoch 387/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4674 - val_loss: 0.6212\n",
            "Epoch 388/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4498 - val_loss: 0.6680\n",
            "Epoch 389/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 0.6354\n",
            "Epoch 390/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4470 - val_loss: 0.6357\n",
            "Epoch 391/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4438 - val_loss: 0.6290\n",
            "Epoch 392/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4497 - val_loss: 0.6287\n",
            "Epoch 393/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.7604\n",
            "Epoch 394/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.6468\n",
            "Epoch 395/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4866 - val_loss: 0.6450\n",
            "Epoch 396/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4514 - val_loss: 0.6361\n",
            "Epoch 397/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4554 - val_loss: 0.6409\n",
            "Epoch 398/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4402 - val_loss: 0.6827\n",
            "Epoch 399/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.6351\n",
            "Epoch 400/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4467 - val_loss: 0.6698\n",
            "Epoch 401/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4711 - val_loss: 0.6399\n",
            "Epoch 402/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.6473\n",
            "Epoch 403/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4715 - val_loss: 0.6484\n",
            "Epoch 404/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.6279\n",
            "Epoch 405/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4699 - val_loss: 0.6430\n",
            "Epoch 406/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.6368\n",
            "Epoch 407/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4465 - val_loss: 0.6882\n",
            "Epoch 408/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.6576\n",
            "Epoch 409/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4444 - val_loss: 0.6782\n",
            "Epoch 410/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4950 - val_loss: 0.6649\n",
            "Epoch 411/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4256 - val_loss: 0.6350\n",
            "Epoch 412/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.6697\n",
            "Epoch 413/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4531 - val_loss: 0.6654\n",
            "Epoch 414/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4475 - val_loss: 0.6671\n",
            "Epoch 415/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4473 - val_loss: 0.6251\n",
            "Epoch 416/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4391 - val_loss: 0.6420\n",
            "Epoch 417/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4459 - val_loss: 0.6575\n",
            "Epoch 418/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5040 - val_loss: 0.6296\n",
            "Epoch 419/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5006 - val_loss: 0.6334\n",
            "Epoch 420/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.6238\n",
            "Epoch 421/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4509 - val_loss: 0.6266\n",
            "Epoch 422/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4532 - val_loss: 0.6328\n",
            "Epoch 423/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4586 - val_loss: 0.7234\n",
            "Epoch 424/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 0.6259\n",
            "Epoch 425/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.6455\n",
            "Epoch 426/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4660 - val_loss: 0.6557\n",
            "Epoch 427/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4503 - val_loss: 0.6457\n",
            "Epoch 428/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.6551\n",
            "Epoch 429/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4495 - val_loss: 0.6445\n",
            "Epoch 430/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4433 - val_loss: 0.7311\n",
            "Epoch 431/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.6160\n",
            "Epoch 432/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4428 - val_loss: 0.6544\n",
            "Epoch 433/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4460 - val_loss: 0.6756\n",
            "Epoch 434/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4852 - val_loss: 0.6414\n",
            "Epoch 435/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.6424\n",
            "Epoch 436/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4514 - val_loss: 0.6704\n",
            "Epoch 437/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4569 - val_loss: 0.6426\n",
            "Epoch 438/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4470 - val_loss: 0.6242\n",
            "Epoch 439/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4475 - val_loss: 0.6518\n",
            "Epoch 440/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4509 - val_loss: 0.6574\n",
            "Epoch 441/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.6117\n",
            "Epoch 442/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 0.6244\n",
            "Epoch 443/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.6538\n",
            "Epoch 444/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4417 - val_loss: 0.6494\n",
            "Epoch 445/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.6257\n",
            "Epoch 446/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.6180\n",
            "Epoch 447/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4465 - val_loss: 0.6515\n",
            "Epoch 448/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4805 - val_loss: 0.6252\n",
            "Epoch 449/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 0.6378\n",
            "Epoch 450/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4509 - val_loss: 0.6216\n",
            "Epoch 451/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4478 - val_loss: 0.6966\n",
            "Epoch 452/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.6331\n",
            "Epoch 453/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4499 - val_loss: 0.6293\n",
            "Epoch 454/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4714 - val_loss: 0.6206\n",
            "Epoch 455/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4340 - val_loss: 0.6414\n",
            "Epoch 456/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4431 - val_loss: 0.6942\n",
            "Epoch 457/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4394 - val_loss: 0.6620\n",
            "Epoch 458/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4345 - val_loss: 0.6535\n",
            "Epoch 459/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4654 - val_loss: 0.6376\n",
            "Epoch 460/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4331 - val_loss: 0.6447\n",
            "Epoch 461/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4475 - val_loss: 0.6624\n",
            "Epoch 462/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.6384\n",
            "Epoch 463/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4705 - val_loss: 0.6496\n",
            "Epoch 464/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4888 - val_loss: 0.7718\n",
            "Epoch 465/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4454 - val_loss: 0.6242\n",
            "Epoch 466/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4516 - val_loss: 0.6231\n",
            "Epoch 467/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 0.6401\n",
            "Epoch 468/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4264 - val_loss: 0.6341\n",
            "Epoch 469/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 0.6368\n",
            "Epoch 470/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.6462\n",
            "Epoch 471/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4433 - val_loss: 0.6475\n",
            "Epoch 472/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 0.6503\n",
            "Epoch 473/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4444 - val_loss: 0.6381\n",
            "Epoch 474/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4410 - val_loss: 0.6669\n",
            "Epoch 475/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4360 - val_loss: 0.6665\n",
            "Epoch 476/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.6340\n",
            "Epoch 477/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4452 - val_loss: 0.6287\n",
            "Epoch 478/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4473 - val_loss: 0.6218\n",
            "Epoch 479/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4483 - val_loss: 0.6245\n",
            "Epoch 480/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4400 - val_loss: 0.6419\n",
            "Epoch 481/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.6197\n",
            "Epoch 482/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4525 - val_loss: 0.6123\n",
            "Epoch 483/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4621 - val_loss: 0.6376\n",
            "Epoch 484/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4729 - val_loss: 0.6229\n",
            "Epoch 485/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4472 - val_loss: 0.6517\n",
            "Epoch 486/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.6472\n",
            "Epoch 487/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4447 - val_loss: 0.6904\n",
            "Epoch 488/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4537 - val_loss: 0.6522\n",
            "Epoch 489/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4441 - val_loss: 0.6510\n",
            "Epoch 490/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.6532\n",
            "Epoch 491/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4349 - val_loss: 0.6799\n",
            "Epoch 492/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4624 - val_loss: 0.6650\n",
            "Epoch 493/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4522 - val_loss: 0.7213\n",
            "Epoch 494/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4465 - val_loss: 0.6836\n",
            "Epoch 495/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.6542\n",
            "Epoch 496/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4507 - val_loss: 0.6177\n",
            "Epoch 497/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4288 - val_loss: 0.6254\n",
            "Epoch 498/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.7262\n",
            "Epoch 499/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4653 - val_loss: 0.6341\n",
            "Epoch 500/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4498 - val_loss: 0.6232\n",
            "Epoch 501/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 0.6360\n",
            "Epoch 502/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4496 - val_loss: 0.6341\n",
            "Epoch 503/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 0.6883\n",
            "Epoch 504/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4367 - val_loss: 0.6554\n",
            "Epoch 505/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4533 - val_loss: 0.6230\n",
            "Epoch 506/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4290 - val_loss: 0.6504\n",
            "Epoch 507/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4381 - val_loss: 0.6253\n",
            "Epoch 508/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4334 - val_loss: 0.6546\n",
            "Epoch 509/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.6586\n",
            "Epoch 510/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.6441\n",
            "Epoch 511/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4345 - val_loss: 0.6198\n",
            "Epoch 512/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4431 - val_loss: 0.6475\n",
            "Epoch 513/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4609 - val_loss: 0.6315\n",
            "Epoch 514/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4273 - val_loss: 0.6737\n",
            "Epoch 515/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4291 - val_loss: 0.6202\n",
            "Epoch 516/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 0.6234\n",
            "Epoch 517/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4421 - val_loss: 0.7732\n",
            "Epoch 518/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4712 - val_loss: 0.6151\n",
            "Epoch 519/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4395 - val_loss: 0.6291\n",
            "Epoch 520/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4470 - val_loss: 0.6280\n",
            "Epoch 521/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.6218\n",
            "Epoch 522/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 0.6196\n",
            "Epoch 523/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4389 - val_loss: 0.6638\n",
            "Epoch 524/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4507 - val_loss: 0.6596\n",
            "Epoch 525/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4729 - val_loss: 0.6141\n",
            "Epoch 526/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4523 - val_loss: 0.6271\n",
            "Epoch 527/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4397 - val_loss: 0.6218\n",
            "Epoch 528/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4367 - val_loss: 0.6057\n",
            "Epoch 529/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.6117\n",
            "Epoch 530/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4553 - val_loss: 0.6308\n",
            "Epoch 531/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.6114\n",
            "Epoch 532/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4221 - val_loss: 0.6547\n",
            "Epoch 533/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.6205\n",
            "Epoch 534/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4523 - val_loss: 0.6409\n",
            "Epoch 535/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.6602\n",
            "Epoch 536/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4303 - val_loss: 0.6474\n",
            "Epoch 537/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4295 - val_loss: 0.6479\n",
            "Epoch 538/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.7271\n",
            "Epoch 539/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.6406\n",
            "Epoch 540/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4252 - val_loss: 0.6864\n",
            "Epoch 541/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4319 - val_loss: 0.7542\n",
            "Epoch 542/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4688 - val_loss: 0.6631\n",
            "Epoch 543/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4382 - val_loss: 0.5968\n",
            "Epoch 544/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4419 - val_loss: 0.6504\n",
            "Epoch 545/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4733 - val_loss: 0.6116\n",
            "Epoch 546/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4433 - val_loss: 0.6302\n",
            "Epoch 547/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 0.6527\n",
            "Epoch 548/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.7188\n",
            "Epoch 549/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.7037\n",
            "Epoch 550/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4368 - val_loss: 0.6344\n",
            "Epoch 551/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4457 - val_loss: 0.6521\n",
            "Epoch 552/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4288 - val_loss: 0.6286\n",
            "Epoch 553/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4309 - val_loss: 0.6440\n",
            "Epoch 554/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4433 - val_loss: 0.6469\n",
            "Epoch 555/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4331 - val_loss: 0.6565\n",
            "Epoch 556/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4241 - val_loss: 0.6621\n",
            "Epoch 557/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4312 - val_loss: 0.7169\n",
            "Epoch 558/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4417 - val_loss: 0.6494\n",
            "Epoch 559/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.6204\n",
            "Epoch 560/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4493 - val_loss: 0.6022\n",
            "Epoch 561/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4628 - val_loss: 0.6043\n",
            "Epoch 562/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4541 - val_loss: 0.6321\n",
            "Epoch 563/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4537 - val_loss: 0.5922\n",
            "Epoch 564/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4470 - val_loss: 0.6086\n",
            "Epoch 565/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.6234\n",
            "Epoch 566/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4445 - val_loss: 0.6025\n",
            "Epoch 567/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4559 - val_loss: 0.6276\n",
            "Epoch 568/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4836 - val_loss: 0.6732\n",
            "Epoch 569/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4589 - val_loss: 0.6911\n",
            "Epoch 570/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4441 - val_loss: 0.6224\n",
            "Epoch 571/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4430 - val_loss: 0.7191\n",
            "Epoch 572/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4514 - val_loss: 0.6073\n",
            "Epoch 573/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4467 - val_loss: 0.6266\n",
            "Epoch 574/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4587 - val_loss: 0.6697\n",
            "Epoch 575/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4533 - val_loss: 0.6187\n",
            "Epoch 576/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4450 - val_loss: 0.6478\n",
            "Epoch 577/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.6028\n",
            "Epoch 578/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.6281\n",
            "Epoch 579/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4563 - val_loss: 0.6589\n",
            "Epoch 580/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.6228\n",
            "Epoch 581/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4479 - val_loss: 0.6260\n",
            "Epoch 582/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.6115\n",
            "Epoch 583/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4743 - val_loss: 0.6053\n",
            "Epoch 584/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4533 - val_loss: 0.6044\n",
            "Epoch 585/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4485 - val_loss: 0.6134\n",
            "Epoch 586/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 0.7305\n",
            "Epoch 587/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4534 - val_loss: 0.6110\n",
            "Epoch 588/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4551 - val_loss: 0.6083\n",
            "Epoch 589/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4531 - val_loss: 0.6003\n",
            "Epoch 590/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 0.6238\n",
            "Epoch 591/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.6306\n",
            "Epoch 592/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4523 - val_loss: 0.6052\n",
            "Epoch 593/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4428 - val_loss: 0.6455\n",
            "Epoch 594/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4529 - val_loss: 0.6220\n",
            "Epoch 595/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4474 - val_loss: 0.6185\n",
            "Epoch 596/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4543 - val_loss: 0.6011\n",
            "Epoch 597/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.6153\n",
            "Epoch 598/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4391 - val_loss: 0.6430\n",
            "Epoch 599/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4489 - val_loss: 0.6421\n",
            "Epoch 600/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4462 - val_loss: 0.6193\n",
            "Epoch 601/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4502 - val_loss: 0.6244\n",
            "Epoch 602/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4592 - val_loss: 0.6092\n",
            "Epoch 603/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 0.6409\n",
            "Epoch 604/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4470 - val_loss: 0.6224\n",
            "Epoch 605/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4521 - val_loss: 0.6098\n",
            "Epoch 606/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4487 - val_loss: 0.6059\n",
            "Epoch 607/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.6220\n",
            "Epoch 608/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4498 - val_loss: 0.6121\n",
            "Epoch 609/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4510 - val_loss: 0.7048\n",
            "Epoch 610/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.6122\n",
            "Epoch 611/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 0.6041\n",
            "Epoch 612/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.5965\n",
            "Epoch 613/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4569 - val_loss: 0.6130\n",
            "Epoch 614/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.6129\n",
            "Epoch 615/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.6299\n",
            "Epoch 616/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 0.6183\n",
            "Epoch 617/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.6375\n",
            "Epoch 618/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.6228\n",
            "Epoch 619/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4407 - val_loss: 0.6018\n",
            "Epoch 620/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4353 - val_loss: 0.6194\n",
            "Epoch 621/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4478 - val_loss: 0.6913\n",
            "Epoch 622/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4309 - val_loss: 0.6384\n",
            "Epoch 623/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4530 - val_loss: 0.6033\n",
            "Epoch 624/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4428 - val_loss: 0.6115\n",
            "Epoch 625/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4450 - val_loss: 0.7282\n",
            "Epoch 626/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4520 - val_loss: 0.6243\n",
            "Epoch 627/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.6995\n",
            "Epoch 628/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 0.6197\n",
            "Epoch 629/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.6124\n",
            "Epoch 630/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4430 - val_loss: 0.6207\n",
            "Epoch 631/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4351 - val_loss: 0.6255\n",
            "Epoch 632/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 0.6187\n",
            "Epoch 633/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 0.6117\n",
            "Epoch 634/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4288 - val_loss: 0.6425\n",
            "Epoch 635/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4428 - val_loss: 0.5998\n",
            "Epoch 636/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4620 - val_loss: 0.6246\n",
            "Epoch 637/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4452 - val_loss: 0.6413\n",
            "Epoch 638/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4510 - val_loss: 0.6138\n",
            "Epoch 639/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4739 - val_loss: 0.6029\n",
            "Epoch 640/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4554 - val_loss: 0.6615\n",
            "Epoch 641/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.6365\n",
            "Epoch 642/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4517 - val_loss: 0.6681\n",
            "Epoch 643/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.6754\n",
            "Epoch 644/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.6250\n",
            "Epoch 645/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.6181\n",
            "Epoch 646/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4501 - val_loss: 0.6146\n",
            "Epoch 647/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4504 - val_loss: 0.6203\n",
            "Epoch 648/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4696 - val_loss: 0.6147\n",
            "Epoch 649/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4754 - val_loss: 0.6327\n",
            "Epoch 650/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 0.5997\n",
            "Epoch 651/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4509 - val_loss: 0.6114\n",
            "Epoch 652/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4501 - val_loss: 0.6342\n",
            "Epoch 653/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4569 - val_loss: 0.6341\n",
            "Epoch 654/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.6388\n",
            "Epoch 655/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.6185\n",
            "Epoch 656/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4672 - val_loss: 0.6167\n",
            "Epoch 657/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4535 - val_loss: 0.5992\n",
            "Epoch 658/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4466 - val_loss: 0.6853\n",
            "Epoch 659/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.6153\n",
            "Epoch 660/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4497 - val_loss: 0.6037\n",
            "Epoch 661/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.6066\n",
            "Epoch 662/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4598 - val_loss: 0.6338\n",
            "Epoch 663/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.6319\n",
            "Epoch 664/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4704 - val_loss: 0.6177\n",
            "Epoch 665/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.6678\n",
            "Epoch 666/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4647 - val_loss: 0.6197\n",
            "Epoch 667/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4505 - val_loss: 0.6244\n",
            "Epoch 668/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 0.6204\n",
            "Epoch 669/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.6000\n",
            "Epoch 670/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4491 - val_loss: 0.6206\n",
            "Epoch 671/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4438 - val_loss: 0.6314\n",
            "Epoch 672/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4465 - val_loss: 0.6607\n",
            "Epoch 673/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4449 - val_loss: 0.6260\n",
            "Epoch 674/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4612 - val_loss: 0.6125\n",
            "Epoch 675/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4468 - val_loss: 0.6109\n",
            "Epoch 676/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4394 - val_loss: 0.6037\n",
            "Epoch 677/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4493 - val_loss: 0.6166\n",
            "Epoch 678/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4684 - val_loss: 0.6160\n",
            "Epoch 679/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4636 - val_loss: 0.6154\n",
            "Epoch 680/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.6364\n",
            "Epoch 681/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4498 - val_loss: 0.6032\n",
            "Epoch 682/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4470 - val_loss: 0.6307\n",
            "Epoch 683/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4739 - val_loss: 0.6315\n",
            "Epoch 684/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4535 - val_loss: 0.6199\n",
            "Epoch 685/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.6183\n",
            "Epoch 686/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 0.6577\n",
            "Epoch 687/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.6220\n",
            "Epoch 688/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4535 - val_loss: 0.5967\n",
            "Epoch 689/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.6228\n",
            "Epoch 690/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4509 - val_loss: 0.6268\n",
            "Epoch 691/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.6287\n",
            "Epoch 692/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 0.6021\n",
            "Epoch 693/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.6176\n",
            "Epoch 694/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4598 - val_loss: 0.6071\n",
            "Epoch 695/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4508 - val_loss: 0.6098\n",
            "Epoch 696/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4436 - val_loss: 0.6110\n",
            "Epoch 697/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4460 - val_loss: 0.6172\n",
            "Epoch 698/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4516 - val_loss: 0.6017\n",
            "Epoch 699/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4507 - val_loss: 0.6102\n",
            "Epoch 700/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4475 - val_loss: 0.6086\n",
            "Epoch 701/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4429 - val_loss: 0.6057\n",
            "Epoch 702/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4532 - val_loss: 0.6236\n",
            "Epoch 703/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4417 - val_loss: 0.6190\n",
            "Epoch 704/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4458 - val_loss: 0.6429\n",
            "Epoch 705/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4477 - val_loss: 0.6249\n",
            "Epoch 706/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4525 - val_loss: 0.7088\n",
            "Epoch 707/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5062 - val_loss: 0.6015\n",
            "Epoch 708/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4559 - val_loss: 0.6244\n",
            "Epoch 709/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4725 - val_loss: 0.7501\n",
            "Epoch 710/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4830 - val_loss: 0.6310\n",
            "Epoch 711/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4461 - val_loss: 0.6150\n",
            "Epoch 712/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 0.6544\n",
            "Epoch 713/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4893 - val_loss: 0.6060\n",
            "Epoch 714/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 0.6127\n",
            "Epoch 715/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4403 - val_loss: 0.6347\n",
            "Epoch 716/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4587 - val_loss: 0.6344\n",
            "Epoch 717/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4472 - val_loss: 0.6212\n",
            "Epoch 718/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4719 - val_loss: 0.6475\n",
            "Epoch 719/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4658 - val_loss: 0.6588\n",
            "Epoch 720/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4411 - val_loss: 0.6063\n",
            "Epoch 721/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4546 - val_loss: 0.6352\n",
            "Epoch 722/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4497 - val_loss: 0.6332\n",
            "Epoch 723/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4517 - val_loss: 0.6111\n",
            "Epoch 724/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4501 - val_loss: 0.6584\n",
            "Epoch 725/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4394 - val_loss: 0.6288\n",
            "Epoch 726/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4500 - val_loss: 0.6209\n",
            "Epoch 727/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4451 - val_loss: 0.7924\n",
            "Epoch 728/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4844 - val_loss: 0.6123\n",
            "Epoch 729/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4569 - val_loss: 0.6456\n",
            "Epoch 730/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4960 - val_loss: 0.6137\n",
            "Epoch 731/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4489 - val_loss: 0.6386\n",
            "Epoch 732/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4481 - val_loss: 0.6042\n",
            "Epoch 733/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4466 - val_loss: 0.6081\n",
            "Epoch 734/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.6102\n",
            "Epoch 735/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.6484\n",
            "Epoch 736/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4630 - val_loss: 0.5942\n",
            "Epoch 737/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 0.6262\n",
            "Epoch 738/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4705 - val_loss: 0.6211\n",
            "Epoch 739/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4618 - val_loss: 0.5993\n",
            "Epoch 740/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4514 - val_loss: 0.6046\n",
            "Epoch 741/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4627 - val_loss: 0.5959\n",
            "Epoch 742/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.6047\n",
            "Epoch 743/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4479 - val_loss: 0.6236\n",
            "Epoch 744/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.6576\n",
            "Epoch 745/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.6125\n",
            "Epoch 746/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4628 - val_loss: 0.6133\n",
            "Epoch 747/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.6254\n",
            "Epoch 748/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.6339\n",
            "Epoch 749/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.6221\n",
            "Epoch 750/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.6055\n",
            "Epoch 751/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.6069\n",
            "Epoch 752/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4444 - val_loss: 0.6319\n",
            "Epoch 753/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4589 - val_loss: 0.6071\n",
            "Epoch 754/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4690 - val_loss: 0.6160\n",
            "Epoch 755/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4511 - val_loss: 0.6262\n",
            "Epoch 756/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4532 - val_loss: 0.6124\n",
            "Epoch 757/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.6115\n",
            "Epoch 758/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.5899\n",
            "Epoch 759/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4468 - val_loss: 0.5952\n",
            "Epoch 760/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4447 - val_loss: 0.5947\n",
            "Epoch 761/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4475 - val_loss: 0.6003\n",
            "Epoch 762/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.5995\n",
            "Epoch 763/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4482 - val_loss: 0.6163\n",
            "Epoch 764/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.6029\n",
            "Epoch 765/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4628 - val_loss: 0.5866\n",
            "Epoch 766/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4458 - val_loss: 0.6163\n",
            "Epoch 767/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4522 - val_loss: 0.5889\n",
            "Epoch 768/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4443 - val_loss: 0.5993\n",
            "Epoch 769/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4395 - val_loss: 0.5932\n",
            "Epoch 770/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.5928\n",
            "Epoch 771/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4543 - val_loss: 0.6113\n",
            "Epoch 772/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4508 - val_loss: 0.6178\n",
            "Epoch 773/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4571 - val_loss: 0.6074\n",
            "Epoch 774/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4526 - val_loss: 0.6292\n",
            "Epoch 775/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4490 - val_loss: 0.6233\n",
            "Epoch 776/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.6025\n",
            "Epoch 777/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4445 - val_loss: 0.6154\n",
            "Epoch 778/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4545 - val_loss: 0.6411\n",
            "Epoch 779/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4455 - val_loss: 0.6014\n",
            "Epoch 780/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4427 - val_loss: 0.6409\n",
            "Epoch 781/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4372 - val_loss: 0.6246\n",
            "Epoch 782/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.5959\n",
            "Epoch 783/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.6370\n",
            "Epoch 784/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.6386\n",
            "Epoch 785/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.5996\n",
            "Epoch 786/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4434 - val_loss: 0.6027\n",
            "Epoch 787/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4706 - val_loss: 0.6202\n",
            "Epoch 788/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4487 - val_loss: 0.5892\n",
            "Epoch 789/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4416 - val_loss: 0.6526\n",
            "Epoch 790/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 0.6172\n",
            "Epoch 791/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.5869\n",
            "Epoch 792/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 0.5922\n",
            "Epoch 793/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.6020\n",
            "Epoch 794/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4519 - val_loss: 0.6336\n",
            "Epoch 795/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4498 - val_loss: 0.6558\n",
            "Epoch 796/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4630 - val_loss: 0.6349\n",
            "Epoch 797/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4495 - val_loss: 0.6764\n",
            "Epoch 798/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.6066\n",
            "Epoch 799/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4486 - val_loss: 0.5983\n",
            "Epoch 800/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4534 - val_loss: 0.6451\n",
            "Epoch 801/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4656 - val_loss: 0.6008\n",
            "Epoch 802/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4665 - val_loss: 0.6414\n",
            "Epoch 803/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4412 - val_loss: 0.6383\n",
            "Epoch 804/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4577 - val_loss: 0.6308\n",
            "Epoch 805/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4670 - val_loss: 0.5956\n",
            "Epoch 806/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4569 - val_loss: 0.6503\n",
            "Epoch 807/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4691 - val_loss: 0.6351\n",
            "Epoch 808/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.5863\n",
            "Epoch 809/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.5839\n",
            "Epoch 810/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4717 - val_loss: 0.6371\n",
            "Epoch 811/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4593 - val_loss: 0.5963\n",
            "Epoch 812/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4941 - val_loss: 0.6558\n",
            "Epoch 813/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.5951\n",
            "Epoch 814/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.6045\n",
            "Epoch 815/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.5897\n",
            "Epoch 816/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4464 - val_loss: 0.6073\n",
            "Epoch 817/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4474 - val_loss: 0.6223\n",
            "Epoch 818/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4561 - val_loss: 0.6069\n",
            "Epoch 819/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4443 - val_loss: 0.6218\n",
            "Epoch 820/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4839 - val_loss: 0.6303\n",
            "Epoch 821/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4599 - val_loss: 0.6073\n",
            "Epoch 822/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.6349\n",
            "Epoch 823/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4512 - val_loss: 0.5919\n",
            "Epoch 824/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4419 - val_loss: 0.6211\n",
            "Epoch 825/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4641 - val_loss: 0.5925\n",
            "Epoch 826/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4496 - val_loss: 0.6068\n",
            "Epoch 827/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4529 - val_loss: 0.5973\n",
            "Epoch 828/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4652 - val_loss: 0.5818\n",
            "Epoch 829/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4462 - val_loss: 0.5899\n",
            "Epoch 830/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4532 - val_loss: 0.6393\n",
            "Epoch 831/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4559 - val_loss: 0.5934\n",
            "Epoch 832/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.5973\n",
            "Epoch 833/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4477 - val_loss: 0.6119\n",
            "Epoch 834/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4554 - val_loss: 0.5982\n",
            "Epoch 835/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4833 - val_loss: 0.5896\n",
            "Epoch 836/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.5871\n",
            "Epoch 837/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.6100\n",
            "Epoch 838/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4446 - val_loss: 0.6241\n",
            "Epoch 839/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.6015\n",
            "Epoch 840/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.6011\n",
            "Epoch 841/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4530 - val_loss: 0.5970\n",
            "Epoch 842/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4457 - val_loss: 0.6077\n",
            "Epoch 843/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4450 - val_loss: 0.6096\n",
            "Epoch 844/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.6181\n",
            "Epoch 845/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.6066\n",
            "Epoch 846/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4486 - val_loss: 0.6313\n",
            "Epoch 847/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.6217\n",
            "Epoch 848/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4625 - val_loss: 0.5918\n",
            "Epoch 849/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4511 - val_loss: 0.6049\n",
            "Epoch 850/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4469 - val_loss: 0.5903\n",
            "Epoch 851/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.6190\n",
            "Epoch 852/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4697 - val_loss: 0.6001\n",
            "Epoch 853/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.6733\n",
            "Epoch 854/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 0.6335\n",
            "Epoch 855/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4435 - val_loss: 0.5972\n",
            "Epoch 856/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4518 - val_loss: 0.6007\n",
            "Epoch 857/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4559 - val_loss: 0.5925\n",
            "Epoch 858/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.5945\n",
            "Epoch 859/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4546 - val_loss: 0.5910\n",
            "Epoch 860/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4471 - val_loss: 0.5930\n",
            "Epoch 861/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4511 - val_loss: 0.6110\n",
            "Epoch 862/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.6604\n",
            "Epoch 863/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4592 - val_loss: 0.5999\n",
            "Epoch 864/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.6008\n",
            "Epoch 865/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4479 - val_loss: 0.5989\n",
            "Epoch 866/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4593 - val_loss: 0.6288\n",
            "Epoch 867/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.5986\n",
            "Epoch 868/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4686 - val_loss: 0.5909\n",
            "Epoch 869/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4700 - val_loss: 0.6389\n",
            "Epoch 870/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.5885\n",
            "Epoch 871/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4481 - val_loss: 0.5907\n",
            "Epoch 872/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4503 - val_loss: 0.6076\n",
            "Epoch 873/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4499 - val_loss: 0.6017\n",
            "Epoch 874/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4496 - val_loss: 0.5898\n",
            "Epoch 875/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4501 - val_loss: 0.6032\n",
            "Epoch 876/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.6195\n",
            "Epoch 877/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4478 - val_loss: 0.6168\n",
            "Epoch 878/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4522 - val_loss: 0.6345\n",
            "Epoch 879/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.5974\n",
            "Epoch 880/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4452 - val_loss: 0.6249\n",
            "Epoch 881/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.6073\n",
            "Epoch 882/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4790 - val_loss: 0.6851\n",
            "Epoch 883/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4748 - val_loss: 0.6136\n",
            "Epoch 884/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5057 - val_loss: 0.6067\n",
            "Epoch 885/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.6814\n",
            "Epoch 886/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4544 - val_loss: 0.6072\n",
            "Epoch 887/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4485 - val_loss: 0.6312\n",
            "Epoch 888/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4393 - val_loss: 0.6210\n",
            "Epoch 889/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4509 - val_loss: 0.5973\n",
            "Epoch 890/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4471 - val_loss: 0.6221\n",
            "Epoch 891/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4507 - val_loss: 0.6153\n",
            "Epoch 892/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.5955\n",
            "Epoch 893/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4454 - val_loss: 0.5965\n",
            "Epoch 894/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4605 - val_loss: 0.6025\n",
            "Epoch 895/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4877 - val_loss: 0.7025\n",
            "Epoch 896/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4993 - val_loss: 0.6475\n",
            "Epoch 897/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4924 - val_loss: 0.6201\n",
            "Epoch 898/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4735 - val_loss: 0.6699\n",
            "Epoch 899/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5216 - val_loss: 0.6323\n",
            "Epoch 900/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 0.6177\n",
            "Epoch 901/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.6312\n",
            "Epoch 902/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4863 - val_loss: 0.6130\n",
            "Epoch 903/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4627 - val_loss: 0.6092\n",
            "Epoch 904/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4722 - val_loss: 0.6677\n",
            "Epoch 905/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4674 - val_loss: 0.6456\n",
            "Epoch 906/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.6049\n",
            "Epoch 907/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.6025\n",
            "Epoch 908/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.6135\n",
            "Epoch 909/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4604 - val_loss: 0.6288\n",
            "Epoch 910/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.6271\n",
            "Epoch 911/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.6351\n",
            "Epoch 912/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4635 - val_loss: 0.6139\n",
            "Epoch 913/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4580 - val_loss: 0.6466\n",
            "Epoch 914/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4738 - val_loss: 0.6278\n",
            "Epoch 915/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 0.6239\n",
            "Epoch 916/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4508 - val_loss: 0.6471\n",
            "Epoch 917/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4689 - val_loss: 0.6193\n",
            "Epoch 918/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.5972\n",
            "Epoch 919/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4505 - val_loss: 0.6184\n",
            "Epoch 920/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.6454\n",
            "Epoch 921/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4566 - val_loss: 0.6552\n",
            "Epoch 922/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.6481\n",
            "Epoch 923/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4561 - val_loss: 0.6160\n",
            "Epoch 924/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4730 - val_loss: 0.6551\n",
            "Epoch 925/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.6489\n",
            "Epoch 926/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4637 - val_loss: 0.6031\n",
            "Epoch 927/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.6011\n",
            "Epoch 928/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.6738\n",
            "Epoch 929/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.6589\n",
            "Epoch 930/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4731 - val_loss: 0.6339\n",
            "Epoch 931/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4750 - val_loss: 0.6115\n",
            "Epoch 932/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4796 - val_loss: 0.6603\n",
            "Epoch 933/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.6087\n",
            "Epoch 934/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4515 - val_loss: 0.6363\n",
            "Epoch 935/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4577 - val_loss: 0.6068\n",
            "Epoch 936/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4612 - val_loss: 0.6243\n",
            "Epoch 937/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4510 - val_loss: 0.6070\n",
            "Epoch 938/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 0.6443\n",
            "Epoch 939/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.6135\n",
            "Epoch 940/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4651 - val_loss: 0.6194\n",
            "Epoch 941/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.7128\n",
            "Epoch 942/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.6298\n",
            "Epoch 943/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4676 - val_loss: 0.6012\n",
            "Epoch 944/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4554 - val_loss: 0.6839\n",
            "Epoch 945/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4674 - val_loss: 0.6002\n",
            "Epoch 946/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.5911\n",
            "Epoch 947/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4593 - val_loss: 0.5994\n",
            "Epoch 948/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.6244\n",
            "Epoch 949/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4593 - val_loss: 0.5946\n",
            "Epoch 950/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.6062\n",
            "Epoch 951/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4599 - val_loss: 0.6030\n",
            "Epoch 952/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4627 - val_loss: 0.6109\n",
            "Epoch 953/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4515 - val_loss: 0.6299\n",
            "Epoch 954/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.6385\n",
            "Epoch 955/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.6216\n",
            "Epoch 956/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4652 - val_loss: 0.6004\n",
            "Epoch 957/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4452 - val_loss: 0.6373\n",
            "Epoch 958/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4609 - val_loss: 0.6275\n",
            "Epoch 959/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.6025\n",
            "Epoch 960/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.6219\n",
            "Epoch 961/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4481 - val_loss: 0.6061\n",
            "Epoch 962/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.6341\n",
            "Epoch 963/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4543 - val_loss: 0.6560\n",
            "Epoch 964/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.5850\n",
            "Epoch 965/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4444 - val_loss: 0.6193\n",
            "Epoch 966/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4413 - val_loss: 0.6587\n",
            "Epoch 967/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4669 - val_loss: 0.6104\n",
            "Epoch 968/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4590 - val_loss: 0.6148\n",
            "Epoch 969/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4521 - val_loss: 0.5945\n",
            "Epoch 970/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4510 - val_loss: 0.6273\n",
            "Epoch 971/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.6259\n",
            "Epoch 972/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 0.6002\n",
            "Epoch 973/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4503 - val_loss: 0.6116\n",
            "Epoch 974/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.6018\n",
            "Epoch 975/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4521 - val_loss: 0.7509\n",
            "Epoch 976/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4579 - val_loss: 0.6869\n",
            "Epoch 977/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.6334\n",
            "Epoch 978/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4675 - val_loss: 0.6512\n",
            "Epoch 979/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4802 - val_loss: 0.6311\n",
            "Epoch 980/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.6435\n",
            "Epoch 981/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.6196\n",
            "Epoch 982/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.6128\n",
            "Epoch 983/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.6517\n",
            "Epoch 984/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4639 - val_loss: 0.6078\n",
            "Epoch 985/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4515 - val_loss: 0.6050\n",
            "Epoch 986/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4404 - val_loss: 0.6041\n",
            "Epoch 987/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4482 - val_loss: 0.6435\n",
            "Epoch 988/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4533 - val_loss: 0.6209\n",
            "Epoch 989/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.6671\n",
            "Epoch 990/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4463 - val_loss: 0.6723\n",
            "Epoch 991/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4452 - val_loss: 0.5894\n",
            "Epoch 992/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4517 - val_loss: 0.6468\n",
            "Epoch 993/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.5871\n",
            "Epoch 994/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.6154\n",
            "Epoch 995/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5063 - val_loss: 0.5692\n",
            "Epoch 996/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.6644\n",
            "Epoch 997/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4672 - val_loss: 0.6384\n",
            "Epoch 998/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4706 - val_loss: 0.6503\n",
            "Epoch 999/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4867 - val_loss: 0.6194\n",
            "Epoch 1000/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4681 - val_loss: 0.6452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOJ_j1PNxHdZ"
      },
      "source": [
        "####Adamax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk9_mDzsxJCz",
        "outputId": "f34ac964-ff30-4841-db07-dcb75792e761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "deep_mode3(opt_Adamax)"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.9977 - val_loss: 0.9951\n",
            "Epoch 2/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9895 - val_loss: 0.9845\n",
            "Epoch 3/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9728 - val_loss: 0.9655\n",
            "Epoch 4/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9460 - val_loss: 0.9375\n",
            "Epoch 5/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9098 - val_loss: 0.9033\n",
            "Epoch 6/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8635 - val_loss: 0.8606\n",
            "Epoch 7/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8126 - val_loss: 0.8196\n",
            "Epoch 8/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7635 - val_loss: 0.7834\n",
            "Epoch 9/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.7187 - val_loss: 0.7511\n",
            "Epoch 10/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6786 - val_loss: 0.7268\n",
            "Epoch 11/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6468 - val_loss: 0.7074\n",
            "Epoch 12/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6222 - val_loss: 0.6949\n",
            "Epoch 13/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6046 - val_loss: 0.6831\n",
            "Epoch 14/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5906 - val_loss: 0.6767\n",
            "Epoch 15/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5811 - val_loss: 0.6705\n",
            "Epoch 16/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5748 - val_loss: 0.6655\n",
            "Epoch 17/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5702 - val_loss: 0.6621\n",
            "Epoch 18/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5662 - val_loss: 0.6583\n",
            "Epoch 19/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5633 - val_loss: 0.6548\n",
            "Epoch 20/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5604 - val_loss: 0.6513\n",
            "Epoch 21/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5582 - val_loss: 0.6487\n",
            "Epoch 22/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5568 - val_loss: 0.6460\n",
            "Epoch 23/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5547 - val_loss: 0.6441\n",
            "Epoch 24/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5535 - val_loss: 0.6421\n",
            "Epoch 25/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5525 - val_loss: 0.6408\n",
            "Epoch 26/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5515 - val_loss: 0.6382\n",
            "Epoch 27/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5508 - val_loss: 0.6379\n",
            "Epoch 28/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5495 - val_loss: 0.6360\n",
            "Epoch 29/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5492 - val_loss: 0.6359\n",
            "Epoch 30/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5484 - val_loss: 0.6331\n",
            "Epoch 31/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5476 - val_loss: 0.6331\n",
            "Epoch 32/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5472 - val_loss: 0.6320\n",
            "Epoch 33/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5464 - val_loss: 0.6309\n",
            "Epoch 34/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5460 - val_loss: 0.6302\n",
            "Epoch 35/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 0.6304\n",
            "Epoch 36/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5449 - val_loss: 0.6284\n",
            "Epoch 37/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5447 - val_loss: 0.6283\n",
            "Epoch 38/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5445 - val_loss: 0.6270\n",
            "Epoch 39/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5442 - val_loss: 0.6271\n",
            "Epoch 40/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5437 - val_loss: 0.6262\n",
            "Epoch 41/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5438 - val_loss: 0.6260\n",
            "Epoch 42/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5430 - val_loss: 0.6251\n",
            "Epoch 43/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5428 - val_loss: 0.6246\n",
            "Epoch 44/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5428 - val_loss: 0.6239\n",
            "Epoch 45/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5425 - val_loss: 0.6234\n",
            "Epoch 46/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 0.6225\n",
            "Epoch 47/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5417 - val_loss: 0.6215\n",
            "Epoch 48/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5412 - val_loss: 0.6207\n",
            "Epoch 49/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5408 - val_loss: 0.6208\n",
            "Epoch 50/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5410 - val_loss: 0.6212\n",
            "Epoch 51/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5404 - val_loss: 0.6196\n",
            "Epoch 52/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 0.6194\n",
            "Epoch 53/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5401 - val_loss: 0.6190\n",
            "Epoch 54/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 0.6182\n",
            "Epoch 55/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5399 - val_loss: 0.6168\n",
            "Epoch 56/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5394 - val_loss: 0.6178\n",
            "Epoch 57/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5389 - val_loss: 0.6176\n",
            "Epoch 58/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5390 - val_loss: 0.6164\n",
            "Epoch 59/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5391 - val_loss: 0.6163\n",
            "Epoch 60/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5384 - val_loss: 0.6153\n",
            "Epoch 61/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5382 - val_loss: 0.6144\n",
            "Epoch 62/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5381 - val_loss: 0.6148\n",
            "Epoch 63/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5375 - val_loss: 0.6142\n",
            "Epoch 64/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5379 - val_loss: 0.6143\n",
            "Epoch 65/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5376 - val_loss: 0.6132\n",
            "Epoch 66/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5368 - val_loss: 0.6129\n",
            "Epoch 67/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5374 - val_loss: 0.6130\n",
            "Epoch 68/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5370 - val_loss: 0.6129\n",
            "Epoch 69/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5370 - val_loss: 0.6116\n",
            "Epoch 70/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5369 - val_loss: 0.6119\n",
            "Epoch 71/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5361 - val_loss: 0.6118\n",
            "Epoch 72/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5360 - val_loss: 0.6110\n",
            "Epoch 73/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5360 - val_loss: 0.6106\n",
            "Epoch 74/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5357 - val_loss: 0.6102\n",
            "Epoch 75/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5353 - val_loss: 0.6100\n",
            "Epoch 76/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5353 - val_loss: 0.6094\n",
            "Epoch 77/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5349 - val_loss: 0.6095\n",
            "Epoch 78/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5347 - val_loss: 0.6082\n",
            "Epoch 79/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5344 - val_loss: 0.6086\n",
            "Epoch 80/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5341 - val_loss: 0.6076\n",
            "Epoch 81/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5342 - val_loss: 0.6076\n",
            "Epoch 82/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5339 - val_loss: 0.6077\n",
            "Epoch 83/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5333 - val_loss: 0.6073\n",
            "Epoch 84/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5330 - val_loss: 0.6067\n",
            "Epoch 85/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5338 - val_loss: 0.6064\n",
            "Epoch 86/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5327 - val_loss: 0.6064\n",
            "Epoch 87/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5333 - val_loss: 0.6051\n",
            "Epoch 88/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5324 - val_loss: 0.6055\n",
            "Epoch 89/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5326 - val_loss: 0.6050\n",
            "Epoch 90/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5321 - val_loss: 0.6054\n",
            "Epoch 91/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5319 - val_loss: 0.6049\n",
            "Epoch 92/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5319 - val_loss: 0.6042\n",
            "Epoch 93/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5310 - val_loss: 0.6043\n",
            "Epoch 94/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5307 - val_loss: 0.6043\n",
            "Epoch 95/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5307 - val_loss: 0.6036\n",
            "Epoch 96/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5308 - val_loss: 0.6040\n",
            "Epoch 97/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5299 - val_loss: 0.6033\n",
            "Epoch 98/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5298 - val_loss: 0.6023\n",
            "Epoch 99/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5297 - val_loss: 0.6022\n",
            "Epoch 100/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5295 - val_loss: 0.6018\n",
            "Epoch 101/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5293 - val_loss: 0.6011\n",
            "Epoch 102/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5294 - val_loss: 0.6014\n",
            "Epoch 103/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 0.6014\n",
            "Epoch 104/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5293 - val_loss: 0.6012\n",
            "Epoch 105/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5287 - val_loss: 0.6004\n",
            "Epoch 106/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5282 - val_loss: 0.6011\n",
            "Epoch 107/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5280 - val_loss: 0.6009\n",
            "Epoch 108/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5282 - val_loss: 0.6007\n",
            "Epoch 109/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5275 - val_loss: 0.6012\n",
            "Epoch 110/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5273 - val_loss: 0.6009\n",
            "Epoch 111/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5275 - val_loss: 0.6003\n",
            "Epoch 112/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 0.5995\n",
            "Epoch 113/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 0.5999\n",
            "Epoch 114/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5270 - val_loss: 0.5996\n",
            "Epoch 115/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 0.5988\n",
            "Epoch 116/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5270 - val_loss: 0.5991\n",
            "Epoch 117/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5267 - val_loss: 0.5989\n",
            "Epoch 118/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 0.5994\n",
            "Epoch 119/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5263 - val_loss: 0.5991\n",
            "Epoch 120/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 0.5998\n",
            "Epoch 121/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5257 - val_loss: 0.5995\n",
            "Epoch 122/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 0.5987\n",
            "Epoch 123/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5250 - val_loss: 0.5987\n",
            "Epoch 124/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 0.5982\n",
            "Epoch 125/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 0.5983\n",
            "Epoch 126/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 0.5984\n",
            "Epoch 127/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 0.5978\n",
            "Epoch 128/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5245 - val_loss: 0.5982\n",
            "Epoch 129/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 0.5982\n",
            "Epoch 130/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 0.5982\n",
            "Epoch 131/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 0.5978\n",
            "Epoch 132/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5238 - val_loss: 0.5980\n",
            "Epoch 133/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 0.5975\n",
            "Epoch 134/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5231 - val_loss: 0.5969\n",
            "Epoch 135/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5964\n",
            "Epoch 136/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5230 - val_loss: 0.5971\n",
            "Epoch 137/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5973\n",
            "Epoch 138/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5224 - val_loss: 0.5967\n",
            "Epoch 139/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5219 - val_loss: 0.5964\n",
            "Epoch 140/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5221 - val_loss: 0.5958\n",
            "Epoch 141/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5219 - val_loss: 0.5952\n",
            "Epoch 142/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5221 - val_loss: 0.5962\n",
            "Epoch 143/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5214 - val_loss: 0.5958\n",
            "Epoch 144/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5215 - val_loss: 0.5960\n",
            "Epoch 145/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5207 - val_loss: 0.5961\n",
            "Epoch 146/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5211 - val_loss: 0.5961\n",
            "Epoch 147/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5208 - val_loss: 0.5953\n",
            "Epoch 148/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5208 - val_loss: 0.5948\n",
            "Epoch 149/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5203 - val_loss: 0.5938\n",
            "Epoch 150/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5198 - val_loss: 0.5948\n",
            "Epoch 151/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5193 - val_loss: 0.5939\n",
            "Epoch 152/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5192 - val_loss: 0.5945\n",
            "Epoch 153/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5189 - val_loss: 0.5934\n",
            "Epoch 154/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5190 - val_loss: 0.5930\n",
            "Epoch 155/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5182 - val_loss: 0.5929\n",
            "Epoch 156/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5185 - val_loss: 0.5927\n",
            "Epoch 157/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5183 - val_loss: 0.5931\n",
            "Epoch 158/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5176 - val_loss: 0.5928\n",
            "Epoch 159/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5180 - val_loss: 0.5916\n",
            "Epoch 160/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5168 - val_loss: 0.5917\n",
            "Epoch 161/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5171 - val_loss: 0.5914\n",
            "Epoch 162/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5174 - val_loss: 0.5914\n",
            "Epoch 163/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5167 - val_loss: 0.5913\n",
            "Epoch 164/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5159 - val_loss: 0.5910\n",
            "Epoch 165/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5154 - val_loss: 0.5904\n",
            "Epoch 166/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5153 - val_loss: 0.5911\n",
            "Epoch 167/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5148 - val_loss: 0.5897\n",
            "Epoch 168/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.5903\n",
            "Epoch 169/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5142 - val_loss: 0.5902\n",
            "Epoch 170/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5140 - val_loss: 0.5902\n",
            "Epoch 171/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5134 - val_loss: 0.5896\n",
            "Epoch 172/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5133 - val_loss: 0.5894\n",
            "Epoch 173/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5129 - val_loss: 0.5889\n",
            "Epoch 174/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5130 - val_loss: 0.5885\n",
            "Epoch 175/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5126 - val_loss: 0.5889\n",
            "Epoch 176/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5125 - val_loss: 0.5885\n",
            "Epoch 177/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5122 - val_loss: 0.5891\n",
            "Epoch 178/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5121 - val_loss: 0.5887\n",
            "Epoch 179/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5118 - val_loss: 0.5880\n",
            "Epoch 180/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5116 - val_loss: 0.5881\n",
            "Epoch 181/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5122 - val_loss: 0.5872\n",
            "Epoch 182/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5114 - val_loss: 0.5872\n",
            "Epoch 183/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5106 - val_loss: 0.5872\n",
            "Epoch 184/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5108 - val_loss: 0.5877\n",
            "Epoch 185/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5102 - val_loss: 0.5872\n",
            "Epoch 186/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5103 - val_loss: 0.5870\n",
            "Epoch 187/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5098 - val_loss: 0.5872\n",
            "Epoch 188/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5096 - val_loss: 0.5866\n",
            "Epoch 189/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5095 - val_loss: 0.5867\n",
            "Epoch 190/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5094 - val_loss: 0.5861\n",
            "Epoch 191/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5088 - val_loss: 0.5866\n",
            "Epoch 192/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5087 - val_loss: 0.5852\n",
            "Epoch 193/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5088 - val_loss: 0.5855\n",
            "Epoch 194/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5080 - val_loss: 0.5862\n",
            "Epoch 195/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5077 - val_loss: 0.5853\n",
            "Epoch 196/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5083 - val_loss: 0.5849\n",
            "Epoch 197/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5076 - val_loss: 0.5856\n",
            "Epoch 198/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5073 - val_loss: 0.5852\n",
            "Epoch 199/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5075 - val_loss: 0.5848\n",
            "Epoch 200/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5073 - val_loss: 0.5855\n",
            "Epoch 201/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5067 - val_loss: 0.5854\n",
            "Epoch 202/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5076 - val_loss: 0.5849\n",
            "Epoch 203/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5063 - val_loss: 0.5844\n",
            "Epoch 204/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5063 - val_loss: 0.5842\n",
            "Epoch 205/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5059 - val_loss: 0.5839\n",
            "Epoch 206/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5061 - val_loss: 0.5847\n",
            "Epoch 207/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5059 - val_loss: 0.5840\n",
            "Epoch 208/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5052 - val_loss: 0.5846\n",
            "Epoch 209/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5053 - val_loss: 0.5844\n",
            "Epoch 210/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5052 - val_loss: 0.5837\n",
            "Epoch 211/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5050 - val_loss: 0.5840\n",
            "Epoch 212/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5048 - val_loss: 0.5839\n",
            "Epoch 213/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5046 - val_loss: 0.5832\n",
            "Epoch 214/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5042 - val_loss: 0.5827\n",
            "Epoch 215/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5042 - val_loss: 0.5836\n",
            "Epoch 216/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5035 - val_loss: 0.5824\n",
            "Epoch 217/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5036 - val_loss: 0.5821\n",
            "Epoch 218/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5037 - val_loss: 0.5823\n",
            "Epoch 219/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5030 - val_loss: 0.5819\n",
            "Epoch 220/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5030 - val_loss: 0.5818\n",
            "Epoch 221/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5030 - val_loss: 0.5816\n",
            "Epoch 222/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5028 - val_loss: 0.5814\n",
            "Epoch 223/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5032 - val_loss: 0.5816\n",
            "Epoch 224/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5028 - val_loss: 0.5825\n",
            "Epoch 225/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5029 - val_loss: 0.5817\n",
            "Epoch 226/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5028 - val_loss: 0.5820\n",
            "Epoch 227/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5019 - val_loss: 0.5819\n",
            "Epoch 228/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5029 - val_loss: 0.5813\n",
            "Epoch 229/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5020 - val_loss: 0.5812\n",
            "Epoch 230/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5019 - val_loss: 0.5808\n",
            "Epoch 231/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5016 - val_loss: 0.5807\n",
            "Epoch 232/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5016 - val_loss: 0.5810\n",
            "Epoch 233/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5013 - val_loss: 0.5806\n",
            "Epoch 234/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5009 - val_loss: 0.5807\n",
            "Epoch 235/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5010 - val_loss: 0.5795\n",
            "Epoch 236/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5016 - val_loss: 0.5795\n",
            "Epoch 237/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5004 - val_loss: 0.5790\n",
            "Epoch 238/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5008 - val_loss: 0.5788\n",
            "Epoch 239/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5000 - val_loss: 0.5797\n",
            "Epoch 240/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5007 - val_loss: 0.5805\n",
            "Epoch 241/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5009 - val_loss: 0.5790\n",
            "Epoch 242/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4998 - val_loss: 0.5793\n",
            "Epoch 243/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4994 - val_loss: 0.5799\n",
            "Epoch 244/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5001 - val_loss: 0.5800\n",
            "Epoch 245/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5001 - val_loss: 0.5788\n",
            "Epoch 246/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4997 - val_loss: 0.5793\n",
            "Epoch 247/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4993 - val_loss: 0.5795\n",
            "Epoch 248/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4994 - val_loss: 0.5792\n",
            "Epoch 249/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4984 - val_loss: 0.5789\n",
            "Epoch 250/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4986 - val_loss: 0.5796\n",
            "Epoch 251/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4985 - val_loss: 0.5787\n",
            "Epoch 252/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4980 - val_loss: 0.5783\n",
            "Epoch 253/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4984 - val_loss: 0.5778\n",
            "Epoch 254/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4984 - val_loss: 0.5787\n",
            "Epoch 255/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4984 - val_loss: 0.5785\n",
            "Epoch 256/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4980 - val_loss: 0.5786\n",
            "Epoch 257/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4979 - val_loss: 0.5786\n",
            "Epoch 258/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4976 - val_loss: 0.5787\n",
            "Epoch 259/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4984 - val_loss: 0.5786\n",
            "Epoch 260/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4975 - val_loss: 0.5785\n",
            "Epoch 261/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4975 - val_loss: 0.5776\n",
            "Epoch 262/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4970 - val_loss: 0.5783\n",
            "Epoch 263/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4980 - val_loss: 0.5776\n",
            "Epoch 264/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4967 - val_loss: 0.5791\n",
            "Epoch 265/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4968 - val_loss: 0.5786\n",
            "Epoch 266/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4971 - val_loss: 0.5785\n",
            "Epoch 267/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4967 - val_loss: 0.5790\n",
            "Epoch 268/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4968 - val_loss: 0.5791\n",
            "Epoch 269/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4962 - val_loss: 0.5783\n",
            "Epoch 270/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4966 - val_loss: 0.5783\n",
            "Epoch 271/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4965 - val_loss: 0.5785\n",
            "Epoch 272/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4962 - val_loss: 0.5783\n",
            "Epoch 273/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4964 - val_loss: 0.5786\n",
            "Epoch 274/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4960 - val_loss: 0.5790\n",
            "Epoch 275/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4963 - val_loss: 0.5790\n",
            "Epoch 276/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4959 - val_loss: 0.5778\n",
            "Epoch 277/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4956 - val_loss: 0.5779\n",
            "Epoch 278/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4957 - val_loss: 0.5789\n",
            "Epoch 279/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4969 - val_loss: 0.5781\n",
            "Epoch 280/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4955 - val_loss: 0.5788\n",
            "Epoch 281/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4952 - val_loss: 0.5786\n",
            "Epoch 282/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4960 - val_loss: 0.5787\n",
            "Epoch 283/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4954 - val_loss: 0.5785\n",
            "Epoch 284/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4951 - val_loss: 0.5776\n",
            "Epoch 285/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4950 - val_loss: 0.5784\n",
            "Epoch 286/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4951 - val_loss: 0.5784\n",
            "Epoch 287/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4959 - val_loss: 0.5784\n",
            "Epoch 288/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4948 - val_loss: 0.5776\n",
            "Epoch 289/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4946 - val_loss: 0.5778\n",
            "Epoch 290/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4945 - val_loss: 0.5785\n",
            "Epoch 291/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4943 - val_loss: 0.5778\n",
            "Epoch 292/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4946 - val_loss: 0.5781\n",
            "Epoch 293/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4951 - val_loss: 0.5779\n",
            "Epoch 294/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4946 - val_loss: 0.5782\n",
            "Epoch 295/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4943 - val_loss: 0.5783\n",
            "Epoch 296/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4943 - val_loss: 0.5778\n",
            "Epoch 297/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4940 - val_loss: 0.5782\n",
            "Epoch 298/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4944 - val_loss: 0.5785\n",
            "Epoch 299/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4945 - val_loss: 0.5779\n",
            "Epoch 300/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4943 - val_loss: 0.5775\n",
            "Epoch 301/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4942 - val_loss: 0.5771\n",
            "Epoch 302/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4939 - val_loss: 0.5775\n",
            "Epoch 303/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4934 - val_loss: 0.5773\n",
            "Epoch 304/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4935 - val_loss: 0.5772\n",
            "Epoch 305/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4937 - val_loss: 0.5780\n",
            "Epoch 306/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4938 - val_loss: 0.5775\n",
            "Epoch 307/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4939 - val_loss: 0.5771\n",
            "Epoch 308/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4937 - val_loss: 0.5775\n",
            "Epoch 309/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4941 - val_loss: 0.5766\n",
            "Epoch 310/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4936 - val_loss: 0.5764\n",
            "Epoch 311/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4932 - val_loss: 0.5777\n",
            "Epoch 312/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4932 - val_loss: 0.5773\n",
            "Epoch 313/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4937 - val_loss: 0.5781\n",
            "Epoch 314/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4931 - val_loss: 0.5771\n",
            "Epoch 315/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4936 - val_loss: 0.5773\n",
            "Epoch 316/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4930 - val_loss: 0.5770\n",
            "Epoch 317/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4931 - val_loss: 0.5776\n",
            "Epoch 318/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4929 - val_loss: 0.5769\n",
            "Epoch 319/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4925 - val_loss: 0.5774\n",
            "Epoch 320/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4930 - val_loss: 0.5784\n",
            "Epoch 321/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4932 - val_loss: 0.5783\n",
            "Epoch 322/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4925 - val_loss: 0.5767\n",
            "Epoch 323/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4927 - val_loss: 0.5768\n",
            "Epoch 324/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4930 - val_loss: 0.5768\n",
            "Epoch 325/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4933 - val_loss: 0.5757\n",
            "Epoch 326/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4933 - val_loss: 0.5767\n",
            "Epoch 327/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4928 - val_loss: 0.5778\n",
            "Epoch 328/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4929 - val_loss: 0.5785\n",
            "Epoch 329/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4923 - val_loss: 0.5771\n",
            "Epoch 330/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4927 - val_loss: 0.5777\n",
            "Epoch 331/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4921 - val_loss: 0.5776\n",
            "Epoch 332/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4920 - val_loss: 0.5768\n",
            "Epoch 333/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4916 - val_loss: 0.5773\n",
            "Epoch 334/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4921 - val_loss: 0.5763\n",
            "Epoch 335/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4917 - val_loss: 0.5775\n",
            "Epoch 336/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4915 - val_loss: 0.5773\n",
            "Epoch 337/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4914 - val_loss: 0.5772\n",
            "Epoch 338/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4915 - val_loss: 0.5777\n",
            "Epoch 339/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4915 - val_loss: 0.5773\n",
            "Epoch 340/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4917 - val_loss: 0.5776\n",
            "Epoch 341/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4916 - val_loss: 0.5780\n",
            "Epoch 342/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 0.5772\n",
            "Epoch 343/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4916 - val_loss: 0.5774\n",
            "Epoch 344/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4917 - val_loss: 0.5766\n",
            "Epoch 345/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4915 - val_loss: 0.5770\n",
            "Epoch 346/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4911 - val_loss: 0.5776\n",
            "Epoch 347/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4923 - val_loss: 0.5781\n",
            "Epoch 348/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4914 - val_loss: 0.5783\n",
            "Epoch 349/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4913 - val_loss: 0.5788\n",
            "Epoch 350/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4916 - val_loss: 0.5780\n",
            "Epoch 351/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 0.5771\n",
            "Epoch 352/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4914 - val_loss: 0.5777\n",
            "Epoch 353/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4914 - val_loss: 0.5777\n",
            "Epoch 354/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4915 - val_loss: 0.5779\n",
            "Epoch 355/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4911 - val_loss: 0.5776\n",
            "Epoch 356/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 0.5777\n",
            "Epoch 357/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4910 - val_loss: 0.5781\n",
            "Epoch 358/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4911 - val_loss: 0.5779\n",
            "Epoch 359/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4910 - val_loss: 0.5777\n",
            "Epoch 360/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4908 - val_loss: 0.5778\n",
            "Epoch 361/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4908 - val_loss: 0.5781\n",
            "Epoch 362/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4910 - val_loss: 0.5782\n",
            "Epoch 363/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4904 - val_loss: 0.5782\n",
            "Epoch 364/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4907 - val_loss: 0.5792\n",
            "Epoch 365/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4910 - val_loss: 0.5780\n",
            "Epoch 366/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4906 - val_loss: 0.5780\n",
            "Epoch 367/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4904 - val_loss: 0.5784\n",
            "Epoch 368/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4902 - val_loss: 0.5785\n",
            "Epoch 369/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4909 - val_loss: 0.5785\n",
            "Epoch 370/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4903 - val_loss: 0.5791\n",
            "Epoch 371/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4906 - val_loss: 0.5789\n",
            "Epoch 372/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4906 - val_loss: 0.5797\n",
            "Epoch 373/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4901 - val_loss: 0.5784\n",
            "Epoch 374/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4905 - val_loss: 0.5786\n",
            "Epoch 375/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4903 - val_loss: 0.5787\n",
            "Epoch 376/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4900 - val_loss: 0.5787\n",
            "Epoch 377/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4902 - val_loss: 0.5794\n",
            "Epoch 378/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4905 - val_loss: 0.5794\n",
            "Epoch 379/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4903 - val_loss: 0.5790\n",
            "Epoch 380/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4899 - val_loss: 0.5785\n",
            "Epoch 381/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4899 - val_loss: 0.5786\n",
            "Epoch 382/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.5791\n",
            "Epoch 383/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4899 - val_loss: 0.5791\n",
            "Epoch 384/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4893 - val_loss: 0.5791\n",
            "Epoch 385/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4897 - val_loss: 0.5783\n",
            "Epoch 386/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 0.5791\n",
            "Epoch 387/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.5785\n",
            "Epoch 388/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.5791\n",
            "Epoch 389/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4899 - val_loss: 0.5783\n",
            "Epoch 390/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4892 - val_loss: 0.5782\n",
            "Epoch 391/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4898 - val_loss: 0.5791\n",
            "Epoch 392/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4895 - val_loss: 0.5773\n",
            "Epoch 393/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4894 - val_loss: 0.5777\n",
            "Epoch 394/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4889 - val_loss: 0.5782\n",
            "Epoch 395/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4898 - val_loss: 0.5781\n",
            "Epoch 396/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4894 - val_loss: 0.5781\n",
            "Epoch 397/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4893 - val_loss: 0.5791\n",
            "Epoch 398/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 0.5786\n",
            "Epoch 399/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4897 - val_loss: 0.5777\n",
            "Epoch 400/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4894 - val_loss: 0.5784\n",
            "Epoch 401/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 0.5785\n",
            "Epoch 402/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4888 - val_loss: 0.5783\n",
            "Epoch 403/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4894 - val_loss: 0.5770\n",
            "Epoch 404/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4886 - val_loss: 0.5783\n",
            "Epoch 405/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.5790\n",
            "Epoch 406/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4888 - val_loss: 0.5784\n",
            "Epoch 407/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4887 - val_loss: 0.5784\n",
            "Epoch 408/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4889 - val_loss: 0.5789\n",
            "Epoch 409/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4887 - val_loss: 0.5786\n",
            "Epoch 410/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 0.5783\n",
            "Epoch 411/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4888 - val_loss: 0.5781\n",
            "Epoch 412/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4886 - val_loss: 0.5776\n",
            "Epoch 413/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4889 - val_loss: 0.5781\n",
            "Epoch 414/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4891 - val_loss: 0.5771\n",
            "Epoch 415/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4886 - val_loss: 0.5779\n",
            "Epoch 416/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4884 - val_loss: 0.5785\n",
            "Epoch 417/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4897 - val_loss: 0.5796\n",
            "Epoch 418/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4889 - val_loss: 0.5789\n",
            "Epoch 419/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4887 - val_loss: 0.5781\n",
            "Epoch 420/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4882 - val_loss: 0.5785\n",
            "Epoch 421/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4882 - val_loss: 0.5799\n",
            "Epoch 422/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4882 - val_loss: 0.5781\n",
            "Epoch 423/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4883 - val_loss: 0.5789\n",
            "Epoch 424/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4891 - val_loss: 0.5786\n",
            "Epoch 425/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4885 - val_loss: 0.5785\n",
            "Epoch 426/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4878 - val_loss: 0.5786\n",
            "Epoch 427/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4881 - val_loss: 0.5789\n",
            "Epoch 428/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4878 - val_loss: 0.5780\n",
            "Epoch 429/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4883 - val_loss: 0.5784\n",
            "Epoch 430/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4881 - val_loss: 0.5787\n",
            "Epoch 431/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4876 - val_loss: 0.5789\n",
            "Epoch 432/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4877 - val_loss: 0.5792\n",
            "Epoch 433/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4881 - val_loss: 0.5790\n",
            "Epoch 434/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5783\n",
            "Epoch 435/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.5783\n",
            "Epoch 436/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4881 - val_loss: 0.5783\n",
            "Epoch 437/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5782\n",
            "Epoch 438/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4876 - val_loss: 0.5784\n",
            "Epoch 439/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4882 - val_loss: 0.5783\n",
            "Epoch 440/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5796\n",
            "Epoch 441/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.5789\n",
            "Epoch 442/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4878 - val_loss: 0.5793\n",
            "Epoch 443/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.5790\n",
            "Epoch 444/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4878 - val_loss: 0.5787\n",
            "Epoch 445/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4881 - val_loss: 0.5784\n",
            "Epoch 446/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.5800\n",
            "Epoch 447/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4875 - val_loss: 0.5791\n",
            "Epoch 448/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.5795\n",
            "Epoch 449/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 0.5788\n",
            "Epoch 450/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4872 - val_loss: 0.5797\n",
            "Epoch 451/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4870 - val_loss: 0.5792\n",
            "Epoch 452/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5786\n",
            "Epoch 453/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4875 - val_loss: 0.5786\n",
            "Epoch 454/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4867 - val_loss: 0.5790\n",
            "Epoch 455/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.5792\n",
            "Epoch 456/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4867 - val_loss: 0.5795\n",
            "Epoch 457/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4872 - val_loss: 0.5794\n",
            "Epoch 458/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4872 - val_loss: 0.5798\n",
            "Epoch 459/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4869 - val_loss: 0.5789\n",
            "Epoch 460/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4876 - val_loss: 0.5784\n",
            "Epoch 461/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4867 - val_loss: 0.5792\n",
            "Epoch 462/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4873 - val_loss: 0.5788\n",
            "Epoch 463/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4881 - val_loss: 0.5785\n",
            "Epoch 464/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4869 - val_loss: 0.5785\n",
            "Epoch 465/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4872 - val_loss: 0.5792\n",
            "Epoch 466/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4870 - val_loss: 0.5788\n",
            "Epoch 467/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 0.5802\n",
            "Epoch 468/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 0.5801\n",
            "Epoch 469/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4872 - val_loss: 0.5804\n",
            "Epoch 470/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4869 - val_loss: 0.5803\n",
            "Epoch 471/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4863 - val_loss: 0.5797\n",
            "Epoch 472/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4869 - val_loss: 0.5792\n",
            "Epoch 473/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4866 - val_loss: 0.5799\n",
            "Epoch 474/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.5795\n",
            "Epoch 475/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4870 - val_loss: 0.5804\n",
            "Epoch 476/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4870 - val_loss: 0.5802\n",
            "Epoch 477/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4869 - val_loss: 0.5809\n",
            "Epoch 478/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4868 - val_loss: 0.5796\n",
            "Epoch 479/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4864 - val_loss: 0.5804\n",
            "Epoch 480/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.5801\n",
            "Epoch 481/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.5813\n",
            "Epoch 482/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4867 - val_loss: 0.5805\n",
            "Epoch 483/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4864 - val_loss: 0.5803\n",
            "Epoch 484/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4868 - val_loss: 0.5807\n",
            "Epoch 485/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4867 - val_loss: 0.5805\n",
            "Epoch 486/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4868 - val_loss: 0.5802\n",
            "Epoch 487/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.5797\n",
            "Epoch 488/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4870 - val_loss: 0.5797\n",
            "Epoch 489/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4861 - val_loss: 0.5804\n",
            "Epoch 490/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4861 - val_loss: 0.5799\n",
            "Epoch 491/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4868 - val_loss: 0.5793\n",
            "Epoch 492/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4866 - val_loss: 0.5799\n",
            "Epoch 493/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4861 - val_loss: 0.5797\n",
            "Epoch 494/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4864 - val_loss: 0.5802\n",
            "Epoch 495/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4867 - val_loss: 0.5802\n",
            "Epoch 496/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.5798\n",
            "Epoch 497/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4860 - val_loss: 0.5810\n",
            "Epoch 498/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4859 - val_loss: 0.5804\n",
            "Epoch 499/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4866 - val_loss: 0.5805\n",
            "Epoch 500/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4855 - val_loss: 0.5791\n",
            "Epoch 501/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.5802\n",
            "Epoch 502/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.5796\n",
            "Epoch 503/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4857 - val_loss: 0.5799\n",
            "Epoch 504/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4859 - val_loss: 0.5804\n",
            "Epoch 505/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4860 - val_loss: 0.5807\n",
            "Epoch 506/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.5810\n",
            "Epoch 507/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4859 - val_loss: 0.5796\n",
            "Epoch 508/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.5809\n",
            "Epoch 509/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.5806\n",
            "Epoch 510/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.5812\n",
            "Epoch 511/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4857 - val_loss: 0.5809\n",
            "Epoch 512/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4858 - val_loss: 0.5808\n",
            "Epoch 513/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4852 - val_loss: 0.5803\n",
            "Epoch 514/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4858 - val_loss: 0.5819\n",
            "Epoch 515/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4859 - val_loss: 0.5804\n",
            "Epoch 516/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4857 - val_loss: 0.5808\n",
            "Epoch 517/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4853 - val_loss: 0.5818\n",
            "Epoch 518/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.5807\n",
            "Epoch 519/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4852 - val_loss: 0.5814\n",
            "Epoch 520/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.5809\n",
            "Epoch 521/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.5806\n",
            "Epoch 522/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4852 - val_loss: 0.5817\n",
            "Epoch 523/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4848 - val_loss: 0.5802\n",
            "Epoch 524/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4848 - val_loss: 0.5810\n",
            "Epoch 525/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4852 - val_loss: 0.5811\n",
            "Epoch 526/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4848 - val_loss: 0.5801\n",
            "Epoch 527/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4849 - val_loss: 0.5803\n",
            "Epoch 528/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.5812\n",
            "Epoch 529/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4849 - val_loss: 0.5817\n",
            "Epoch 530/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4846 - val_loss: 0.5812\n",
            "Epoch 531/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4848 - val_loss: 0.5803\n",
            "Epoch 532/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4843 - val_loss: 0.5811\n",
            "Epoch 533/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4846 - val_loss: 0.5804\n",
            "Epoch 534/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4845 - val_loss: 0.5800\n",
            "Epoch 535/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4846 - val_loss: 0.5802\n",
            "Epoch 536/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4845 - val_loss: 0.5807\n",
            "Epoch 537/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4845 - val_loss: 0.5807\n",
            "Epoch 538/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4847 - val_loss: 0.5820\n",
            "Epoch 539/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4851 - val_loss: 0.5813\n",
            "Epoch 540/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4844 - val_loss: 0.5804\n",
            "Epoch 541/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4855 - val_loss: 0.5798\n",
            "Epoch 542/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4844 - val_loss: 0.5810\n",
            "Epoch 543/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4846 - val_loss: 0.5809\n",
            "Epoch 544/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4849 - val_loss: 0.5815\n",
            "Epoch 545/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4845 - val_loss: 0.5801\n",
            "Epoch 546/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4851 - val_loss: 0.5802\n",
            "Epoch 547/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4843 - val_loss: 0.5804\n",
            "Epoch 548/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4844 - val_loss: 0.5807\n",
            "Epoch 549/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4844 - val_loss: 0.5809\n",
            "Epoch 550/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.5820\n",
            "Epoch 551/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4841 - val_loss: 0.5811\n",
            "Epoch 552/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4842 - val_loss: 0.5809\n",
            "Epoch 553/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4838 - val_loss: 0.5806\n",
            "Epoch 554/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4838 - val_loss: 0.5804\n",
            "Epoch 555/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4845 - val_loss: 0.5812\n",
            "Epoch 556/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4843 - val_loss: 0.5808\n",
            "Epoch 557/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4842 - val_loss: 0.5819\n",
            "Epoch 558/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4837 - val_loss: 0.5814\n",
            "Epoch 559/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4837 - val_loss: 0.5811\n",
            "Epoch 560/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4841 - val_loss: 0.5806\n",
            "Epoch 561/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4847 - val_loss: 0.5815\n",
            "Epoch 562/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.5815\n",
            "Epoch 563/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.5814\n",
            "Epoch 564/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4835 - val_loss: 0.5805\n",
            "Epoch 565/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4835 - val_loss: 0.5809\n",
            "Epoch 566/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.5814\n",
            "Epoch 567/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4841 - val_loss: 0.5817\n",
            "Epoch 568/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4838 - val_loss: 0.5809\n",
            "Epoch 569/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4832 - val_loss: 0.5810\n",
            "Epoch 570/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4843 - val_loss: 0.5814\n",
            "Epoch 571/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4830 - val_loss: 0.5802\n",
            "Epoch 572/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4837 - val_loss: 0.5806\n",
            "Epoch 573/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4834 - val_loss: 0.5807\n",
            "Epoch 574/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4836 - val_loss: 0.5808\n",
            "Epoch 575/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4837 - val_loss: 0.5815\n",
            "Epoch 576/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4839 - val_loss: 0.5807\n",
            "Epoch 577/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4828 - val_loss: 0.5811\n",
            "Epoch 578/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4836 - val_loss: 0.5812\n",
            "Epoch 579/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4830 - val_loss: 0.5808\n",
            "Epoch 580/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4838 - val_loss: 0.5804\n",
            "Epoch 581/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4843 - val_loss: 0.5807\n",
            "Epoch 582/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4833 - val_loss: 0.5817\n",
            "Epoch 583/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4829 - val_loss: 0.5807\n",
            "Epoch 584/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4831 - val_loss: 0.5806\n",
            "Epoch 585/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4832 - val_loss: 0.5800\n",
            "Epoch 586/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4825 - val_loss: 0.5809\n",
            "Epoch 587/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4838 - val_loss: 0.5812\n",
            "Epoch 588/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4826 - val_loss: 0.5806\n",
            "Epoch 589/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4826 - val_loss: 0.5813\n",
            "Epoch 590/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4833 - val_loss: 0.5811\n",
            "Epoch 591/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4829 - val_loss: 0.5817\n",
            "Epoch 592/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4834 - val_loss: 0.5809\n",
            "Epoch 593/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4826 - val_loss: 0.5814\n",
            "Epoch 594/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4823 - val_loss: 0.5820\n",
            "Epoch 595/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4828 - val_loss: 0.5820\n",
            "Epoch 596/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4830 - val_loss: 0.5812\n",
            "Epoch 597/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4833 - val_loss: 0.5820\n",
            "Epoch 598/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4829 - val_loss: 0.5815\n",
            "Epoch 599/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4830 - val_loss: 0.5805\n",
            "Epoch 600/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4828 - val_loss: 0.5810\n",
            "Epoch 601/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 0.5816\n",
            "Epoch 602/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4829 - val_loss: 0.5814\n",
            "Epoch 603/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4836 - val_loss: 0.5817\n",
            "Epoch 604/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 0.5812\n",
            "Epoch 605/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4831 - val_loss: 0.5813\n",
            "Epoch 606/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 0.5821\n",
            "Epoch 607/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4826 - val_loss: 0.5807\n",
            "Epoch 608/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4825 - val_loss: 0.5811\n",
            "Epoch 609/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 0.5817\n",
            "Epoch 610/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4826 - val_loss: 0.5814\n",
            "Epoch 611/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4835 - val_loss: 0.5806\n",
            "Epoch 612/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 0.5805\n",
            "Epoch 613/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4825 - val_loss: 0.5811\n",
            "Epoch 614/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 0.5812\n",
            "Epoch 615/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4821 - val_loss: 0.5808\n",
            "Epoch 616/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 0.5801\n",
            "Epoch 617/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4828 - val_loss: 0.5806\n",
            "Epoch 618/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.5813\n",
            "Epoch 619/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 0.5800\n",
            "Epoch 620/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4818 - val_loss: 0.5811\n",
            "Epoch 621/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.5811\n",
            "Epoch 622/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4825 - val_loss: 0.5803\n",
            "Epoch 623/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.5808\n",
            "Epoch 624/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4823 - val_loss: 0.5813\n",
            "Epoch 625/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.5813\n",
            "Epoch 626/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 0.5812\n",
            "Epoch 627/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4823 - val_loss: 0.5823\n",
            "Epoch 628/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.5820\n",
            "Epoch 629/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4819 - val_loss: 0.5804\n",
            "Epoch 630/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4821 - val_loss: 0.5803\n",
            "Epoch 631/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4821 - val_loss: 0.5818\n",
            "Epoch 632/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4819 - val_loss: 0.5816\n",
            "Epoch 633/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4821 - val_loss: 0.5821\n",
            "Epoch 634/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5817\n",
            "Epoch 635/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5809\n",
            "Epoch 636/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.5804\n",
            "Epoch 637/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4819 - val_loss: 0.5809\n",
            "Epoch 638/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4821 - val_loss: 0.5808\n",
            "Epoch 639/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.5810\n",
            "Epoch 640/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.5796\n",
            "Epoch 641/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.5810\n",
            "Epoch 642/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4819 - val_loss: 0.5810\n",
            "Epoch 643/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4823 - val_loss: 0.5817\n",
            "Epoch 644/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.5812\n",
            "Epoch 645/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5800\n",
            "Epoch 646/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5815\n",
            "Epoch 647/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5805\n",
            "Epoch 648/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5812\n",
            "Epoch 649/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 0.5808\n",
            "Epoch 650/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 0.5812\n",
            "Epoch 651/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 0.5805\n",
            "Epoch 652/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.5804\n",
            "Epoch 653/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5817\n",
            "Epoch 654/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4809 - val_loss: 0.5803\n",
            "Epoch 655/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5804\n",
            "Epoch 656/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 0.5802\n",
            "Epoch 657/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 0.5810\n",
            "Epoch 658/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4806 - val_loss: 0.5804\n",
            "Epoch 659/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.5800\n",
            "Epoch 660/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.5797\n",
            "Epoch 661/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.5798\n",
            "Epoch 662/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4818 - val_loss: 0.5806\n",
            "Epoch 663/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5803\n",
            "Epoch 664/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4817 - val_loss: 0.5806\n",
            "Epoch 665/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.5807\n",
            "Epoch 666/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5813\n",
            "Epoch 667/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4826 - val_loss: 0.5811\n",
            "Epoch 668/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5799\n",
            "Epoch 669/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5817\n",
            "Epoch 670/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.5803\n",
            "Epoch 671/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5812\n",
            "Epoch 672/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4814 - val_loss: 0.5812\n",
            "Epoch 673/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4807 - val_loss: 0.5807\n",
            "Epoch 674/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4809 - val_loss: 0.5819\n",
            "Epoch 675/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5803\n",
            "Epoch 676/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.5801\n",
            "Epoch 677/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5804\n",
            "Epoch 678/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 0.5806\n",
            "Epoch 679/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5800\n",
            "Epoch 680/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5807\n",
            "Epoch 681/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4809 - val_loss: 0.5812\n",
            "Epoch 682/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 0.5813\n",
            "Epoch 683/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4804 - val_loss: 0.5813\n",
            "Epoch 684/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4809 - val_loss: 0.5803\n",
            "Epoch 685/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5787\n",
            "Epoch 686/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5806\n",
            "Epoch 687/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.5796\n",
            "Epoch 688/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.5798\n",
            "Epoch 689/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4806 - val_loss: 0.5794\n",
            "Epoch 690/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5811\n",
            "Epoch 691/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4802 - val_loss: 0.5809\n",
            "Epoch 692/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4806 - val_loss: 0.5800\n",
            "Epoch 693/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4809 - val_loss: 0.5802\n",
            "Epoch 694/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 0.5804\n",
            "Epoch 695/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4809 - val_loss: 0.5796\n",
            "Epoch 696/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4814 - val_loss: 0.5794\n",
            "Epoch 697/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5785\n",
            "Epoch 698/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.5787\n",
            "Epoch 699/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5797\n",
            "Epoch 700/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4806 - val_loss: 0.5792\n",
            "Epoch 701/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4806 - val_loss: 0.5802\n",
            "Epoch 702/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5796\n",
            "Epoch 703/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4801 - val_loss: 0.5800\n",
            "Epoch 704/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4806 - val_loss: 0.5788\n",
            "Epoch 705/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.5799\n",
            "Epoch 706/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5802\n",
            "Epoch 707/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4799 - val_loss: 0.5800\n",
            "Epoch 708/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4801 - val_loss: 0.5803\n",
            "Epoch 709/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4802 - val_loss: 0.5799\n",
            "Epoch 710/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5803\n",
            "Epoch 711/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4798 - val_loss: 0.5806\n",
            "Epoch 712/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4798 - val_loss: 0.5797\n",
            "Epoch 713/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5791\n",
            "Epoch 714/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4801 - val_loss: 0.5791\n",
            "Epoch 715/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5794\n",
            "Epoch 716/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5792\n",
            "Epoch 717/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4794 - val_loss: 0.5797\n",
            "Epoch 718/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4801 - val_loss: 0.5795\n",
            "Epoch 719/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5805\n",
            "Epoch 720/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5799\n",
            "Epoch 721/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4798 - val_loss: 0.5804\n",
            "Epoch 722/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4793 - val_loss: 0.5798\n",
            "Epoch 723/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5802\n",
            "Epoch 724/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4802 - val_loss: 0.5802\n",
            "Epoch 725/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4804 - val_loss: 0.5806\n",
            "Epoch 726/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4796 - val_loss: 0.5808\n",
            "Epoch 727/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5797\n",
            "Epoch 728/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4798 - val_loss: 0.5809\n",
            "Epoch 729/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4794 - val_loss: 0.5811\n",
            "Epoch 730/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4802 - val_loss: 0.5805\n",
            "Epoch 731/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4796 - val_loss: 0.5795\n",
            "Epoch 732/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4798 - val_loss: 0.5804\n",
            "Epoch 733/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4799 - val_loss: 0.5806\n",
            "Epoch 734/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4804 - val_loss: 0.5792\n",
            "Epoch 735/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5807\n",
            "Epoch 736/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4792 - val_loss: 0.5809\n",
            "Epoch 737/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5794\n",
            "Epoch 738/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4792 - val_loss: 0.5794\n",
            "Epoch 739/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5800\n",
            "Epoch 740/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4795 - val_loss: 0.5790\n",
            "Epoch 741/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4793 - val_loss: 0.5787\n",
            "Epoch 742/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4795 - val_loss: 0.5788\n",
            "Epoch 743/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4796 - val_loss: 0.5792\n",
            "Epoch 744/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4790 - val_loss: 0.5803\n",
            "Epoch 745/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 0.5808\n",
            "Epoch 746/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4792 - val_loss: 0.5794\n",
            "Epoch 747/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4792 - val_loss: 0.5788\n",
            "Epoch 748/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4793 - val_loss: 0.5796\n",
            "Epoch 749/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5801\n",
            "Epoch 750/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4795 - val_loss: 0.5812\n",
            "Epoch 751/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4791 - val_loss: 0.5807\n",
            "Epoch 752/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4793 - val_loss: 0.5793\n",
            "Epoch 753/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4801 - val_loss: 0.5805\n",
            "Epoch 754/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4788 - val_loss: 0.5802\n",
            "Epoch 755/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4792 - val_loss: 0.5805\n",
            "Epoch 756/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4794 - val_loss: 0.5797\n",
            "Epoch 757/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4788 - val_loss: 0.5807\n",
            "Epoch 758/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.5804\n",
            "Epoch 759/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 0.5798\n",
            "Epoch 760/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.5790\n",
            "Epoch 761/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4790 - val_loss: 0.5797\n",
            "Epoch 762/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4788 - val_loss: 0.5798\n",
            "Epoch 763/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.5797\n",
            "Epoch 764/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4780 - val_loss: 0.5799\n",
            "Epoch 765/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.5798\n",
            "Epoch 766/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 0.5806\n",
            "Epoch 767/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.5805\n",
            "Epoch 768/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.5798\n",
            "Epoch 769/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.5807\n",
            "Epoch 770/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.5794\n",
            "Epoch 771/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.5810\n",
            "Epoch 772/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4788 - val_loss: 0.5797\n",
            "Epoch 773/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.5799\n",
            "Epoch 774/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.5807\n",
            "Epoch 775/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4788 - val_loss: 0.5805\n",
            "Epoch 776/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.5808\n",
            "Epoch 777/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4796 - val_loss: 0.5813\n",
            "Epoch 778/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.5813\n",
            "Epoch 779/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.5805\n",
            "Epoch 780/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.5802\n",
            "Epoch 781/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.5800\n",
            "Epoch 782/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4780 - val_loss: 0.5800\n",
            "Epoch 783/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.5806\n",
            "Epoch 784/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.5811\n",
            "Epoch 785/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4778 - val_loss: 0.5802\n",
            "Epoch 786/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.5800\n",
            "Epoch 787/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.5801\n",
            "Epoch 788/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.5805\n",
            "Epoch 789/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.5791\n",
            "Epoch 790/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.5807\n",
            "Epoch 791/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4792 - val_loss: 0.5810\n",
            "Epoch 792/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4780 - val_loss: 0.5808\n",
            "Epoch 793/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.5801\n",
            "Epoch 794/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.5801\n",
            "Epoch 795/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.5802\n",
            "Epoch 796/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.5799\n",
            "Epoch 797/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.5796\n",
            "Epoch 798/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.5796\n",
            "Epoch 799/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.5802\n",
            "Epoch 800/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4779 - val_loss: 0.5800\n",
            "Epoch 801/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4780 - val_loss: 0.5786\n",
            "Epoch 802/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.5796\n",
            "Epoch 803/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4774 - val_loss: 0.5796\n",
            "Epoch 804/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4775 - val_loss: 0.5791\n",
            "Epoch 805/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.5797\n",
            "Epoch 806/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4775 - val_loss: 0.5800\n",
            "Epoch 807/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.5786\n",
            "Epoch 808/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4779 - val_loss: 0.5785\n",
            "Epoch 809/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.5794\n",
            "Epoch 810/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.5801\n",
            "Epoch 811/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.5806\n",
            "Epoch 812/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4780 - val_loss: 0.5803\n",
            "Epoch 813/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.5801\n",
            "Epoch 814/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.5798\n",
            "Epoch 815/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.5802\n",
            "Epoch 816/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4775 - val_loss: 0.5797\n",
            "Epoch 817/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.5808\n",
            "Epoch 818/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.5797\n",
            "Epoch 819/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4778 - val_loss: 0.5791\n",
            "Epoch 820/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4775 - val_loss: 0.5795\n",
            "Epoch 821/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.5802\n",
            "Epoch 822/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.5805\n",
            "Epoch 823/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4774 - val_loss: 0.5802\n",
            "Epoch 824/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.5800\n",
            "Epoch 825/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4780 - val_loss: 0.5797\n",
            "Epoch 826/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.5793\n",
            "Epoch 827/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4773 - val_loss: 0.5790\n",
            "Epoch 828/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.5795\n",
            "Epoch 829/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4775 - val_loss: 0.5791\n",
            "Epoch 830/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.5788\n",
            "Epoch 831/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.5786\n",
            "Epoch 832/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4778 - val_loss: 0.5783\n",
            "Epoch 833/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.5784\n",
            "Epoch 834/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4774 - val_loss: 0.5785\n",
            "Epoch 835/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.5798\n",
            "Epoch 836/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.5784\n",
            "Epoch 837/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4778 - val_loss: 0.5787\n",
            "Epoch 838/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.5791\n",
            "Epoch 839/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.5800\n",
            "Epoch 840/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4771 - val_loss: 0.5786\n",
            "Epoch 841/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.5792\n",
            "Epoch 842/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4775 - val_loss: 0.5789\n",
            "Epoch 843/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.5792\n",
            "Epoch 844/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4769 - val_loss: 0.5797\n",
            "Epoch 845/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4775 - val_loss: 0.5787\n",
            "Epoch 846/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4773 - val_loss: 0.5792\n",
            "Epoch 847/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.5797\n",
            "Epoch 848/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 0.5810\n",
            "Epoch 849/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.5792\n",
            "Epoch 850/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4773 - val_loss: 0.5798\n",
            "Epoch 851/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 0.5803\n",
            "Epoch 852/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.5791\n",
            "Epoch 853/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.5787\n",
            "Epoch 854/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.5793\n",
            "Epoch 855/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4769 - val_loss: 0.5788\n",
            "Epoch 856/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.5794\n",
            "Epoch 857/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.5790\n",
            "Epoch 858/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4773 - val_loss: 0.5803\n",
            "Epoch 859/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.5805\n",
            "Epoch 860/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.5797\n",
            "Epoch 861/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4771 - val_loss: 0.5797\n",
            "Epoch 862/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4769 - val_loss: 0.5793\n",
            "Epoch 863/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4771 - val_loss: 0.5787\n",
            "Epoch 864/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 0.5792\n",
            "Epoch 865/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.5790\n",
            "Epoch 866/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.5790\n",
            "Epoch 867/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.5790\n",
            "Epoch 868/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4769 - val_loss: 0.5794\n",
            "Epoch 869/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.5796\n",
            "Epoch 870/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4767 - val_loss: 0.5799\n",
            "Epoch 871/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.5789\n",
            "Epoch 872/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.5794\n",
            "Epoch 873/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 0.5785\n",
            "Epoch 874/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.5791\n",
            "Epoch 875/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 0.5786\n",
            "Epoch 876/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4774 - val_loss: 0.5776\n",
            "Epoch 877/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4769 - val_loss: 0.5795\n",
            "Epoch 878/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4769 - val_loss: 0.5784\n",
            "Epoch 879/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.5782\n",
            "Epoch 880/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.5787\n",
            "Epoch 881/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.5785\n",
            "Epoch 882/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 0.5785\n",
            "Epoch 883/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.5780\n",
            "Epoch 884/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 0.5787\n",
            "Epoch 885/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.5793\n",
            "Epoch 886/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 0.5785\n",
            "Epoch 887/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 0.5788\n",
            "Epoch 888/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4767 - val_loss: 0.5776\n",
            "Epoch 889/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.5786\n",
            "Epoch 890/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.5778\n",
            "Epoch 891/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.5783\n",
            "Epoch 892/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4757 - val_loss: 0.5789\n",
            "Epoch 893/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.5781\n",
            "Epoch 894/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4757 - val_loss: 0.5778\n",
            "Epoch 895/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.5793\n",
            "Epoch 896/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5780\n",
            "Epoch 897/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.5775\n",
            "Epoch 898/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4762 - val_loss: 0.5773\n",
            "Epoch 899/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 0.5774\n",
            "Epoch 900/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 0.5786\n",
            "Epoch 901/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5778\n",
            "Epoch 902/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.5778\n",
            "Epoch 903/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 0.5776\n",
            "Epoch 904/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.5772\n",
            "Epoch 905/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4757 - val_loss: 0.5777\n",
            "Epoch 906/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5772\n",
            "Epoch 907/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.5768\n",
            "Epoch 908/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5767\n",
            "Epoch 909/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4762 - val_loss: 0.5760\n",
            "Epoch 910/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.5775\n",
            "Epoch 911/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.5772\n",
            "Epoch 912/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5776\n",
            "Epoch 913/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5796\n",
            "Epoch 914/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4757 - val_loss: 0.5776\n",
            "Epoch 915/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 0.5767\n",
            "Epoch 916/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5765\n",
            "Epoch 917/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5773\n",
            "Epoch 918/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5774\n",
            "Epoch 919/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5778\n",
            "Epoch 920/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.5772\n",
            "Epoch 921/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5775\n",
            "Epoch 922/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.5777\n",
            "Epoch 923/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4754 - val_loss: 0.5779\n",
            "Epoch 924/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4757 - val_loss: 0.5769\n",
            "Epoch 925/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.5775\n",
            "Epoch 926/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.5769\n",
            "Epoch 927/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4757 - val_loss: 0.5771\n",
            "Epoch 928/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.5773\n",
            "Epoch 929/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5776\n",
            "Epoch 930/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5774\n",
            "Epoch 931/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5772\n",
            "Epoch 932/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5763\n",
            "Epoch 933/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.5768\n",
            "Epoch 934/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 0.5761\n",
            "Epoch 935/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.5778\n",
            "Epoch 936/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5761\n",
            "Epoch 937/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 0.5761\n",
            "Epoch 938/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4754 - val_loss: 0.5773\n",
            "Epoch 939/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4750 - val_loss: 0.5778\n",
            "Epoch 940/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5770\n",
            "Epoch 941/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5779\n",
            "Epoch 942/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4757 - val_loss: 0.5762\n",
            "Epoch 943/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5756\n",
            "Epoch 944/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4750 - val_loss: 0.5764\n",
            "Epoch 945/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4748 - val_loss: 0.5764\n",
            "Epoch 946/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.5765\n",
            "Epoch 947/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5769\n",
            "Epoch 948/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5773\n",
            "Epoch 949/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4754 - val_loss: 0.5782\n",
            "Epoch 950/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.5775\n",
            "Epoch 951/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 0.5763\n",
            "Epoch 952/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.5768\n",
            "Epoch 953/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.5772\n",
            "Epoch 954/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5768\n",
            "Epoch 955/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.5778\n",
            "Epoch 956/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.5774\n",
            "Epoch 957/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4748 - val_loss: 0.5774\n",
            "Epoch 958/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4748 - val_loss: 0.5765\n",
            "Epoch 959/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.5771\n",
            "Epoch 960/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.5766\n",
            "Epoch 961/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5775\n",
            "Epoch 962/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.5769\n",
            "Epoch 963/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.5777\n",
            "Epoch 964/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4748 - val_loss: 0.5771\n",
            "Epoch 965/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.5775\n",
            "Epoch 966/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.5768\n",
            "Epoch 967/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5768\n",
            "Epoch 968/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4748 - val_loss: 0.5768\n",
            "Epoch 969/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4762 - val_loss: 0.5775\n",
            "Epoch 970/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.5769\n",
            "Epoch 971/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.5768\n",
            "Epoch 972/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.5759\n",
            "Epoch 973/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.5766\n",
            "Epoch 974/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4754 - val_loss: 0.5774\n",
            "Epoch 975/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4750 - val_loss: 0.5784\n",
            "Epoch 976/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.5777\n",
            "Epoch 977/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4748 - val_loss: 0.5779\n",
            "Epoch 978/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.5760\n",
            "Epoch 979/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4748 - val_loss: 0.5768\n",
            "Epoch 980/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.5770\n",
            "Epoch 981/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.5758\n",
            "Epoch 982/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.5772\n",
            "Epoch 983/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.5774\n",
            "Epoch 984/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.5774\n",
            "Epoch 985/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.5794\n",
            "Epoch 986/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.5797\n",
            "Epoch 987/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 0.5785\n",
            "Epoch 988/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.5769\n",
            "Epoch 989/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 0.5757\n",
            "Epoch 990/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.5771\n",
            "Epoch 991/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.5783\n",
            "Epoch 992/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.5780\n",
            "Epoch 993/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4750 - val_loss: 0.5794\n",
            "Epoch 994/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.5770\n",
            "Epoch 995/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4743 - val_loss: 0.5767\n",
            "Epoch 996/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.5775\n",
            "Epoch 997/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.5766\n",
            "Epoch 998/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4755 - val_loss: 0.5767\n",
            "Epoch 999/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4754 - val_loss: 0.5769\n",
            "Epoch 1000/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.5765\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m0HTO_SxKXT"
      },
      "source": [
        "####Adadelta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i93mW6DfxMY0",
        "outputId": "d784a1bc-e939-4164-c179-7b4d71025cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "deep_mode3(opt_Adadelta)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 2/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 3/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 4/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 5/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 6/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 7/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 8/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 9/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 10/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 11/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 12/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 13/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 14/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 15/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 16/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 17/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 18/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 19/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 20/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 21/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 22/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 23/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 24/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 25/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 1.0000\n",
            "Epoch 26/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 0.9999\n",
            "Epoch 27/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 0.9999\n",
            "Epoch 28/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 0.9999\n",
            "Epoch 29/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 0.9999\n",
            "Epoch 30/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 0.9999\n",
            "Epoch 31/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 0.9999\n",
            "Epoch 32/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 1.0000 - val_loss: 0.9999\n",
            "Epoch 33/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 34/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 35/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 36/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 37/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 38/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 39/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 40/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 41/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 42/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 43/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 44/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 45/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 46/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 47/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 48/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 49/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 50/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 51/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 52/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 53/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 54/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 55/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 56/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 57/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 58/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 59/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 60/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 61/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 62/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 63/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 64/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 65/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 66/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 67/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 68/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 69/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 70/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 71/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 72/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 73/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 74/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 75/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 76/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 77/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 78/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 79/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 80/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9999\n",
            "Epoch 81/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9998\n",
            "Epoch 82/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9998\n",
            "Epoch 83/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9998\n",
            "Epoch 84/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9998\n",
            "Epoch 85/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9998\n",
            "Epoch 86/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9998\n",
            "Epoch 87/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9998\n",
            "Epoch 88/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9998\n",
            "Epoch 89/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9998\n",
            "Epoch 90/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9999 - val_loss: 0.9998\n",
            "Epoch 91/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 92/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 93/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 94/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 95/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 96/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 97/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 98/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 99/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 100/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 101/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 102/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 103/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 104/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 105/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 106/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 107/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 108/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 109/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 110/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 111/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 112/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 113/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 114/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 115/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 116/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 117/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 118/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 119/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 120/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 121/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 122/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 123/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 124/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 125/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 126/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 127/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 128/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 129/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 130/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9998\n",
            "Epoch 131/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9997\n",
            "Epoch 132/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9997\n",
            "Epoch 133/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9997\n",
            "Epoch 134/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9997\n",
            "Epoch 135/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9997\n",
            "Epoch 136/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9997\n",
            "Epoch 137/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9997\n",
            "Epoch 138/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9997\n",
            "Epoch 139/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9997\n",
            "Epoch 140/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9997\n",
            "Epoch 141/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9997\n",
            "Epoch 142/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9998 - val_loss: 0.9997\n",
            "Epoch 143/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 144/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 145/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 146/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 147/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 148/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 149/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 150/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 151/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 152/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 153/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 154/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 155/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 156/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 157/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 158/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 159/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 160/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 161/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 162/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 163/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 164/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 165/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 166/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 167/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 168/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 169/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9997\n",
            "Epoch 170/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9996\n",
            "Epoch 171/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9996\n",
            "Epoch 172/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9996\n",
            "Epoch 173/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9996\n",
            "Epoch 174/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9996\n",
            "Epoch 175/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9996\n",
            "Epoch 176/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9996\n",
            "Epoch 177/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9996\n",
            "Epoch 178/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9996\n",
            "Epoch 179/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9996\n",
            "Epoch 180/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9996\n",
            "Epoch 181/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9996\n",
            "Epoch 182/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 0.9996\n",
            "Epoch 183/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 184/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 185/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 186/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 187/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 188/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 189/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 190/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 191/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 192/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 193/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 194/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 195/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 196/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 197/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 198/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 199/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 200/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 201/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 202/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 203/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 204/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9996\n",
            "Epoch 205/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9995\n",
            "Epoch 206/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9995\n",
            "Epoch 207/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9995\n",
            "Epoch 208/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9995\n",
            "Epoch 209/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9995\n",
            "Epoch 210/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9995\n",
            "Epoch 211/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9995\n",
            "Epoch 212/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9995\n",
            "Epoch 213/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9995\n",
            "Epoch 214/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9995\n",
            "Epoch 215/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9995\n",
            "Epoch 216/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9995\n",
            "Epoch 217/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9996 - val_loss: 0.9995\n",
            "Epoch 218/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 219/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 220/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 221/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 222/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 223/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 224/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 225/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 226/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 227/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 228/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 229/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 230/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 231/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 232/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 233/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 234/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 235/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 236/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9995\n",
            "Epoch 237/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9994\n",
            "Epoch 238/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9994\n",
            "Epoch 239/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9994\n",
            "Epoch 240/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9994\n",
            "Epoch 241/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9994\n",
            "Epoch 242/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9994\n",
            "Epoch 243/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9994\n",
            "Epoch 244/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9994\n",
            "Epoch 245/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9994\n",
            "Epoch 246/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9994\n",
            "Epoch 247/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9995 - val_loss: 0.9994\n",
            "Epoch 248/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9994\n",
            "Epoch 249/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9994\n",
            "Epoch 250/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9994\n",
            "Epoch 251/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9994\n",
            "Epoch 252/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9994\n",
            "Epoch 253/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9994\n",
            "Epoch 254/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9994\n",
            "Epoch 255/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9994\n",
            "Epoch 256/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9994\n",
            "Epoch 257/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9994\n",
            "Epoch 258/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9994\n",
            "Epoch 259/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9994\n",
            "Epoch 260/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9994\n",
            "Epoch 261/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9994\n",
            "Epoch 262/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9994\n",
            "Epoch 263/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9993\n",
            "Epoch 264/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9993\n",
            "Epoch 265/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9993\n",
            "Epoch 266/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9993\n",
            "Epoch 267/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9993\n",
            "Epoch 268/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9993\n",
            "Epoch 269/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9993\n",
            "Epoch 270/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9993\n",
            "Epoch 271/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9993\n",
            "Epoch 272/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9993\n",
            "Epoch 273/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9993\n",
            "Epoch 274/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.9993\n",
            "Epoch 275/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9993\n",
            "Epoch 276/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9993\n",
            "Epoch 277/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9993\n",
            "Epoch 278/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9993\n",
            "Epoch 279/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9993\n",
            "Epoch 280/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9993\n",
            "Epoch 281/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9993\n",
            "Epoch 282/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9993\n",
            "Epoch 283/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9993\n",
            "Epoch 284/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9993\n",
            "Epoch 285/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9993\n",
            "Epoch 286/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9993\n",
            "Epoch 287/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9992\n",
            "Epoch 288/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9992\n",
            "Epoch 289/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9992\n",
            "Epoch 290/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9992\n",
            "Epoch 291/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9992\n",
            "Epoch 292/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9992\n",
            "Epoch 293/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9992\n",
            "Epoch 294/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9992\n",
            "Epoch 295/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9992\n",
            "Epoch 296/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9992\n",
            "Epoch 297/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9992\n",
            "Epoch 298/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9993 - val_loss: 0.9992\n",
            "Epoch 299/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9992\n",
            "Epoch 300/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9992\n",
            "Epoch 301/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9992\n",
            "Epoch 302/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9992\n",
            "Epoch 303/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9992\n",
            "Epoch 304/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9992\n",
            "Epoch 305/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9992\n",
            "Epoch 306/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9992\n",
            "Epoch 307/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9992\n",
            "Epoch 308/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9992\n",
            "Epoch 309/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9992\n",
            "Epoch 310/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9991\n",
            "Epoch 311/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9991\n",
            "Epoch 312/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9991\n",
            "Epoch 313/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9991\n",
            "Epoch 314/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9991\n",
            "Epoch 315/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9991\n",
            "Epoch 316/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9991\n",
            "Epoch 317/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9991\n",
            "Epoch 318/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9991\n",
            "Epoch 319/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9991\n",
            "Epoch 320/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9991\n",
            "Epoch 321/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9991\n",
            "Epoch 322/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9991\n",
            "Epoch 323/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9991\n",
            "Epoch 324/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9991\n",
            "Epoch 325/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9991\n",
            "Epoch 326/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9991\n",
            "Epoch 327/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9991\n",
            "Epoch 328/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9991\n",
            "Epoch 329/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9991\n",
            "Epoch 330/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9991\n",
            "Epoch 331/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9990\n",
            "Epoch 332/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9990\n",
            "Epoch 333/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9990\n",
            "Epoch 334/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9990\n",
            "Epoch 335/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9990\n",
            "Epoch 336/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9990\n",
            "Epoch 337/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9990\n",
            "Epoch 338/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9990\n",
            "Epoch 339/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9990\n",
            "Epoch 340/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9990\n",
            "Epoch 341/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9990\n",
            "Epoch 342/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9991 - val_loss: 0.9990\n",
            "Epoch 343/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9990\n",
            "Epoch 344/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9990\n",
            "Epoch 345/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9990\n",
            "Epoch 346/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9990\n",
            "Epoch 347/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9990\n",
            "Epoch 348/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9990\n",
            "Epoch 349/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9990\n",
            "Epoch 350/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9990\n",
            "Epoch 351/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9989\n",
            "Epoch 352/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9989\n",
            "Epoch 353/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9989\n",
            "Epoch 354/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9989\n",
            "Epoch 355/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9989\n",
            "Epoch 356/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9989\n",
            "Epoch 357/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9989\n",
            "Epoch 358/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9989\n",
            "Epoch 359/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9989\n",
            "Epoch 360/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9989\n",
            "Epoch 361/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.9989\n",
            "Epoch 362/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9989\n",
            "Epoch 363/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9989\n",
            "Epoch 364/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9989\n",
            "Epoch 365/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9989\n",
            "Epoch 366/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9989\n",
            "Epoch 367/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9989\n",
            "Epoch 368/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9989\n",
            "Epoch 369/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9989\n",
            "Epoch 370/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9988\n",
            "Epoch 371/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9988\n",
            "Epoch 372/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9988\n",
            "Epoch 373/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9988\n",
            "Epoch 374/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9988\n",
            "Epoch 375/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9988\n",
            "Epoch 376/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9988\n",
            "Epoch 377/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9988\n",
            "Epoch 378/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9988\n",
            "Epoch 379/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9989 - val_loss: 0.9988\n",
            "Epoch 380/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9988\n",
            "Epoch 381/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9988\n",
            "Epoch 382/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9988\n",
            "Epoch 383/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9988\n",
            "Epoch 384/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9988\n",
            "Epoch 385/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9988\n",
            "Epoch 386/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9988\n",
            "Epoch 387/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9988\n",
            "Epoch 388/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9988\n",
            "Epoch 389/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9987\n",
            "Epoch 390/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9987\n",
            "Epoch 391/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9987\n",
            "Epoch 392/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9987\n",
            "Epoch 393/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9987\n",
            "Epoch 394/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9987\n",
            "Epoch 395/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9987\n",
            "Epoch 396/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9988 - val_loss: 0.9987\n",
            "Epoch 397/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9987\n",
            "Epoch 398/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9987\n",
            "Epoch 399/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9987\n",
            "Epoch 400/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9987\n",
            "Epoch 401/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9987\n",
            "Epoch 402/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9987\n",
            "Epoch 403/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9987\n",
            "Epoch 404/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9987\n",
            "Epoch 405/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9987\n",
            "Epoch 406/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9986\n",
            "Epoch 407/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9986\n",
            "Epoch 408/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9986\n",
            "Epoch 409/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9986\n",
            "Epoch 410/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9986\n",
            "Epoch 411/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9986\n",
            "Epoch 412/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9987 - val_loss: 0.9986\n",
            "Epoch 413/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9986\n",
            "Epoch 414/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9986\n",
            "Epoch 415/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9986\n",
            "Epoch 416/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9986\n",
            "Epoch 417/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9986\n",
            "Epoch 418/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9986\n",
            "Epoch 419/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9986\n",
            "Epoch 420/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9986\n",
            "Epoch 421/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9986\n",
            "Epoch 422/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9985\n",
            "Epoch 423/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9985\n",
            "Epoch 424/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9985\n",
            "Epoch 425/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9985\n",
            "Epoch 426/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9985\n",
            "Epoch 427/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9985\n",
            "Epoch 428/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9986 - val_loss: 0.9985\n",
            "Epoch 429/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9985\n",
            "Epoch 430/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9985\n",
            "Epoch 431/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9985\n",
            "Epoch 432/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9985\n",
            "Epoch 433/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9985\n",
            "Epoch 434/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9985\n",
            "Epoch 435/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9985\n",
            "Epoch 436/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9985\n",
            "Epoch 437/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9984\n",
            "Epoch 438/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9984\n",
            "Epoch 439/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9984\n",
            "Epoch 440/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9984\n",
            "Epoch 441/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9984\n",
            "Epoch 442/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9984\n",
            "Epoch 443/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.9984\n",
            "Epoch 444/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 0.9984\n",
            "Epoch 445/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 0.9984\n",
            "Epoch 446/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 0.9984\n",
            "Epoch 447/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 0.9984\n",
            "Epoch 448/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 0.9984\n",
            "Epoch 449/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 0.9984\n",
            "Epoch 450/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 0.9984\n",
            "Epoch 451/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 0.9984\n",
            "Epoch 452/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 0.9984\n",
            "Epoch 453/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 0.9983\n",
            "Epoch 454/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 0.9983\n",
            "Epoch 455/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 0.9983\n",
            "Epoch 456/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 0.9983\n",
            "Epoch 457/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9984 - val_loss: 0.9983\n",
            "Epoch 458/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 0.9983\n",
            "Epoch 459/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 0.9983\n",
            "Epoch 460/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 0.9983\n",
            "Epoch 461/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 0.9983\n",
            "Epoch 462/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 0.9983\n",
            "Epoch 463/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 0.9983\n",
            "Epoch 464/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 0.9983\n",
            "Epoch 465/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 0.9983\n",
            "Epoch 466/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 0.9983\n",
            "Epoch 467/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 0.9982\n",
            "Epoch 468/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 0.9982\n",
            "Epoch 469/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 0.9982\n",
            "Epoch 470/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 0.9982\n",
            "Epoch 471/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9983 - val_loss: 0.9982\n",
            "Epoch 472/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 0.9982\n",
            "Epoch 473/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 0.9982\n",
            "Epoch 474/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 0.9982\n",
            "Epoch 475/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 0.9982\n",
            "Epoch 476/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 0.9982\n",
            "Epoch 477/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 0.9982\n",
            "Epoch 478/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 0.9982\n",
            "Epoch 479/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 0.9982\n",
            "Epoch 480/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 0.9982\n",
            "Epoch 481/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 0.9981\n",
            "Epoch 482/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 0.9981\n",
            "Epoch 483/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 0.9981\n",
            "Epoch 484/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9982 - val_loss: 0.9981\n",
            "Epoch 485/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9981\n",
            "Epoch 486/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9981\n",
            "Epoch 487/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9981\n",
            "Epoch 488/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9981\n",
            "Epoch 489/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9981\n",
            "Epoch 490/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9981\n",
            "Epoch 491/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9981\n",
            "Epoch 492/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9981\n",
            "Epoch 493/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9981\n",
            "Epoch 494/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9980\n",
            "Epoch 495/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9980\n",
            "Epoch 496/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9980\n",
            "Epoch 497/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9981 - val_loss: 0.9980\n",
            "Epoch 498/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 0.9980\n",
            "Epoch 499/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 0.9980\n",
            "Epoch 500/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 0.9980\n",
            "Epoch 501/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 0.9980\n",
            "Epoch 502/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 0.9980\n",
            "Epoch 503/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 0.9980\n",
            "Epoch 504/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 0.9980\n",
            "Epoch 505/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 0.9980\n",
            "Epoch 506/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 0.9980\n",
            "Epoch 507/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 0.9979\n",
            "Epoch 508/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 0.9979\n",
            "Epoch 509/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 0.9979\n",
            "Epoch 510/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 0.9979\n",
            "Epoch 511/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 0.9979\n",
            "Epoch 512/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 0.9979\n",
            "Epoch 513/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 0.9979\n",
            "Epoch 514/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 0.9979\n",
            "Epoch 515/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 0.9979\n",
            "Epoch 516/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 0.9979\n",
            "Epoch 517/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 0.9979\n",
            "Epoch 518/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 0.9979\n",
            "Epoch 519/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 0.9978\n",
            "Epoch 520/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 0.9978\n",
            "Epoch 521/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9979 - val_loss: 0.9978\n",
            "Epoch 522/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 0.9978\n",
            "Epoch 523/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 0.9978\n",
            "Epoch 524/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 0.9978\n",
            "Epoch 525/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 0.9978\n",
            "Epoch 526/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 0.9978\n",
            "Epoch 527/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 0.9978\n",
            "Epoch 528/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 0.9978\n",
            "Epoch 529/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 0.9978\n",
            "Epoch 530/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 0.9978\n",
            "Epoch 531/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 0.9978\n",
            "Epoch 532/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 0.9977\n",
            "Epoch 533/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9978 - val_loss: 0.9977\n",
            "Epoch 534/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 0.9977\n",
            "Epoch 535/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 0.9977\n",
            "Epoch 536/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 0.9977\n",
            "Epoch 537/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 0.9977\n",
            "Epoch 538/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 0.9977\n",
            "Epoch 539/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 0.9977\n",
            "Epoch 540/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 0.9977\n",
            "Epoch 541/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 0.9977\n",
            "Epoch 542/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 0.9977\n",
            "Epoch 543/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 0.9977\n",
            "Epoch 544/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9977 - val_loss: 0.9976\n",
            "Epoch 545/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 0.9976\n",
            "Epoch 546/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 0.9976\n",
            "Epoch 547/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 0.9976\n",
            "Epoch 548/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 0.9976\n",
            "Epoch 549/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 0.9976\n",
            "Epoch 550/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 0.9976\n",
            "Epoch 551/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 0.9976\n",
            "Epoch 552/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 0.9976\n",
            "Epoch 553/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 0.9976\n",
            "Epoch 554/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 0.9976\n",
            "Epoch 555/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9976 - val_loss: 0.9975\n",
            "Epoch 556/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 0.9975\n",
            "Epoch 557/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 0.9975\n",
            "Epoch 558/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 0.9975\n",
            "Epoch 559/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 0.9975\n",
            "Epoch 560/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 0.9975\n",
            "Epoch 561/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 0.9975\n",
            "Epoch 562/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 0.9975\n",
            "Epoch 563/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 0.9975\n",
            "Epoch 564/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 0.9975\n",
            "Epoch 565/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 0.9975\n",
            "Epoch 566/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 0.9974\n",
            "Epoch 567/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 0.9974\n",
            "Epoch 568/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 0.9974\n",
            "Epoch 569/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 0.9974\n",
            "Epoch 570/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 0.9974\n",
            "Epoch 571/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 0.9974\n",
            "Epoch 572/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 0.9974\n",
            "Epoch 573/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 0.9974\n",
            "Epoch 574/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 0.9974\n",
            "Epoch 575/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9974 - val_loss: 0.9974\n",
            "Epoch 576/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 0.9973\n",
            "Epoch 577/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 0.9973\n",
            "Epoch 578/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 0.9973\n",
            "Epoch 579/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 0.9973\n",
            "Epoch 580/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 0.9973\n",
            "Epoch 581/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 0.9973\n",
            "Epoch 582/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 0.9973\n",
            "Epoch 583/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 0.9973\n",
            "Epoch 584/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 0.9973\n",
            "Epoch 585/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9973 - val_loss: 0.9973\n",
            "Epoch 586/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 0.9972\n",
            "Epoch 587/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 0.9972\n",
            "Epoch 588/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 0.9972\n",
            "Epoch 589/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 0.9972\n",
            "Epoch 590/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 0.9972\n",
            "Epoch 591/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 0.9972\n",
            "Epoch 592/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 0.9972\n",
            "Epoch 593/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 0.9972\n",
            "Epoch 594/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 0.9972\n",
            "Epoch 595/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9972 - val_loss: 0.9972\n",
            "Epoch 596/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 0.9971\n",
            "Epoch 597/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 0.9971\n",
            "Epoch 598/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 0.9971\n",
            "Epoch 599/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 0.9971\n",
            "Epoch 600/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 0.9971\n",
            "Epoch 601/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 0.9971\n",
            "Epoch 602/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 0.9971\n",
            "Epoch 603/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 0.9971\n",
            "Epoch 604/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9971 - val_loss: 0.9971\n",
            "Epoch 605/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 0.9970\n",
            "Epoch 606/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 0.9970\n",
            "Epoch 607/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 0.9970\n",
            "Epoch 608/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 0.9970\n",
            "Epoch 609/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 0.9970\n",
            "Epoch 610/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 0.9970\n",
            "Epoch 611/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 0.9970\n",
            "Epoch 612/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 0.9970\n",
            "Epoch 613/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 0.9970\n",
            "Epoch 614/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 0.9969\n",
            "Epoch 615/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 0.9969\n",
            "Epoch 616/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 0.9969\n",
            "Epoch 617/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 0.9969\n",
            "Epoch 618/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 0.9969\n",
            "Epoch 619/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 0.9969\n",
            "Epoch 620/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 0.9969\n",
            "Epoch 621/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 0.9969\n",
            "Epoch 622/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9969 - val_loss: 0.9969\n",
            "Epoch 623/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9968 - val_loss: 0.9968\n",
            "Epoch 624/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9968 - val_loss: 0.9968\n",
            "Epoch 625/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9968 - val_loss: 0.9968\n",
            "Epoch 626/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9968 - val_loss: 0.9968\n",
            "Epoch 627/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9968 - val_loss: 0.9968\n",
            "Epoch 628/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9968 - val_loss: 0.9968\n",
            "Epoch 629/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9968 - val_loss: 0.9968\n",
            "Epoch 630/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9968 - val_loss: 0.9968\n",
            "Epoch 631/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9967 - val_loss: 0.9968\n",
            "Epoch 632/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9967 - val_loss: 0.9967\n",
            "Epoch 633/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9967 - val_loss: 0.9967\n",
            "Epoch 634/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9967 - val_loss: 0.9967\n",
            "Epoch 635/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9967 - val_loss: 0.9967\n",
            "Epoch 636/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9967 - val_loss: 0.9967\n",
            "Epoch 637/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9967 - val_loss: 0.9967\n",
            "Epoch 638/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9967 - val_loss: 0.9967\n",
            "Epoch 639/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9966 - val_loss: 0.9967\n",
            "Epoch 640/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9966 - val_loss: 0.9966\n",
            "Epoch 641/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9966 - val_loss: 0.9966\n",
            "Epoch 642/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9966 - val_loss: 0.9966\n",
            "Epoch 643/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9966 - val_loss: 0.9966\n",
            "Epoch 644/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9966 - val_loss: 0.9966\n",
            "Epoch 645/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9966 - val_loss: 0.9966\n",
            "Epoch 646/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9966 - val_loss: 0.9966\n",
            "Epoch 647/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9965 - val_loss: 0.9966\n",
            "Epoch 648/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9965 - val_loss: 0.9965\n",
            "Epoch 649/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9965 - val_loss: 0.9965\n",
            "Epoch 650/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9965 - val_loss: 0.9965\n",
            "Epoch 651/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9965 - val_loss: 0.9965\n",
            "Epoch 652/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9965 - val_loss: 0.9965\n",
            "Epoch 653/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9965 - val_loss: 0.9965\n",
            "Epoch 654/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9965 - val_loss: 0.9965\n",
            "Epoch 655/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9964 - val_loss: 0.9964\n",
            "Epoch 656/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9964 - val_loss: 0.9964\n",
            "Epoch 657/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9964 - val_loss: 0.9964\n",
            "Epoch 658/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9964 - val_loss: 0.9964\n",
            "Epoch 659/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9964 - val_loss: 0.9964\n",
            "Epoch 660/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9964 - val_loss: 0.9964\n",
            "Epoch 661/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9963 - val_loss: 0.9964\n",
            "Epoch 662/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9963 - val_loss: 0.9964\n",
            "Epoch 663/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9963 - val_loss: 0.9963\n",
            "Epoch 664/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9963 - val_loss: 0.9963\n",
            "Epoch 665/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9963 - val_loss: 0.9963\n",
            "Epoch 666/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9963 - val_loss: 0.9963\n",
            "Epoch 667/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9963 - val_loss: 0.9963\n",
            "Epoch 668/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9962 - val_loss: 0.9963\n",
            "Epoch 669/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9962 - val_loss: 0.9963\n",
            "Epoch 670/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9962 - val_loss: 0.9962\n",
            "Epoch 671/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9962 - val_loss: 0.9962\n",
            "Epoch 672/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9962 - val_loss: 0.9962\n",
            "Epoch 673/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9962 - val_loss: 0.9962\n",
            "Epoch 674/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9962 - val_loss: 0.9962\n",
            "Epoch 675/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9961 - val_loss: 0.9962\n",
            "Epoch 676/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9961 - val_loss: 0.9962\n",
            "Epoch 677/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9961 - val_loss: 0.9961\n",
            "Epoch 678/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9961 - val_loss: 0.9961\n",
            "Epoch 679/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9961 - val_loss: 0.9961\n",
            "Epoch 680/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9961 - val_loss: 0.9961\n",
            "Epoch 681/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9960 - val_loss: 0.9961\n",
            "Epoch 682/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9960 - val_loss: 0.9961\n",
            "Epoch 683/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9960 - val_loss: 0.9961\n",
            "Epoch 684/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9960 - val_loss: 0.9960\n",
            "Epoch 685/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9960 - val_loss: 0.9960\n",
            "Epoch 686/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9960 - val_loss: 0.9960\n",
            "Epoch 687/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9960 - val_loss: 0.9960\n",
            "Epoch 688/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9959 - val_loss: 0.9960\n",
            "Epoch 689/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9959 - val_loss: 0.9960\n",
            "Epoch 690/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9959 - val_loss: 0.9959\n",
            "Epoch 691/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9959 - val_loss: 0.9959\n",
            "Epoch 692/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9959 - val_loss: 0.9959\n",
            "Epoch 693/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9959 - val_loss: 0.9959\n",
            "Epoch 694/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9958 - val_loss: 0.9959\n",
            "Epoch 695/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9958 - val_loss: 0.9959\n",
            "Epoch 696/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9958 - val_loss: 0.9958\n",
            "Epoch 697/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9958 - val_loss: 0.9958\n",
            "Epoch 698/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9958 - val_loss: 0.9958\n",
            "Epoch 699/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9958 - val_loss: 0.9958\n",
            "Epoch 700/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9957 - val_loss: 0.9958\n",
            "Epoch 701/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9957 - val_loss: 0.9958\n",
            "Epoch 702/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9957 - val_loss: 0.9958\n",
            "Epoch 703/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9957 - val_loss: 0.9957\n",
            "Epoch 704/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9957 - val_loss: 0.9957\n",
            "Epoch 705/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9957 - val_loss: 0.9957\n",
            "Epoch 706/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9956 - val_loss: 0.9957\n",
            "Epoch 707/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9956 - val_loss: 0.9957\n",
            "Epoch 708/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9956 - val_loss: 0.9957\n",
            "Epoch 709/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9956 - val_loss: 0.9956\n",
            "Epoch 710/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9956 - val_loss: 0.9956\n",
            "Epoch 711/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9956 - val_loss: 0.9956\n",
            "Epoch 712/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9955 - val_loss: 0.9956\n",
            "Epoch 713/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9955 - val_loss: 0.9956\n",
            "Epoch 714/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9955 - val_loss: 0.9956\n",
            "Epoch 715/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9955 - val_loss: 0.9956\n",
            "Epoch 716/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9955 - val_loss: 0.9955\n",
            "Epoch 717/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9955 - val_loss: 0.9955\n",
            "Epoch 718/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9954 - val_loss: 0.9955\n",
            "Epoch 719/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9954 - val_loss: 0.9955\n",
            "Epoch 720/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9954 - val_loss: 0.9955\n",
            "Epoch 721/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9954 - val_loss: 0.9955\n",
            "Epoch 722/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9954 - val_loss: 0.9954\n",
            "Epoch 723/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9954 - val_loss: 0.9954\n",
            "Epoch 724/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9953 - val_loss: 0.9954\n",
            "Epoch 725/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9953 - val_loss: 0.9954\n",
            "Epoch 726/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9953 - val_loss: 0.9954\n",
            "Epoch 727/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9953 - val_loss: 0.9954\n",
            "Epoch 728/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9953 - val_loss: 0.9953\n",
            "Epoch 729/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9953 - val_loss: 0.9953\n",
            "Epoch 730/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9952 - val_loss: 0.9953\n",
            "Epoch 731/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9952 - val_loss: 0.9953\n",
            "Epoch 732/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9952 - val_loss: 0.9953\n",
            "Epoch 733/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9952 - val_loss: 0.9953\n",
            "Epoch 734/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9952 - val_loss: 0.9953\n",
            "Epoch 735/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9952 - val_loss: 0.9952\n",
            "Epoch 736/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9951 - val_loss: 0.9952\n",
            "Epoch 737/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9951 - val_loss: 0.9952\n",
            "Epoch 738/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9951 - val_loss: 0.9952\n",
            "Epoch 739/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9951 - val_loss: 0.9952\n",
            "Epoch 740/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9951 - val_loss: 0.9952\n",
            "Epoch 741/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9951 - val_loss: 0.9951\n",
            "Epoch 742/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9950 - val_loss: 0.9951\n",
            "Epoch 743/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9950 - val_loss: 0.9951\n",
            "Epoch 744/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9950 - val_loss: 0.9951\n",
            "Epoch 745/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9950 - val_loss: 0.9951\n",
            "Epoch 746/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9950 - val_loss: 0.9951\n",
            "Epoch 747/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9949 - val_loss: 0.9950\n",
            "Epoch 748/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9949 - val_loss: 0.9950\n",
            "Epoch 749/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9949 - val_loss: 0.9950\n",
            "Epoch 750/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9949 - val_loss: 0.9950\n",
            "Epoch 751/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9949 - val_loss: 0.9950\n",
            "Epoch 752/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9949 - val_loss: 0.9950\n",
            "Epoch 753/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9948 - val_loss: 0.9949\n",
            "Epoch 754/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9948 - val_loss: 0.9949\n",
            "Epoch 755/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9948 - val_loss: 0.9949\n",
            "Epoch 756/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9948 - val_loss: 0.9949\n",
            "Epoch 757/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9948 - val_loss: 0.9949\n",
            "Epoch 758/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9948 - val_loss: 0.9949\n",
            "Epoch 759/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9947 - val_loss: 0.9948\n",
            "Epoch 760/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9947 - val_loss: 0.9948\n",
            "Epoch 761/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9947 - val_loss: 0.9948\n",
            "Epoch 762/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9947 - val_loss: 0.9948\n",
            "Epoch 763/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9947 - val_loss: 0.9948\n",
            "Epoch 764/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9946 - val_loss: 0.9948\n",
            "Epoch 765/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9946 - val_loss: 0.9947\n",
            "Epoch 766/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9946 - val_loss: 0.9947\n",
            "Epoch 767/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9946 - val_loss: 0.9947\n",
            "Epoch 768/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9946 - val_loss: 0.9947\n",
            "Epoch 769/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9946 - val_loss: 0.9947\n",
            "Epoch 770/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9945 - val_loss: 0.9947\n",
            "Epoch 771/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9945 - val_loss: 0.9946\n",
            "Epoch 772/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9945 - val_loss: 0.9946\n",
            "Epoch 773/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9945 - val_loss: 0.9946\n",
            "Epoch 774/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9945 - val_loss: 0.9946\n",
            "Epoch 775/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 0.9946\n",
            "Epoch 776/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 0.9946\n",
            "Epoch 777/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 0.9945\n",
            "Epoch 778/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 0.9945\n",
            "Epoch 779/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 0.9945\n",
            "Epoch 780/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 0.9945\n",
            "Epoch 781/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9943 - val_loss: 0.9945\n",
            "Epoch 782/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9943 - val_loss: 0.9945\n",
            "Epoch 783/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9943 - val_loss: 0.9944\n",
            "Epoch 784/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9943 - val_loss: 0.9944\n",
            "Epoch 785/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9943 - val_loss: 0.9944\n",
            "Epoch 786/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9942 - val_loss: 0.9944\n",
            "Epoch 787/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9942 - val_loss: 0.9944\n",
            "Epoch 788/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9942 - val_loss: 0.9943\n",
            "Epoch 789/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9942 - val_loss: 0.9943\n",
            "Epoch 790/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9942 - val_loss: 0.9943\n",
            "Epoch 791/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9941 - val_loss: 0.9943\n",
            "Epoch 792/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9941 - val_loss: 0.9943\n",
            "Epoch 793/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9941 - val_loss: 0.9943\n",
            "Epoch 794/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9941 - val_loss: 0.9942\n",
            "Epoch 795/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9941 - val_loss: 0.9942\n",
            "Epoch 796/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9940 - val_loss: 0.9942\n",
            "Epoch 797/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9940 - val_loss: 0.9942\n",
            "Epoch 798/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9940 - val_loss: 0.9942\n",
            "Epoch 799/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9940 - val_loss: 0.9941\n",
            "Epoch 800/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9940 - val_loss: 0.9941\n",
            "Epoch 801/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9940 - val_loss: 0.9941\n",
            "Epoch 802/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 0.9941\n",
            "Epoch 803/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 0.9941\n",
            "Epoch 804/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 0.9941\n",
            "Epoch 805/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 0.9940\n",
            "Epoch 806/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 0.9940\n",
            "Epoch 807/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 0.9940\n",
            "Epoch 808/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 0.9940\n",
            "Epoch 809/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 0.9940\n",
            "Epoch 810/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 0.9940\n",
            "Epoch 811/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9938 - val_loss: 0.9939\n",
            "Epoch 812/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9937 - val_loss: 0.9939\n",
            "Epoch 813/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9937 - val_loss: 0.9939\n",
            "Epoch 814/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9937 - val_loss: 0.9939\n",
            "Epoch 815/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9937 - val_loss: 0.9939\n",
            "Epoch 816/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9937 - val_loss: 0.9938\n",
            "Epoch 817/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9936 - val_loss: 0.9938\n",
            "Epoch 818/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9936 - val_loss: 0.9938\n",
            "Epoch 819/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9936 - val_loss: 0.9938\n",
            "Epoch 820/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9936 - val_loss: 0.9938\n",
            "Epoch 821/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9936 - val_loss: 0.9938\n",
            "Epoch 822/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 0.9937\n",
            "Epoch 823/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 0.9937\n",
            "Epoch 824/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 0.9937\n",
            "Epoch 825/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 0.9937\n",
            "Epoch 826/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9935 - val_loss: 0.9937\n",
            "Epoch 827/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 0.9936\n",
            "Epoch 828/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 0.9936\n",
            "Epoch 829/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 0.9936\n",
            "Epoch 830/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 0.9936\n",
            "Epoch 831/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9934 - val_loss: 0.9936\n",
            "Epoch 832/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 0.9935\n",
            "Epoch 833/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 0.9935\n",
            "Epoch 834/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 0.9935\n",
            "Epoch 835/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 0.9935\n",
            "Epoch 836/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9933 - val_loss: 0.9935\n",
            "Epoch 837/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 0.9934\n",
            "Epoch 838/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 0.9934\n",
            "Epoch 839/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 0.9934\n",
            "Epoch 840/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 0.9934\n",
            "Epoch 841/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 0.9934\n",
            "Epoch 842/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 0.9934\n",
            "Epoch 843/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 0.9933\n",
            "Epoch 844/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 0.9933\n",
            "Epoch 845/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9931 - val_loss: 0.9933\n",
            "Epoch 846/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 0.9933\n",
            "Epoch 847/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 0.9933\n",
            "Epoch 848/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 0.9932\n",
            "Epoch 849/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 0.9932\n",
            "Epoch 850/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9930 - val_loss: 0.9932\n",
            "Epoch 851/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 0.9932\n",
            "Epoch 852/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 0.9932\n",
            "Epoch 853/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 0.9931\n",
            "Epoch 854/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9929 - val_loss: 0.9931\n",
            "Epoch 855/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 0.9931\n",
            "Epoch 856/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 0.9931\n",
            "Epoch 857/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 0.9931\n",
            "Epoch 858/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 0.9930\n",
            "Epoch 859/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9928 - val_loss: 0.9930\n",
            "Epoch 860/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 0.9930\n",
            "Epoch 861/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 0.9930\n",
            "Epoch 862/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 0.9929\n",
            "Epoch 863/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9927 - val_loss: 0.9929\n",
            "Epoch 864/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9926 - val_loss: 0.9929\n",
            "Epoch 865/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9926 - val_loss: 0.9929\n",
            "Epoch 866/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9926 - val_loss: 0.9929\n",
            "Epoch 867/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9926 - val_loss: 0.9928\n",
            "Epoch 868/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9926 - val_loss: 0.9928\n",
            "Epoch 869/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9925 - val_loss: 0.9928\n",
            "Epoch 870/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9925 - val_loss: 0.9928\n",
            "Epoch 871/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9925 - val_loss: 0.9928\n",
            "Epoch 872/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9925 - val_loss: 0.9927\n",
            "Epoch 873/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 0.9927\n",
            "Epoch 874/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 0.9927\n",
            "Epoch 875/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 0.9927\n",
            "Epoch 876/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 0.9927\n",
            "Epoch 877/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9924 - val_loss: 0.9926\n",
            "Epoch 878/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9923 - val_loss: 0.9926\n",
            "Epoch 879/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9923 - val_loss: 0.9926\n",
            "Epoch 880/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9923 - val_loss: 0.9926\n",
            "Epoch 881/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9923 - val_loss: 0.9925\n",
            "Epoch 882/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9922 - val_loss: 0.9925\n",
            "Epoch 883/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9922 - val_loss: 0.9925\n",
            "Epoch 884/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9922 - val_loss: 0.9925\n",
            "Epoch 885/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9922 - val_loss: 0.9925\n",
            "Epoch 886/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9921 - val_loss: 0.9924\n",
            "Epoch 887/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9921 - val_loss: 0.9924\n",
            "Epoch 888/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9921 - val_loss: 0.9924\n",
            "Epoch 889/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9921 - val_loss: 0.9924\n",
            "Epoch 890/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9920 - val_loss: 0.9924\n",
            "Epoch 891/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9920 - val_loss: 0.9923\n",
            "Epoch 892/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9920 - val_loss: 0.9923\n",
            "Epoch 893/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9920 - val_loss: 0.9923\n",
            "Epoch 894/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9920 - val_loss: 0.9923\n",
            "Epoch 895/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9919 - val_loss: 0.9922\n",
            "Epoch 896/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9919 - val_loss: 0.9922\n",
            "Epoch 897/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9919 - val_loss: 0.9922\n",
            "Epoch 898/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9919 - val_loss: 0.9922\n",
            "Epoch 899/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9918 - val_loss: 0.9922\n",
            "Epoch 900/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9918 - val_loss: 0.9921\n",
            "Epoch 901/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9918 - val_loss: 0.9921\n",
            "Epoch 902/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9918 - val_loss: 0.9921\n",
            "Epoch 903/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9917 - val_loss: 0.9921\n",
            "Epoch 904/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9917 - val_loss: 0.9920\n",
            "Epoch 905/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9917 - val_loss: 0.9920\n",
            "Epoch 906/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9917 - val_loss: 0.9920\n",
            "Epoch 907/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9916 - val_loss: 0.9920\n",
            "Epoch 908/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9916 - val_loss: 0.9920\n",
            "Epoch 909/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9916 - val_loss: 0.9919\n",
            "Epoch 910/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9916 - val_loss: 0.9919\n",
            "Epoch 911/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9915 - val_loss: 0.9919\n",
            "Epoch 912/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9915 - val_loss: 0.9919\n",
            "Epoch 913/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9915 - val_loss: 0.9918\n",
            "Epoch 914/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9915 - val_loss: 0.9918\n",
            "Epoch 915/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9914 - val_loss: 0.9918\n",
            "Epoch 916/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9914 - val_loss: 0.9918\n",
            "Epoch 917/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9914 - val_loss: 0.9918\n",
            "Epoch 918/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9914 - val_loss: 0.9917\n",
            "Epoch 919/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9914 - val_loss: 0.9917\n",
            "Epoch 920/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9913 - val_loss: 0.9917\n",
            "Epoch 921/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9913 - val_loss: 0.9917\n",
            "Epoch 922/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9913 - val_loss: 0.9916\n",
            "Epoch 923/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9913 - val_loss: 0.9916\n",
            "Epoch 924/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9912 - val_loss: 0.9916\n",
            "Epoch 925/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9912 - val_loss: 0.9916\n",
            "Epoch 926/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9912 - val_loss: 0.9916\n",
            "Epoch 927/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9912 - val_loss: 0.9915\n",
            "Epoch 928/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9911 - val_loss: 0.9915\n",
            "Epoch 929/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9911 - val_loss: 0.9915\n",
            "Epoch 930/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9911 - val_loss: 0.9915\n",
            "Epoch 931/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9911 - val_loss: 0.9914\n",
            "Epoch 932/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9910 - val_loss: 0.9914\n",
            "Epoch 933/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9910 - val_loss: 0.9914\n",
            "Epoch 934/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9910 - val_loss: 0.9914\n",
            "Epoch 935/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9910 - val_loss: 0.9914\n",
            "Epoch 936/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 0.9913\n",
            "Epoch 937/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 0.9913\n",
            "Epoch 938/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9909 - val_loss: 0.9913\n",
            "Epoch 939/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9908 - val_loss: 0.9913\n",
            "Epoch 940/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9908 - val_loss: 0.9912\n",
            "Epoch 941/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9908 - val_loss: 0.9912\n",
            "Epoch 942/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9908 - val_loss: 0.9912\n",
            "Epoch 943/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9907 - val_loss: 0.9912\n",
            "Epoch 944/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9907 - val_loss: 0.9911\n",
            "Epoch 945/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9907 - val_loss: 0.9911\n",
            "Epoch 946/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9907 - val_loss: 0.9911\n",
            "Epoch 947/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9906 - val_loss: 0.9911\n",
            "Epoch 948/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9906 - val_loss: 0.9910\n",
            "Epoch 949/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9906 - val_loss: 0.9910\n",
            "Epoch 950/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9906 - val_loss: 0.9910\n",
            "Epoch 951/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9905 - val_loss: 0.9910\n",
            "Epoch 952/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9905 - val_loss: 0.9909\n",
            "Epoch 953/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9905 - val_loss: 0.9909\n",
            "Epoch 954/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9904 - val_loss: 0.9909\n",
            "Epoch 955/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9904 - val_loss: 0.9909\n",
            "Epoch 956/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9904 - val_loss: 0.9908\n",
            "Epoch 957/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9904 - val_loss: 0.9908\n",
            "Epoch 958/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9903 - val_loss: 0.9908\n",
            "Epoch 959/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9903 - val_loss: 0.9908\n",
            "Epoch 960/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9903 - val_loss: 0.9907\n",
            "Epoch 961/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9903 - val_loss: 0.9907\n",
            "Epoch 962/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9902 - val_loss: 0.9907\n",
            "Epoch 963/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9902 - val_loss: 0.9907\n",
            "Epoch 964/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9902 - val_loss: 0.9906\n",
            "Epoch 965/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9902 - val_loss: 0.9906\n",
            "Epoch 966/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9901 - val_loss: 0.9906\n",
            "Epoch 967/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9901 - val_loss: 0.9906\n",
            "Epoch 968/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9901 - val_loss: 0.9905\n",
            "Epoch 969/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9900 - val_loss: 0.9905\n",
            "Epoch 970/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9900 - val_loss: 0.9905\n",
            "Epoch 971/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9900 - val_loss: 0.9905\n",
            "Epoch 972/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9900 - val_loss: 0.9904\n",
            "Epoch 973/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9899 - val_loss: 0.9904\n",
            "Epoch 974/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9899 - val_loss: 0.9904\n",
            "Epoch 975/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9899 - val_loss: 0.9904\n",
            "Epoch 976/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9899 - val_loss: 0.9903\n",
            "Epoch 977/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9898 - val_loss: 0.9903\n",
            "Epoch 978/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9898 - val_loss: 0.9903\n",
            "Epoch 979/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9898 - val_loss: 0.9903\n",
            "Epoch 980/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9897 - val_loss: 0.9902\n",
            "Epoch 981/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9897 - val_loss: 0.9902\n",
            "Epoch 982/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9897 - val_loss: 0.9902\n",
            "Epoch 983/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9896 - val_loss: 0.9901\n",
            "Epoch 984/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9896 - val_loss: 0.9901\n",
            "Epoch 985/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9896 - val_loss: 0.9901\n",
            "Epoch 986/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9896 - val_loss: 0.9901\n",
            "Epoch 987/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9895 - val_loss: 0.9900\n",
            "Epoch 988/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9895 - val_loss: 0.9900\n",
            "Epoch 989/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9895 - val_loss: 0.9900\n",
            "Epoch 990/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9894 - val_loss: 0.9900\n",
            "Epoch 991/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9894 - val_loss: 0.9899\n",
            "Epoch 992/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9894 - val_loss: 0.9899\n",
            "Epoch 993/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9894 - val_loss: 0.9899\n",
            "Epoch 994/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9893 - val_loss: 0.9899\n",
            "Epoch 995/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9893 - val_loss: 0.9898\n",
            "Epoch 996/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9893 - val_loss: 0.9898\n",
            "Epoch 997/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9892 - val_loss: 0.9898\n",
            "Epoch 998/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9892 - val_loss: 0.9898\n",
            "Epoch 999/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9892 - val_loss: 0.9897\n",
            "Epoch 1000/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9892 - val_loss: 0.9897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3gV1dbH8e/KSYN0EkhCAgkdggQCoXoRgoIISJMigqKiXHtXQLFx9VqwXAu2V7k2EBH1inQFIhZUihAIzdATWighBAhp+/3jDBqRknYyKevzPPN4zp6Zc9bOxPyY2VPEGINSSilVVG52F6CUUqpy0eBQSilVLBocSimlikWDQymlVLFocCillCoWd7sLKA8hISEmOjq6ROseP34cHx+fsi2ogtM+Vw/a5+qhNH1etWrVQWNM7TPbq0VwREdHs3LlyhKtm5iYSPfu3cu2oApO+1w9aJ+rh9L0WUR2nq1dD1UppZQqFg0OpZRSxaLBoZRSqliqxRiHUqr6yc3NJTU1lezs7D/aAgIC2Lhxo41Vlb+i9Nnb25vIyEg8PDyK9JkaHEqpKik1NRU/Pz+io6MREQCOHTuGn5+fzZWVrwv12RjDoUOHSE1NpUGDBkX6TJceqhKRqSJyQETWn2O+iMirIpIiIkki0rbQvNEi8rs1jS7U3k5E1lnrvCqnfyOUUqqQ7OxsgoOD0T8R5yciBAcH/2XP7EJcPcbxPtD7PPOvAJpY01jgTQARqQU8DnQEOgCPi0iQtc6bwM2F1jvf5yulqjENjaIp7s/JpYeqjDHLRCT6PIsMAD40znu7/ywigSISDnQHvjHGHAYQkW+A3iKSCPgbY3622j8EBgLzXVH/T/M+Zm/KBhKP78MzKByf4Lr41wqjlq83/t7u+kuplKqW7B7jiAB2F3qfarWdrz31LO1/IyJjce7FEBoaSmJiYrGLC1z1FiPy18HhP9tyjYN0AthhAjkigRx1BJHlCOSERxA5HkHkeQVRUKMWbjUD8ff2JMhL8PcS3CpRyGRlZZXo51WZaZ+rnoCAAI4dO/aXtvz8/L+1uVJ4eDh79+4tt+87m6L2OTs7u8i/D3YHh8sYY94B3gGIj483JbpysstCvl/0Fc0b1OXEoTRyMvZQkLkPOX4AvxMHqH0qHd+cbfjnZkDu31dPN/7sNcHsI5gMj1BO1AgjzzcCAuvhFRyFf0gE4YE1CQ/wJtTfG0/3inF2tF5dWz1U9T5v3Ljxb4PCdgyO2z0YX9Q+e3t7ExcXV6TPtDs40oB6hd5HWm1pOA9XFW5PtNojz7K8a3j6kO9bl9otu59/ufxcOJ4Ox/aRk7GX44fTyD6yl/wjqQQfS6Pu8T34nkrGO+skZAH7nKtlGw/STAjbTQg/EEKGRxgnfSIhoB6ewVEEhNYjopYvEYE1iQiqga+X3ZtLKVUSxhgeeugh5s+fj4gwceJEhg8fzt69exk+fDiZmZnk5eXx5ptv0qVLF8aMGcPKlSsREW688Ubuvfdeu7vwF3b/JZoN3CEiM3AOhB81xuwVkYXAvwsNiPcCJhhjDotIpoh0An4BrgNes6Xywhwe4F8X/OviGQGeZ1vGGMg+CkdTMRm7yD60k+wD2/E/vJPAzFTiT6yhZu4ROIZzSnUeFttrapFqapNkQjjkHspJnwgKAiLxDG6Ab+36RAT7ExFUg8igmgTUKNo52EpVN09+ncyGPZnk5+fjcDjK5DNj6vrz+JUti7TsF198wZo1a1i7di0HDx6kffv2XHLJJUyfPp3LL7+cRx55hPz8fE6cOMGaNWtIS0tj/XrnyagZGRllUm9ZcmlwiMgnOPccQkQkFeeZUh4Axpi3gHlAHyAFOAHcYM07LCL/AlZYHzXp9EA5cBvOs7Vq4BwUd8nAeJkTgRqBUCMQCbuIGjg78Bc5J+BoKmTsoiBjFznp2/E9uIPmGbuJzdpIzZzvcTtu4DiwB/KNsJ8gUk1tlpgQ9rmFc9QnmpzARjhCGlMnJITIoBo0rO1LdEhNvNzL5n8YpVTx/PDDD4wYMQKHw0FoaCjdunVjxYoVtG/fnhtvvJHc3FwGDhxImzZtaNiwIdu2bePOO++kb9++9OrVy+7y/8bVZ1WNuMB8A9x+jnlTgalnaV8JXFQmBVY0njWhdlOo3RQ3wMea/pCXA5nOYDEZu8hJ34n3we00OrKLFlnb8MlejtuJAmcE74E0E8y2gnCWm7pMJ4Is3waYOi2oE1aPxqF+NKrtQ+M6vvh5656KqtpO7xlUtAsAL7nkEpYtW8bcuXO5/vrrue+++7juuutYu3YtCxcu5K233mLmzJlMnfq3P4W2svtQlSoOd0+o1RBqNUTg73steafg8DY4uAUObqH2/s0EHdhCpyM/4pF3HLKBXXB4px+bC+qx1kTymanH/hqNKagTQ/3QEJqE+pF9JJ/2p/Lw0TEVpcpE165defvttxk9ejSHDx9m2bJlTJ48mZ07dxIZGcnNN9/MqVOnWL16NX369MHT05OrrrqKZs2aMWrUKLvL/xv9y1CVuHtBnRbOCedYiyc4x1eO7YP0TZC+icD9G4jbs572h37APe8E5EH+Hjd2pIWzriCKnQXRjF2xkszAFkTWjaBFuL81+RERWEOvX1GqmAYNGsTy5ctp3bo1IsLzzz9PWFgYH3zwAZMnT8bDwwNfX18+/PBD0tLSuOGGGygoKADgmWeesbn6v9PgqA5EwD/cOTVKwA3wBmegZOyCfetw7Eui4d61RO1JYmDWT871TsC+rbVZt7k+ySaKmQXR7PRsTGBYA2LqBtAi3I+WdQNoFuaHh6NinEqsVEWSlZUFOK/Mnjx5MpMnT/7L/NGjRzN69Oi/rbd69epyqa+kNDiqMxEIinJOLfohOH8hflw0m4sb+cG+JML2JlFn71ouO/QlggEgc78/yXvrk5QfxTsF0Wx1NMQ/sjlto0NoWz+ItvWDCPI567llSqkqQIND/U2upz806g6NEgDrhmY5x2F/Muxdi/++JDrtW0en/d8i+acAOLXXiw1p9Vn5fRM+LWjGgaC2NImOom1UEO2igmhc2xc3Nz3EpVRVoMGhisbTB+p1cE6AgPPCx4NbYG8SXvuSiE37jdZp33JzwTw4DtuSI/l5bVOmFDRng+dF1K3fhLb1nUHSpn6gXtCoVCWl/+eqknN4QGhL58QIHOA8s2vPb7DzRxrsXE70rp+5JmcJAPt312b59qbMK2jO46Yl/hHN6NI4hIsbhdA2KghvD73ORKnKQINDlS13L6jfCep3QrqCFOQ7D3Ht/InQXT/Rf+dyBh7/EYD0Q7VZuq8lM75ryf1urYiu34CLGwfTuVEIrSMDcNcBd6UqJA0O5VpuDgiPdU6dbsHNGDiUAtu/o/a2RIZu/55h2YkAbN8fzZJdLXj924tY79GKVg3q0qVRMF0ahdA8zE/HSJSqIDQ4VPkSgZAmzqn9Tc49kr1rYft3NNiWyI27ljImbz554k7S7hYs/P0i7i+IJb1mY3q0CKVnTBj/aBxCDU89rKWUXTQ4lL3cHBDR1jn9414kNxt2/4x7ymLabl1C2/2fMIFPOEotlqyLZdbqOMY7YolrXJ+eMXXo0TyU2n5edvdCqTLh6+v7x7UfZ9qxYwf9+vX74+aHdtLgUBWLhzc07O6c+Bdk7oWtSwhI+YaBKYsZJInkiQerdrRk7pbWvFbQljr1mtAzJoyeMaE0qu2jV7Yr5WIaHKpi8w+HuJEQNxLJz4VdP+O+ZQEdtiyg46EPmMQH7DxUn7nftuH+hfFk1oqlZ8swLmsRSruoIBw6LqIA5o+HfeuokZ8HjjL6sxfWCq549ryLjB8/nnr16nH77c57uT7xxBO4u7uzdOlSjhw5Qm5uLk899RQDBgwo1ldnZ2dz6623snLlStzd3XnppZdISEggOTmZG264gZycHAoKCvj888/x8/Pj6quvJjU1lfz8fB599FGGDx9e4m6DBoeqTBwe0KArNOiKXP40HEyBLQuI2rKAW3fO5Tb32RzODmHu8rb854d4fvdqxSUtIugZE0q3prV1XESVu+HDh3PPPff8ERwzZ85k4cKF3HXXXfj7+3Pw4EE6depE//79i7WnPGXKFESEdevWsWnTJnr16sWWLVt46623uPvuuxk5ciQ5OTnk5+fz+eefU7duXebOnQvA0aNHS90vDQ5VeYU0hpA7oMsdyInDsGUBtTbOYdTWxVybt4jj4sfiDXF8saYdj7jH0e2iKAa0ieDiRsF6qm91Y+0ZnCzn26rHxcVx4MAB9uzZQ3p6OkFBQYSFhXHvvfeybNky3NzcSEtLY//+/YSFhRX5c3/44QfuvPNOAJo3b05UVBRbtmyhc+fOPP3006SmpjJ48GCaNGlCTEwMEydOZNy4cfTr14+uXbuWul8aHKpqqFkL2lwDba5Bco7D1iX4bJzDlVvm059l5IgX321ozWdrOvJIjY5c1rohA9rUpU29QB0TUS41dOhQZs2axb59+xg+fDjTpk0jPT2dVatW4eHhQXR0NNnZ2WXyXddccw0dO3Zk7ty59OnTh7fffpv27duzevVq5s2bx8SJE7n00kt57LHHSvU9Ghyq6vH0gRZXQosrneMiO37Ac9McLtvwNT35lVMF/8filW14++dObA3szBVtGhCeU2B31aqKGj58ODfffDMHDx7ku+++Y+bMmdSpUwcPDw+WLl3Kzp07i/2ZXbt2Zdq0afTo0YMtW7awa9cumjVrxrZt22jYsCF33XUXu3btIikpicjISOrXr8+oUaMIDAzk3XffLXWfNDhU1ebwcN6ssVECcsXzsPMnvJK/pPeGr+hz4mdOnnybRd/H8XV+Zz7dBv3bNmBw2wgCa+rdfVXZaNmyJceOHSMiIoLw8HBGjhzJlVdeSatWrYiPj6d58+bF/szbbruNW2+9lVatWuHu7s7777+Pl5cXM2fO5KOPPsLDw4OwsDAefvhhvvvuO4YMGYKbmxseHh68+eabpe6TOJ/eWrXFx8eblStXlmjdxMREunfvXrYFVXDVos/5ebDje0j+goINX+OWfYQs8eGL3C58RXeiLrqYazpF0S4qqMoeyqrq23njxo20aNHiL20V7dGx5aGofT7bz0tEVhlj4s9cVvc4VPXkcP9jT8St70sk/e9VYs0GRm38muvyv2HLxnp8uu4Snq/Vmz6dWjGobSQBNfTZ7EqBBodS4PDgcHA76H4/biczYP3nNFr9MY/unUbesRksWdCGCQsS8G3Vh6s7NSROB9SVC61bt45rr732L21eXl788ssvNlX0dxocShVWIxDaj8HRfgwc2IT7mo9J+G0GvU6+QHryu3ya1I1XgvpxWZcODIiLwN9b90IqMmNMpQv5Vq1asWbNmnL9zuIOWWhwKHUudZpDr6fwuPRx+P0bgla+z20pX+N27CuWzWvFxHk98Ym9kqs7NSQ2MqDS/YGq6ry9vTl06BDBwcG6bc7DGMOhQ4fw9vYu8joaHEpdiMMDmvfBvXkfOJqKWf0RnVZ+wCXHXyJ9/Xt8trYbrwZfSY8uHRnQJkKfbFhBREZGkpqaSnp6+h9t2dnZxfoDWRUUpc/e3t5ERkYW+TP1N1yp4giIRBIm4NntIUj5lsBfp3JLyhzcjs7m+zkXMWFub0LaDWD0xY2IDvGxu9pqzcPDgwYNGvylLTExkbi4OJsqsocr+qzBoVRJuDmg6eV4NL0cMvdgVn9ExxXv0/X4C+xe/QEfrejJvobDuLpbKzo31EMlqmrRG/YoVVr+dZHu4/C8bx0M+4jQek142H06z+0axo7/3sytL3/MrFWp5OTp1emqanBpcIhIbxHZLCIpIjL+LPOjRGSxiCSJSKKIRBaa95yIrLem4YXaLxWR1SKyRkR+EJHGruyDUkXmcIeY/njeNB9u+QGP1sMY5vkjb2XeQe3/jeDeZ//DW4kpZGbn2l2pUqXisuAQEQcwBbgCiAFGiEjMGYu9AHxojIkFJgHPWOv2BdoCbYCOwAMi4m+t8yYw0hjTBpgOTHRVH5QqsbBWuA+agvsDmzAJE+nss4cpeU/yjyVX8dQzk3hx/noyTuTYXaVSJeLKPY4OQIoxZpsxJgeYAZz5tJIYYIn1emmh+THAMmNMnjHmOJAE9LbmGeB0iAQAe1xUv1KlV7MW0u1BPO9PhitfpUmQg+flVYb/PIB3nruf1+f/xtGTugeiKhdXBkcEsLvQ+1SrrbC1wGDr9SDAT0SCrfbeIlJTREKABKCetdxNwDwRSQWuBc7/CC6lKgIPb2g3Gq+7V8KIGdSq25CH5EOu+7kPs54bw3vzl5N1Ks/uKpUqEpfd5FBEhgC9jTE3We+vBToaY+4otExd4HWgAbAMuAq4yBiTISKPAEOBdOAAsMIY8x8R+QJ4zhjzi4g8CDQ7/R1nfP9YYCxAaGhouxkzZpSoH1lZWfj6+pZo3cpK+1w+/DI3E7ztS+pl/EyecedL041tkYNo1zACL3fXn4Wl27l6KE2fExISznqTQ4wxLpmAzsDCQu8nABPOs7wvkHqOedOBPkBtYGuh9vrAhgvV0q5dO1NSS5cuLfG6lZX2uZwdTDEHp//T5D5ey+Q8FmRmP9HfzJy/2Jw4lefSr9XtXD2Ups/ASnOWv6muPFS1AmgiIg1ExBO4GphdeAERCRGR0zVMAKZa7Q7rkBUiEgvEAouAI0CAiDS11ukJbHRhH5RyveBGBI94C/d7kzjc8jp6sZyrlg/mh2f6MnvBfLJz8+2uUKm/cNkFgMaYPBG5A1gIOICpxphkEZmEM8VmA92BZ0TE4DxUdbu1ugfwvXXRVCYwyhiTByAiNwOfi0gBziC50VV9UKpcBUQQOuw/kPUIaQte5OLkD6j589X8+Gs7Mjvcx6WX9cHTXS+9UvZz6ZXjxph5wLwz2h4r9HoWMOss62XjPLPqbJ/5JfBl2VaqVAXiW5uIIc9i+o5j54JXaJX0Hv4/j+SHX+M53vlBevTohYdDA0TZR3/7lKqgpEYQUYOewG9cMttb30drs4nLfxzO8n/35psl35KXr1eiK3tocChVwYm3Pw0GPY7vQ8lsu+gu2hasp+eyq1j2zJUs+3VFsZ+loFRpaXAoVUlIjUAaDvkXPg8ms7X5LXTJ+5WOc3sz98Wb2bor1e7yVDWiwaFUJSM1g2h09XM47v6NXRF96JM1i6D3OjLvvUkczTphd3mqGtDgUKqS8giKpMnYj8i89luO+Dalz+4XOfxCOxLnfEx+gR6+Uq6jwaFUJRfYKJ5GDyxhZ6938XII3Vfezi/P9mHT5k12l6aqKA0OpaoCEaK6DCV8wm8kt7iHtjkriZzejYXvPUbWyWy7q1NVjAaHUlWIuHvRcviT5Iz9iTT/Nly++xXSnu/E8mWL9OwrVWY0OJSqgvzrNqHZfQvYlvAGwRyl4+JhLHlpNGn79tldmqoCNDiUqqpEaNhtJIEP/saGelfTPXM2nm925JuZb5Cbp/e/UiWnwaFUFedeM5CLbnqLQ9cs4Lh3KD03TCDp2Us5eCDN7tJUJaXBoVQ1UadZJ6LHLWdj3KM0z9tEv+S7WfbuQ2Sf1Gs/VPFocChVnbg5aDHgAfJv+5W1XvFckvo2+ye3Z8sv8y68rlIWDQ6lqiH/OvU52WU86xPew93k0nT+CJLeuI7cE0ftLk1VAhocSlVjF3Ubgt99K1gSfA0t98/m0Avt2b1msd1lqQpOg0Opas7fL4Aed77JioRp5BZAxJdXkfTfuynI0QsH1dlpcCilAOjUvS/edy7ne78riN35Pruf70R6yiq7y1IVkAaHUuoPtYODueT+6XwXPwWf3MMEfNyLlC+fhgJ9aJT6kwaHUuovRIRu/UaRNeYHfvXoQOO1z7P1lSvIzTxgd2mqgtDgUEqdVXT9+sQ/+DVfRTxAZMYqMv/TifTkRLvLUhWABodS6py8Pd0ZcPOj/NxjBln5HgR9NoitX/xLD11VcxocSqkL6tbtMvjnd/zocTGNkl5g+5SBmFPH7C5L2USDQylVJFF1w+jwwP/4rPYd1D+4jD0vdSP74A67y1I20OBQShVZDS93htz2FHNavYZf9l6y3+hG1u8/2V2WKmcaHEqpYhERBgy5lhWXzeRovhee067kyPKP7C5LlSMNDqVUiVzatSv7h81ljWlG0MI7OPi/h3XQvJrQ4FBKlViHlk3wu/lrvnTrSciaKaR/eB3knbK7LOViGhxKqVJpERlMxzs/5F3v0dTe8TWH3u4HJzPsLku5kEuDQ0R6i8hmEUkRkfFnmR8lIotFJElEEkUkstC850RkvTUNL9QuIvK0iGwRkY0icpcr+6CUurC6QTUZctcLvOz/EH4HVpExpQdk7La7LOUiLgsOEXEAU4ArgBhghIjEnLHYC8CHxphYYBLwjLVuX6At0AboCDwgIv7WOtcD9YDmxpgWwAxX9UEpVXSBNT255Y7xvBz2LG7H9nL8je6YvWvtLku5gCv3ODoAKcaYbcaYHJx/4AecsUwMsMR6vbTQ/BhgmTEmzxhzHEgCelvzbgUmGWMKAIwxegMdpSqIGp4O7ht7E282nMLRUwXk/F9vCn7X53tUNWKMcc0HiwwBehtjbrLeXwt0NMbcUWiZ6cAvxphXRGQw8DkQArQDHgd6AjWBX4EpxpgXReQQ8BIwCEgH7jLG/H6W7x8LjAUIDQ1tN2NGyXZMsrKy8PX1LdG6lZX2uXpwZZ8LjGFh8j6uP/BvmrilsaXpbRyoe5lLvqs4dDsXT0JCwipjTPyZ7e6lrqp0HgBeF5HrgWVAGpBvjFkkIu2Bn3CGw3Ig31rHC8g2xsRbYTMV6HrmBxtj3gHeAYiPjzfdu3cvUYGJiYmUdN3KSvtcPbi6zwndDf/3bQsOLrudrlteo1lUGI6L77jwii6k27lsuPJQVRrOsYjTIq22Pxhj9hhjBhtj4oBHrLYM679PG2PaGGN6AgJssVZLBb6wXn8JxLquC0qpkhIRxvZsw+ZL32Nefgcc3zxC3tLnwEVHOVT5cWVwrACaiEgDEfEErgZmF15AREJE5HQNE3DuPSAiDhEJtl7H4gyHRdZy/wMSrNfd+DNQlFIV0E3dm7Ov5xt8nt8V9+/+Tf6iRzU8KjmXBYcxJg+4A1gIbARmGmOSRWSSiPS3FusObBaRLUAo8LTV7gF8LyIbcB5uGmV9HsCzwFUisg7nWVg3uaoPSqmyceMlTTh+xat8lHcZjuWvkT/nPr3KvBJz6RiHMWYeMO+MtscKvZ4FzDrLetk4z6w622dmAH3LtlKllKtd16Uh09xe5K05E7ll1VTyc07gGDgFHHYPtari0ivHlVLlZmSnaIL6P82LeUNxrJtB/mfXQ16O3WWpYtLgUEqVq+Edoqg38HEm5V2LY9PX5H8yAnJP2l2WKgYNDqVUuRsWX4+YQeMZn3szsnUx+R9dBfpEwUpDg0MpZYsh7SLpOOQe7s29HXYtJ/+D/nDisN1lqSLQ4FBK2WZQXCQ9ht7Grbn3ULBnHfnv94MsvYtQRafBoZSy1YA2EfQbdjNjch8gNz2Fgqm94WjahVdUttHgUErZrn/rugwfPprrcsaTfWSvMzwOb7O7LHUOGhxKqQqhb2w41wwZzvBTD3Pi2BHM1CvgwCa7y1JnocGhlKowBsZFMLx/fwafnEjmyRzM+31gzxq7y1Jn0OBQSlUoozpFMejynvQ/MZGMXHfMB1fCrl/sLksVosGhlKpwbu3eiL7dLqbvsUc4TADmo0Gw7Tu7y1IWDQ6lVIX04OXNuKxzO3ofncAhjzCYNhQ2L7C7LEURg0NEfE7f/lxEmopIfxHxcG1pSqnqTER44sqWdI1ryWWHHyLdpxF8Ogo2z7e7tGqvqHscywBvEYnA+VyMa4H3XVWUUkoBuLkJzw+JpWPLxlx64F4O+zWDT6+FTfMuvLJymaIGhxhjTgCDgTeMMUOBlq4rSymlnNwdbrw6Io7WTaJIOHA3GQEtYOZ1sGmu3aVVW0UODhHpDIwETm8th2tKUkqpv/Jyd/D2te1oXD+ShAN3kxkUAzNHa3jYpKjBcQ/OR7t+aT3FryGw1HVlKaXUX9X0dGfq9e0JrxNKjwN3k1Wrpe552KRIwWGM+c4Y098Y85w1SH7QGHOXi2tTSqm/CKjhwYdjOuAfGEzP9Hs4EdLKGR4b59hdWrVS1LOqpouIv4j4AOuBDSLyoGtLU0qpvwvx9eLjMR1xqxFA74P3kF07Fj7Tw1blqaiHqmKMMZnAQGA+0ADnmVVKKVXu6gbW4OObOnLCzZc+h+/lVO1W8Nn1sHWJ3aVVC0UNDg/ruo2BwGxjTC5gXFeWUkqdX4MQHz6+qQOH8rwZnHkfuUGNYcZI2Lnc7tKqvKIGx9vADsAHWCYiUUCmq4pSSqmiaB7mz/s3tGf7cU9GnhpHvm84TB8Ge36zu7QqraiD468aYyKMMX2M004gwcW1KaXUBcXVD+Ld0fGsOeLFzTxKgVcAfDQYDmy0u7Qqq6iD4wEi8pKIrLSmF3HufSillO26NArhjWvasmy/F3d7PYlxeMKHA/VhUC5S1ENVU4FjwDBrygT+66qilFKquC6LCeXFYa35erc3T9V6BpOfAx8MgKOpdpdW5RQ1OBoZYx43xmyzpieBhq4sTCmlimtAmwgmXNGc97Z48d9GL0F2Bnw4ALIO2F1alVLU4DgpIv84/UZELgZOuqYkpZQqubGXNGRUp/pMWunJwjavQeYe+GgQnDhsd2lVRlGD4xZgiojsEJEdwOvAPy+0koj0FpHNIpIiIuPPMj9KRBaLSJKIJIpIZKF5z4nIemsafpZ1XxWRrCLWr5SqJk7fjr1H8zrcusyD3y6eAge3wLQhOPJO2F1elVDUs6rWGmNaA7FArDEmDuhxvnVExAFMAa4AYoARIhJzxmIvAB8aY2KBScAz1rp9gbZAG6Aj8ICI+Bf67HggqCi1K6WqH3eHG6+NiCOmrj8jl9RkZ483YM8aWq17GnL1YElpFesJgMaYTOsKcoD7LrB4ByDFGhPJAWYAA85YJgY4fann0kLzY4Blxpg8Y8xxIAnoDX8E0mTgoeLUrpSqXny83Jk6uj1BNT25amkQh3q9RsDRZOe9rfJy7C6vUivNo2PlAvMjgN2F3qdabch3tAEAABb6SURBVIWtxfmMD4BBgJ+IBFvtvUWkpoiE4LxmpJ613B04r17fW4ralVLVQB1/bz64sT05efkM/SmCdQ1vgd8XwZf/hIJ8u8urtNxLsW5Z3HLkAeB1Ebke51MG04B8Y8wiEWkP/ASkA8uBfBGpCwwFul/og0VkLDAWIDQ0lMTExBIVmJWVVeJ1Kyvtc/VQnfp8e6w7k1ce557sf/BWgxM0Tf6APYePsaXp7SAX+jdw5eaS7WyMOeeE89qNzLNMx4C8C6zbGVhY6P0EYMJ5lvcFUs8xbzrQB+gL7MN5+5MdQAHOw2Hn7Ue7du1MSS1durTE61ZW2ufqobr1eW7SHhM9bo7554crTcE3k4x53N+YhRPtLsvlSrOdgZXmLH9Tz7vHYYzxK0UmrQCaiEgDnHsSVwPXFF7AOgx12BhTYAXLVKvdAQQaYw6JSCzOQflFxpg8IKzQ+lnGmMalqFEpVU30aRXO1c09+SR5H8/WuooJ7TPgp1choB50HGt3eZVKaQ5VnZcxJk9E7gAW4nzM7FTjfHrgJJwpNhvnIadnRMTgPFR1u7W6B/C9OHchM4FRVmgopVSJ9Ypyxz0wnLe/3070wDsY0WwPLBgHgfWg2RV2l1dpuCw4AIwx84B5Z7Q9Vuj1LGDWWdbLxnlm1YU+37cMylRKVRMiwuNXxrD7yAkmzt5IvVHP8o9je2HWjXD9XIhoa3eJlUJpzqpSSqlKx93hxuvXtKVJHV9u+XQTKZe9BzVDYPpwOLLT7vIqBQ0OpVS14+vlzn9vaI+Pl4PrP9tJxlWfQP4pmDYUTmbYXV6Fp8GhlKqWwgNq8M618Rw4dopbFhwjb+hHztuwfzpKLxC8AA0OpVS11bpeIM9d1Yqftx1m0vpgGDAFdnwPs+8Eo0/HPhcNDqVUtTYoLpKxlzTkw+U7+eRUZ0h4BJJmQOIzdpdWYWlwKKWqvXG9m9OtaW0e+2o9K+qPgTaj4Lvn4LdpdpdWIWlwKKWqPYeb8OqIOOoF1eSWj1eT1vUZaNgdvr4Lti61u7wKR4NDKaWAgBoevHNdPDl5BYydtpaTA9+HkGbOu+nu32B3eRWKBodSSlka1/Hl1RFxbNibyUNzd2Cu+RQ8asL0YZCVbnd5FYYGh1JKFZLQvA4P9GrG12v38H5yHlwzA46nw8xr9TRdiwaHUkqd4bbujegZE8rTczeyMifKeZruruUw/0E9TRcNDqWU+hsR4cVhrYkMqsHt01eTHn0l/ONeWPU+rHjX7vJsp8GhlFJn4e/twZuj2nH0ZC53frKavG6PQNPesGA8bF9md3m20uBQSqlzaBHuz78HOa8sn/xNCgz+P6jVCGaOhiM77C7PNhocSil1HoPbRjKqU33eXraNhVtPwIhPwOTDJ9fAqSy7y7OFBodSSl3Ao/1iiI0M4MHP1rJbwmHIfyF9I3z5TygosLu8cqfBoZRSF+Dl7uC1EXEYA3d+8hu5DRKg11OwaQ78+LLd5ZU7DQ6llCqCqGAfnr0qljW7M3hh4WbodBtcdBUs/hekLLa7vHKlwaGUUkXUNzb8j/GOpZvTof9rUKcFfD6mWj09UINDKaWKYWLfGJqH+XHfzDXsPekGwz92jnN8OgpyT9pdXrnQ4FBKqWLw9nAwZWRbTuUVcPcna8gLbACD34F9STD3/mpxZbkGh1JKFVOj2r48Pegift1xmFcW/w7NekO3cbBmGqycand5LqfBoZRSJTAoLpJh8ZG8vjSFH34/CN3GQ5NeMH8c7P7V7vJcSoNDKaVK6In+LWlc25d7Pl3DgeM5zkNWARHOZ3hkHbC7PJfR4FBKqRKq6enOlJFtyTqVy32frqXAK9A5WH4yA2bdCPl5dpfoEhocSilVCk1D/XisX0t+SDnI1B+3Q1gr6PcS7PgevnvW7vJcQoNDKaVKaUSHevSMCeX5BZvZsCcT2lwDbUbBsheq5MWBGhxKKVVKIsKzg1sRUNODez79jezcfOgz2Xlx4Bc3Q+Yeu0ssUy4NDhHpLSKbRSRFRMafZX6UiCwWkSQRSRSRyELznhOR9dY0vFD7NOsz14vIVBHxcGUflFKqKIJ9vXhhaGu27M/i2fmbwLMmDP0AcrNh1pgqNd7hsuAQEQcwBbgCiAFGiEjMGYu9AHxojIkFJgHPWOv2BdoCbYCOwAMi4m+tMw1oDrQCagA3uaoPSilVHN2a1uaGi6N5/6cdLN18AGo3hSv/A7t+gqVP2V1emXHlHkcHIMUYs80YkwPMAAacsUwMsMR6vbTQ/BhgmTEmzxhzHEgCegMYY+YZC/ArEIlSSlUQ43o3p1moHw9+lsTBrFMQOwzajoYfXoYti+wur0yIcdHl8SIyBOhtjLnJen8t0NEYc0ehZaYDvxhjXhGRwcDnQAjQDngc6AnUxBkQU4wxLxZa1wP4BbjbGPP9Wb5/LDAWIDQ0tN2MGTNK1I+srCx8fX1LtG5lpX2uHrTPrrP7WAFPLj9Jy2AH97T1wlGQQ9vV4/A6dZCV8S9zyru2y2s4rTR9TkhIWGWMiT+z3b3UVZXOA8DrInI9sAxIA/KNMYtEpD3wE5AOLAfyz1j3DZx7JX8LDQBjzDvAOwDx8fGme/fuJSowMTGRkq5bWWmfqwfts2vlBm1n0pwNpNVoyKhOUdC6EbzTjc6p78AN88BRPsOzruizKw9VpQH1Cr2PtNr+YIzZY4wZbIyJAx6x2jKs/z5tjGljjOkJCLDl9Hoi8jhQG7jPhfUrpVSJXd8lmq5NQnhq7ga2pmdBSGPo/yqk/gqLn7S7vFJxZXCsAJqISAMR8QSuBmYXXkBEQkTkdA0TgKlWu0NEgq3XsUAssMh6fxNwOTDCGFP9ntmolKoU3NyEF4e2xtvDwX2friE3v8D54Kf4MfDTa7B5vt0llpjLgsMYkwfcASwENgIzjTHJIjJJRPpbi3UHNovIFiAUeNpq9wC+F5ENOA83jbI+D+Ata9nlIrJGRB5zVR+UUqo06vh78/TAVqxNPcqUpSnOxsv/DWGx8OUtkLHL3gJLyKVjHMaYecC8M9oeK/R6FjDrLOtl4zyz6myfafe4jFJKFVnf2HC+2VCX15akkNCsDq3rBcKwD+DtbvDZ9XDDAnD3tLvMYtErx5VSysWeHHARdfy8uHfmGk7m5EOthjDgdUhbBUufvvAHVDAaHEop5WIBNTx4YWhrtqUf57kFm5yNMQOg3fXw4yuwLdHO8opNg0MppcrBxY1D/riq/Pvf052Nl/8bQpo4xzuOH7K3wGLQ4FBKqXIyrndzGtfx5cHPkjh6Ihc8feCqd+HEIZh9Z6V5XrkGh1JKlRNvDwcvD2vDwaxTPPrVemdjeGu47AnYPLfSPK9cg0MppcpRq8gA7r60CbPX7mFu0l5nY8dbodGlsPBhOLDR3gKLQINDKaXK2a3dG9EqIoDHvlrPoaxT4OYGA98ET1/nLdhzs+0u8bw0OJRSqpy5O9x4YWhrMrNzeeLrDc5Gv1BneBxIhm8ft7fAC9DgUEopGzQL8+OuHk34eu0eFqy3Dlk17eU8bPXLWxX6FuwaHEopZZNbujeiZV1/Jv5vPUeO5zgbL3sC6sQ4z7I6ecTO8s5Jg0MppWziYR2yyjiRyxNfJ1uN3s5DVicOwvxx9hZ4DhocSilloxbh/tzZowlfrdnDouR9zsa6baDrA5D0KWycY2+BZ6HBoZRSNrstoREtwv155H/ryThhHbLqej+EtYI591S4q8o1OJRSymbOQ1axHDmew6TTZ1m5e8LAt+BkBsx7wN4Cz6DBoZRSFUDLugHcltCYL35LY/HG/c7GsIug+zhI/gKSv7S3wEI0OJRSqoK4I6ExzcP8ePjLdRw9metsvPheqBsHc++HrHR7C7RocCilVAXh6e7G5CGtST92iskLrduvO9ydh6xOZcHc+yrEjRA1OJRSqgJpFRnA9V0aMO2XXfy2y7qOo05zSJgAG2dXiENWGhxKKVXB3NerKWH+3jz85Xry8gucjZ3vhIh2zoFymw9ZaXAopVQF4+vlzuNXtmTj3kz+++MOZ6PDHQa8AaeOwbz7ba1Pg0MppSqgy1uGclmLOrz0zRZSj5xwNtZpDt0nwIavYP0XttWmwaGUUhWQiPBE/5YAPDE7GXN6ULzLXVC3ra2HrDQ4lFKqgooMqsm9PZvw7cYDLEy2ru1wuDvvZXXqmG0XBmpwKKVUBXbDxQ1oHubHE7OTyTqV52z845DV/2w5y0qDQymlKjAPhxv/HtyK/ceyeWnRlj9nnD5kNfd+OH6wXGvS4FBKqQqubf0grulQn/d/2s76tKPORoc7DHwDsjNh0cRyrUeDQymlKoGHejenlo8XD3+5jvwCa6C8Tgu4+G5Y+wlsSyy3WlwaHCLSW0Q2i0iKiIw/y/woEVksIkkikigikYXmPSci661peKH2BiLyi/WZn4qIpyv7oJRSFUFADQ8e7deCpNSjfPzzzj9nXPIA1GoIc+6F3JPlUovLgkNEHMAU4AogBhghIjFnLPYC8KExJhaYBDxjrdsXaAu0AToCD4iIv7XOc8DLxpjGwBFgjKv6oJRSFUn/1nXp2iSEyQs3sz8z29noUQP6vQyHt8GyF8qlDlfucXQAUowx24wxOcAMYMAZy8QAS6zXSwvNjwGWGWPyjDHHgSSgt4gI0AOYZS33ATDQhX1QSqkKQ0T414CLyMkv+PO5HQANu0PrEfDjf2D/hnOtXmZcGRwRwO5C71OttsLWAoOt14MAPxEJttp7i0hNEQkBEoB6QDCQYYzJO89nKqVUlRUd4sOdCY2Zu24vSzcd+HNGr6fBOwBm3wkF+S6twd2ln35hDwCvi8j1wDIgDcg3xiwSkfbAT0A6sBwo1k9CRMYCYwFCQ0NJTEwsUYFZWVklXrey0j5XD9rnyqu5GMJ9hHEzV/L0P2rg4SYA1Im6jpiNL/P79HGkRfYDXNRnY4xLJqAzsLDQ+wnAhPMs7wuknmPedKAPIMBBwP1s33GuqV27dqakli5dWuJ1Kyvtc/Wgfa7cvtt8wESNm2PeWJryZ2NBgTEfDTbmqXBjjuwyxpSuz8BKc5a/qa48VLUCaGKdBeUJXA3MLryAiISIyOkaJgBTrXaHdcgKEYkFYoFFVkeWAkOsdUYDX7mwD0opVSFd0rQ2l7UI5fUlv3Pg9EC5CPR9CTAufeiTy4LDOMch7gAWAhuBmcaYZBGZJCL9rcW6A5tFZAsQCjxttXsA34vIBuAdYJT5c1xjHHCfiKTgHPN4z1V9UEqpiuzRfi3IzTc8u2DTn41BUdDjUfh9Eaz/3CXf69IxDmPMPGDeGW2PFXo9iz/PkCq8TDbOM6vO9pnbcJ6xpZRS1VpUsA9jujbgzcStXNspirj6Qc4ZHf8J6z6D+eNwj3u5zL9XrxxXSqlK7PaExtTx8+KJ2ckUnL6i3M0B/V+DoGg8crPK/Ds1OJRSqhLz9XJn/BXNWZt6lM9Xp/45I+wiuOlbTtasW+bfqcGhlFKV3MA2EcTVD+S5BZs5lp375wwRl3yfBodSSlVybm7CE1e25GDWKV5fkuL673P5NyillHK51vUCGdoukqk/bmdbetmPaxSmwaGUUlXEg72b4eXu4Km5G136PRocSilVRdTx8+auSxuzZNMBlm4+cOEVSkiDQymlqpDruzSgYYgP//p6Azl5BS75Dg0OpZSqQjzd3Xi0XwzbDh7ng592uOQ7NDiUUqqKSWheh4RmtXll8e9knCr7vQ4NDqWUqoIe7RdDfHQQuS54NIcGh1JKVUENa/vy/g0dqF2z7P/Ma3AopZQqFg0OpZRSxaLBoZRSqlg0OJRSShWLBodSSqli0eBQSilVLBocSimlikWDQymlVLGIMcbuGlxORNKBnSVcPQQ4WIblVAba5+pB+1w9lKbPUcaY2mc2VovgKA0RWWmMibe7jvKkfa4etM/Vgyv6rIeqlFJKFYsGh1JKqWLR4Liwd+wuwAba5+pB+1w9lHmfdYxDKaVUsegeh1JKqWLR4FBKKVUsGhznISK9RWSziKSIyHi76ykLIlJPRJaKyAYRSRaRu632WiLyjYj8bv03yGoXEXnV+hkkiUhbe3tQciLiEJHfRGSO9b6BiPxi9e1TEfG02r2s9ynW/Gg76y4pEQkUkVkisklENopI56q+nUXkXuv3er2IfCIi3lVtO4vIVBE5ICLrC7UVe7uKyGhr+d9FZHRxatDgOAcRcQBTgCuAGGCEiMTYW1WZyAPuN8bEAJ2A261+jQcWG2OaAIut9+DsfxNrGgu8Wf4ll5m7gY2F3j8HvGyMaQwcAcZY7WOAI1b7y9ZyldErwAJjTHOgNc6+V9ntLCIRwF1AvDHmIsABXE3V287vA73PaCvWdhWRWsDjQEegA/D46bApEmOMTmeZgM7AwkLvJwAT7K7LBf38CugJbAbCrbZwYLP1+m1gRKHl/1iuMk1ApPU/VA9gDiA4r6Z1P3N7AwuBztZrd2s5sbsPxexvALD9zLqr8nYGIoDdQC1ru80BLq+K2xmIBtaXdLsCI4C3C7X/ZbkLTbrHcW6nfwlPS7Xaqgxr1zwO+AUINcbstWbtA0Kt11Xl5/Af4CGgwHofDGQYY/Ks94X79UefrflHreUrkwZAOvBf6/DcuyLiQxXezsaYNOAFYBewF+d2W0XV3s6nFXe7lmp7a3BUUyLiC3wO3GOMySw8zzj/CVJlztMWkX7AAWPMKrtrKUfuQFvgTWNMHHCcPw9fAFVyOwcBA3CGZl3Ah78f0qnyymO7anCcWxpQr9D7SKut0hMRD5yhMc0Y84XVvF9Ewq354cABq70q/BwuBvqLyA5gBs7DVa8AgSLibi1TuF9/9NmaHwAcKs+Cy0AqkGqM+cV6PwtnkFTl7XwZsN0Yk26MyQW+wLntq/J2Pq2427VU21uD49xWAE2sMzI8cQ6yzba5plITEQHeAzYaY14qNGs2cPrMitE4xz5Ot19nnZ3RCThaaJe4UjDGTDDGRBpjonFuxyXGmJHAUmCItdiZfT79sxhiLV+p/mVujNkH7BaRZlbTpcAGqvB2xnmIqpOI1LR+z0/3ucpu50KKu10XAr1EJMjaU+tltRWN3YM8FXkC+gBbgK3AI3bXU0Z9+gfO3dgkYI019cF5bHcx8DvwLVDLWl5wnl22FViH84wV2/tRiv53B+ZYrxsCvwIpwGeAl9Xubb1PseY3tLvuEva1DbDS2tb/A4Kq+nYGngQ2AeuBjwCvqradgU9wjuHk4tyzHFOS7QrcaPU9BbihODXoLUeUUkoVix6qUkopVSwaHEoppYpFg0MppVSxaHAopZQqFg0OpZRSxaLBoVQZEJF8EVlTaCqzuymLSHThO6EqZTf3Cy+ilCqCk8aYNnYXoVR50D0OpVxIRHaIyPMisk5EfhWRxlZ7tIgssZ6RsFhE6lvtoSLypYistaYu1kc5ROT/rGdNLBKRGrZ1SlV7GhxKlY0aZxyqGl5o3lFjTCvgdZx36QV4DfjAGBMLTANetdpfBb4zxrTGeW+pZKu9CTDFGNMSyACucnF/lDonvXJcqTIgIlnGGN+ztO8Aehhjtlk3l9xnjAkWkYM4n5+Qa7XvNcaEiEg6EGmMOVXoM6KBb4zzIT2IyDjAwxjzlOt7ptTf6R6HUq5nzvG6OE4Vep2Pjk8qG2lwKOV6wwv9d7n1+iecd+oFGAl8b71eDNwKfzwjPaC8ilSqqPRfLUqVjRoisqbQ+wXGmNOn5AaJSBLOvYYRVtudOJ/O9yDOJ/XdYLXfDbwjImNw7lncivNOqEpVGDrGoZQLWWMc8caYg3bXolRZ0UNVSimlikX3OJRSShWL7nEopZQqFg0OpZRSxaLBoZRSqlg0OJRSShWLBodSSqli+X+VIQAF4JMoewAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-1F4-CXxM8e"
      },
      "source": [
        "####RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGF9zVlVxPLi",
        "outputId": "e5d323c6-eebe-4d67-eb2b-6cb61f634fbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "deep_mode3(opt_RMSprop)"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.9926 - val_loss: 0.9766\n",
            "Epoch 2/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.9353 - val_loss: 0.8945\n",
            "Epoch 3/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.8183 - val_loss: 0.7825\n",
            "Epoch 4/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6893 - val_loss: 0.6916\n",
            "Epoch 5/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6066 - val_loss: 0.6477\n",
            "Epoch 6/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5691 - val_loss: 0.6342\n",
            "Epoch 7/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5576 - val_loss: 0.6240\n",
            "Epoch 8/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5522 - val_loss: 0.6217\n",
            "Epoch 9/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5483 - val_loss: 0.6186\n",
            "Epoch 10/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5434 - val_loss: 0.6226\n",
            "Epoch 11/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5440 - val_loss: 0.6197\n",
            "Epoch 12/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5431 - val_loss: 0.6167\n",
            "Epoch 13/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5383 - val_loss: 0.6191\n",
            "Epoch 14/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5391 - val_loss: 0.6163\n",
            "Epoch 15/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5382 - val_loss: 0.6149\n",
            "Epoch 16/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5382 - val_loss: 0.6109\n",
            "Epoch 17/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5359 - val_loss: 0.6100\n",
            "Epoch 18/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5367 - val_loss: 0.6081\n",
            "Epoch 19/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5348 - val_loss: 0.6053\n",
            "Epoch 20/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5345 - val_loss: 0.6072\n",
            "Epoch 21/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5329 - val_loss: 0.6060\n",
            "Epoch 22/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5333 - val_loss: 0.6045\n",
            "Epoch 23/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5312 - val_loss: 0.6055\n",
            "Epoch 24/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5309 - val_loss: 0.6053\n",
            "Epoch 25/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5308 - val_loss: 0.6051\n",
            "Epoch 26/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5311 - val_loss: 0.6023\n",
            "Epoch 27/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 0.6020\n",
            "Epoch 28/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5287 - val_loss: 0.6007\n",
            "Epoch 29/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5273 - val_loss: 0.6004\n",
            "Epoch 30/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5270 - val_loss: 0.5967\n",
            "Epoch 31/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 0.5953\n",
            "Epoch 32/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5251 - val_loss: 0.5933\n",
            "Epoch 33/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5218 - val_loss: 0.5946\n",
            "Epoch 34/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 0.5925\n",
            "Epoch 35/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 0.5932\n",
            "Epoch 36/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5220 - val_loss: 0.5939\n",
            "Epoch 37/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5917\n",
            "Epoch 38/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 0.5908\n",
            "Epoch 39/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5197 - val_loss: 0.5931\n",
            "Epoch 40/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5203 - val_loss: 0.5901\n",
            "Epoch 41/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5211 - val_loss: 0.5909\n",
            "Epoch 42/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5191 - val_loss: 0.5900\n",
            "Epoch 43/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5196 - val_loss: 0.5864\n",
            "Epoch 44/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5191 - val_loss: 0.5876\n",
            "Epoch 45/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5187 - val_loss: 0.5854\n",
            "Epoch 46/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5181 - val_loss: 0.5866\n",
            "Epoch 47/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5181 - val_loss: 0.5862\n",
            "Epoch 48/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5175 - val_loss: 0.5842\n",
            "Epoch 49/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5155 - val_loss: 0.5854\n",
            "Epoch 50/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5177 - val_loss: 0.5842\n",
            "Epoch 51/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5159 - val_loss: 0.5811\n",
            "Epoch 52/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5156 - val_loss: 0.5843\n",
            "Epoch 53/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5143 - val_loss: 0.5844\n",
            "Epoch 54/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.5831\n",
            "Epoch 55/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5131 - val_loss: 0.5834\n",
            "Epoch 56/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5132 - val_loss: 0.5849\n",
            "Epoch 57/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5135 - val_loss: 0.5836\n",
            "Epoch 58/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5132 - val_loss: 0.5831\n",
            "Epoch 59/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5117 - val_loss: 0.5838\n",
            "Epoch 60/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5117 - val_loss: 0.5819\n",
            "Epoch 61/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5113 - val_loss: 0.5829\n",
            "Epoch 62/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5114 - val_loss: 0.5814\n",
            "Epoch 63/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5099 - val_loss: 0.5857\n",
            "Epoch 64/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5102 - val_loss: 0.5839\n",
            "Epoch 65/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5103 - val_loss: 0.5834\n",
            "Epoch 66/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5094 - val_loss: 0.5812\n",
            "Epoch 67/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5090 - val_loss: 0.5796\n",
            "Epoch 68/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5096 - val_loss: 0.5838\n",
            "Epoch 69/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5079 - val_loss: 0.5825\n",
            "Epoch 70/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5089 - val_loss: 0.5813\n",
            "Epoch 71/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5068 - val_loss: 0.5865\n",
            "Epoch 72/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5075 - val_loss: 0.5834\n",
            "Epoch 73/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5071 - val_loss: 0.5842\n",
            "Epoch 74/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5057 - val_loss: 0.5811\n",
            "Epoch 75/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5073 - val_loss: 0.5794\n",
            "Epoch 76/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5065 - val_loss: 0.5759\n",
            "Epoch 77/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5078 - val_loss: 0.5824\n",
            "Epoch 78/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5055 - val_loss: 0.5844\n",
            "Epoch 79/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5056 - val_loss: 0.5785\n",
            "Epoch 80/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5049 - val_loss: 0.5851\n",
            "Epoch 81/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5057 - val_loss: 0.5820\n",
            "Epoch 82/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5064 - val_loss: 0.5860\n",
            "Epoch 83/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5044 - val_loss: 0.5833\n",
            "Epoch 84/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5051 - val_loss: 0.5851\n",
            "Epoch 85/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5032 - val_loss: 0.5911\n",
            "Epoch 86/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5040 - val_loss: 0.5849\n",
            "Epoch 87/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5034 - val_loss: 0.5848\n",
            "Epoch 88/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5034 - val_loss: 0.5800\n",
            "Epoch 89/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5030 - val_loss: 0.5831\n",
            "Epoch 90/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5030 - val_loss: 0.5820\n",
            "Epoch 91/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5026 - val_loss: 0.5847\n",
            "Epoch 92/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5029 - val_loss: 0.5804\n",
            "Epoch 93/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5033 - val_loss: 0.5814\n",
            "Epoch 94/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5009 - val_loss: 0.5833\n",
            "Epoch 95/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5023 - val_loss: 0.5845\n",
            "Epoch 96/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5016 - val_loss: 0.5855\n",
            "Epoch 97/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5016 - val_loss: 0.5844\n",
            "Epoch 98/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5009 - val_loss: 0.5841\n",
            "Epoch 99/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5011 - val_loss: 0.5889\n",
            "Epoch 100/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5009 - val_loss: 0.5876\n",
            "Epoch 101/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5010 - val_loss: 0.5828\n",
            "Epoch 102/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5007 - val_loss: 0.5858\n",
            "Epoch 103/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5014 - val_loss: 0.5845\n",
            "Epoch 104/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5009 - val_loss: 0.5801\n",
            "Epoch 105/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4993 - val_loss: 0.5780\n",
            "Epoch 106/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.5003 - val_loss: 0.5775\n",
            "Epoch 107/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5014 - val_loss: 0.5778\n",
            "Epoch 108/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4996 - val_loss: 0.5811\n",
            "Epoch 109/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5003 - val_loss: 0.5789\n",
            "Epoch 110/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.5005 - val_loss: 0.5778\n",
            "Epoch 111/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4996 - val_loss: 0.5809\n",
            "Epoch 112/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4987 - val_loss: 0.5865\n",
            "Epoch 113/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4982 - val_loss: 0.5849\n",
            "Epoch 114/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4989 - val_loss: 0.5861\n",
            "Epoch 115/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4985 - val_loss: 0.5790\n",
            "Epoch 116/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4998 - val_loss: 0.5823\n",
            "Epoch 117/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4988 - val_loss: 0.5763\n",
            "Epoch 118/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4974 - val_loss: 0.5842\n",
            "Epoch 119/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4991 - val_loss: 0.5828\n",
            "Epoch 120/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4994 - val_loss: 0.5909\n",
            "Epoch 121/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4969 - val_loss: 0.5877\n",
            "Epoch 122/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4982 - val_loss: 0.5895\n",
            "Epoch 123/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4996 - val_loss: 0.5875\n",
            "Epoch 124/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4974 - val_loss: 0.5902\n",
            "Epoch 125/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4987 - val_loss: 0.5865\n",
            "Epoch 126/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4983 - val_loss: 0.5889\n",
            "Epoch 127/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4976 - val_loss: 0.5881\n",
            "Epoch 128/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4971 - val_loss: 0.5889\n",
            "Epoch 129/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4973 - val_loss: 0.5842\n",
            "Epoch 130/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4988 - val_loss: 0.5851\n",
            "Epoch 131/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4970 - val_loss: 0.5847\n",
            "Epoch 132/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4975 - val_loss: 0.5831\n",
            "Epoch 133/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4976 - val_loss: 0.5829\n",
            "Epoch 134/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4969 - val_loss: 0.5845\n",
            "Epoch 135/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4961 - val_loss: 0.5904\n",
            "Epoch 136/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4981 - val_loss: 0.5849\n",
            "Epoch 137/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4967 - val_loss: 0.5855\n",
            "Epoch 138/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4963 - val_loss: 0.5875\n",
            "Epoch 139/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4965 - val_loss: 0.5842\n",
            "Epoch 140/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4975 - val_loss: 0.5852\n",
            "Epoch 141/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4963 - val_loss: 0.5886\n",
            "Epoch 142/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4968 - val_loss: 0.5886\n",
            "Epoch 143/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4962 - val_loss: 0.5897\n",
            "Epoch 144/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4966 - val_loss: 0.5929\n",
            "Epoch 145/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4968 - val_loss: 0.5905\n",
            "Epoch 146/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4956 - val_loss: 0.5867\n",
            "Epoch 147/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4958 - val_loss: 0.5807\n",
            "Epoch 148/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4960 - val_loss: 0.5868\n",
            "Epoch 149/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4966 - val_loss: 0.5859\n",
            "Epoch 150/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4964 - val_loss: 0.5913\n",
            "Epoch 151/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4958 - val_loss: 0.5874\n",
            "Epoch 152/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4959 - val_loss: 0.5898\n",
            "Epoch 153/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4969 - val_loss: 0.5917\n",
            "Epoch 154/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4952 - val_loss: 0.5888\n",
            "Epoch 155/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4965 - val_loss: 0.5871\n",
            "Epoch 156/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4952 - val_loss: 0.5859\n",
            "Epoch 157/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4969 - val_loss: 0.5870\n",
            "Epoch 158/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4956 - val_loss: 0.5823\n",
            "Epoch 159/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4947 - val_loss: 0.5863\n",
            "Epoch 160/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4946 - val_loss: 0.5884\n",
            "Epoch 161/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4963 - val_loss: 0.5885\n",
            "Epoch 162/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4952 - val_loss: 0.5849\n",
            "Epoch 163/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4955 - val_loss: 0.5838\n",
            "Epoch 164/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4946 - val_loss: 0.5819\n",
            "Epoch 165/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4962 - val_loss: 0.5844\n",
            "Epoch 166/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4956 - val_loss: 0.5925\n",
            "Epoch 167/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4956 - val_loss: 0.5955\n",
            "Epoch 168/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4958 - val_loss: 0.5934\n",
            "Epoch 169/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4950 - val_loss: 0.5903\n",
            "Epoch 170/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4944 - val_loss: 0.5888\n",
            "Epoch 171/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4952 - val_loss: 0.5909\n",
            "Epoch 172/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4949 - val_loss: 0.5873\n",
            "Epoch 173/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4937 - val_loss: 0.5921\n",
            "Epoch 174/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4952 - val_loss: 0.5905\n",
            "Epoch 175/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4943 - val_loss: 0.5871\n",
            "Epoch 176/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4950 - val_loss: 0.5911\n",
            "Epoch 177/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4947 - val_loss: 0.5916\n",
            "Epoch 178/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4947 - val_loss: 0.5920\n",
            "Epoch 179/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4926 - val_loss: 0.5882\n",
            "Epoch 180/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4942 - val_loss: 0.5895\n",
            "Epoch 181/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4940 - val_loss: 0.5912\n",
            "Epoch 182/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4943 - val_loss: 0.5889\n",
            "Epoch 183/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4950 - val_loss: 0.5911\n",
            "Epoch 184/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4944 - val_loss: 0.5925\n",
            "Epoch 185/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4935 - val_loss: 0.5930\n",
            "Epoch 186/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4938 - val_loss: 0.5896\n",
            "Epoch 187/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4934 - val_loss: 0.5911\n",
            "Epoch 188/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4923 - val_loss: 0.5866\n",
            "Epoch 189/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4941 - val_loss: 0.5891\n",
            "Epoch 190/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4931 - val_loss: 0.5883\n",
            "Epoch 191/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4926 - val_loss: 0.5923\n",
            "Epoch 192/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4926 - val_loss: 0.5941\n",
            "Epoch 193/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4934 - val_loss: 0.5937\n",
            "Epoch 194/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4924 - val_loss: 0.5840\n",
            "Epoch 195/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4928 - val_loss: 0.5882\n",
            "Epoch 196/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4934 - val_loss: 0.5908\n",
            "Epoch 197/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4916 - val_loss: 0.5881\n",
            "Epoch 198/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 0.5961\n",
            "Epoch 199/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4936 - val_loss: 0.5898\n",
            "Epoch 200/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4920 - val_loss: 0.5927\n",
            "Epoch 201/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4921 - val_loss: 0.5891\n",
            "Epoch 202/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 0.5909\n",
            "Epoch 203/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4903 - val_loss: 0.5888\n",
            "Epoch 204/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4925 - val_loss: 0.5874\n",
            "Epoch 205/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4915 - val_loss: 0.5941\n",
            "Epoch 206/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4910 - val_loss: 0.5921\n",
            "Epoch 207/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4918 - val_loss: 0.5908\n",
            "Epoch 208/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4918 - val_loss: 0.5956\n",
            "Epoch 209/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4909 - val_loss: 0.5902\n",
            "Epoch 210/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4916 - val_loss: 0.5936\n",
            "Epoch 211/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4913 - val_loss: 0.5939\n",
            "Epoch 212/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4916 - val_loss: 0.5932\n",
            "Epoch 213/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4910 - val_loss: 0.5942\n",
            "Epoch 214/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4913 - val_loss: 0.5912\n",
            "Epoch 215/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4910 - val_loss: 0.5943\n",
            "Epoch 216/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4901 - val_loss: 0.5878\n",
            "Epoch 217/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4915 - val_loss: 0.5935\n",
            "Epoch 218/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 0.5886\n",
            "Epoch 219/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4900 - val_loss: 0.5938\n",
            "Epoch 220/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4905 - val_loss: 0.5959\n",
            "Epoch 221/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4901 - val_loss: 0.5910\n",
            "Epoch 222/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4906 - val_loss: 0.5887\n",
            "Epoch 223/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4897 - val_loss: 0.5938\n",
            "Epoch 224/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4899 - val_loss: 0.5923\n",
            "Epoch 225/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4910 - val_loss: 0.5913\n",
            "Epoch 226/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4891 - val_loss: 0.5954\n",
            "Epoch 227/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4895 - val_loss: 0.5956\n",
            "Epoch 228/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4889 - val_loss: 0.5965\n",
            "Epoch 229/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4901 - val_loss: 0.5922\n",
            "Epoch 230/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4881 - val_loss: 0.5919\n",
            "Epoch 231/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4901 - val_loss: 0.5957\n",
            "Epoch 232/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4902 - val_loss: 0.5976\n",
            "Epoch 233/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4904 - val_loss: 0.5962\n",
            "Epoch 234/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4899 - val_loss: 0.5924\n",
            "Epoch 235/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.5958\n",
            "Epoch 236/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4894 - val_loss: 0.5909\n",
            "Epoch 237/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4895 - val_loss: 0.5920\n",
            "Epoch 238/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4887 - val_loss: 0.5956\n",
            "Epoch 239/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4900 - val_loss: 0.5934\n",
            "Epoch 240/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4901 - val_loss: 0.5935\n",
            "Epoch 241/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4889 - val_loss: 0.5934\n",
            "Epoch 242/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4884 - val_loss: 0.5949\n",
            "Epoch 243/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4884 - val_loss: 0.5912\n",
            "Epoch 244/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4891 - val_loss: 0.5957\n",
            "Epoch 245/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4892 - val_loss: 0.5985\n",
            "Epoch 246/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4898 - val_loss: 0.5918\n",
            "Epoch 247/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4897 - val_loss: 0.5908\n",
            "Epoch 248/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4907 - val_loss: 0.5974\n",
            "Epoch 249/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 0.5928\n",
            "Epoch 250/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5932\n",
            "Epoch 251/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4901 - val_loss: 0.5933\n",
            "Epoch 252/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4870 - val_loss: 0.5957\n",
            "Epoch 253/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4900 - val_loss: 0.5955\n",
            "Epoch 254/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4892 - val_loss: 0.5946\n",
            "Epoch 255/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4888 - val_loss: 0.5995\n",
            "Epoch 256/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4892 - val_loss: 0.5979\n",
            "Epoch 257/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4876 - val_loss: 0.5972\n",
            "Epoch 258/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4885 - val_loss: 0.6015\n",
            "Epoch 259/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5958\n",
            "Epoch 260/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4876 - val_loss: 0.5990\n",
            "Epoch 261/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4880 - val_loss: 0.6002\n",
            "Epoch 262/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4889 - val_loss: 0.5970\n",
            "Epoch 263/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4885 - val_loss: 0.5967\n",
            "Epoch 264/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.5914\n",
            "Epoch 265/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4872 - val_loss: 0.5997\n",
            "Epoch 266/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4877 - val_loss: 0.5947\n",
            "Epoch 267/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4868 - val_loss: 0.5965\n",
            "Epoch 268/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4880 - val_loss: 0.5999\n",
            "Epoch 269/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4882 - val_loss: 0.5977\n",
            "Epoch 270/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.5984\n",
            "Epoch 271/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4888 - val_loss: 0.5968\n",
            "Epoch 272/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4882 - val_loss: 0.5985\n",
            "Epoch 273/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.5963\n",
            "Epoch 274/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4878 - val_loss: 0.5963\n",
            "Epoch 275/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4859 - val_loss: 0.5971\n",
            "Epoch 276/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4880 - val_loss: 0.5970\n",
            "Epoch 277/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4872 - val_loss: 0.5980\n",
            "Epoch 278/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4875 - val_loss: 0.5938\n",
            "Epoch 279/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4884 - val_loss: 0.5941\n",
            "Epoch 280/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5971\n",
            "Epoch 281/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.5969\n",
            "Epoch 282/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4881 - val_loss: 0.5986\n",
            "Epoch 283/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4858 - val_loss: 0.5989\n",
            "Epoch 284/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5939\n",
            "Epoch 285/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4847 - val_loss: 0.6048\n",
            "Epoch 286/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4858 - val_loss: 0.6064\n",
            "Epoch 287/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.5973\n",
            "Epoch 288/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.5947\n",
            "Epoch 289/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4852 - val_loss: 0.5983\n",
            "Epoch 290/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4868 - val_loss: 0.5961\n",
            "Epoch 291/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4860 - val_loss: 0.6017\n",
            "Epoch 292/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4872 - val_loss: 0.5976\n",
            "Epoch 293/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4863 - val_loss: 0.6006\n",
            "Epoch 294/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4872 - val_loss: 0.6033\n",
            "Epoch 295/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4870 - val_loss: 0.6001\n",
            "Epoch 296/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4879 - val_loss: 0.5994\n",
            "Epoch 297/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.5991\n",
            "Epoch 298/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4859 - val_loss: 0.5967\n",
            "Epoch 299/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4864 - val_loss: 0.5974\n",
            "Epoch 300/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4877 - val_loss: 0.5950\n",
            "Epoch 301/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.5964\n",
            "Epoch 302/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 0.5966\n",
            "Epoch 303/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4855 - val_loss: 0.6038\n",
            "Epoch 304/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4858 - val_loss: 0.6051\n",
            "Epoch 305/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4868 - val_loss: 0.6018\n",
            "Epoch 306/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4869 - val_loss: 0.5976\n",
            "Epoch 307/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4873 - val_loss: 0.5997\n",
            "Epoch 308/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4858 - val_loss: 0.5955\n",
            "Epoch 309/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4838 - val_loss: 0.6062\n",
            "Epoch 310/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4860 - val_loss: 0.5976\n",
            "Epoch 311/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4866 - val_loss: 0.6014\n",
            "Epoch 312/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4872 - val_loss: 0.6001\n",
            "Epoch 313/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4845 - val_loss: 0.6008\n",
            "Epoch 314/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4862 - val_loss: 0.6035\n",
            "Epoch 315/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4864 - val_loss: 0.6027\n",
            "Epoch 316/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4849 - val_loss: 0.6015\n",
            "Epoch 317/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4851 - val_loss: 0.5974\n",
            "Epoch 318/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4855 - val_loss: 0.5953\n",
            "Epoch 319/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.6037\n",
            "Epoch 320/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 0.5975\n",
            "Epoch 321/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.6049\n",
            "Epoch 322/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4863 - val_loss: 0.6020\n",
            "Epoch 323/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4855 - val_loss: 0.5988\n",
            "Epoch 324/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4841 - val_loss: 0.5966\n",
            "Epoch 325/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4857 - val_loss: 0.5922\n",
            "Epoch 326/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4855 - val_loss: 0.5948\n",
            "Epoch 327/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4845 - val_loss: 0.5955\n",
            "Epoch 328/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4849 - val_loss: 0.5939\n",
            "Epoch 329/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4837 - val_loss: 0.5972\n",
            "Epoch 330/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4850 - val_loss: 0.5967\n",
            "Epoch 331/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4842 - val_loss: 0.5926\n",
            "Epoch 332/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4843 - val_loss: 0.5953\n",
            "Epoch 333/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.5963\n",
            "Epoch 334/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.5982\n",
            "Epoch 335/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4842 - val_loss: 0.5951\n",
            "Epoch 336/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4845 - val_loss: 0.5963\n",
            "Epoch 337/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4835 - val_loss: 0.5987\n",
            "Epoch 338/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.5980\n",
            "Epoch 339/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4835 - val_loss: 0.5994\n",
            "Epoch 340/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4842 - val_loss: 0.5941\n",
            "Epoch 341/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4815 - val_loss: 0.5947\n",
            "Epoch 342/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4814 - val_loss: 0.5988\n",
            "Epoch 343/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4842 - val_loss: 0.5940\n",
            "Epoch 344/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.5958\n",
            "Epoch 345/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4843 - val_loss: 0.5955\n",
            "Epoch 346/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4834 - val_loss: 0.5950\n",
            "Epoch 347/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4834 - val_loss: 0.5930\n",
            "Epoch 348/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4838 - val_loss: 0.5977\n",
            "Epoch 349/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4834 - val_loss: 0.5941\n",
            "Epoch 350/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4837 - val_loss: 0.5975\n",
            "Epoch 351/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.5956\n",
            "Epoch 352/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4842 - val_loss: 0.5913\n",
            "Epoch 353/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4827 - val_loss: 0.5960\n",
            "Epoch 354/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.5908\n",
            "Epoch 355/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 0.5953\n",
            "Epoch 356/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 0.5947\n",
            "Epoch 357/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4823 - val_loss: 0.5898\n",
            "Epoch 358/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4821 - val_loss: 0.5968\n",
            "Epoch 359/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5975\n",
            "Epoch 360/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4839 - val_loss: 0.5948\n",
            "Epoch 361/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4823 - val_loss: 0.5969\n",
            "Epoch 362/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4830 - val_loss: 0.5973\n",
            "Epoch 363/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5995\n",
            "Epoch 364/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4823 - val_loss: 0.5912\n",
            "Epoch 365/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4792 - val_loss: 0.5890\n",
            "Epoch 366/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4832 - val_loss: 0.5941\n",
            "Epoch 367/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 0.5943\n",
            "Epoch 368/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4821 - val_loss: 0.5922\n",
            "Epoch 369/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4821 - val_loss: 0.5940\n",
            "Epoch 370/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4819 - val_loss: 0.5950\n",
            "Epoch 371/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4810 - val_loss: 0.5922\n",
            "Epoch 372/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.5960\n",
            "Epoch 373/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.5950\n",
            "Epoch 374/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.5949\n",
            "Epoch 375/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4829 - val_loss: 0.5969\n",
            "Epoch 376/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4812 - val_loss: 0.5945\n",
            "Epoch 377/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4806 - val_loss: 0.5937\n",
            "Epoch 378/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 0.5985\n",
            "Epoch 379/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.5994\n",
            "Epoch 380/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4821 - val_loss: 0.5955\n",
            "Epoch 381/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5967\n",
            "Epoch 382/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4804 - val_loss: 0.5959\n",
            "Epoch 383/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.5962\n",
            "Epoch 384/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4806 - val_loss: 0.5905\n",
            "Epoch 385/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.5962\n",
            "Epoch 386/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 0.5983\n",
            "Epoch 387/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4813 - val_loss: 0.6024\n",
            "Epoch 388/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4800 - val_loss: 0.5994\n",
            "Epoch 389/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4779 - val_loss: 0.5977\n",
            "Epoch 390/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4794 - val_loss: 0.5942\n",
            "Epoch 391/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.5923\n",
            "Epoch 392/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4809 - val_loss: 0.5953\n",
            "Epoch 393/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4797 - val_loss: 0.5963\n",
            "Epoch 394/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4809 - val_loss: 0.5922\n",
            "Epoch 395/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4799 - val_loss: 0.5926\n",
            "Epoch 396/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.5924\n",
            "Epoch 397/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.6012\n",
            "Epoch 398/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4794 - val_loss: 0.5976\n",
            "Epoch 399/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4802 - val_loss: 0.5944\n",
            "Epoch 400/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4771 - val_loss: 0.6017\n",
            "Epoch 401/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4801 - val_loss: 0.5970\n",
            "Epoch 402/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4793 - val_loss: 0.5930\n",
            "Epoch 403/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4795 - val_loss: 0.5964\n",
            "Epoch 404/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.6019\n",
            "Epoch 405/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.5978\n",
            "Epoch 406/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4796 - val_loss: 0.5953\n",
            "Epoch 407/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.6021\n",
            "Epoch 408/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4784 - val_loss: 0.5887\n",
            "Epoch 409/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4773 - val_loss: 0.5939\n",
            "Epoch 410/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.5952\n",
            "Epoch 411/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 0.5936\n",
            "Epoch 412/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4767 - val_loss: 0.5977\n",
            "Epoch 413/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.5982\n",
            "Epoch 414/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4781 - val_loss: 0.5942\n",
            "Epoch 415/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4773 - val_loss: 0.6005\n",
            "Epoch 416/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.5992\n",
            "Epoch 417/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4795 - val_loss: 0.5938\n",
            "Epoch 418/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.5971\n",
            "Epoch 419/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 0.5962\n",
            "Epoch 420/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4779 - val_loss: 0.5956\n",
            "Epoch 421/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.5986\n",
            "Epoch 422/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.5935\n",
            "Epoch 423/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4800 - val_loss: 0.5973\n",
            "Epoch 424/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4768 - val_loss: 0.6043\n",
            "Epoch 425/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.6024\n",
            "Epoch 426/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.5969\n",
            "Epoch 427/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4771 - val_loss: 0.5957\n",
            "Epoch 428/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.6026\n",
            "Epoch 429/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.5988\n",
            "Epoch 430/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4769 - val_loss: 0.5973\n",
            "Epoch 431/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.5948\n",
            "Epoch 432/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4771 - val_loss: 0.5950\n",
            "Epoch 433/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4778 - val_loss: 0.5962\n",
            "Epoch 434/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.6001\n",
            "Epoch 435/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.5977\n",
            "Epoch 436/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 0.5934\n",
            "Epoch 437/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.6025\n",
            "Epoch 438/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4763 - val_loss: 0.6011\n",
            "Epoch 439/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4767 - val_loss: 0.5897\n",
            "Epoch 440/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4772 - val_loss: 0.5920\n",
            "Epoch 441/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 0.5906\n",
            "Epoch 442/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4758 - val_loss: 0.5961\n",
            "Epoch 443/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.5938\n",
            "Epoch 444/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 0.5919\n",
            "Epoch 445/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.5944\n",
            "Epoch 446/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4776 - val_loss: 0.5923\n",
            "Epoch 447/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.5964\n",
            "Epoch 448/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.5916\n",
            "Epoch 449/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4757 - val_loss: 0.5971\n",
            "Epoch 450/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.5887\n",
            "Epoch 451/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5965\n",
            "Epoch 452/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 0.5983\n",
            "Epoch 453/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.5970\n",
            "Epoch 454/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4754 - val_loss: 0.5949\n",
            "Epoch 455/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.5933\n",
            "Epoch 456/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5983\n",
            "Epoch 457/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.5980\n",
            "Epoch 458/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.5956\n",
            "Epoch 459/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4742 - val_loss: 0.5981\n",
            "Epoch 460/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 0.5992\n",
            "Epoch 461/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.5956\n",
            "Epoch 462/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4739 - val_loss: 0.5995\n",
            "Epoch 463/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.5974\n",
            "Epoch 464/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4764 - val_loss: 0.5973\n",
            "Epoch 465/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5941\n",
            "Epoch 466/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4754 - val_loss: 0.5902\n",
            "Epoch 467/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.5945\n",
            "Epoch 468/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4759 - val_loss: 0.5974\n",
            "Epoch 469/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4736 - val_loss: 0.5957\n",
            "Epoch 470/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 0.5926\n",
            "Epoch 471/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.5935\n",
            "Epoch 472/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4750 - val_loss: 0.5934\n",
            "Epoch 473/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4744 - val_loss: 0.5926\n",
            "Epoch 474/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.6006\n",
            "Epoch 475/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 0.5983\n",
            "Epoch 476/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4748 - val_loss: 0.6007\n",
            "Epoch 477/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 0.6008\n",
            "Epoch 478/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4732 - val_loss: 0.6002\n",
            "Epoch 479/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.5953\n",
            "Epoch 480/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.6052\n",
            "Epoch 481/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4732 - val_loss: 0.6010\n",
            "Epoch 482/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4756 - val_loss: 0.5917\n",
            "Epoch 483/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5977\n",
            "Epoch 484/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4738 - val_loss: 0.5971\n",
            "Epoch 485/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4742 - val_loss: 0.5991\n",
            "Epoch 486/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.5988\n",
            "Epoch 487/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4742 - val_loss: 0.6033\n",
            "Epoch 488/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4737 - val_loss: 0.5933\n",
            "Epoch 489/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4750 - val_loss: 0.5924\n",
            "Epoch 490/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.5945\n",
            "Epoch 491/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4742 - val_loss: 0.6061\n",
            "Epoch 492/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4736 - val_loss: 0.5961\n",
            "Epoch 493/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 0.6016\n",
            "Epoch 494/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4735 - val_loss: 0.6007\n",
            "Epoch 495/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4743 - val_loss: 0.5962\n",
            "Epoch 496/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4712 - val_loss: 0.5961\n",
            "Epoch 497/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4762 - val_loss: 0.6003\n",
            "Epoch 498/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4709 - val_loss: 0.6097\n",
            "Epoch 499/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4738 - val_loss: 0.5974\n",
            "Epoch 500/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4713 - val_loss: 0.6032\n",
            "Epoch 501/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4750 - val_loss: 0.5967\n",
            "Epoch 502/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4731 - val_loss: 0.5998\n",
            "Epoch 503/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4714 - val_loss: 0.6003\n",
            "Epoch 504/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4728 - val_loss: 0.5988\n",
            "Epoch 505/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4734 - val_loss: 0.6000\n",
            "Epoch 506/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4719 - val_loss: 0.6002\n",
            "Epoch 507/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.5963\n",
            "Epoch 508/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4723 - val_loss: 0.5978\n",
            "Epoch 509/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4721 - val_loss: 0.6017\n",
            "Epoch 510/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4705 - val_loss: 0.5983\n",
            "Epoch 511/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4707 - val_loss: 0.6059\n",
            "Epoch 512/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4733 - val_loss: 0.6030\n",
            "Epoch 513/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4711 - val_loss: 0.6058\n",
            "Epoch 514/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4731 - val_loss: 0.6027\n",
            "Epoch 515/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4723 - val_loss: 0.5985\n",
            "Epoch 516/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 0.5974\n",
            "Epoch 517/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.5987\n",
            "Epoch 518/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 0.5977\n",
            "Epoch 519/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4733 - val_loss: 0.5994\n",
            "Epoch 520/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4713 - val_loss: 0.6004\n",
            "Epoch 521/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4723 - val_loss: 0.5990\n",
            "Epoch 522/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4725 - val_loss: 0.5941\n",
            "Epoch 523/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4734 - val_loss: 0.6011\n",
            "Epoch 524/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4706 - val_loss: 0.5987\n",
            "Epoch 525/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.5916\n",
            "Epoch 526/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4731 - val_loss: 0.6039\n",
            "Epoch 527/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4738 - val_loss: 0.6052\n",
            "Epoch 528/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4732 - val_loss: 0.5960\n",
            "Epoch 529/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4744 - val_loss: 0.6008\n",
            "Epoch 530/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4725 - val_loss: 0.5981\n",
            "Epoch 531/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.6001\n",
            "Epoch 532/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4716 - val_loss: 0.5985\n",
            "Epoch 533/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.5986\n",
            "Epoch 534/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4723 - val_loss: 0.5985\n",
            "Epoch 535/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4723 - val_loss: 0.5977\n",
            "Epoch 536/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 0.5979\n",
            "Epoch 537/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4729 - val_loss: 0.6039\n",
            "Epoch 538/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4724 - val_loss: 0.5998\n",
            "Epoch 539/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4713 - val_loss: 0.6066\n",
            "Epoch 540/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4730 - val_loss: 0.6009\n",
            "Epoch 541/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.5967\n",
            "Epoch 542/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 0.6057\n",
            "Epoch 543/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4728 - val_loss: 0.6023\n",
            "Epoch 544/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4697 - val_loss: 0.6086\n",
            "Epoch 545/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4712 - val_loss: 0.6027\n",
            "Epoch 546/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.6063\n",
            "Epoch 547/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4704 - val_loss: 0.6119\n",
            "Epoch 548/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4709 - val_loss: 0.6096\n",
            "Epoch 549/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.6062\n",
            "Epoch 550/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.6063\n",
            "Epoch 551/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4713 - val_loss: 0.6097\n",
            "Epoch 552/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4709 - val_loss: 0.6005\n",
            "Epoch 553/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4712 - val_loss: 0.6075\n",
            "Epoch 554/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4708 - val_loss: 0.5979\n",
            "Epoch 555/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4690 - val_loss: 0.6064\n",
            "Epoch 556/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4681 - val_loss: 0.6069\n",
            "Epoch 557/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4715 - val_loss: 0.6084\n",
            "Epoch 558/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4678 - val_loss: 0.6128\n",
            "Epoch 559/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4700 - val_loss: 0.6019\n",
            "Epoch 560/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4709 - val_loss: 0.6041\n",
            "Epoch 561/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4696 - val_loss: 0.6028\n",
            "Epoch 562/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4688 - val_loss: 0.6015\n",
            "Epoch 563/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4680 - val_loss: 0.5968\n",
            "Epoch 564/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4690 - val_loss: 0.6084\n",
            "Epoch 565/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4688 - val_loss: 0.6123\n",
            "Epoch 566/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 0.6060\n",
            "Epoch 567/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 0.6157\n",
            "Epoch 568/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.6053\n",
            "Epoch 569/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.6026\n",
            "Epoch 570/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4690 - val_loss: 0.6107\n",
            "Epoch 571/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4683 - val_loss: 0.6076\n",
            "Epoch 572/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4669 - val_loss: 0.6210\n",
            "Epoch 573/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4692 - val_loss: 0.6053\n",
            "Epoch 574/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.5999\n",
            "Epoch 575/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4669 - val_loss: 0.6045\n",
            "Epoch 576/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.6097\n",
            "Epoch 577/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4691 - val_loss: 0.6139\n",
            "Epoch 578/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4687 - val_loss: 0.6155\n",
            "Epoch 579/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4687 - val_loss: 0.6067\n",
            "Epoch 580/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4671 - val_loss: 0.6017\n",
            "Epoch 581/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.6136\n",
            "Epoch 582/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4683 - val_loss: 0.6016\n",
            "Epoch 583/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4691 - val_loss: 0.6025\n",
            "Epoch 584/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4681 - val_loss: 0.6030\n",
            "Epoch 585/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4670 - val_loss: 0.6109\n",
            "Epoch 586/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4661 - val_loss: 0.6056\n",
            "Epoch 587/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.6177\n",
            "Epoch 588/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.6284\n",
            "Epoch 589/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4663 - val_loss: 0.6130\n",
            "Epoch 590/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4652 - val_loss: 0.6189\n",
            "Epoch 591/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4643 - val_loss: 0.6135\n",
            "Epoch 592/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.6119\n",
            "Epoch 593/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.6080\n",
            "Epoch 594/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.6104\n",
            "Epoch 595/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.6132\n",
            "Epoch 596/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.6090\n",
            "Epoch 597/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4651 - val_loss: 0.6009\n",
            "Epoch 598/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 0.6050\n",
            "Epoch 599/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.6147\n",
            "Epoch 600/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4658 - val_loss: 0.6116\n",
            "Epoch 601/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.6043\n",
            "Epoch 602/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.6150\n",
            "Epoch 603/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4685 - val_loss: 0.6198\n",
            "Epoch 604/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4625 - val_loss: 0.6260\n",
            "Epoch 605/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4651 - val_loss: 0.6185\n",
            "Epoch 606/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4651 - val_loss: 0.6105\n",
            "Epoch 607/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4627 - val_loss: 0.6109\n",
            "Epoch 608/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.6182\n",
            "Epoch 609/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4647 - val_loss: 0.6139\n",
            "Epoch 610/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4646 - val_loss: 0.6100\n",
            "Epoch 611/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.6312\n",
            "Epoch 612/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.6228\n",
            "Epoch 613/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4646 - val_loss: 0.6193\n",
            "Epoch 614/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 0.6151\n",
            "Epoch 615/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.6061\n",
            "Epoch 616/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.6073\n",
            "Epoch 617/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4652 - val_loss: 0.6133\n",
            "Epoch 618/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4638 - val_loss: 0.6133\n",
            "Epoch 619/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4637 - val_loss: 0.6191\n",
            "Epoch 620/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4651 - val_loss: 0.6188\n",
            "Epoch 621/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.6214\n",
            "Epoch 622/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.6189\n",
            "Epoch 623/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.6081\n",
            "Epoch 624/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.6210\n",
            "Epoch 625/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.6270\n",
            "Epoch 626/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4661 - val_loss: 0.6126\n",
            "Epoch 627/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.6261\n",
            "Epoch 628/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4624 - val_loss: 0.6236\n",
            "Epoch 629/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.6188\n",
            "Epoch 630/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4637 - val_loss: 0.6190\n",
            "Epoch 631/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4635 - val_loss: 0.6172\n",
            "Epoch 632/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.6281\n",
            "Epoch 633/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.6145\n",
            "Epoch 634/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.6223\n",
            "Epoch 635/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4640 - val_loss: 0.6254\n",
            "Epoch 636/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4647 - val_loss: 0.6203\n",
            "Epoch 637/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4648 - val_loss: 0.6147\n",
            "Epoch 638/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.6233\n",
            "Epoch 639/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4627 - val_loss: 0.6306\n",
            "Epoch 640/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4646 - val_loss: 0.6248\n",
            "Epoch 641/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.6123\n",
            "Epoch 642/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4612 - val_loss: 0.6154\n",
            "Epoch 643/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.6175\n",
            "Epoch 644/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4630 - val_loss: 0.6185\n",
            "Epoch 645/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.6250\n",
            "Epoch 646/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.6249\n",
            "Epoch 647/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4658 - val_loss: 0.6235\n",
            "Epoch 648/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4636 - val_loss: 0.6251\n",
            "Epoch 649/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.6240\n",
            "Epoch 650/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 0.6286\n",
            "Epoch 651/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 0.6214\n",
            "Epoch 652/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.6271\n",
            "Epoch 653/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4640 - val_loss: 0.6255\n",
            "Epoch 654/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4627 - val_loss: 0.6294\n",
            "Epoch 655/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.6356\n",
            "Epoch 656/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4625 - val_loss: 0.6285\n",
            "Epoch 657/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4612 - val_loss: 0.6180\n",
            "Epoch 658/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4628 - val_loss: 0.6291\n",
            "Epoch 659/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.6245\n",
            "Epoch 660/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4638 - val_loss: 0.6250\n",
            "Epoch 661/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.6254\n",
            "Epoch 662/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.6276\n",
            "Epoch 663/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.6247\n",
            "Epoch 664/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4620 - val_loss: 0.6227\n",
            "Epoch 665/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4648 - val_loss: 0.6331\n",
            "Epoch 666/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4633 - val_loss: 0.6202\n",
            "Epoch 667/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.6193\n",
            "Epoch 668/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4628 - val_loss: 0.6229\n",
            "Epoch 669/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4561 - val_loss: 0.6232\n",
            "Epoch 670/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4647 - val_loss: 0.6294\n",
            "Epoch 671/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4625 - val_loss: 0.6242\n",
            "Epoch 672/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.6180\n",
            "Epoch 673/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.6261\n",
            "Epoch 674/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4630 - val_loss: 0.6181\n",
            "Epoch 675/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.6231\n",
            "Epoch 676/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.6186\n",
            "Epoch 677/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.6240\n",
            "Epoch 678/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4628 - val_loss: 0.6253\n",
            "Epoch 679/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.6299\n",
            "Epoch 680/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.6284\n",
            "Epoch 681/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.6287\n",
            "Epoch 682/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.6249\n",
            "Epoch 683/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.6233\n",
            "Epoch 684/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4625 - val_loss: 0.6229\n",
            "Epoch 685/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.6284\n",
            "Epoch 686/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.6106\n",
            "Epoch 687/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4620 - val_loss: 0.6209\n",
            "Epoch 688/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.6262\n",
            "Epoch 689/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.6282\n",
            "Epoch 690/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4599 - val_loss: 0.6260\n",
            "Epoch 691/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4628 - val_loss: 0.6240\n",
            "Epoch 692/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.6262\n",
            "Epoch 693/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.6245\n",
            "Epoch 694/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.6165\n",
            "Epoch 695/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.6106\n",
            "Epoch 696/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.6317\n",
            "Epoch 697/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4605 - val_loss: 0.6180\n",
            "Epoch 698/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4602 - val_loss: 0.6280\n",
            "Epoch 699/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.6225\n",
            "Epoch 700/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 0.6260\n",
            "Epoch 701/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.6263\n",
            "Epoch 702/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 0.6189\n",
            "Epoch 703/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.6285\n",
            "Epoch 704/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4575 - val_loss: 0.6459\n",
            "Epoch 705/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4624 - val_loss: 0.6309\n",
            "Epoch 706/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4566 - val_loss: 0.6465\n",
            "Epoch 707/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4637 - val_loss: 0.6273\n",
            "Epoch 708/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.6382\n",
            "Epoch 709/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.6295\n",
            "Epoch 710/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.6485\n",
            "Epoch 711/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4639 - val_loss: 0.6353\n",
            "Epoch 712/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.6241\n",
            "Epoch 713/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.6216\n",
            "Epoch 714/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.6247\n",
            "Epoch 715/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4637 - val_loss: 0.6300\n",
            "Epoch 716/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.6265\n",
            "Epoch 717/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.6304\n",
            "Epoch 718/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.6221\n",
            "Epoch 719/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4582 - val_loss: 0.6348\n",
            "Epoch 720/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4599 - val_loss: 0.6273\n",
            "Epoch 721/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4609 - val_loss: 0.6342\n",
            "Epoch 722/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4604 - val_loss: 0.6270\n",
            "Epoch 723/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.6284\n",
            "Epoch 724/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4638 - val_loss: 0.6334\n",
            "Epoch 725/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.6339\n",
            "Epoch 726/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.6208\n",
            "Epoch 727/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.6369\n",
            "Epoch 728/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.6239\n",
            "Epoch 729/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4603 - val_loss: 0.6348\n",
            "Epoch 730/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4563 - val_loss: 0.6461\n",
            "Epoch 731/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.6350\n",
            "Epoch 732/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.6210\n",
            "Epoch 733/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.6377\n",
            "Epoch 734/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 0.6430\n",
            "Epoch 735/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.6388\n",
            "Epoch 736/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.6419\n",
            "Epoch 737/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.6289\n",
            "Epoch 738/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.6243\n",
            "Epoch 739/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4605 - val_loss: 0.6228\n",
            "Epoch 740/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.6445\n",
            "Epoch 741/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4606 - val_loss: 0.6399\n",
            "Epoch 742/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4577 - val_loss: 0.6297\n",
            "Epoch 743/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.6508\n",
            "Epoch 744/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.6277\n",
            "Epoch 745/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.6262\n",
            "Epoch 746/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.6308\n",
            "Epoch 747/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4628 - val_loss: 0.6364\n",
            "Epoch 748/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.6439\n",
            "Epoch 749/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4575 - val_loss: 0.6321\n",
            "Epoch 750/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.6438\n",
            "Epoch 751/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.6435\n",
            "Epoch 752/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.6326\n",
            "Epoch 753/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.6236\n",
            "Epoch 754/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.6317\n",
            "Epoch 755/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.6397\n",
            "Epoch 756/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.6308\n",
            "Epoch 757/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4604 - val_loss: 0.6297\n",
            "Epoch 758/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4592 - val_loss: 0.6306\n",
            "Epoch 759/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4636 - val_loss: 0.6326\n",
            "Epoch 760/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4605 - val_loss: 0.6378\n",
            "Epoch 761/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4620 - val_loss: 0.6243\n",
            "Epoch 762/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4564 - val_loss: 0.6141\n",
            "Epoch 763/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4614 - val_loss: 0.6271\n",
            "Epoch 764/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.6208\n",
            "Epoch 765/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4553 - val_loss: 0.6387\n",
            "Epoch 766/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4599 - val_loss: 0.6339\n",
            "Epoch 767/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.6348\n",
            "Epoch 768/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4537 - val_loss: 0.6387\n",
            "Epoch 769/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.6354\n",
            "Epoch 770/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4586 - val_loss: 0.6395\n",
            "Epoch 771/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4604 - val_loss: 0.6332\n",
            "Epoch 772/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.6407\n",
            "Epoch 773/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.6506\n",
            "Epoch 774/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4604 - val_loss: 0.6326\n",
            "Epoch 775/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.6558\n",
            "Epoch 776/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4638 - val_loss: 0.6296\n",
            "Epoch 777/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.6372\n",
            "Epoch 778/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.6341\n",
            "Epoch 779/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4620 - val_loss: 0.6330\n",
            "Epoch 780/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4622 - val_loss: 0.6343\n",
            "Epoch 781/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.6322\n",
            "Epoch 782/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.6272\n",
            "Epoch 783/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4556 - val_loss: 0.6219\n",
            "Epoch 784/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.6327\n",
            "Epoch 785/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.6380\n",
            "Epoch 786/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4637 - val_loss: 0.6339\n",
            "Epoch 787/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4566 - val_loss: 0.6294\n",
            "Epoch 788/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4603 - val_loss: 0.6328\n",
            "Epoch 789/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4554 - val_loss: 0.6404\n",
            "Epoch 790/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 0.6404\n",
            "Epoch 791/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4564 - val_loss: 0.6426\n",
            "Epoch 792/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.6294\n",
            "Epoch 793/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4593 - val_loss: 0.6288\n",
            "Epoch 794/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4577 - val_loss: 0.6342\n",
            "Epoch 795/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4589 - val_loss: 0.6365\n",
            "Epoch 796/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4598 - val_loss: 0.6328\n",
            "Epoch 797/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.6342\n",
            "Epoch 798/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4588 - val_loss: 0.6381\n",
            "Epoch 799/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.6343\n",
            "Epoch 800/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.6266\n",
            "Epoch 801/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4598 - val_loss: 0.6374\n",
            "Epoch 802/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4543 - val_loss: 0.6268\n",
            "Epoch 803/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.6409\n",
            "Epoch 804/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4554 - val_loss: 0.6341\n",
            "Epoch 805/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4589 - val_loss: 0.6452\n",
            "Epoch 806/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.6279\n",
            "Epoch 807/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.6331\n",
            "Epoch 808/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.6434\n",
            "Epoch 809/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.6404\n",
            "Epoch 810/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4580 - val_loss: 0.6455\n",
            "Epoch 811/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4563 - val_loss: 0.6496\n",
            "Epoch 812/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.6311\n",
            "Epoch 813/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.6231\n",
            "Epoch 814/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4561 - val_loss: 0.6420\n",
            "Epoch 815/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.6405\n",
            "Epoch 816/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.6388\n",
            "Epoch 817/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.6423\n",
            "Epoch 818/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4586 - val_loss: 0.6394\n",
            "Epoch 819/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.6440\n",
            "Epoch 820/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4575 - val_loss: 0.6422\n",
            "Epoch 821/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4580 - val_loss: 0.6392\n",
            "Epoch 822/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.6351\n",
            "Epoch 823/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.6336\n",
            "Epoch 824/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 0.6450\n",
            "Epoch 825/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.6384\n",
            "Epoch 826/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4602 - val_loss: 0.6345\n",
            "Epoch 827/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.6354\n",
            "Epoch 828/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4608 - val_loss: 0.6437\n",
            "Epoch 829/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4580 - val_loss: 0.6465\n",
            "Epoch 830/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 0.6361\n",
            "Epoch 831/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.6344\n",
            "Epoch 832/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4561 - val_loss: 0.6312\n",
            "Epoch 833/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.6416\n",
            "Epoch 834/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.6401\n",
            "Epoch 835/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4580 - val_loss: 0.6355\n",
            "Epoch 836/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4599 - val_loss: 0.6334\n",
            "Epoch 837/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.6394\n",
            "Epoch 838/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.6333\n",
            "Epoch 839/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.6396\n",
            "Epoch 840/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.6479\n",
            "Epoch 841/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4569 - val_loss: 0.6538\n",
            "Epoch 842/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4529 - val_loss: 0.6401\n",
            "Epoch 843/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4580 - val_loss: 0.6507\n",
            "Epoch 844/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.6449\n",
            "Epoch 845/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4543 - val_loss: 0.6397\n",
            "Epoch 846/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.6438\n",
            "Epoch 847/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.6429\n",
            "Epoch 848/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4603 - val_loss: 0.6408\n",
            "Epoch 849/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.6497\n",
            "Epoch 850/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4573 - val_loss: 0.6430\n",
            "Epoch 851/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4553 - val_loss: 0.6431\n",
            "Epoch 852/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4579 - val_loss: 0.6515\n",
            "Epoch 853/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.6507\n",
            "Epoch 854/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4556 - val_loss: 0.6405\n",
            "Epoch 855/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4541 - val_loss: 0.6397\n",
            "Epoch 856/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4616 - val_loss: 0.6470\n",
            "Epoch 857/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.6450\n",
            "Epoch 858/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.6575\n",
            "Epoch 859/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4551 - val_loss: 0.6442\n",
            "Epoch 860/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4575 - val_loss: 0.6426\n",
            "Epoch 861/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4531 - val_loss: 0.6424\n",
            "Epoch 862/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4589 - val_loss: 0.6568\n",
            "Epoch 863/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4580 - val_loss: 0.6492\n",
            "Epoch 864/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.6405\n",
            "Epoch 865/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.6373\n",
            "Epoch 866/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.6456\n",
            "Epoch 867/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4577 - val_loss: 0.6432\n",
            "Epoch 868/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4534 - val_loss: 0.6438\n",
            "Epoch 869/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4508 - val_loss: 0.6539\n",
            "Epoch 870/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4613 - val_loss: 0.6471\n",
            "Epoch 871/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.6588\n",
            "Epoch 872/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4592 - val_loss: 0.6471\n",
            "Epoch 873/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4553 - val_loss: 0.6410\n",
            "Epoch 874/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.6363\n",
            "Epoch 875/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.6484\n",
            "Epoch 876/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.6497\n",
            "Epoch 877/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4558 - val_loss: 0.6441\n",
            "Epoch 878/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.6422\n",
            "Epoch 879/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4575 - val_loss: 0.6458\n",
            "Epoch 880/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.6447\n",
            "Epoch 881/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4593 - val_loss: 0.6497\n",
            "Epoch 882/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.6464\n",
            "Epoch 883/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 0.6528\n",
            "Epoch 884/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4603 - val_loss: 0.6402\n",
            "Epoch 885/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4556 - val_loss: 0.6426\n",
            "Epoch 886/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.6555\n",
            "Epoch 887/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4587 - val_loss: 0.6522\n",
            "Epoch 888/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.6524\n",
            "Epoch 889/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.6424\n",
            "Epoch 890/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.6408\n",
            "Epoch 891/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.6522\n",
            "Epoch 892/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4553 - val_loss: 0.6554\n",
            "Epoch 893/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.6537\n",
            "Epoch 894/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4571 - val_loss: 0.6440\n",
            "Epoch 895/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4587 - val_loss: 0.6404\n",
            "Epoch 896/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.6526\n",
            "Epoch 897/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.6467\n",
            "Epoch 898/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4531 - val_loss: 0.6457\n",
            "Epoch 899/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.6523\n",
            "Epoch 900/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4571 - val_loss: 0.6561\n",
            "Epoch 901/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4586 - val_loss: 0.6430\n",
            "Epoch 902/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.6509\n",
            "Epoch 903/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 0.6504\n",
            "Epoch 904/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4539 - val_loss: 0.6454\n",
            "Epoch 905/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 0.6513\n",
            "Epoch 906/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.6580\n",
            "Epoch 907/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.6531\n",
            "Epoch 908/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.6566\n",
            "Epoch 909/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4532 - val_loss: 0.6495\n",
            "Epoch 910/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.6545\n",
            "Epoch 911/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4561 - val_loss: 0.6575\n",
            "Epoch 912/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4501 - val_loss: 0.6709\n",
            "Epoch 913/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.6483\n",
            "Epoch 914/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4545 - val_loss: 0.6409\n",
            "Epoch 915/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.6569\n",
            "Epoch 916/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.6517\n",
            "Epoch 917/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4522 - val_loss: 0.6486\n",
            "Epoch 918/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4544 - val_loss: 0.6682\n",
            "Epoch 919/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 0.6463\n",
            "Epoch 920/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.6577\n",
            "Epoch 921/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4541 - val_loss: 0.6521\n",
            "Epoch 922/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.6502\n",
            "Epoch 923/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.6515\n",
            "Epoch 924/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4501 - val_loss: 0.6610\n",
            "Epoch 925/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4577 - val_loss: 0.6499\n",
            "Epoch 926/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4556 - val_loss: 0.6533\n",
            "Epoch 927/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.6550\n",
            "Epoch 928/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4541 - val_loss: 0.6582\n",
            "Epoch 929/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4569 - val_loss: 0.6533\n",
            "Epoch 930/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4556 - val_loss: 0.6416\n",
            "Epoch 931/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.6522\n",
            "Epoch 932/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.6588\n",
            "Epoch 933/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4579 - val_loss: 0.6648\n",
            "Epoch 934/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.6534\n",
            "Epoch 935/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4546 - val_loss: 0.6640\n",
            "Epoch 936/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.6640\n",
            "Epoch 937/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.6580\n",
            "Epoch 938/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4550 - val_loss: 0.6651\n",
            "Epoch 939/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4545 - val_loss: 0.6544\n",
            "Epoch 940/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.6697\n",
            "Epoch 941/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.6593\n",
            "Epoch 942/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.6671\n",
            "Epoch 943/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4520 - val_loss: 0.6749\n",
            "Epoch 944/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 0.6583\n",
            "Epoch 945/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4531 - val_loss: 0.6513\n",
            "Epoch 946/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.6572\n",
            "Epoch 947/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4550 - val_loss: 0.6571\n",
            "Epoch 948/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.6649\n",
            "Epoch 949/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4519 - val_loss: 0.6504\n",
            "Epoch 950/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 0.6519\n",
            "Epoch 951/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4535 - val_loss: 0.6474\n",
            "Epoch 952/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.6619\n",
            "Epoch 953/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.6753\n",
            "Epoch 954/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.6630\n",
            "Epoch 955/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4546 - val_loss: 0.6740\n",
            "Epoch 956/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4523 - val_loss: 0.6522\n",
            "Epoch 957/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.6581\n",
            "Epoch 958/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4544 - val_loss: 0.6692\n",
            "Epoch 959/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.6543\n",
            "Epoch 960/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4440 - val_loss: 0.6717\n",
            "Epoch 961/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.6669\n",
            "Epoch 962/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4522 - val_loss: 0.6472\n",
            "Epoch 963/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4516 - val_loss: 0.6602\n",
            "Epoch 964/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4522 - val_loss: 0.6787\n",
            "Epoch 965/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.6570\n",
            "Epoch 966/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4563 - val_loss: 0.6687\n",
            "Epoch 967/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 0.6677\n",
            "Epoch 968/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.6724\n",
            "Epoch 969/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4522 - val_loss: 0.6608\n",
            "Epoch 970/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 0.6777\n",
            "Epoch 971/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.6749\n",
            "Epoch 972/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4543 - val_loss: 0.6757\n",
            "Epoch 973/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.6819\n",
            "Epoch 974/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4543 - val_loss: 0.6800\n",
            "Epoch 975/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.6753\n",
            "Epoch 976/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4492 - val_loss: 0.6719\n",
            "Epoch 977/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.6662\n",
            "Epoch 978/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.6694\n",
            "Epoch 979/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.6784\n",
            "Epoch 980/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4529 - val_loss: 0.6679\n",
            "Epoch 981/1000\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.4542 - val_loss: 0.6836\n",
            "Epoch 982/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4514 - val_loss: 0.6740\n",
            "Epoch 983/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.6710\n",
            "Epoch 984/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4494 - val_loss: 0.6981\n",
            "Epoch 985/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.6733\n",
            "Epoch 986/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4531 - val_loss: 0.6624\n",
            "Epoch 987/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4479 - val_loss: 0.6819\n",
            "Epoch 988/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4556 - val_loss: 0.6718\n",
            "Epoch 989/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.6665\n",
            "Epoch 990/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4520 - val_loss: 0.6756\n",
            "Epoch 991/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.6771\n",
            "Epoch 992/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4532 - val_loss: 0.6737\n",
            "Epoch 993/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4556 - val_loss: 0.6877\n",
            "Epoch 994/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.6704\n",
            "Epoch 995/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4529 - val_loss: 0.6786\n",
            "Epoch 996/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.6837\n",
            "Epoch 997/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4530 - val_loss: 0.6654\n",
            "Epoch 998/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4554 - val_loss: 0.6741\n",
            "Epoch 999/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4521 - val_loss: 0.7074\n",
            "Epoch 1000/1000\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.6868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftuj3ETrD-U1"
      },
      "source": [
        "untuk deeper model, val_loss sudah mulai stabil pada epoch ke 300 dengan kisaran nilai val_loss 0.56 dan loss 0.50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSpB4_wQt2Oa"
      },
      "source": [
        "#Nomor 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVcj_sxzuIAA"
      },
      "source": [
        "4. Lakukan prediksi terhadap dataset `winequality-white.csv`.\n",
        "  - Split dataset menggunakan library scikit-learn dengan perbandingan 80:20 dan random_state=10.\n",
        "  - Hasil prediksi dapat ditemui di kolom *quality*.\n",
        "  - Penjelasan dataset: https://archive.ics.uci.edu/ml/datasets/wine+quality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_EitCAAt1Wt"
      },
      "source": [
        "dataset4 = pd.read_csv('/content/drive/My Drive/dataset_quiz/winequality-white.csv', sep=';') #tabular dipisah menggunakan ';'"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t789QWc1Ai7g"
      },
      "source": [
        "##Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOdTTPdT7_p9",
        "outputId": "dfa7170a-66f0-4725-9ccc-b58abf8118b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "dataset4.head()"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.36</td>\n",
              "      <td>20.7</td>\n",
              "      <td>0.045</td>\n",
              "      <td>45.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>1.0010</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>8.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.049</td>\n",
              "      <td>14.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.9940</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.49</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.40</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0.050</td>\n",
              "      <td>30.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.9951</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.44</td>\n",
              "      <td>10.1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.9956</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.9956</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0            7.0              0.27         0.36  ...       0.45      8.8        6\n",
              "1            6.3              0.30         0.34  ...       0.49      9.5        6\n",
              "2            8.1              0.28         0.40  ...       0.44     10.1        6\n",
              "3            7.2              0.23         0.32  ...       0.40      9.9        6\n",
              "4            7.2              0.23         0.32  ...       0.40      9.9        6\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46PL7dwu_RY0",
        "outputId": "5c11b1bb-e1fe-46a1-fe0a-e86327878048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "dataset4.info()"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4898 entries, 0 to 4897\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         4898 non-null   float64\n",
            " 1   volatile acidity      4898 non-null   float64\n",
            " 2   citric acid           4898 non-null   float64\n",
            " 3   residual sugar        4898 non-null   float64\n",
            " 4   chlorides             4898 non-null   float64\n",
            " 5   free sulfur dioxide   4898 non-null   float64\n",
            " 6   total sulfur dioxide  4898 non-null   float64\n",
            " 7   density               4898 non-null   float64\n",
            " 8   pH                    4898 non-null   float64\n",
            " 9   sulphates             4898 non-null   float64\n",
            " 10  alcohol               4898 non-null   float64\n",
            " 11  quality               4898 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 459.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvsLgE9pAnHa"
      },
      "source": [
        "##Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL3g_BZm-ASc",
        "outputId": "6b3303e7-5f2b-4c18-84ba-9e5e38f76cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "label4 = dataset4['quality']\n",
        "features4 = dataset4.drop(['quality'], axis=1)\n",
        "\n",
        "from sklearn import preprocessing\n",
        "scaler4 = preprocessing.StandardScaler()\n",
        "\n",
        "features4 = scaler4.fit_transform(features4.values)\n",
        "label4 = scaler4.fit_transform(label4.values.reshape(-1,1)).flatten()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "feature_train4, feature_test4, label_train4, label_test4 = train_test_split(features4, label4, test_size=0.2, random_state=10) #perbandingan train dan test 80:20\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "lm4 = LinearRegression()\n",
        "lm4.fit(feature_train4, label_train4)\n",
        "\n",
        "predictions4 = lm4.predict(feature_test4)\n",
        "\n",
        "mse4 = mean_squared_error(label_test4, predictions4)\n",
        "mae4 = mean_absolute_error(label_test4, predictions4)\n",
        "r24 = r2_score(label_test4, predictions4)\n",
        "print(\"MSE (Mean Squared Error)\", mse4)\n",
        "print(\"MAE (Mean Absolute Error)\", mae4)\n",
        "print(\"r^2 score\", r24)\n",
        "print('RMSE (Root Mean Squared Error', np.sqrt(mean_squared_error(label_test4, predictions4)))"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE (Mean Squared Error) 0.7059920630290911\n",
            "MAE (Mean Absolute Error) 0.6532309508687619\n",
            "r^2 score 0.2742868892098229\n",
            "RMSE (Root Mean Squared Error 0.840233338441823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG2hEQCaBWF1"
      },
      "source": [
        "untuk linear regression, r2 yg didapat rendah yaitu 0.27"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lByAuzRNAraN"
      },
      "source": [
        "##Wider Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OLilSLE--xs",
        "outputId": "b413527b-38df-4e81-cb08-dec614833b87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "wider_model4 = Sequential()\n",
        "wider_model4.add(Dense(20, input_dim=11, kernel_initializer='normal', activation='relu')) #menggunakan neuron 20, input_dim=features=11\n",
        "wider_model4.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "wider_model4.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "historyw4 = wider_model4.fit(x=feature_train4, y=label_train4, validation_data=(feature_test4, label_test4), epochs=100, batch_size=8)\n"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7992 - val_loss: 0.6705\n",
            "Epoch 2/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6823 - val_loss: 0.6510\n",
            "Epoch 3/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6664 - val_loss: 0.6417\n",
            "Epoch 4/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6531 - val_loss: 0.6396\n",
            "Epoch 5/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6464 - val_loss: 0.6368\n",
            "Epoch 6/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6378 - val_loss: 0.6296\n",
            "Epoch 7/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6354 - val_loss: 0.6287\n",
            "Epoch 8/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6300 - val_loss: 0.6274\n",
            "Epoch 9/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6283 - val_loss: 0.6263\n",
            "Epoch 10/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6270 - val_loss: 0.6353\n",
            "Epoch 11/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6243 - val_loss: 0.6288\n",
            "Epoch 12/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6220 - val_loss: 0.6238\n",
            "Epoch 13/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6214 - val_loss: 0.6194\n",
            "Epoch 14/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6186 - val_loss: 0.6242\n",
            "Epoch 15/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6179 - val_loss: 0.6205\n",
            "Epoch 16/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6156 - val_loss: 0.6176\n",
            "Epoch 17/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6146 - val_loss: 0.6198\n",
            "Epoch 18/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6131 - val_loss: 0.6211\n",
            "Epoch 19/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6111 - val_loss: 0.6247\n",
            "Epoch 20/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6101 - val_loss: 0.6184\n",
            "Epoch 21/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6104 - val_loss: 0.6192\n",
            "Epoch 22/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6111 - val_loss: 0.6228\n",
            "Epoch 23/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6093 - val_loss: 0.6229\n",
            "Epoch 24/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6073 - val_loss: 0.6254\n",
            "Epoch 25/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6088 - val_loss: 0.6177\n",
            "Epoch 26/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6069 - val_loss: 0.6202\n",
            "Epoch 27/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6072 - val_loss: 0.6218\n",
            "Epoch 28/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6046 - val_loss: 0.6209\n",
            "Epoch 29/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6037 - val_loss: 0.6179\n",
            "Epoch 30/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6043 - val_loss: 0.6206\n",
            "Epoch 31/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6036 - val_loss: 0.6190\n",
            "Epoch 32/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6043 - val_loss: 0.6141\n",
            "Epoch 33/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6010 - val_loss: 0.6200\n",
            "Epoch 34/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6013 - val_loss: 0.6269\n",
            "Epoch 35/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6030 - val_loss: 0.6216\n",
            "Epoch 36/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6014 - val_loss: 0.6156\n",
            "Epoch 37/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6009 - val_loss: 0.6183\n",
            "Epoch 38/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5965 - val_loss: 0.6240\n",
            "Epoch 39/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5990 - val_loss: 0.6180\n",
            "Epoch 40/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5969 - val_loss: 0.6159\n",
            "Epoch 41/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5969 - val_loss: 0.6125\n",
            "Epoch 42/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5963 - val_loss: 0.6173\n",
            "Epoch 43/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5960 - val_loss: 0.6210\n",
            "Epoch 44/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5951 - val_loss: 0.6131\n",
            "Epoch 45/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5939 - val_loss: 0.6227\n",
            "Epoch 46/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5934 - val_loss: 0.6170\n",
            "Epoch 47/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5914 - val_loss: 0.6263\n",
            "Epoch 48/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5913 - val_loss: 0.6244\n",
            "Epoch 49/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5906 - val_loss: 0.6179\n",
            "Epoch 50/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5918 - val_loss: 0.6170\n",
            "Epoch 51/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5924 - val_loss: 0.6237\n",
            "Epoch 52/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5912 - val_loss: 0.6193\n",
            "Epoch 53/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5917 - val_loss: 0.6180\n",
            "Epoch 54/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5907 - val_loss: 0.6226\n",
            "Epoch 55/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5895 - val_loss: 0.6268\n",
            "Epoch 56/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5885 - val_loss: 0.6213\n",
            "Epoch 57/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5895 - val_loss: 0.6199\n",
            "Epoch 58/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5857 - val_loss: 0.6322\n",
            "Epoch 59/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5871 - val_loss: 0.6133\n",
            "Epoch 60/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5880 - val_loss: 0.6193\n",
            "Epoch 61/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5833 - val_loss: 0.6223\n",
            "Epoch 62/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5857 - val_loss: 0.6155\n",
            "Epoch 63/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5825 - val_loss: 0.6127\n",
            "Epoch 64/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5840 - val_loss: 0.6135\n",
            "Epoch 65/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5820 - val_loss: 0.6200\n",
            "Epoch 66/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5835 - val_loss: 0.6125\n",
            "Epoch 67/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5819 - val_loss: 0.6202\n",
            "Epoch 68/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5813 - val_loss: 0.6139\n",
            "Epoch 69/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5807 - val_loss: 0.6313\n",
            "Epoch 70/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5805 - val_loss: 0.6184\n",
            "Epoch 71/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5815 - val_loss: 0.6199\n",
            "Epoch 72/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5785 - val_loss: 0.6231\n",
            "Epoch 73/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5796 - val_loss: 0.6236\n",
            "Epoch 74/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5782 - val_loss: 0.6155\n",
            "Epoch 75/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5780 - val_loss: 0.6129\n",
            "Epoch 76/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5781 - val_loss: 0.6244\n",
            "Epoch 77/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5745 - val_loss: 0.6391\n",
            "Epoch 78/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5751 - val_loss: 0.6102\n",
            "Epoch 79/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5757 - val_loss: 0.6168\n",
            "Epoch 80/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5722 - val_loss: 0.6242\n",
            "Epoch 81/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5775 - val_loss: 0.6211\n",
            "Epoch 82/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5731 - val_loss: 0.6177\n",
            "Epoch 83/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5740 - val_loss: 0.6167\n",
            "Epoch 84/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5731 - val_loss: 0.6163\n",
            "Epoch 85/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5754 - val_loss: 0.6140\n",
            "Epoch 86/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5736 - val_loss: 0.6131\n",
            "Epoch 87/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5711 - val_loss: 0.6192\n",
            "Epoch 88/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5738 - val_loss: 0.6135\n",
            "Epoch 89/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5710 - val_loss: 0.6158\n",
            "Epoch 90/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5716 - val_loss: 0.6197\n",
            "Epoch 91/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5717 - val_loss: 0.6149\n",
            "Epoch 92/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5717 - val_loss: 0.6184\n",
            "Epoch 93/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5705 - val_loss: 0.6141\n",
            "Epoch 94/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5721 - val_loss: 0.6186\n",
            "Epoch 95/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5702 - val_loss: 0.6271\n",
            "Epoch 96/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5703 - val_loss: 0.6189\n",
            "Epoch 97/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5680 - val_loss: 0.6193\n",
            "Epoch 98/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5696 - val_loss: 0.6169\n",
            "Epoch 99/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5679 - val_loss: 0.6159\n",
            "Epoch 100/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5682 - val_loss: 0.6199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqt2OPQvAwv3",
        "outputId": "b2c85efe-63d2-4f84-aa55-9347f8060b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(historyw4)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVfrA8e+ZyaSTDklIAgkQpIUamhQRAbFglyJiL4vddd113d+qa9tVd9VVURcVK1LsqCiiEJoovXdCSygptCSQfn5/nEkySSaQNhmSvJ/nyZO5dc7JTO57T71Ka40QQghRkcXdCRBCCHFukgAhhBDCKQkQQgghnJIAIYQQwikJEEIIIZzycHcC6ktYWJiOjY2t9fE5OTn4+fnVX4IageaYZ2ie+W6OeYbmme+a5nn16tUZWuuWzrY1mQARGxvLqlWran18UlISw4YNq78ENQLNMc/QPPPdHPMMzTPfNc2zUmpfVdukikkIIYRTEiCEEEI4JQFCCCGEU02mDUII0TwVFBSQkpJCbm5upW2BgYFs3brVDalyn6ry7O3tTXR0NDabrdrnkgAhhGjUUlJSaNGiBbGxsSilym3LysqiRYsWbkqZezjLs9aazMxMUlJSiIuLq/a5pIpJCNGo5ebmEhoaWik4iDJKKUJDQ52Wss5EAoQQotGT4HB2tfkbNfsAkZ1XyMvzd7D7eJG7kyKEEOcUlwYIpdRopdR2pdQupdRjTra3UUotVEqtVUptUEpd6rDtr/bjtiulLnZVGvMLi3ntl50knyh21VsIIZo4f39/dyfBJVzWSK2UsgJTgJFACrBSKTVHa73FYbf/A2Zrrd9SSnUB5gKx9tfjga5Aa+BnpVRHrXW93+Z720yMLCiWBycJIYQjV5Yg+gG7tNbJWut8YCZwZYV9NBBgfx0IHLS/vhKYqbXO01rvAXbZz1fvPK32ACE1TEKIOtJa8+ijj9KtWzcSEhKYNWsWAIcOHWLo0KH07NmTbt26sWTJEoqKirjllltK933llVfcnPrKXNnNNQo44LCcAvSvsM9TwE9KqfsBP2CEw7G/VTg2quIbKKXuAu4CCA8PJykpqVYJtSrIyc2v9fGNVXZ2drPLMzTPfDflPAcGBpKVlQXACz/tZtuR7NJtWus6N2B3CvfnL6Pan3W/rKwsvvnmG1avXs3SpUvJzMxk2LBh9O7dm88++4xhw4bx6KOPUlRUxKlTp1i2bBn79+9n+fLlABw/frw0H3VRVFRU5Xlyc3Nr9D1w9ziICcAHWuv/KKUGAh8rpbpV92Ct9VRgKkBiYqKu7aRcPgvnoazIpF7NRHPMd1PO89atW0v7/ds8bVit1tJtRUVF5ZZrw+Zpq9ZYihYtWrB69WpuvPFGgoKCCAoKYtiwYWzdupXBgwdz2223YbFYuOqqq+jZsyc+Pj7s27ePxx9/nMsuu4xRo0ZhsdS9UudMYz+8vb3p1atXtc/lygCRCsQ4LEfb1zm6HRgNoLVerpTyBsKqeWy98fKwkF8sjdRCNHZPjulabvlcGSg3dOhQFi9ezPfff88tt9zCH//4R2666SbWr1/PvHnzePvtt5k9ezbTpk1zd1LLcWUbxEogXikVp5TyxDQ6z6mwz37gIgClVGfAG0i37zdeKeWllIoD4oEVrkqol4eFAokPQog6GjJkCLNmzaKoqIj09HQWL15Mv3792LdvH+Hh4dx5553ccccdrFmzhoyMDIqLi7n22mt59tlnWbNmjbuTX4nLShBa60Kl1H3APMAKTNNab1ZKPQ2s0lrPAR4B3lFKPYxpsL5Fa62BzUqp2cAWoBC41xU9mEp42awUFBW46vRCiGbi6quvZvny5fTo0QOlFC+++CIRERF8+OGHvPTSS9hsNvz9/fnoo49ITU3l1ltvpdhee/HPf/7TzamvzKVtEFrruZiuq47rnnB4vQUYVMWxzwHPuTJ9JaQEIYSoi+xs0zCulOKll17ipZdeKrf95ptv5uabb6503LlYanDU7EdSgylB5EuAEEKIciRAYC9BFMlAOSGEcCQBAvC2WaWKSQghKpAAgbRBCCGEMxIgkComIYRwRgIE4OUhVUxCCFGRBAjMjK4ym6sQQpQnAQJTgsiX2VyFEA3gTM+O2Lt3L926VXs6OpeTAAF42aSRWgghKnL3bK7nBC8PC0Uaioo1Vos821aIRuuHx+DwxtJFn6JCsNbxMheRAJf8q8rNjz32GDExMdx7770APPXUU3h4eLBw4UKOHTtGQUEBzz77LFdeWfFxOGeWm5vL5MmTWbVqFR4eHrz88stceOGFbN68mVtvvZX8/HyKi4v54osvaN26NWPHjiUlJYWCggKefPJJxo0bV6dsgwQIwIyDAPP4UR/Puk0NLIRoXsaNG8dDDz1UGiBmz57NvHnzeOCBBwgICCAjI4MBAwZwxRVX1OjZFFOmTEEpxcaNG9m2bRujRo1ix44dvP322zz44INMnDiR/Px8ioqKmDt3Lq1bt+b7778nKyurdH6nupIAgSlBAOQWFEmAEKIxq3Cnf7oBpvvu1asXaWlpHDx4kPT0dIKDg4mIiODhhx9m8eLFWCwWUlNTOXLkCBEREdU+79KlS7n//vsB6NSpE23btmXHjh0MHDiQ5557jpSUFK655hri4+NJSEjgkUce4S9/+QvDhw/n4osvrpe8SRsEppEaIK9QGiKEEDV3/fXX8/nnnzNr1izGjRvH9OnTSU9PZ/Xq1axbt47w8HByc3Pr5b1uuOEG5syZg4+PD5deeikLFiygY8eOrFmzhoSEBJ555hmefvrpenkvKUFgurkC5BVKVyYhRM2NGzeOO++8k4yMDBYtWsTs2bNp1aoVNpuNhQsXsm/fvhqfc8iQIUyfPp3hw4ezY8cO9u/fz3nnnUdycjLt2rXjgQceYP/+/WzYsIFOnToREhLCjTfeiKenJ59++mm95EsCBFKCEELUTdeuXcnKyiIqKorIyEgmTpzImDFjSEhIIDExkU6dOtX4nPfccw+TJ08mISEBDw8PPvjgA7y8vJg9ezYff/wxNpuNiIgIHn/8cVauXMmjjz6KxWLBYrEwderUesmXBAjKt0EIIURtbNxY1nsqLCyM5cuXO92v5NkRzsTGxrJp0ybAPD/6/fffr7TPY489xmOPPVZu3cUXX1za7lCfj1mVNgjMOAiQEoQQQjiSEgRl3VzzZLScEKIBbNy4kUmTJpVb5+Xlxe+//+6mFDknAQKpYhKisdNa12iMgbslJCSwbt26Bn1PrWs+35xUMSGN1EI0Zt7e3mRmZtbqAthcaK3JzMzE29u7RsdJCQLp5ipEYxYdHU1KSgrp6emVtuXm5tb4otjYVZVnb29voqOja3QuCRBICUKIxsxmsxEXF+d0W1JSEr169WrgFLlXfeZZqpiQNgghhHBGAgTSzVUIIZyRAIFDFZN0cxVCiFISIACrRWFV0kgthBCOJEDY2SyQKyUIIYQoJQHCzmaVEoQQQjiSAGHnaVHSSC2EEA4kQNiZKiYpQQghRAkJEHY2q5QghBDCkQQIO5tFxkEIIYQjlwYIpdRopdR2pdQupdRjTra/opRaZ//ZoZQ67rCtyGHbHFemE+wBQqqYhBCilMvmYlJKWYEpwEggBViplJqjtd5Sso/W+mGH/e8HHCcQOa217umq9FVksypypQQhhBClXFmC6Afs0lona63zgZnAlWfYfwIww4XpOSMpQQghRHmunM01CjjgsJwC9He2o1KqLRAHLHBY7a2UWgUUAv/SWn/t5Li7gLsAwsPDSUpKqnViLcWFHM/OrtM5GpvsZpbfEs0x380xz9A8812feT5XpvseD3yutXa8hW+rtU5VSrUDFiilNmqtdzsepLWeCkwFSExM1MOGDat1At7dOA9roY26nKOxSUpKalb5LdEc890c8wzNM9/1mWdXVjGlAjEOy9H2dc6Mp0L1ktY61f47GUiifPtEvZNxEEIIUZ4rA8RKIF4pFaeU8sQEgUq9kZRSnYBgYLnDumCllJf9dRgwCNhS8dj65CndXIUQohyXVTFprQuVUvcB8wArME1rvVkp9TSwSmtdEizGAzN1+QfKdgb+p5QqxgSxfzn2fnIFM1Cu0JVvIYQQjYpL2yC01nOBuRXWPVFh+Sknx/0KJLgybRXZLFBQpCkq1lgtqiHfWgghzkkyktrO/lA5mdFVCCHsJEDY2aym1CBPlRNCCEMChF1ZCUIChBBCgASIUiUBQrq6CiGEIQHCzrOkiklKEEIIAUiAKCWN1EIIUZ4ECDubRUoQQgjhSAKEnc1qfksbhBBCGBIg7DxLqpikm6sQQgASIEpJFZMQQpQnAcJOqpiEEKI8CRB2MlBOCCHKkwBhV1bFJCUIIYQACRClSqqYpAQhhBCGBAg7mWpDCCHKkwBhZ1EKT6tFShBCCGEnAcKBl4dFxkEIIYSdBAgHXjaLNFILIYSdBAgHXh5WcqUEIYQQgASIcqQEIYQQZSRAOPDysEojtRBC2EmAcODlYZFurkIIYScBwoG3Tbq5CiFECQkQDqSKSQghykiAcGDGQUgVkxBCgASIcrxsUoIQQogSEiAceEsJQgghSkmAcOAljdRCCFFKAoQDaaQWQogyEiAcyDgIIYQoIwHCgbfNSmGxprBIShFCCCEBwoGXh/lz5EuAEEII1wYIpdRopdR2pdQupdRjTra/opRaZ//ZoZQ67rDtZqXUTvvPza5MZ4mSACEzugohBHi46sRKKSswBRgJpAArlVJztNZbSvbRWj/ssP/9QC/76xDgSSAR0MBq+7HHXJVeMFVMgMzoKoQQuLYE0Q/YpbVO1lrnAzOBK8+w/wRghv31xcB8rfVRe1CYD4x2YVoB080VkKfKCSEELixBAFHAAYflFKC/sx2VUm2BOGDBGY6NcnLcXcBdAOHh4SQlJdU6sdnZ2ew6vA2Apct/Z2+Lpt88k52dXae/WWPVHPPdHPMMzTPf9ZlnVwaImhgPfK61rlHdjtZ6KjAVIDExUQ8bNqzWCUhKSqJ3+86wbhUJPXvTIyao1udqLJKSkqjL36yxao75bo55huaZ7/rMsytvk1OBGIflaPs6Z8ZTVr1U02PrTVkbhFQxCSGEKwPESiBeKRWnlPLEBIE5FXdSSnUCgoHlDqvnAaOUUsFKqWBglH2dS5X0YpJGaiGEcGEVk9a6UCl1H+bCbgWmaa03K6WeBlZprUuCxXhgptZaOxx7VCn1DCbIADyttT7qqrSW8PKwlyCkkVoIIVzbBqG1ngvMrbDuiQrLT1Vx7DRgmssS54S3vRdTrpQghBCielVMSik/pZTF/rqjUuoKpZTNtUlreFKCEEKIMtVtg1gMeCulooCfgEnAB65KlLuUjoOQRmohhKh2gFBa61PANcCbWuvrga6uS5Z7lE21IVVMQghR7QChlBoITAS+t6+zuiZJ7iPdXIUQokx1A8RDwF+Br+w9kdoBC12XLPfwtFrw8rCQnpXn7qQIIYTbVasXk9Z6EbAIwN5YnaG1fsCVCXMHi0WREBXI+pTjZ99ZCCGauOr2YvpUKRWglPIDNgFblFKPujZp7tEzJoiNqSfIl2omIUQzV90qpi5a65PAVcAPmIn1JrksVW7Uq00w+YXFbDt80t1JEUIIt6pugLDZxz1cBczRWhdgntPQ5PRqYybpW7tfqpmEEM1bdQPE/4C9gB+w2D49d5O8xY4M9KZVCy/W7nfps4mEEOKcV91G6teA1xxW7VNKXeiaJLmXUopebYJYd0BKEEKI5q26jdSBSqmXlVKr7D//wZQmmqRebYLZm3mKozn57k6KEEK4TXWrmKYBWcBY+89J4H1XJcrdetofFrTugFQzCSGar+oGiPZa6yftz5dO1lr/A2jnyoS5U/foQCwK1klDtRCiGatugDitlBpcsqCUGgScdk2S3M/X04NOEQGslXYIIUQzVt3nQfwB+EgpFWhfPgbc7JoknRt6tgni23UHKS7WWCzK3ckRQogGV60ShNZ6vda6B9Ad6K617gUMd2nK3KxXTBBZeYUkZ2S7OylCCOEWNXomtdb6pH1ENcAfXZCec0avNsEArJF2CCFEM1WjAFFBk653aRfmR6CPjd+TXf4obCGEOCfVJUA0nak2igpQxYXlVlksimHntWTh9jSKiptOVoUQorrOGCCUUllKqZNOfrKA1g2URtc6thf+04mW6csqbRrZJZyjOfmskWk3hBDN0Bl7MWmtWzRUQtwmsA14eBN+ZFGlTRd0bInNqpi/5Qh9Y0PckDghhHCfulQxNQ0WC3S/npCjayE7vdymFt42BrQLZf6WI2gt1UxCiOZFAgRAwlgUxbD5q0qbRnUJZ09GDrvTpburEKJ5kQABEN6FbL9Y2Di70qYRXcIBmL8lrYETJYQQ7iUBwu5I+AWQshKOJpdbHxnoQ0JUIPO3HHZTyoQQwj0kQNiltRoCKNjwWaVtI7uEs/bAcdKz8ho+YUII4SYSIOzyvFtC7GBTzVShQXpkl3C0hl+2HnFT6oQQouFJgHCUcD1k7oKDa8ut7hTRgrahvny6Yj/FMmhOCNFMSIBw1OVKsHrBmg/LrVZK8dCIeDaknODLtaluSpwQ57CD6yBPevo1NRIgHPkEQY/xsG5GpTERV/aIomdMEC/+uI2cvMIqTiBEM5R1BN4ZDr+/5e6UiHomAaKi8++HojxY+U651RaL4skxXUjLyuPNpF1uSpwQ56Bd80EXQdpWd6dE1DOXBgil1Gil1Hal1C6l1GNV7DNWKbVFKbVZKfWpw/oipdQ6+88cV6aznLB4OO9SWPEO5J8qt6lXm2Cu7hXFO0v2cODoqSpOIEQzs2Oe+Z2xw73paKy0huVvwslD7k5JJS4LEEopKzAFuAToAkxQSnWpsE888FdgkNa6K/CQw+bTWuue9p8rXJVOp85/AE4fhXXTK2368+jzsCrFP3+QuyUhKMyH3QvN68zdUFzs3vQ0RofWwby/wpJ/uzsllbiyBNEP2KW1TtZa5wMzgSsr7HMnMEVrfQxAa31uDFduMwCi+8LyN6C4qNymyEAf/nBBe+ZuPMxvyZl1e59iKZaLRm7/csjPgg4joeAUZB10d4rO7qf/g33L3Z2KMnuWmN8bP4fCc2uslSsDRBRwwGE5xb7OUUego1JqmVLqN6XUaIdt3kqpVfb1V7kwnZUpZdoiju2FX56GwxvLBYq7hrajdaA3T3+7pW7Pitj8Fbw5ANbPrHuahXCHnT+Znn997zDLGTvdm56zyToMv74Ov7/dMO+Xvh2+exhyT1S9z94lYPWE3OOw/YeGSVc1nXG67wZ6/3hgGBANLFZKJWitjwNttdapSql2wAKl1Eat9W7Hg5VSdwF3AYSHh5OUlFTrhGRnZ5c/XvvTM7AbQctehWWvUmj1Y1eH2zgcOQKAK2I1b68/ybPTf+aCGFut3rPj9tm0Boq+eZDVKYWc8ouudfqr4lFguh4W2vwrbauU52aiOebbVXnut+4rcgO6sG1vDucDO5fPJfVAAz5sUmv8cvaT49/W6eaK+Q7JXEV3IH/nQn5duNDcDLqIR8FJ+qx+FJ/cw+w6BikxFStQQBUXMSh5CWmthhGauYqsBW+wKT3I6flUcQFaWUGd+b6+Xj9rrbVLfoCBwDyH5b8Cf62wz9vArQ7LvwB9nZzrA+C6M71fnz59dF0sXLjQ+YZj+7ReN1PrN8/X+uWuWhcXa621Li4u1te+uUz3eeYnffJ0fu3edMpArd8eqvULceZ1/qnanedMPrhc6w+vcLqpyjw3cc0x3y7Jc8YurZ8M0Pq3t83/xXOttf7+T/X/Pmey6SuThm1znW6ulO9FL5r9nwzQ+sgW16WrMF/r9y/T+umWWv+3l9b/7al1UVHl/Q6sNGnZ+IXWPz2h9VPBWmcdqbxfQa7Wrydq/d0jZ33rmn7WwCpdxXXVlVVMK4F4pVScUsoTGA9U7I30Nab0gFIqDFPllKyUClZKeTmsHwRscWFaqxbUBnqMM1VOJw6YCf1MunhiTBcysvN5fUEtur3mnoC0LabH1NVTIW0z/Oi0o1ft5Z6AvcsgZZU0Hor6t/Mn8zt+lLkTD4tv+Cqmko4kS/5TaYocpw6tB69A83rv0uq9R8pqOLCiZun68TFTdTTmv3Dh42YS0OSFlffbs9j8jh0CPW8w3YU3VJ5VmhVTTS+xjZ9BUUHN0lIHLgsQWutC4D5gHrAVmK213qyUelopVdIraR6QqZTaAiwEHtVaZwKdgVVKqfX29f/SWrsnQJQ471JT17rpy9JV3aODuL5PNNOW7mFXWlbNzpeyCtAQ0w/iR8Dgh2H1B9X/0lbHniXmC5efDcf21N95hQDTvTWsI4TEmeXQeDNVTUPJToNdv0BQW3Pjtu/Xsx9zaAO0vxACY8ouzmc6/1eT4d3h8OEV1Q9+23+Ale+am8qeE6DzGPANg5XvVd5371Jo2Qn8W0LL8yCqD6z7tHywO3UUFr8Efq1MO8XeJdVLRz1w6TgIrfVcrXVHrXV7rfVz9nVPaK3n2F9rrfUftdZdtNYJWuuZ9vW/2pd72H87+cs2MO8AiB9pGpYdGqz/ckknfD2t/P3rzTV76tyBFaYuMaqPWb7gL+Ad5PxLVFu7F5S9Pryx/s4rzh1aV+/Oub7lZMC+Zab0UCIs3pSy83MaJg2bvjA3QGM/NBfgZa+eef/Tx+D4PojsYSbm3Les6pL1hs/g9URzxz7wPvDwgq/uhqJqzKKw9Tvzv3zRU2bZwwt63wQ7foDjDv12igpg/2+m9FCi5w2mNuHQurJ1S/4DeVkwYSbY/GDrt2dPQz2RkdQ10fVqyD5suvbZhfl78ejoTixPzmTO+hp08TvwO7TqagIPgM0HekwwH35ORv2kd/cCaHchKCsc2VQ/5xTnjvxT8O5F9V81WR0//MUEpl6TytaFdjC/M3c7P6Y6Th+r/vHrZ5iLfeteMOAPpsrr8Bm+5yU3SZE9zEX5VCakb6u834EV8PUfoFVnmPwrXPwcXP4ypK6GpS+X7Zd7Ak5UmJtNa0hOgrihYHXoA5R4q9m2+oOydalroCAH4hwCRLdrwbMFfHQl/D4VMnbB7/8zgSO6j7lJ3fpdpe73riIBoiY6jgYPn3LVTAA39GtD9+hAnvt+K1m51agfLC4yVUwx/cqvT7wVigucDtCrsaPJplqp02Xmzk5KEE3P/L+bi9bKd103CrfgtJlVIMdhzM+272HT53DBn6FVp7L1YR3N78xatkOk74C3h8L/hppAcSZpW017Qo8JZrnvHeDpD8v+W/Uxh9ab3yUlCKhcXXPqKHx2KwREwQ2zoKU9T92uhW7XwaIXTBvBnPvhP51MN3XHSQozd8PJFGg3rPx5g9qY68eaD8vGOuy1V3G1HVy2n08w3PEzRPaEHx6FtweB1QYX/s1s7zwGctLMDWYDkABRE17+0PFi2PJNuaKm1aJ45spupGfn8cr8avxzpG0xg4ti+pdf3/I8aHO+ucuoa6NyyejW9sMhIkECRFNTUs/d7VrQxZXmDqs3v74Oc/9kLtopq8yF+7s/Qng3027mKLQ9oMxdb03t/x2mjTL/F/nZsPYsN0nrZ5qScbfrzLJPMPS5xVQ7Hdvr/JhDG8yF3y8MgttCYJvyAUJr+HqyuQBf/4GZvNPRpS+BX0v48k5TBRV3AeSdhO1zy/YpaYhuN6zy+/e/C3LSzcSG+38zbYTh3cAvtPx+rTrBTd/AuE8gOM4Eh4DWZlvHi82YiQaqZpIAUVPdroVTGZXuPHrEBDEhMYqZy3ewL/MsdbAl0b9iCQLMl/xoctndRW3tXmDuWkLamQBxMtXcHYnGL+sIfHMvhCfAVW+ZDhSrplWaO6zOTh01ASJmAFgsMG00fHyNuchd+Ya5s3Vk8zGNvzWdk2n7j/DRFeATAncuNDdJK6ZWXY1SXGTaBjqMMI27JQbeCxYP06DrzKH1ENG9bDluiGkkLi42wWHxv2HHjzDqOYjqXfl43xC4YTZc/io8sg3GfwoB0SYtJZKTyv7vKmo/3Fz0Tx+HaReba4hj+4MjpUxp4d7f4Pz7ytZ7tTDn2fptg7Q9SYCoqfiR9qLsq+WLwek7+MehycyzPcpbP6w88zkOrDA9EoJjK2/rcqW5G1r1fu3TWFRoemi0H26+aBEJZr2UIpqGOfebhuBr3zUNoAPuMd/FDfU8Iv/X10zj6OUvw92LocNFcHANDHrA1Ps7ExZfsyqmfcth9k2mvv/2n0yPqP53mcbkkkkAK1r7sbnh6TGu/PqA1tD3djNdf8VSTH6OSVdkj7J1sYPN323HD/DJNbDwWeh6DfS7s+r0RnY3VcE+QSZodrvG3IzlZJrAtWeJKT1UNQCv8xi4b4UpfXn4mOWa6nyF6QxQ4cFmriABoqZsPqbIt2cJvNEPNn9tvpBTL8CWc5jWlqOM2P4Um1Mr1KE6RvsDv5vSg7Mvkc0betwA276Dbx+CmRPhg8vL6k9LFBXA1AtNQ1ZFqatN0bf9cLMc3sgDRGEeHFgJO38289UkJ9X/e+xdau7Mz3V7l8LOeaZvfUn9f9vzzYXvt7fM3XBxsen+WZ1un1XJOmIaR7tdC+FdzU3L+Blw208w/O9VHxcWb+rhnd3dHttXvgE6bRvMGA9BMTDxC1P1A9DpclMVtOJ/5Y8vLoKf/g7fPghtB5n9Khr8RxM0k/5Zfv2RzaYqrmKAAJh5g7lpu/TfcO17NRtdnXA9FBfClq/NBTvvhPPqJUeefjDiKXg8FWIHVf+9Spx3iale2/xVzY+tIQkQtTHwHrhrIQREwmc3mx4PrXvB5GXkX/QMI6xr2fjZ82bfE6kwfSz8M9p8sfcsNnWkbQZUff6+t4PN17R1HE02F/wlL5ffZ/sP5m4u6Xlzl+do9wLThTZuqFn2bwn+EY03QPzyNLw3AqZfC1/cbnp41Kaeuyq7foYPLoMPL4fck/V3XldY9IIpffa7q2ydUjDgXlO189Pf4K2B5o74/Utg3t+cD6zKP2UGUTp2hXa09BUTmC98vGydxQJt+oPFWnX6QjuYNoSsCo3m6Tvgf0Pg9d6mqmrlu/DJteZifuOX5evhrTbzP5CcZIIIwIkUmH69KdUk3g6TvjbHVuTfEvr/wbRFHBFOgDIAACAASURBVNlctr60gdqhiimojbmJ6nQ53Pu7KTlYanhJjEgwjfObvihrf4i7oHrH1naaD98Q0/nktzcheVHtzlFN7p6LqfGK7AF3LDCNg4V5pq+01QOfQZNJXv8z16W9S8oXNqJ3fGzuMOJHmoa1km5uFRuoHYW2h8f2l32B5v3NTC6WdRhaRJh1qz8wI0JPHzP/bCUNhkUFJrC07m3u+kpEJDTerq7bvjd3jCOeAhS8P9rUuY9+vu7nzjoMX95tLhaZu00D5PgZNb9Q1IeUVSYYtuoCvSeZO3dH+5abG4xRz5mSrKOuV8PPT5qLRngCXP0/c2Ox/A1IXU1gyBhYvc/0r09dbbqDansd/6SvzeCxEsf3w6r3TNfK0PY1y0NYvPmdsaOsYTU7HaZfZxpXL/yb6QX0/SOmO+et35sG44p63wJJL5iAp6zmoUTKakYm97nlzGk4/37zP7HweYiwVxcdWg++oaZk4mhSHe/ClTKliIXPmbaZiISykpArXfE6TNsBsyaZqjnH3mT1SEoQdWH1gAGTYfBDZX2elaL1Te9xWLUkeuMUClt1g8nLYOxH8PAWuOgJ0zUvsueZz+14d5F4mwkyaz4yy8f2mju/AZNNQ92vr5cNTlr4HKRvNfXEjiISTJ/vc2w64bPK3G2663a92lTLxfQ1dbDrPql7o2xxkQkI+Tlww2dwyQumkXLhc/WT9urS2nQlnTba9HBb+S68db7p7eJ4h7joBTMgLPHWyufw8ISJn8Et38MflphH5176kqkyObSBXuseh28fgI1fmEFcgx82gTCkvSnZlvwtiwrgizvAYjODN2uqpKvr/t/Nd63gNMycYEYlT5hlusbetxJu/xnumF++yseRXyh0v96U7g6thyGPwP2rzx4cwNxhn38/bPuOdrs/NIH14DrTQO2Kyfm6XWt+Z+ww444agk+Q+bxt3qZk5aLqUSlBuIB3i2D2XPIJL377LRsyhzG1oCUdwXzphzxS8xOGtjdfvNUfmDrW1R+aL3rvSabh8L2R5o46ojssfdWM2uxSYebIiAQTZNK3Vf1PeS4qme+nw4iydf3uhM1fmr74vW+q/bmXvGzuyK94w9yBtTwPDm8wD24J72oaIOti/2+mmqRlJ9MrJjCm8gWq4LRpa9ow04xKvmaqaUPYMMvUwX90hak+Ou8SU4Ux8mlTh+1MSWcERwnXQVQfNv0yg27Dx5neNY5p8A4w1WtJz8OoZ2H+E6aN7Lpppm2gplpEmiCW9DwsftG8zj4C4z42A73AvH9M37Of6+LnIWGsKT1aa3ipGjAZDqwgZtfX8L593NKgh858TG2Ftjcl9oNrzt7+UJ+C2pixGu9faoLw7fPPXP1XCxIgXGRI/374RnTgD5+s4eopy/jP2J6M7hZR+xP2vR1m3Wgar9d+Yi4mgdHmp90wM0DI4mGK+KP/Vfn40p5Mm+o3QOSeNNUaCdfXvDqiOnbON3P8lMz3A9BmoKmGWfGOGclb07tCrU2pa+FzJt29bjTrlTINlek7TH/4oDYQnVjzNB/eCL88YxqTHQVEw2X/gfPsjz05fQxmTDCBZNjjMPTRsqqtgfeYu+X5f4ffppgqRt9QU/9eUyFxZLQ83/nnEzvYvM/yKeDhbT7LfneX3RXXlFKmBLP/N/N3SN9mSny16a3jHQjtqlmfX5FXC7jxc5bN/47BrQtNeupyM3E2fe+ABc+a72ZDat0LrnvfDLCt5+AAEiBcqk/bEL69bzB3f7KaydNX88I13RnbtxZ3ZQAdL4EWreH7P5opAvo4VDMM/TN8cKmp471htvM7zJB2puHbWUP14Y1m+H5IO9PdMKyjKbqeTU6GaQw9tN70W58wq3p3htWVn2N67ZQ8jKaEUiZgfv+IqU+PTjRVI8f3nz1IFRUSv/N/cPAH6HKVqct1DDAeXjB+upnCYsZ4uOMX53Xkp46aXitKAcr8LVJWQsoKU53hHWCqExNvMx0NDq6FVR/AjHHmAtz/btND7ehuc7furLTi6WsCSsfRZrDa+Q+YwZr1bcQ/zFiExS+ZJymOerZu5wtobfJT1xJYPSi0+UPXYdDVxc8c6zXR/LhDyQ2HC0iAcLGIQG9m3TWAuz9ezZ+/2EB+UTE3DnD+cJMzsnqYO72k582daPzIsm2xg0ydcni38r00HFmsptpkz2Jz118yB9S+5aYOM9+hJ5RPsGm8q6qvO5hJxz6+yvTSuvwVWPaa6QV07XvQ2Un3w9rYswSK8sxstxV1HwfznzTVROFdTPtM9pHKDa6O8nPgs1uIOvgTDHrQTKbmrDHaL8y0Sbw3Aj4dC7fNKz+q9sAKc3HPqfCEXJufqUq68HFTDVbSSSCqj/npNQl+fsrcpa+Yar/L/aKst1lV4kfCg+vPvE9d+ATBVVPMQLFr3zXtGUIgjdQNwttmZepNfRjRuRX/9/Um3lu6p2Yzv5bofZMZXNP3tsrFyRFPmfrmM+lzq2nAfnsQ7PuVoGPrTQkgIBIe2gj3rjDFVc8WZsRsmpOJzMBUU0272PROmfSVuUu+42cToGbdWGmuqmor6cNfYtd8U+pp66SvuFcL0xC7/XtzYYvsaer4f/q78xG4uSdMnnb9zI74P5i6/DP1VGrZ0Yx6zdxlumf++ropNaydbursPf1M3/3b5sGtP8AflpmeZ7d8ZxpiHXuQlfDwgtH/NMGnw0Vw69yzB4eG0mEE3PajqbIUwk5KEA3Ey8PKmxP78MCMtTzz3RZ+3HSIxy7pTJ+2Ti4kVQmIhIc2mLro2ug10bRRfHkXvH8p3ZXVNMze9DX4tzL7tDzPtFG8f4kpIdz2Y/kR31u/Nd1CvQPMxbCkxOIXBjd/a46Z8wC07ul8uoGqFBWYkszJVNO7JrS9aaCOu8B5f3eAYX81/e47XWbaCzZ+bsZJbJhlumiWyMmET642/eKvm8bB9GA6VidNcUNNT5FFL5kH3f/yjCnRxA2F6z80vWVqo+Mo8yPEOU5KEA3I08PCGzf04rmru7E38xTXvvUrd3+8igNHa9Bd079V3RqjYvrBH5ZCn1s4HtTNXORLgkOJ0PamqqYw13S9/PYh0yD8y9OmhNCqM9yVVLk6y9PXVFFYLPD57VCYb9Zn7oaPrjLdKbMOO0/X/CdML52sw+YBLSvfNW0KjlVpFfmFmd4qQW3MctdrTG+SBc+a3kFgSkEfXGoeHj9+hukuWxPth8NtP5i/Wa+Jpirvxi9rHxyEaEQkQDQwD6uFif3bsujRYTwysiNLdmYw4uVF/PfnneQWNMwc73j5w5hX2dDjH1Vf6MK7mAthaAczpH/un8yDS7qPN33tW1TRIyuojWn4PbgGFjxj2gbeHmIak9dOh9d6Q9K/yo9YXj/L1Mv3n2x6wLRobd4PzhwgKrJYTAPryVRTJbT436Z6KDvNlATqctcekWDaWkY8VXmSOiGaKKlichNfTw/uvyie6xKjee77rbzy8w4+X3OASxMiOb99GH1jg/H1dPPHE9XblDC0hpMHzSy21Rls1OVK097x62tmOW4oXPW2KZH88g8zT86Sl01jcttBZsRr28Ew6hlz8b39J/jmHlMKKCkdVFfsIDO7aclgty5Xmq6rFUtJQoizkgDhZpGBPrxxQ28m9MvgtV92Mm3pHv63KBlPDwv/uiaBa3qfA42GSkFglPmproufN/38oxPNQK+SBuGxH5knaW38zHSt3fGjmf7g+vfL7sy9A0wDcW2NetbMT9X3Dtd3bxSiCZMAcY4Y1CGMQR3COJVfyOp9x5iycBePfLaeYg3X9TkHgkRNefqaZwU7E9Xb/Fz8vJkfyje0fu/wQ9ubko8Qok4kQJxjfD09GBLfksS2Idz50Soe/Xw9xVozNrGWA+zOZY7PqhBCnHMkQJyjfDytvHtzInd+tIo/f76BV+fvwN/bA38vD+LC/OnaOoCurQPo2SYIL4/6H2IvhBASIM5h3jYr79yUyFtJu0k9fprs3EJOnC5g0Y50vliTAkCYvxcT+7dhYv82tAqoxvQYQghRTRIgznHeNisPj6w8rCvtZC5rDxxn9soDvLZgJ28m7eLy7q25Y0gcXVsHuiGlQoimRgJEI9UqwJuLu0ZwcdcI9mbk8OHyvcxeeYCv1qYyqEMowzuF4+9lxdfTg54xQcSE+Lo7yUKIRkYCRBMQG+bHk2O68tBFHfl0xX4++HUPy3Zllm7387Ty2oReXNQ53I2pFEI0NhIgmpBAXxuTh7Xn7qHtOJlbQE5+EUez83n8q43c8dEqHr+kM3cMiUO54qlaQogmR6baaIIsFkWQrydRQT4kRAcy++6BXNItgufmbuWe6WvYkHLc3UkUQjQCUoJoBnw8rbwxoTdTInbx9qLd/LDpMD1jghgQXMiQYo3V4rxEUVysyczJp2WLKmZTFUI0aVKCaCYsFsX9F8Wz/PGLeGpMF06eLuDtDXlc8t/F/LjpcKXnU2xKPcG1b/9K/+d/ZunODDelWgjhTlKCaGYCvG3cMiiOmwbG8tKsX5iXqvnDJ6tp19KP7lGBxIe34ODx08xYsZ9gX0+ign14ePY6fnxwCKH+UpIQojmREkQzZbEo+kd68NPDQ3nxuu7EBPuycu8xXpq3nRkr9nPTwFgW/GkYUyclcuJ0AX/6bD3FxWWljAabmlwI4TZSgmjmPKwWxibGlM71lJ1XSG5BEWH20kKgj43/u6wzT3yzmTeTdhHq78WXa1JYufcYHcP9GdklnJFdIugeFYilirYMIUTj5NIAoZQaDfwXsALvaq3/5WSfscBTgAbWa61vsK+/Gfg/+27Paq2rmBpU1Cd/LzPfk6NJA9qyZGcG//5pBwDtW/px99B2rE85ztuLkpmycDdh/l5ceF5LhndqRWyYH0G+NoJ8PPHxlHmihGisXBYglFJWYAowEkgBViql5mittzjsEw/8FRiktT6mlGplXx8CPAkkYgLHavuxx1yVXlE1pRT/vq4H01fsY3CHMBKiAkvHUhzLyWfh9jQWbEtj3ubDfLY6pdyx7Vr6MTS+JUM7htGnTQiBvvI0NiEaC1eWIPoBu7TWyQBKqZnAlcAWh33uBKaUXPi11mn29RcD87XWR+3HzgdGAzNcmF5xBoG+Nu4Z1qHS+mA/T67pHc01vaMpKCpmQ8oJ0rNyOX6qgIzsPFbuPcbMlfv54Ne9AEQF+dA5sgWDO4Rxde9oAn0kYAhxrlIVuzfW24mVug4YrbW+w748Ceivtb7PYZ+vgR3AIEw11FNa6x+VUn8CvLXWz9r3+ztwWmv97wrvcRdwF0B4eHifmTNn1jq92dnZ+Pv71/r4xqih8pxfpNl1vJg9J4o4kFXM3pPFHM7ReFqgX6QH8cEWioqhSENsgIX4YNdWS8ln3Xw0x3zXNM8XXnjhaq11orNt7m6k9gDigWFANLBYKVXtJ8horacCUwESExP1sGHDap2QpKQk6nJ8Y9SQeR5VYXlT6gmm/76fb9alsjQ1v3S9RcGzVyVwQ/8aPou6BuSzbj6aY77rM8+uDBCpgONj0KLt6xylAL9rrQuAPUqpHZiAkYoJGo7HJrkspaLBdYsK5J/XJPD3yztzNCcfT6sFDfzliw08/tVG0rJyefCieJk3Sgg3cmWAWAnEK6XiMBf88cANFfb5GpgAvK+UCgM6AsnAbuB5pVSwfb9RmMZs0cT4enrg61n2NXznpkT++uVGXv15J+sPHCcxNoT2Lf0JD/DiVH4R2XmF+Hl6cH77UOlWK4SLuSxAaK0LlVL3AfMw7QvTtNablVJPA6u01nPs20YppbYARcCjWutMAKXUM5ggA/B0SYO1aNpsVgsv2QfuzVixn4Xb053u1zHcn/uGx3NZQmSVc0kJIerGpW0QWuu5wNwK655weK2BP9p/Kh47DZjmyvSJc5NSigdHxPPgiHiy8wpJTs8mIzsPP08P/Lw82J2ezRsLdvHAjLW8+vMOHh11HqO7RVRZHaW1lqoqIWrB3Y3UQpyRv5cH3aODyq3rFhXImO6tmbf5MK/8vIPJ09fQIyaIP47sSLfWAQT7elJYrPl56xFmrjzA8t0ZTOjXhscv7Yy3TQbuCVFdEiBEo2SxKC5JiGRU1wi+WJPCK/N3cPO0FQDYrApPq4Wc/CIiA70Z0Tmcj5bvY+XeY7w+oZebUy5E4yEBQjRqVotibGIMV/RozaId6Rw6fpojWXlk5RZwUadwhnZsidWiWLDtCH/6bANjXl/KhdEW2iWcok2oPKdbiDORACGaBG+blYu7RlS5fXincH54cAj/+HYzP246zA//XsjQ+JaM6BJO7zZBnBfeggPHTjNv82EWbEsjPMCbmwa2JbFtsLRfiGZLAoRoNsIDvHlzYh+++nEBe63RzF51gEU7TC8pTw8L+YXFAHRtHcCi7Wl8u/4gnSMD6NM2iPzCYvIKi+nTNphJA9qWBo3ComL+9tUm1h44xpQbehMf3sJt+ROivkmAEM1OsLeFq4d15KER8aQcO82a/cfYkHKC6GAfRnWNICrIh1P5hXyz7iCf/LaPuRsP4+VhHp3yzbqDbEg5wfNXJ6AUPDRzHd9vPEQLLw+uefNXXruhFxee18rNORSifkiAEM2WUoqYEF9iQny5smdUuW2+nh5M6NeGCf3KpvzQWvPqzzv57y87OXj8NL6eHvy89Qj/d1lnLkmI5M4PV3H7BysZ17cNmdl5bDl0ktP5Rdw/vAM3DmiLh1WezyUaFwkQQlSTUoqHR3akbagvf/liAwVFmmeu7MqkgbEAfD55II9+toFZK/cTG+ZHz5ggMrPzeerbLcxceYAnLu9CYmwInh4SKETjIAFCiBq6pnc0HVr5czQnn2EO1Um+nh5MmdibwqLi0tKC1pofNx3mme+2cMO7v2O1KGJDfWkT4sup/CJOnC4gt6CISxMiuWVQLK1aeDt9z9Tjpwn185RxHKJBSYAQohYqDt5z5FiVpJQZr3HBeS2Zv+UIO49kszMtiwNHT+Pv5UGbEF/yi4p5a9Fu3l26h2t6RdEtKpBgX098Pa38vucoP205THJ6DmH+ntxyfiw3DmhLkK9nQ2RTNHMSIIRoAL6eHpXaORztycjh3SXJfL46hZkrD5Su97AoBrYPZULfNizdZR77OmXhbq7o0Zore7amf7vQ0rmoios1SiHdckW9kQAhxDkgLsyP565O4MkxXTl+Kp9jpwo4mVtAx/AWpU/du3NoO7YdPsl7S/bw3YaDzFp1gPAALyIDfUg7mUtaVh4hfp5c3DWCi7tG0L9dCDZpGBd1IAFCiHOIp4eFVgHetApw3hbRKSKAl67vwTNXdeOXrWl8t+Eg2XmFtG8ZRqsAL/Zm5PD56hQ+/m0fbUJ8eeHa7gxsH1p6fHGxJr+oWNoyRLVIgBCiEfK2WbmseySXdY+stO10fhFJ29P414/bmPDOb9w0sC2xuojlP2zl23UHOZKVR7fWAQxoF0pMiC+bUk+wZv8xdqfnYLUovKwWvGxWWrXwIjLQm4hAb+LC/GjX0o8OLVsQE+Ij1VjNhAQIIZoYH08rlyREMuy8Vrw4bxsf/LoXrcFq2cPQ+DCu6BnF6n1HmbZsDwVFmiBfG71ighjeKRyNJr+wmNP5RRw5mcvBE7ms2neME6cLSs/fKaIFYxNjuLpXFEG+NnILisnOK8TbZsHfywOlFFprsvMKyczOJ8jXJo3qjZQECCGaKB9PK0+O6coVPVrz3eJV3HPVUEL9vUq35xYUkZ6VR3Tw2UsEx3LySc7IZlPqSb5Yk8LT323hublbASgq1qX7WS2KFt4enM4vIs8+dQlAVJAPnSMDuOC8llzbO6rcUwQPHj8NQOsgn3LvmbQ9jeXJmYzp3ppuUYG1/0OIWpMAIUQT16tNMCeibeWCA5hqqpiQ6s1oG+znSR+/EPq0DeHm82PZeugkczceolhr/L1s+HlZySso5sTpAk6cLsDH00qonyeh/l5kZOex5eBJNqae4OetR/jPT9u5sX9bWgV4MWfdQVbtO4bVorhtUCwPjuiIzap44YftTFu2B4D/LUqmd5sgLuvemtP5haRl5VFQVMw1vaPLTaZYWFTMvqOniA31q9VTBrPzCrFZFV4e0j5TQgKEEKLGOkcG0DkyoEbHaK1Zte8Y7yxOZkrSLrQ2j47906iOpBw7zTtL9jBn/UFC/LzYeugkt5wfyz0Xtufb9Yf45Ld9PPPdFgACfWwUFWtmrDhAj+hAru4VxYbUEyzclsaxUwVEB/swsX9bxiZGnzVNB46eYu7GQ/yyLY3V+44R6GPjxgFtmTSgLS1beJ31+KZOAoQQokEopegbG0Lf2BAOHD1FXmERHVqVzX47tm8Mf/96E6nHTzN1Uh9G2advv31wHLeeH0taVh5Bvja8bVZO5xfx+ZoUpi3dw1PfbiHQx8bwTq3oGRPED5sO8cKP23hl/g4uiLbQo28+wX6V20B+2HiIh2atI6+wmM6RAdw1tB07j2Tz+oKdvJ20m1FdwxnVNYILOrYs7Wrc3EiAEEI0OGdVW73bBPPd/YPJK6zcDddiUUQElnX99fG0MmlAWyb2a0NyRg6xob6lI9hvPj+WnUeyeGdJMp+tSmHoSwu5Z1gHru0dRasAb7TWTF2czD9/2EbvNkH8d3yvcunZk5HD+8v28P2GQ3y34RAeFsXl3SN5/pqEcm0nWw+dZMG2NIJ8bYT5e5W2s1RVvXXiVAFTl+xmcIeWDGgXUqeeYKnHT2NREBnoc/ad60AChBDinKGUqtEYDYtF0aGVf6X18eEtePG6HvTwymRBZgte+HEbL/y4jdaB3kQG+bB63zEu6x7Jf67vUen94sL8ePrKbjw5pivrDhxn7sZDvL9sjxntfnNfwvw9mbnyAE/O2Vz6DJESLbw96B8XyoWdWjK+b5vSYFFYVMy9n65h6a4MpizcTcdwf8YmxpBXWMyutGz2ZuYQF+bHgHahDIgLpXWQt9PZf3elZfPGgp3MWX8QgJFdwrl1UBz94+oWcKoiAUII0WRFtbDw3pi+bEo9wW/Jmaw9cJxth07ywPAOPDSiI5YzNGZbLYo+bYPp0zaYAe1CuX/GGq55axk9Y4L5dv1BhsSH8Z/re1CsISM7j+SMHJbvzuDX3Zn8vPUIC7am8d8JvfD38uD5udtYuiuDZ67qhpeHhY+X7+PZ700vsNaB3sSE+LJoezpfrkktfX9PDwu+nlb8PD3w9/LAy2ZhY+oJvD2s3DmkHRaLYsaK/czbfIT+cSHMvGtAvQcJCRBCiCavW1RgnbrKjuwSzsy7BnLHhyv5bsNBHh7RkfuGdygtIUQEetMtKpArerQG4OPf9vHUnM1c//ZyxvSIZNqyPdw6KJZJA9oCcH2faFKOnSbI10YLb9O+obVmZ1o2K/YcJTM7n1MFhZzKKyInv5CcvEJy8oqYfEF7bh8cV9oj7cGL4vl6bSqnC4qkBCGEEO7SMyaI7x8YQnpW3lmDzaQBbWkT4st909fw4o/bGdwhjL9d2rl0e8nDqhwppegY3oKONXhsrbfNyniHh1rVNwkQQghRTeEB3oRXMU9WRRd0bMkX95zPzBUHeOCiDo3yiYISIIQQwkU6hrfgiTFd3J2MWmt8IU0IIUSDkAAhhBDCKQkQQgghnJIAIYQQwikJEEIIIZySACGEEMIpCRBCCCGckgAhhBDCKaW1PvtejYBSKh3YV4dThAEZ9ZScxqI55hmaZ76bY56heea7pnluq7Vu6WxDkwkQdaWUWqW1TnR3OhpSc8wzNM98N8c8Q/PMd33mWaqYhBBCOCUBQgghhFMSIMpMdXcC3KA55hmaZ76bY56heea73vIsbRBCCCGckhKEEEIIpyRACCGEcKrZBwil1Gil1Hal1C6l1GPuTo+rKKVilFILlVJblFKblVIP2teHKKXmK6V22n8Huzut9U0pZVVKrVVKfWdfjlNK/W7/zGcppTzdncb6ppQKUkp9rpTappTaqpQa2NQ/a6XUw/bv9ial1AyllHdT/KyVUtOUUmlKqU0O65x+tsp4zZ7/DUqp3jV5r2YdIJRSVmAKcAnQBZiglGq8j386s0LgEa11F2AAcK89r48Bv2it44Ff7MtNzYPAVoflF4BXtNYdgGPA7W5JlWv9F/hRa90J6IHJf5P9rJVSUcADQKLWuhtgBcbTND/rD4DRFdZV9dleAsTbf+4C3qrJGzXrAAH0A3ZprZO11vnATOBKN6fJJbTWh7TWa+yvszAXjChMfj+07/YhcJV7UugaSqlo4DLgXfuyAoYDn9t3aYp5DgSGAu8BaK3ztdbHaeKfNeYRyj5KKQ/AFzhEE/ystdaLgaMVVlf12V4JfKSN34AgpVRkdd+ruQeIKOCAw3KKfV2TppSKBXoBvwPhWutD9k2HgXA3JctVXgX+DBTbl0OB41rrQvtyU/zM44B04H171dq7Sik/mvBnrbVOBf4N7McEhhPAapr+Z12iqs+2Tte45h4gmh2llD/wBfCQ1vqk4zZt+jw3mX7PSqnLgTSt9Wp3p6WBeQC9gbe01r2AHCpUJzXBzzoYc7ccB7QG/KhcDdMs1Odn29wDRCoQ47AcbV/XJCmlbJjgMF1r/aV99ZGSIqf9d5q70ucCg4ArlFJ7MdWHwzF180H2aghomp95CpCitf7dvvw5JmA05c96BLBHa52utS4AvsR8/k39sy5R1Wdbp2tccw8QK4F4e08HT0yj1hw3p8kl7HXv7wFbtdYvO2yaA9xsf30z8E1Dp81VtNZ/1VpHa61jMZ/tAq31RGAhcJ19tyaVZwCt9WHggFLqPPuqi4AtNOHPGlO1NEAp5Wv/rpfkuUl/1g6q+mznADfZezMNAE44VEWdVbMfSa2UuhRTT20Fpmmtn3NzklxCKTUYWAJspKw+/nFMO8RsoA1muvSxWuuKDWCNnlJqGPAnrfXlSql2mBJFCLAWuFFrnefO9NU3pVRPTMO8J5AM3Iq5IWyyn7VS6h/AOEyPvbXAHZj6B++TnAAAAfBJREFU9ib1WSulZgDDMNN6HwGeBL7GyWdrD5ZvYKrbTgG3aq1XVfu9mnuAEEII4Vxzr2ISQghRBQkQQgghnJIAIYQQwikJEEIIIZySACGEEMIpCRBC1IBSqkgptc7hp94mvFNKxTrO0CmEu3mcfRchhIPTWuue7k6EEA1BShBC1AOl1F6l1ItKqY1KqRVKqQ729bFKqQX2ufh/UUq1sa8PV0p9pZRab/85334qq1LqHftzDX5SSvm4LVOi2ZMAIUTN+FSoYhrnsO2E1joBM3L1Vfu614EPtdbdgenAa/b1rwGLtNY9MPMkbbavjwemaK27AseBa12cHyGqJCOphagBpVS21trfyfq9wHCtdbJ9UsTDWutQpVQGEKm1LrCvP6S1DlNKpQPRjtM+2Kdhn29/6AtKqb8ANq31s67PmRCVSQlCiPqjq3hdE47zBBUh7YTCjSRACFF/xjn8Xm5//StmJlmAiZgJE8E8FnIylD4zO7ChEilEdcndiRA146OUWuew/KPWuqSra7BSagOmFDDBvu5+zJPdHsU85e1W+/oHgalKqdsxJYXJmCehCXHOkDYIIeqBvQ0iUWud4e60CFFfpIpJCCGEU1KCEEII4ZSUIIQQQjglAUIIIYRTEiCEEEI4JQFCCCGEUxIghBBCOPX/bekOLuPcZe0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoZd3IIHHMjD"
      },
      "source": [
        "pada diagram, val_loss mulai stabil pada kisaran epoch 25-30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opmlh6bDBDHC"
      },
      "source": [
        "Nilai Val_loss terendah yg didapat berada pada epoch 25 dengan nilai val_loss 0.60 dan loss 0.62"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ywtw0DTCTiq"
      },
      "source": [
        "##Deeper Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P99Vho5xCVox",
        "outputId": "84ce0e57-e4e2-4d5c-8a3a-464164994d75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "deeper_model4 = Sequential()\n",
        "deeper_model4.add(Dense(11, input_dim=11, kernel_initializer='normal', activation='relu')) #menggunakan 3 layer, dengan featur = input_dim yaitu 11\n",
        "deeper_model4.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
        "deeper_model4.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "deeper_model4.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "historyd4 = deeper_model4.fit(x=feature_train4, y=label_train4, validation_data=(feature_test4, label_test4), epochs=100, batch_size=8)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.8511 - val_loss: 0.6940\n",
            "Epoch 2/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7005 - val_loss: 0.6668\n",
            "Epoch 3/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6793 - val_loss: 0.6584\n",
            "Epoch 4/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6687 - val_loss: 0.6629\n",
            "Epoch 5/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6620 - val_loss: 0.6520\n",
            "Epoch 6/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6586 - val_loss: 0.6533\n",
            "Epoch 7/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6551 - val_loss: 0.6560\n",
            "Epoch 8/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6524 - val_loss: 0.6452\n",
            "Epoch 9/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6499 - val_loss: 0.6473\n",
            "Epoch 10/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6483 - val_loss: 0.6437\n",
            "Epoch 11/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6442 - val_loss: 0.6443\n",
            "Epoch 12/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6450 - val_loss: 0.6437\n",
            "Epoch 13/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6392 - val_loss: 0.6435\n",
            "Epoch 14/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6384 - val_loss: 0.6437\n",
            "Epoch 15/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6363 - val_loss: 0.6491\n",
            "Epoch 16/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6356 - val_loss: 0.6426\n",
            "Epoch 17/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6330 - val_loss: 0.6374\n",
            "Epoch 18/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6321 - val_loss: 0.6374\n",
            "Epoch 19/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6310 - val_loss: 0.6448\n",
            "Epoch 20/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6296 - val_loss: 0.6447\n",
            "Epoch 21/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6304 - val_loss: 0.6375\n",
            "Epoch 22/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6281 - val_loss: 0.6353\n",
            "Epoch 23/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6269 - val_loss: 0.6352\n",
            "Epoch 24/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6240 - val_loss: 0.6385\n",
            "Epoch 25/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6236 - val_loss: 0.6365\n",
            "Epoch 26/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6240 - val_loss: 0.6351\n",
            "Epoch 27/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6226 - val_loss: 0.6349\n",
            "Epoch 28/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6214 - val_loss: 0.6318\n",
            "Epoch 29/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6198 - val_loss: 0.6381\n",
            "Epoch 30/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6203 - val_loss: 0.6291\n",
            "Epoch 31/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6210 - val_loss: 0.6444\n",
            "Epoch 32/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6183 - val_loss: 0.6336\n",
            "Epoch 33/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6176 - val_loss: 0.6290\n",
            "Epoch 34/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6170 - val_loss: 0.6294\n",
            "Epoch 35/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6161 - val_loss: 0.6308\n",
            "Epoch 36/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6165 - val_loss: 0.6294\n",
            "Epoch 37/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6161 - val_loss: 0.6284\n",
            "Epoch 38/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6133 - val_loss: 0.6284\n",
            "Epoch 39/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6149 - val_loss: 0.6284\n",
            "Epoch 40/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6135 - val_loss: 0.6283\n",
            "Epoch 41/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6112 - val_loss: 0.6281\n",
            "Epoch 42/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6110 - val_loss: 0.6281\n",
            "Epoch 43/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6095 - val_loss: 0.6453\n",
            "Epoch 44/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6109 - val_loss: 0.6331\n",
            "Epoch 45/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6098 - val_loss: 0.6361\n",
            "Epoch 46/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6101 - val_loss: 0.6309\n",
            "Epoch 47/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6098 - val_loss: 0.6298\n",
            "Epoch 48/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6080 - val_loss: 0.6303\n",
            "Epoch 49/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6068 - val_loss: 0.6527\n",
            "Epoch 50/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6081 - val_loss: 0.6328\n",
            "Epoch 51/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6066 - val_loss: 0.6331\n",
            "Epoch 52/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6061 - val_loss: 0.6336\n",
            "Epoch 53/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6050 - val_loss: 0.6308\n",
            "Epoch 54/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6056 - val_loss: 0.6273\n",
            "Epoch 55/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6039 - val_loss: 0.6285\n",
            "Epoch 56/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6035 - val_loss: 0.6343\n",
            "Epoch 57/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6002 - val_loss: 0.6279\n",
            "Epoch 58/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5985 - val_loss: 0.6325\n",
            "Epoch 59/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5999 - val_loss: 0.6288\n",
            "Epoch 60/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5996 - val_loss: 0.6345\n",
            "Epoch 61/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5994 - val_loss: 0.6327\n",
            "Epoch 62/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5962 - val_loss: 0.6346\n",
            "Epoch 63/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5963 - val_loss: 0.6344\n",
            "Epoch 64/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5948 - val_loss: 0.6318\n",
            "Epoch 65/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5929 - val_loss: 0.6349\n",
            "Epoch 66/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5942 - val_loss: 0.6288\n",
            "Epoch 67/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5916 - val_loss: 0.6282\n",
            "Epoch 68/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5912 - val_loss: 0.6322\n",
            "Epoch 69/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5896 - val_loss: 0.6310\n",
            "Epoch 70/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5923 - val_loss: 0.6373\n",
            "Epoch 71/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5914 - val_loss: 0.6347\n",
            "Epoch 72/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5892 - val_loss: 0.6274\n",
            "Epoch 73/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5891 - val_loss: 0.6370\n",
            "Epoch 74/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5902 - val_loss: 0.6360\n",
            "Epoch 75/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5860 - val_loss: 0.6378\n",
            "Epoch 76/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5876 - val_loss: 0.6344\n",
            "Epoch 77/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5880 - val_loss: 0.6302\n",
            "Epoch 78/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5878 - val_loss: 0.6345\n",
            "Epoch 79/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5873 - val_loss: 0.6359\n",
            "Epoch 80/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5880 - val_loss: 0.6349\n",
            "Epoch 81/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5868 - val_loss: 0.6429\n",
            "Epoch 82/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5871 - val_loss: 0.6351\n",
            "Epoch 83/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5856 - val_loss: 0.6354\n",
            "Epoch 84/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5856 - val_loss: 0.6433\n",
            "Epoch 85/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5839 - val_loss: 0.6336\n",
            "Epoch 86/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5839 - val_loss: 0.6407\n",
            "Epoch 87/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5850 - val_loss: 0.6383\n",
            "Epoch 88/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5850 - val_loss: 0.6382\n",
            "Epoch 89/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5841 - val_loss: 0.6382\n",
            "Epoch 90/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5829 - val_loss: 0.6437\n",
            "Epoch 91/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5834 - val_loss: 0.6399\n",
            "Epoch 92/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5831 - val_loss: 0.6424\n",
            "Epoch 93/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5816 - val_loss: 0.6458\n",
            "Epoch 94/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5813 - val_loss: 0.6474\n",
            "Epoch 95/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5825 - val_loss: 0.6436\n",
            "Epoch 96/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5820 - val_loss: 0.6445\n",
            "Epoch 97/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5811 - val_loss: 0.6433\n",
            "Epoch 98/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5802 - val_loss: 0.6425\n",
            "Epoch 99/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5807 - val_loss: 0.6465\n",
            "Epoch 100/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5824 - val_loss: 0.6475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbDuPTbUCiT-",
        "outputId": "e950ec15-b0d8-4eb9-bda6-35cd34c9dce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plot_loss(historyd4)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKTxOiymmTLA"
      },
      "source": [
        "##Mencari nilai terbaik berdasarkan optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3c0xhCXmb_f"
      },
      "source": [
        "###Wider model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR6VjUnLmZRV"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "opt_sgd=SGD(lr=0.01, momentum=0.9)\n",
        "opt_Adadelta=Adadelta(lr=0.001, rho=0.95, epsilon=1e-07)\n",
        "opt_Adamax=Adamax(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
        "opt_RMSprop=RMSprop(lr=0.001,rho=0.9, momentum=0.0, epsilon=1e-07, centered=False)\n",
        "\n",
        "def wide_opt(optim):\n",
        "  wider_model4 = Sequential()\n",
        "  wider_model4.add(Dense(20, input_dim=11, kernel_initializer='normal', activation='relu')) #menggunakan neuron 20, input_dim=features=11\n",
        "  wider_model4.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "  opt=optim\n",
        "  wider_model4.compile(loss='mean_squared_error', optimizer=opt)\n",
        "\n",
        "  historyw4 = wider_model4.fit(x=feature_train4, y=label_train4, validation_data=(feature_test4, label_test4), epochs=100, batch_size=8)\n",
        "\n",
        "  plot_loss(historyw4)\n"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8amzFl0ozbQ"
      },
      "source": [
        "####SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09ndP8pZo1oY",
        "outputId": "e52e43d9-c2f5-4fcf-c75c-f79f5fbd59b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wide_opt(opt_sgd)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7653 - val_loss: 0.7252\n",
            "Epoch 2/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7270 - val_loss: 0.6591\n",
            "Epoch 3/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7111 - val_loss: 0.7807\n",
            "Epoch 4/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7007 - val_loss: 0.6623\n",
            "Epoch 5/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6995 - val_loss: 0.6946\n",
            "Epoch 6/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6902 - val_loss: 0.6780\n",
            "Epoch 7/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6866 - val_loss: 0.6673\n",
            "Epoch 8/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6790 - val_loss: 0.6932\n",
            "Epoch 9/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6886 - val_loss: 0.7102\n",
            "Epoch 10/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6890 - val_loss: 0.7486\n",
            "Epoch 11/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7204 - val_loss: 0.6901\n",
            "Epoch 12/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6950 - val_loss: 0.6778\n",
            "Epoch 13/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6774 - val_loss: 0.6627\n",
            "Epoch 14/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6990 - val_loss: 0.6743\n",
            "Epoch 15/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6897 - val_loss: 0.6662\n",
            "Epoch 16/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7039 - val_loss: 0.6543\n",
            "Epoch 17/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6805 - val_loss: 0.6985\n",
            "Epoch 18/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6867 - val_loss: 0.6517\n",
            "Epoch 19/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6779 - val_loss: 0.6808\n",
            "Epoch 20/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6673 - val_loss: 0.6729\n",
            "Epoch 21/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6732 - val_loss: 0.6903\n",
            "Epoch 22/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6785 - val_loss: 0.6855\n",
            "Epoch 23/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6755 - val_loss: 0.7007\n",
            "Epoch 24/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6607 - val_loss: 0.8391\n",
            "Epoch 25/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6583 - val_loss: 0.7111\n",
            "Epoch 26/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6687 - val_loss: 0.6463\n",
            "Epoch 27/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6612 - val_loss: 0.6645\n",
            "Epoch 28/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6644 - val_loss: 0.6690\n",
            "Epoch 29/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6720 - val_loss: 0.6492\n",
            "Epoch 30/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6770 - val_loss: 0.6585\n",
            "Epoch 31/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6537 - val_loss: 0.6485\n",
            "Epoch 32/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6622 - val_loss: 0.6475\n",
            "Epoch 33/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6717 - val_loss: 0.7766\n",
            "Epoch 34/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6650 - val_loss: 0.6621\n",
            "Epoch 35/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6555 - val_loss: 0.6939\n",
            "Epoch 36/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6516 - val_loss: 0.6876\n",
            "Epoch 37/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6435 - val_loss: 0.6774\n",
            "Epoch 38/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6520 - val_loss: 0.6736\n",
            "Epoch 39/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6570 - val_loss: 0.6867\n",
            "Epoch 40/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6551 - val_loss: 0.6605\n",
            "Epoch 41/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6584 - val_loss: 0.6670\n",
            "Epoch 42/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6526 - val_loss: 0.6590\n",
            "Epoch 43/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6511 - val_loss: 0.6895\n",
            "Epoch 44/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6528 - val_loss: 0.7036\n",
            "Epoch 45/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6617 - val_loss: 0.6999\n",
            "Epoch 46/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6577 - val_loss: 0.7043\n",
            "Epoch 47/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6562 - val_loss: 0.6522\n",
            "Epoch 48/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6441 - val_loss: 0.6959\n",
            "Epoch 49/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6546 - val_loss: 0.7121\n",
            "Epoch 50/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6554 - val_loss: 0.7007\n",
            "Epoch 51/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6604 - val_loss: 0.6729\n",
            "Epoch 52/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6491 - val_loss: 0.6722\n",
            "Epoch 53/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6466 - val_loss: 0.6529\n",
            "Epoch 54/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6639 - val_loss: 0.6869\n",
            "Epoch 55/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6878 - val_loss: 0.7573\n",
            "Epoch 56/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6583 - val_loss: 0.6943\n",
            "Epoch 57/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6600 - val_loss: 0.6837\n",
            "Epoch 58/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6664 - val_loss: 0.7346\n",
            "Epoch 59/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6824 - val_loss: 0.6873\n",
            "Epoch 60/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6614 - val_loss: 0.6938\n",
            "Epoch 61/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6544 - val_loss: 0.7754\n",
            "Epoch 62/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6837 - val_loss: 0.6787\n",
            "Epoch 63/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6781 - val_loss: 0.6918\n",
            "Epoch 64/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6536 - val_loss: 0.7658\n",
            "Epoch 65/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6427 - val_loss: 0.8144\n",
            "Epoch 66/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6404 - val_loss: 0.6710\n",
            "Epoch 67/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6350 - val_loss: 0.7214\n",
            "Epoch 68/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6467 - val_loss: 0.6895\n",
            "Epoch 69/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6687 - val_loss: 0.6563\n",
            "Epoch 70/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6584 - val_loss: 0.6825\n",
            "Epoch 71/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6379 - val_loss: 0.7526\n",
            "Epoch 72/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6318 - val_loss: 0.6878\n",
            "Epoch 73/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6492 - val_loss: 0.6554\n",
            "Epoch 74/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6258 - val_loss: 0.6921\n",
            "Epoch 75/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6731 - val_loss: 0.7270\n",
            "Epoch 76/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6389 - val_loss: 0.7154\n",
            "Epoch 77/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6711 - val_loss: 0.6517\n",
            "Epoch 78/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6426 - val_loss: 0.6868\n",
            "Epoch 79/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6393 - val_loss: 0.6476\n",
            "Epoch 80/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6426 - val_loss: 0.7475\n",
            "Epoch 81/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6332 - val_loss: 0.6600\n",
            "Epoch 82/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6399 - val_loss: 0.7025\n",
            "Epoch 83/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6344 - val_loss: 0.6769\n",
            "Epoch 84/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6554 - val_loss: 0.7011\n",
            "Epoch 85/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6625 - val_loss: 0.7797\n",
            "Epoch 86/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6412 - val_loss: 0.7038\n",
            "Epoch 87/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6302 - val_loss: 0.7015\n",
            "Epoch 88/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6234 - val_loss: 0.6772\n",
            "Epoch 89/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6369 - val_loss: 0.6637\n",
            "Epoch 90/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6438 - val_loss: 0.7795\n",
            "Epoch 91/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6881 - val_loss: 0.6893\n",
            "Epoch 92/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6409 - val_loss: 0.6631\n",
            "Epoch 93/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6357 - val_loss: 0.6787\n",
            "Epoch 94/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6354 - val_loss: 0.6843\n",
            "Epoch 95/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6463 - val_loss: 0.6869\n",
            "Epoch 96/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6486 - val_loss: 0.6395\n",
            "Epoch 97/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6652 - val_loss: 0.6440\n",
            "Epoch 98/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6475 - val_loss: 0.6714\n",
            "Epoch 99/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6380 - val_loss: 0.6525\n",
            "Epoch 100/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6486 - val_loss: 0.6455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9d5hcV33//zpTt/fVSqu2klxkFcuy5YabbIqJAzYlYEoIEBKeAMEJSQgOJMGhJHzDL/BNCHyJE2wCAWzTggkOptiybCzbklWsYltWXe2utL3Ntmn398e5Z+bOnXun7czuaue8n2ef2Wn33pm597zP+/0pRxiGgYaGhoaGhh2e+T4ADQ0NDY2FCU0QGhoaGhqO0AShoaGhoeEITRAaGhoaGo7QBKGhoaGh4QjffB9AsdDS0mJ0dHQU/P6JiQmqq6uLd0DnAcrxM0N5fu5y/MxQnp8738/8/PPPDxiG0er03KIhiI6ODvbs2VPw+3fs2MH27duLd0DnAcrxM0N5fu5y/MxQnp87388shDjt9py2mDQ0NDQ0HKEJQkNDQ0PDEZogNDQ0NDQcsWhiEBoaGuWJSCRCV1cX09PTac/V19fz4osvzsNRzR/cPnNFRQUrVqzA7/fnvC1NEBoaGuc1urq6qK2tpaOjAyFEynPj4+PU1tbO05HND5w+s2EYDA4O0tXVxZo1a3LelraYNDQ0zmtMT0/T3NycRg4aSQghaG5udlRZmaAJQkND47yHJofsKOQ70gSh4Y6ZcTjw4HwfhYaGxjxBE4SGO178H/jxB2HYtY5GQ0MDqKmpme9DKAk0QWi4IzIpb6P5+ZYaGhqLA5ogNNwRi8jb6Mz8HoeGxnkCwzD4+Mc/zqZNm9i8eTMPPigt2rNnz3LjjTdy2WWXsWnTJp588klisRjve9/7Eq/98pe/PM9Hnw6d5qrhjlg49VZDY4Hj7356mCM9Y4n7sVgMr9c7q21uaK/j02/cmNNrf/SjH7F//34OHDjAwMAAV155JTfeeCPf/e53ufXWW/nUpz5FLBZjcnKS/fv3093dzaFDhwAYGRmZ1XGWAlpBaLhDEYNWEBoaOeGpp57ine98J16vl7a2Nm666SZ2797NlVdeyf33388999zDwYMHqa2tZe3atZw4cYKPfvSj/PznP6eurm6+Dz8NWkFouENZTFpBaJwnsM/0F0qh3I033sjOnTv52c9+xvve9z7+7M/+jN/7vd/jwIEDPProo3z961/noYce4r777pvvQ02BVhAa7oiZykEThIZGTrjhhht48MEHicVi9Pf3s3PnTq666ipOnz5NW1sbf/iHf8gf/MEfsHfvXgYGBojH47z1rW/lc5/7HHv37p3vw0+DVhAa7tBBag2NvPDmN7+ZXbt2sWXLFoQQ/OM//iNLly7lP//zP/niF7+I3++npqaGb33rW3R3d/P+97+feDwOwD/8wz/M89GnQxOEhjt0kFpDIyeEQiFAVit/8Ytf5Itf/GLK8+9973t573vfm/a+hagarNAWk4Y7NEFoaJQ1NEFouENbTBoaZQ1NEBruiOogtYZGOUMThIY7tMWkoVHW0ASh4Q5tMWlolDU0QWi4QysIDY2yhiYIDXdogtDQKGtogtBwR6IXkyYIDY1iIdPaEadOnWLTpk1zeDSZoQlCwx0JBaFjEBoa5QhdSa3hDh2k1jjf8L93w7mDibuVsSh4ZznMLd0Mv/UF16fvvvtuVq5cyUc+8hEA7rnnHnw+H48//jjDw8NEIhE+97nPcccdd+S12+npaT70oQ+xZ88efD4fX/rSl7j55ps5fPgw73//+wmHw8TjcX74wx/S3t7O29/+drq6uohEInz605/mzjvvnNXHBk0QGpmQUBCR+T0ODY0FjDvvvJM//dM/TRDEQw89xKOPPspdd91FXV0dAwMDXHPNNdx+++0IIXLe7le/+lWEEBw8eJCXXnqJ173udRw9epSvf/3r/Mmf/Anvfve7CYfDxGIxHnnkEdrb2/nZz37G+Ph4or/TbKEJQsMdiUI5rSA0zhPYZvpTc9Due+vWrfT19dHT00N/fz+NjY0sXbqUj33sY+zcuROPx0N3dze9vb0sXbo05+0+9dRTfPSjHwVg/fr1rF69mqNHj3Lttdfy+c9/nq6uLt7ylrdw4YUXsnnzZv78z/+cT3ziE9xyyy3ceuutRflsOgah4Y6ExaSD1BoamfC2t72NH/zgBzz44IPceeedfOc736G/v5/nn3+e/fv309bWxvR0cdZ2f9e73sXDDz9MZWUlt912G4899hgXXXQRe/fuZfPmzXz2s5/lM5/5TFH2pQlCwx06zbU8MXQCvvkGmB7L/loNQNpMDzzwAD/4wQ9429vexujoKEuWLMHv9/P4449z+vTpvLd5ww038J3vfAeAo0eP0tnZycUXX8yJEydYu3Ytd911F3fccQcvvPACPT09VFVV8bu/+7vcddddResSqy0mDXckVpTTFlNZofMZOPUkDJ+EZVvm+2jOC2zcuJHx8XGWL1/OsmXLePe7380b3/hGNm/ezLZt21i/fn3e2/zwhz/Mhz70ITZv3ozP5+Ob3/wmwWCQhx56iG9/+9v4/X6WLl3KJz/5SXbv3s3HP/5xPB4PHo+He++9tyifSxOEhjt0HUR5YmpE3urkhLxw8GAye6qlpYVdu3Y5vk6tHeGEjo4ODh06BEBFRQX3339/2mvuvvtu7r777pTHbr311kTcoZjLrGqLScMdMR2kLktMDctbbS2WPbSC0HBGPAaGmSqnZ5LlBU0QJcfBgwd5z3vek/JYMBjk2WefnacjcoYmCA1nWAcHXShXXpg+/ywmwzDyqjGYb2zevJn9+/fP6T4Nw8j7Pdpi0nCGlSC0xVReOM8UREVFBYODgwUNgOUCwzAYHBykoqIir/dpBaHhDOvs8TyaSWoUAecZQaxYsYKuri76+/vTnpuens57UDzf4faZKyoqWLFiRV7b0gSh4QxlK3kD2mIqN5xnWUx+v581a9Y4Prdjxw62bt06x0c0vyjmZ9YWk4Yz1OwxUH3ezCQ1ioTzTEFolA6aIDScoWaPgVqtIMoJ8bglSK0JotxRUoIQQrxeCPGyEOKYEOJuh+dXCSEeF0LsE0K8IIS4zfLcX5nve1kIUZzOUxq5Qw0OwVqIR0AHAMsD4XGd3qyRQMkIQgjhBb4K/BawAXinEGKD7WV/DTxkGMZW4B3A18z3bjDvbwReD3zN3J7GXCFBEDWp9zUWN5S9BPo31yipgrgKOGYYxgnDMMLAA4B9xQwDqDP/rwd6zP/vAB4wDGPGMIyTwDFzexpzBWsMArTNVC7QBKFhQSmzmJYDZyz3u4Crba+5B/iFEOKjQDXwGst7n7G9d7l9B0KIDwIfBGhra2PHjh0FH2woFJrV+89HZPrMDcMvcBnQPzpFK/CbnTuIBOocX3u+Qf/W7mgc2o9qz3fy+CucjmV/z0KG/q1nh/lOc30n8E3DMP5JCHEt8G0hRM4rdhuGcS9wL8C2bduM7du3F3wgO3bsYDbvPx+R8TMfi8IBaF2xFgZ2cd0126CufU6Pr1TQv3UGHBqCF+S/a1a2s+Y8/570bz07lJIguoGVlvsrzMes+AAyxoBhGLuEEBVAS47v1SglEllMZgxCW0zlAW0xaVhQyhjEbuBCIcQaIUQAGXR+2PaaTuDVAEKIS4AKoN983TuEEEEhxBrgQuC5Eh6rhh2KEHSQurygUlx9FTqLSaN0CsIwjKgQ4o+BRwEvcJ9hGIeFEJ8B9hiG8TDw58C/CyE+hgxYv8+QDVUOCyEeAo4AUeAjhmHESnWsGg6wKwhNEOWBqWHwVcqJgf7Nyx4ljUEYhvEI8Ijtsb+1/H8EuM7lvZ8HPl/K49PIgEQWk7KY9GBRFpgahsoGEB5NEBq6klrDBWl1EDoGURaYGoHKRvD6tcWkMe9ZTBoLFWpwCJpLF+rZZHlAEUQ8qn9zDa0gNFygFIO2mMoLU8OmgghoBaGhCULDBfYYhLaYygNTw1DRYFpMelJQ7tAEoeGMhMWks5jKCtMjMkjtDejfXEMThIYLYmEQXpkPD9piKgdEpiEyqS0mjQQ0QWg4IxaWg4Q3YN7XFtOihyqSq9QWk4aEJggNZ0TD4AuAL5i8r7G4oZYaTSgI/ZuXOzRBaDgjTUHowWLRQ/Vh0nUQGiY0QWg4IxbRFlO5QRFEhQ5Sa0hogtBwRiwsZ5GKILTFtPgxrS0mjVRogsiE770T9n1nvo9ifhALgzcIHg94dMCyLKAtJg0bNEFkwokd0P38fB/F/EDFIEAGqjVBLH5MDcsmfcG68lQQ370Tfvm32V/nhJM74b9+B+KLq+m07sWUCdGZ8vXelcUE8lYvGLT4MTUCFfVSNZZjHUTfETCMwt7b+Swc+yXMjMs04UUCrSDcEI+BESvfgdGqILzBuSHK6TGYHCr9fjScofowQXnWQYQnZaFgIVDXR2SqeMezAKAJwg2KGMqWICJJBeGbo9nkI38BP3h/6fdTbjAMMOLZX5dCEGVoMUUmITxR2Huj0+atJojygJoRlNtFohCdSRbJeQNzQ5Tj5yDUV/r9lBse/3u27vtk9tdNj8gUV5C/uRFfdJ66K+JxSRCFKgiV5acVRJkgoSCm5/c45guqDgJMi2kOiDIWKd/vu5QYPEblVE/219ktJiifCZKa+ReqIBIW0+I6fzVBuCFBEGVygdhhDVL75shuiM2U7/ddSkQm8cRz+F7tFhOUD0GETeVQsMWkCKJABbJAoQnCDerCKOssJouCmAuLKRrWCqIUyIUg4nGYHnUgiDLJZIqYxFCwxbQ4HQdNEG4oewVhtZjmKKMlFi6fGetcIjyJx4hBLOr+mpkxGXNQKZrlZjEpBRGdLizuohVEmSG2OGcEOSM2k1ooNxcKIjZTvt93KaECp5m+W2sVNZSfxWQd2AuxmXQMoswQ1RZTapB6DqyGWETut9BiJQ1nKPskH4LwKAVRJhaTlRQKUQFaQZQZYtpiSqmknguiLPfak1JBKYhMKZiqUV9FmVpMs1UQOgZRZtAKYh4spjL/zksFq7/uhnK3mKykMCuLSSuIRYW+sWku+8wveOKMTUrHyng2G49DPJpaKDcnFpM5GJXjd14qGEZy0MqoIEblbUW9vC27LCbLdzMri0kriEWFuko/I5MRRsM237uc7Q41UCcspkDpZ/WGUd7feakQC8ueYpBZQahZc7BG3pa1xRTK//06BrE4UeH3Uhv0MTZjIwh1YRix8mk3oJAgCKvFVOKBIh4FzN9AE0TxkBJ8zaAg1Ov8VfK2rC2mWSgIHYNYfGipDTLmpiDs/5cDlK2QyGKaAwVhHYgW2UU2r7CSQjYF4asEj1feLzuLadL5/1yhu7kuXjRXBxi3E0Q5D1h2i0ktGFTK9FMrCesgdfGQMvBlURCB6uT9crOYwsWymDRBLDq01ATdYxBQPheJQoIgVJB6DnLiUwhZE0TRYCWITN9reAICVcn75WYxRSbAbxLkbCwmTRCLD801AcbTYhDlbDHZYhCKKEo5s9cEURpYB7tMaxVEJiBQk7w/F5OChYTwJFQ3y//ztZjicYib35NeD2LxobkmSCgC0ZhlURWtIFItJijtYBHVBJGGfd+BUP/stpFiMWWJQfjLWUFMQqBWxmHytZisEyetIBYfWmsCGMDQpMsgVbYxCEuzPijtwB3TMYgUTA7BTz4MLzw4u+1EclQQ4UlbDKLMCEJZbIGq/C0m63Wh01wXH5pr5Ax5MGS5GFIsjzK5SBTSspi0xTTnmBlLvS0UKQVgWRREOVtMkUmpoALV+Q/yKQSxuCaTmiCQQWqAgZBL3KHcZrTqs/ssdRBQWqLUFlMqVF7+zHhxtgNZFESovIPUSkH5q/NvtaEtpsWN5hp5MbgriDIbsNwsplIOFrEytvScUCyCMAcsA0/m2W2kRBZTqG/2n2EuEDFjMIGq/AlCjQ/Beh2kzgdCiNcLIV4WQhwTQtzt8PyXhRD7zb+jQogRy3Mxy3MPl/I4W6qzKIiyIwhlMalWG3NsMZXLrDUTVKB01gQhB7uIvyaLgiiRxfStN8GvPzu7bcwFwpPgr5QkUajFVFm/6BSEr1QbFkJ4ga8CrwW6gN1CiIcNwziiXmMYxscsr/8osNWyiSnDMC4r1fFZUVfpwytgIEVBlLHFlNZqw7ydM4tJKwhmTIIopGjLivAkeHzEvFXuCsIw0rOYhJBrQsyWrMd7YKx7dtuYCygFFajJ/3jV+FDRACNn5PcpRPGPcR5QSgVxFXDMMIwThmGEgQeAOzK8/p3A90p4PK4QQlAXEAymKIhwsnCm7ILUbnUQc2Uxldn37YRiWkz+auIevzvxRqYAI9ViguJ08Z0JzZ7kSg0rQc7GYqpsAIxF5TiUTEEAy4EzlvtdwNVOLxRCrAbWAI9ZHq4QQuwBosAXDMP4b4f3fRD4IEBbWxs7duwo+GBrfHGOdp5lxw7ZF//SgXNUiyBBJnjp8AHODbUWvG0r/OFRWgZ2cbb99UXZ3mwQCoUcv7O2cy9wCfDMnn1MV56lbvRlLgde2LeHoc7StNtY0nuADeb/nSeOckKkH1ex4Pa5FxLau/dxERAaOseeWRzrRZ3HaDY8RPAx2NvNQYdt+cMjXAccPd1NTzT5/HWGoLfzJMcK3L+IR7gpHmGsv4e98/R95/Jbi3iEm4wYJ7p7qZwapSk0zK48jrdxaD9bgP7xCK3AUzt+RdRfk+1tJUMxz+9SEkQ+eAfwA8MwrG1TVxuG0S2EWAs8JoQ4aBjGceubDMO4F7gXYNu2bcb27dsLPoCGPT/HCNawffv18oET1eBtgYEh1l/QwforC992CnZ9FZ7+f1z8hj+BumXF2WaB2LFjB47f2fOn4CW45lU3QP1yONsI++DSDRfDJQ6vLwb2noEX5b+rli9l1Sx+y2xw/dwLCU/th1egxmfM7lgH/wtmGpmKVdBcV+W8reFT8DRctHErF11meX53FSuWtrKi0P1PDsFOqKvwzM33HY/B7v+Ay98L/gogx996ahh2wtqLNsFIHQzvzu94X56GF6B11YUwsIvrr74c6toL/hizRTHP71JaTN3ASsv9FeZjTngHNnvJMIxu8/YEsIPU+ETRIS0mWwwiWCf/L6blEeqTt2qBloWIea+D0DGIZJB6lnUQYZnfH/cE3L9XZakU22Iqlk2WK3r2wf/+JZx4PL/3qcK4RKFcKL/GlNYYBCyqQHUpCWI3cKEQYo0QIoAkgbRsJCHEeqAR2GV5rFEIETT/bwGuA47Y31tM1AUFA6EZDHViRMMQrJX/F3NgnDBbJyzk1L+0BYPmsFmfv1rHICB1cJ1NF92IhSDcgtRqgPTbCWKWQeoEyc1RDEJlH+UbQ4hYPr+/Sq4Bk8/nVudrpSaInGEYRhT4Y+BRpHnwkGEYh4UQnxFC3G556TuABwwj5Sq4BNgjhDgAPI6MQZSWIAKCmWic0ExUPhCbSRJEMYNOCYJYyArCPOFVgVyiUK6ECiKRS16rFQQkB1cjNrvvIyLTN6WCcBm41L4cFcRsCMIcqMOzJLlcoQgw3wE6oaCqkqm++ZCM+n2UglhE529JYxCGYTwCPGJ77G9t9+9xeN/TwOZSHpsddaabMhgKU1vhlwOWvxI8vuIOjAmLaZbWQSkRnY8sJlOdBGvLL63YCdYBamZcnouFIDIJVc3EvNMwk81iqkp93BuAWLSw/YKF5OJy0LZvv9hQA3O+A3RCQVQljzE8AVVNub0/Zs1iYlH1Y9KV1CbqAjJvOVEsF52RF4g3WNyBcWJA3s7WWy4lYmEQnuTqYqoOouRprkLOYhdRmmDBsBNEwdtRCiLoriDUgBawZd7M2mIq0mfIFYoY8h2gEzGI6mQtSD7biNpjEItHQWiCMFEXVARhXhCxGWmt+ILFG7AM4/yJQSj1AMn/S20x+YLgq9AEAam+/WzOlchUDjGIEllM1s8wF7UQylrK12KKWNbjLshi0gpi0UMpiMEJpSDCUj34gsXzFGfGknJ0IVtMsYiNIObIYvIGpFrRBCEHVDWbnRVBTJgEkaFQLmyxWKzw+meZxVQkkssViVXdClUQNosp3/0uwhhETgQhhKgWQnjM/y8SQtwuhPCX9tDmFrXKYhq3KojA7GdRVih7CRa4xTSTShAeT/FjMW779FXoGATIAap2qfx/thZToEpaTEbMecDPmOZaJItpLhREdLYKojqZyZUPycRmZFuSQuypBY5cFcROZGXzcuAXwHuAb5bqoOYDPo+gvtIvFUQ8DvGoRUEUacBSAWo4vywmKC5ROiEalt+1VysIQA6uNSZBFDq4xiJyKUx/NTH1ezoNnuGQJGYVc1IoJkHMqYLIN4vJqiDUutT5KAjz3FWJBGUYgxCGYUwCbwG+ZhjG24CNpTus+UFLTUAWy6kZrC8gf/iiKQgz/iA8C79QzmsTiKUmiFhY7lPHICRSFESBajORnWOmuYKz/WFv9a1QVItpIccgXLKYckV02kYQ5acghBDiWuDdwM/Mx7wZXn9eorkmSH9oJjlAeYPyr1ieoiKI+pUL3GJyUBDFVFKO+5wpvmI7X2EYsnag1mzFUujgqgbKQFWSIBwVxIQLQcxWQYQAs6tpeCEriImkgirUYvKa6ld4yi8GAfwp8FfAj81it7XIArZFhdaaoOzoai0U8wWLV9mrCKJpzQK3mCIuFlMJK6mjYYtiK3OCiE7L2oHqFjngZDpXnv5XOOKyXEo4mZ2TUUGEQ+lV1FCcVhvVZpPLuVAQiRhEnjN4s5gQKNBiMjPwhABf5aKqpM6pUM4wjCeAJwDMYPWAYRh3lfLA5gPNNQGZ5ppQEGaQulgBtol+qGyEqmbZN36hIjqTrH1Q8AZK34tJ1Z2Uu4JQg1OwVv5lIohnvw5tm2DD7enPqYHKX0VMZaI5KohMFtMs01xrlsjzfi4mRAVXUk8mCdIXlKRcCEGAJJpFRBC5ZjF9VwhRJ4SoBg4BR4QQHy/toc09mquDjE5FCIfNE81XUVxPfKJfzqiCddpictyntpiA1LqEYF3mCcrUiOxG6gSLt55ZQUw4VzkXw2IK1Mi/OcliKrBQLmL5/EJIssi3UE5dL+VIEMAGwzDGgDcB/4tcu+E9JTuqeUJLrfyRx0Lmyewrcl5+qB+ql2SfFc43XC2mUmYxzZhBatNimovePQsV1rTTQI37ZCIWld5+NoLIFoOITKRXUUNxLKZgjfyby0rqvFttTKXWgOS7aFBsRk4kQRLEIlqXOleC8Jt1D28CHjYMIwIsuiu42VybemTMJAgVpC6WtTLRL33lijp5Ei/UrqUqo8iKuchiUjEfdb9cMWNVEBkmEyoTzo0gwjlmMbkGqYvQakN9hjlVEAVYTNbPH8hXQYQtjS0rylJB/BtwCqgGdporwC1gj6QwtJoKYnzCPDkSCqJYQeo+02Kql/cXqs3kajGVOs01kKzaXkSZIHkjYTGp2bfL4Do9Im+nhp0Vl6WNdVaCsFdRQ3JSUKias1pMcxqDKMBisn5+f3Vhaa4gt1NuBGEYxr8YhrHcMIzbDInTwM0lPrY5h1IQ4xMWBeGrKM5gFQ3LGV/NEqkg4PwiiFIHqZWPm2gtXsYKImEx1WRWEFMmQcQjzgOapQ4iWSjnRBCT7hYThlyprRCEQ6aCyEByxUShldRmtXkCeVtM4eTExl+GCkIIUS+E+JIQYo/5909INbGo0FwjL6JQyDw5fMpiKsJgNWm22ahuSa4zsVD7Mc1HJXUskmoxlbWCsMQgMlpMFmtpashhO8kupUkFYRu8DCM5kNuRWCiqgN/dMEyLqQYCeVhMr/wKfnVP/vuD1F5M+aieyGRqmm/eFpNNQZRhDOI+YBx4u/k3BtxfqoOaU8SiMHQCXyRETdBHc3WA3mFz4C5m8zjVZqN6SXIp0wWrIByC1MW02hz3aenFBOUdg7BaTJkGV6UgwDkOkVJJrdJcbcQbnQYM9ywmKOy3iIVlu5psJGfHwe/DU1+GsZ7892mdueczwbBncfnzVBDWGESZZjGtMwzj04ZhnDD//g5YW8oDmzNMDcG/bGVJ306EEGxZ2UDPgHnhKQURj8j+TLOBatRX3Zq0mBa0grAHqUtcwJaIQWTwyssFYYcgtdOM2NquxZUgBPgq3BWE1c6yYzZLzc7Y4yg5EkTonLx95Zf579M6kctnkDaXZU0gUEAMQp23vsqy7MU0JYS4Xt0RQlwHLA6aNC8Mb0x+nC0rGhgaM09mqyc+28FxQikIi8W0UFNdY5YZkUKpFYSahSkFUc61EOEJWazlrzTPFcN5wJrOpiCm5GAnhGz3jUgfvBQZuQWpoTAFobYbzLMOYrxX3r7yi/z3GZ1KxgJyJYi4uaTrbLKY7Gmui6gXU65Ljv4R8C0hhJl+wzDw3tIc0hzDXwnCg8+cWW1ZWc9ZzGUWUzzxmcKXfYRkm42aJcmBdqFaTNH5iEHMJC090AQRqJFFW0FzZj8znvxfIZvFFJ5InrNCmAkXdgVhWU3NjlkRhDWOUiO3odqpZELIJIgTO3J7vRWRablM6PjZ3AnC2qhPoSCLSRXKlWGQ2jCMA4ZhbAEuBS41DGMrcEtJj2yuIAQEalMURABTUqsGXDD7wXGiX16gKjMFzkOLqUQEkWivbo1BlDNBWILGiXiVg9qcHkkuUuOmIFIGvgoHBZGHxRSLwuP/kEpMrp/BmollfoZsKiIalpbvssvkazt3Zd+PgmFIJVDZKO/nOou3tvpWUAoiF1tZ7TehIMwg9SIp9MxrRTnDMMbMimqAPyvB8cwPgjUJgmisDtBWbXag9AVSFcRsEDLbbAhhbreC0NgQf/H9A0xHCkwjLAUMQ8ZcHIPUJRq0E80RrXUQ5UwQlsI1NZlw6oY6NSJbgvsqXQjClt/vc6jyVYvl5BKk7j0IT3wBXn4kh89gHq+qBofsilmph0vvlPvOx2aKhQHDQhC5KgjLYkEK6rvPJRspHpX79VoK5WDRxNBms+SoKNpRzDcCSYIAWFVnOm/eInriqg+TQrCOs319/OD5Lg52L6C1IdRs0a2SuhQzI6UWvMHiEfL5jBmLgghYLCY7lIKobIRJtxiETUHYv1e31eQgnSAUCeWSYZSiIBPUq04AACAASURBVNRnyKIgVKZf01pYfV1+gWo1IBdDQfjzWBNC7TdhMalV5RaHzTQbglgcGgogWJOIQQAsr5VfS99k3HKRFJkgKuqITUli6BxcQEEt62BthTeILJqKlmCfipSKqNjOZ4QnZHorZE5omBqBSpMgHGMQtuwcpzYQYYcZtILdYlLW0vjZ3D4DJDOxILvFpDKYapbAha+DgZdh+FT2fUHSOlMEkesM3lJtnkA+Lb9VPDFhMZm35UAQQohxIcSYw9840D5Hx1h62BTEsmoPM4aPA93jxRuwJvqhxqogahMxiDPDC4kgLIO1FaUMHqtt+oqYNXY+IyUGoQjCYXCdHoGKehmYdUtztROEfeDMR0GorKmxXAjCVsvh9hmsUBZT7VJJEJC7ilCfq6pJ3uasIBRBWhJQ1HeRyzYSEyqbgigHi8kwjFrDMOoc/moNw8g1A2rhI1ibQhCtlRDGz4EzI8UJUhuGo8XkMX3azqGFRBDm53SymKzPF3WfthX8YNFcYAXBKQbhaDGNmhZTQwaCsAx8focc/bwsJqUgcrCYUhoO5hiDGO8FhLxOmtdB45r8CSLvGISTxZSPgrAsDWC9XSSprrOxmBYPbArCZ0SIe/wc6BopTtBpalhaMzaLKRCVF9GZBUkQDmmu1ueLuk9L3EP3YnIhCNvgGo9LBZrNYrIO/E5prpFMaa42iykvBTEBCHOdZ5MgcrGYqprlfoWAC14DJ3fmFvdShJA3QahFlawWUz4xCEuCBVhiEItjgqMJAtJiELLwJciBMyOWCtRZDFiJKuolln3WEYzLE3BhKQg3i6mEsYGExaR7MQHJLqggvw+PP31wnRkFjGSQ2qmja04KIpRcj9kONwUx0SdTXjN+BpPkPJ7MNpkVoT5pLynUr5CElstsXJ1DeQepHbK48rGY7ArCrxXE4oNNQRAN4/UHGZuO0hMyU1Bn44mrIrnqlsRDEX8N1cYkNUEfvWMzCyfV1RoPsEJZPyVREEq1BEu7n7lAPD67AKVqnmctinPqZaQGa6UgYjPp+3WMQTgEqZ2qqME9BmHEk/ECN4QdMrGyKYjxc1DTlryfT8cB9bkqVQxiNoVyeVhM1nMXkoS8SCY4miAAgjV4jGhSJcRm8AflD/3SgDlgzmbmrNps1CQVRMioooZptq2Sxeldwwsk68HVYppFZ8+c9+mXM05v4Py9wJ75GvzfSwu3GKLTcgC2Wj7B2vTZtxqslYKA1I6u8bjcVtZCOZdW3+CexQTZM5msBOH1yRqMXOogHAkihzYd6voMVMnBOleCcIrB5GUx2dJcfSZBaAWxiBCwpeFFZwgEK6gOeNnXM514rGBYG/WZGDUq8AiDV62SknTBxCFcLaYSFgBZLSaQF/j5GoM48bicEJx+qrD3O1U2Z1UQ5qzZGodwCr46Fcq5tfoGZwVRY1pA2WohVLuQxGfIsiZEPG5aTE4EkUPHAUUIvor8OqpGJkF4U8/3vCwme5qrIojzdIJjgyYISO13AxCdQXiD3HRxK48dM4vYZmMxjXRKH1ldyMBQTJ5QVy6V3u+CiUO4ZTGpi6YUC7/YZboveH4qCMOA7r3y/6MFNJuD5DmYpiBsg2RCQdRbFISVIFTwNUuhXMS2WI4VToVySy6R/2dVEHaCyLImxNSwrOCvscQgcrWmIDUW4K/Kr1DObGiYQMJiKiTNVSuIxQf7iWh2M339pmWcDZn9WGYzoz17ANo2SKltoj8sB8P1jVDh9yxAgrAVygXzuFgL3qdJSr4StxYvFUZOS5vH44NXHi2s6tzJ8nAaXKecLCYrQaj8fodCOetxua1HDQ4W0yg0XyAnO/lYTGAuO5rh3LEWySnkFYOwEkQeDfPs7UhAXqfeQP7EBDoGsShhbwVgLn95y/olsy/cMgxJEMsuS3m4d0bOOCrjE6xqqlqABGGzmHItdioEdovJFzw/K6mVerjsXbICeOCV/LfhZDE5rems1oKodCMIc4AM2AgCIzWOFA45V1FDqoKIx2TmVFWTzDTKluo6k0Og3QprkZz1PWpb2aAsHX9lfutC25cbVchVhdjTXHUMYhEiYGuIZqa51gR9XHWBLBg3CvUUR05LO6A9lSC6p8zZ2cw4q5qqFlAMwsViytQ0rmj7NC8y73lKED175We4/mPy/iuP5r8NawWygtPgOj0iZ/L+KmeCCDtl56jBayr1dVljEJEkIVU0QO2y7MVydmUSqMl87qh1IByD1DnEIFIURB5rMtiXG0053gLSXL1+GdPQMYhFhDQFkVwP4dbNy4kZIrkMab44e0DeLtuS8nDXpGk3TY+y0iQIYyG0CHZTELk2XCvGPs9bBbEPlm6WzeaWbISjhRCEi8Vk/95VHyYh5IDoDToHqe0WE6TaH5ksJo8XEPL3mbYExeuWZVcQTjGInCwmC0EUHIOozN3isS83mth3VW77tVuy6vcoh15MZYO0GMRMwu54zSVthPFzqs+hUjUX9OyXnvSSjSkPn5owCWJmjFVNVUyEYwxN5BfneHB3J6/0FnlG79bN1V8lVzkrxSp4CZlusZjmMwbRvRdGu1Ifi8fgwd+Fn/6p83viMTi7H5ZfIe9f9Dq5nsF0np16rcuNKgRrpVcet9TKWNeCEEJaP5OWNFfH/H4HBRHJoCCESHbxtcY8atszxyBULUfKZ8iyqlyoL7Xzqzpe4c3tnItMyWP1ePILUttrRRL7rkpdsc8N9jRXddy5tAo/D6AJAtK9zmg4MSOor/IT9wTo6R8ubIZ/9gC0XpKssASisTinQ2bl6sw4KxvlCZpPHGJ4IswnfniQbz59Kv9jyoSYbbBWECK/pSML2edCUBDxOPzXW+Abr4PR7uTjT/4TvPhT6Nrt/L6Bo/K7ab9c3r/wVtle5fhj+e3fLc0VUgdKpSAU7O02nCqE7QrCaSC3wxswLSabggiH3Be8ik6DEcseR7HCXiQHyRX1cq2DSFn20zZAn97lXNfgZrEtu1SuavfDP0gl3rT92tJcwVyXWhNEVgghXi+EeFkIcUwIcbfD818WQuw3/44KIUYsz71XCPGK+Vfa5U0TCiI1BqHgCVQwPT3FkbN52kyGIWeV7an2Un9ohpARJC68MD3Gqub8CWL3KXnSnhrMY2nEXBC1pe1Zkc0mKBT2VMH5jEH0vygH2rFu+M7vyIH4xA54/O+lgnJTBCpAvdwkiBVXytl2vumu1rWcFZysFquCAJMgLDPeRJqrrdWG9Tmnojw7vH5nBQHuKsKN5CKTqSrICnuRXOJ9dblXUica5tkG6KkR+OZtsOe+9Pc5ZTEB/PaXYPsn4fCP4WvXyHPACbEZQEiXQEFbTNkhhPACXwV+C9gAvFMIscH6GsMwPmYYxmWGYVwGfAX4kfneJuDTwNXAVcCnhRCNpTpWfAHiwpeqICwEEQhWEhRRvvSLoxzpyYMkxrphcjAtg+ns6DQgiPlrYGYsoSDyCVQnCGKgyMFtN4sJsgcaC0V0ASmI00/L2zf+s8xC+t475Cyy5SK47N3uy2327JXJDs0Xyvten2w298ovclu6UiE8IYnIOiN1UxAV9cn7dgXhtM6BXUGEHV5jh7KY7AoC3Ivl3Gwy63N2hHpTi+QUcj3nojNJlW4PUk/0SyIcPOZwrC4xCK8ftn8C/vBxSSCPfNxlv+Zyoyl1FItnXepSKoirgGOGYZwwDCMMPADckeH17wS+Z/5/K/BLwzCGDMMYBn4JvL6Ex0rMW5kag7DMoL3+IBuWBHnylQFu+5cnue2fn2Tn0f7sG+3ZL2/tKa6j8gI1AjI7pTLgpbU2yJkh55MqHE0fYJ47JQeDntGp4vZxGj4lBwyV2WVFMItNUChiYZmR4zFPx/mMQXTuklk6l78X3vQ1eT88AW//FtQtl4OVU6O67r0yU81juaQ6roPJATlRyBUquGsdcJzWpZ62W0wNLgSRQUE4DeR2KIspRUGYBOGmIGYcthvIkuQw3ptaJKeQLT1WITLlbjFNDspb++JDkSlJHnXL3be77FLYcAcMnXRWP9Fwet8ytS71IkAp13RYDpyx3O9CKoI0CCFWA2sAZdg6vTftVxRCfBD4IEBbWxs7duwo+GCv8lQw2HmMlx5/nO2xMKe6znLK3N626QitFeN86aYKnjkb5dFT43zsu7v54k2VeIT7yqsdJ3/Cajw8eXSI+PHksT11Ss7Sp+I+xrpOcGjHDuq9EV440c2OHal+53jY4C+emOQDm4NctVT+XDNRg0Ndk7RUCgamDH748ye4avQRJqpXMdJ4ac6fORQKpX1nl7/4a2LVazjwZHqriC0TETzj3eybxffshHWnjtOOlyfN7V48MExjaJRnirwfBafPDYBhcO3RHYzWX8KRJ54AltCy8RNEfbWMHDnHiq5+LgCeeuwRov66xNtEPMINZ1+ga8XtnLBst3FohC3Avh0PM9qw0b43R1x86ihNho9dlu3Ujb7C5cCB3b9h+PgkGAY3TY3S2TvKSfN1awdCLJ8YSHyHHSeP0AHsePo5EB5CoRB7DhxnG3Bw/x4Gu7xUTXRyFXD4lVP0jzp8H8BV4SjjZ7uYGZpmhfCx8zfP4omHuRE4ceA3dI6krxtWN/qiPN6XTzDcL7fb2tfJRuC5p37NZPWqlNd7YtPcGB7nRF+ITtvvculEGN/oCHuznAubersJzkR5fscOOnr6WB2Z4onHHyc0McHB555lMzDV8xLPWrajPv+Rc9P0Zdj+sv4IF8cjPPPoD5iuTFU5F505SUtM8LTl/ZeOT+GNDRX9OskVrud3AVgoi/68A/iBYRh5TYUNw7gXuBdg27Ztxvbt2ws+gNDuKpY21rD0hlfBE9Cx7iI6bjS3d7SZmqpa3vC6m3kDcOX+bv7kgf1UrrqUa9c1u2+0+6uwZD03vvrWlId3PfIigWOnqGtZhvD42L59Oz/p3c9zJ4ewf4anjw0w89iz7Bur4S/fcU3isZjxLO+57kK+/KujtK7dwIU/fZ8MjG6/K+fPvGPHjtT9RaZg5yl41V1pxwHAuVUwdML5udlg4n9gsDK53fH/hvFDxd+PibTPrTB8Gp4YZMmVb2LJVep5y+v298Dxb3D9FZtkKqtC917YGWXVNXewaqPl9f3t8MLfsXVNC2xx2J8T+v8TIk2px9fbCvtgy8VrYON2GRx+Is7q9VtY/Srzdd7n4cx/s/26q+UMOvxr6K5g+823JD7ztg0XwPOwef0FsGk7dO2B3bBx61VwocvxHa6nqrkBKmthqIntN98sH9/dwNqWCtY6fY/HYvJ4t70KVslzlqNhOAJXbdkAK7alvn7oBDwJa7e8irWX2bbXtxr6Xsp+LnR+GcJCvs67F04bbL/+Wnb85hk2ty+DQ1AZHmD7jTckW5u/9DPYDRuu+202rLjCfdsnBBz9Ktdc3AZrbccx/ABM1qUe39nlMNJZsvM3G1zP7wJQSoupG1hpub/CfMwJ7yBpL+X73qIg5q2UUtZe1av+t3jir9uwlOqAlx/vs6VCWmEY0mKy2UsA58amWVpXgQjWJYqAVjZVcXZ0Ks1OOt4vJfkzJwfpHpGy9blTQwgBb71CiqrT/aMyeOq0aEw+6NkvM29WXOn8fMmC1MmsMcBsSz0PFlPnLnm76lrn55Xnb49DdD8vb1WAWqF+hbwd7cz9GOz1A5Du31s7uSrYG/Y5pW8m1ipQMYhcLCZ/MovJamnVtbvXQrjVcoCzXeRUJKcQyNLDSSEybYlBqEV7TJtNNcuMR1PtvqGT8rZpTeZtq+fV662ITjtYTHkU6i1wlJIgdgMXCiHWCCECSBJ42P4iIcR6oBHYZXn4UeB1QohGMzj9OvOxkiERg0hk8VgGLBWoM1HpjXPbxlb+9+A5d/9//Jzs6mkrkAMZpF5aVwEVdYlUwZWNlcQN6BlJ9S6P908Q8HowDPjvffLk3n1qiEuW1rGisYrGKj+9feYFNpUhHS8XqBRON4II1ORW1ZovYuHUrCnfPLX7Pv00BOuTDensUAOyPZOp74gMEtevTH08UAVVLTByhpzhRBAJ/94cXK2dXBXs1dSRqXSCUG0glD/uVG1th7UOwkpImaqpHavBMxS9hTIQRK4xiOh08vMliND8nCoGAalxiKETyTW9M6Fuufwehp0IIpyaUKD2r3sxZYZhGFHgj5ED+4vAQ4ZhHBZCfEYIcbvlpe8AHjAsRQaGYQwBn0WSzG7gM+ZjJUPUVylnxyo4ap0V2LuLPvi7fHzqnxmfifLLIy4Lp5w1A9Tt6Qqid2yapfUVZgqfHHDXtMjZllIMCsf7Q1y8tJYrOxr58b5uIrE4e0+PcNUaeVJ3tFQz3G9Woc5WQXQ9B40dUNPq/Lwqdip2xXd0xvZ9V8jfQe1n5EzuaxPPBp27YNXVzqurQVJB2AuoJgbk4OYUj2pYCaP5EIRDXYKafSticlQQNoJwys5JUxAO6ah2WLOYUhREhmpqt35S4DzYO/VhUlCJEdnOueh0UvUnFIQiiKFkGurw6eR7hk+mWoVu8HihYbUkFDtsCS2J/WsFkR2GYTxiGMZFhmGsMwzj8+Zjf2sYxsOW19xjGEZajYRhGPcZhnGB+Xd/KY8TsigIn219gnOHaO3fxdLaYGJWn4azBwAhWy9YYBgG50YVQSRnRxcvlYOAPY32eF+Ida3VvHnrCo71hXhw9xmmIjGu7DAJormaiRFzQaLZEIRhwJndsOIq99cEa6VML7b9Y7eY7G2mn/4KfOdt0HukuPu1YmJAFru52UuQHCDtCmJySK6l7IT6lXkqCAeC8PplF1VlgWVTELGoPP/sM3K7gog4FNPZoSymNAXR7r70qGOaq8rEclAQ4+fkAF7pMJMP1gJG9sV7otPJLC17y+3JQWi5WFZl2xVEYxZ7SaFpDQydSn/cWqCn4HNYmOk8ha6kNhHzVpgKwtadEeTgpZRFPA6hc4iJPn53o58njvYzGHIYMAdegYZVaRf7yGSEmWg8aTHFwhCZprbCT0dzVUox3mQ4Ss/oNOtaa/jtzcsIeD188dGXAbiyQw4IHc3VxJXHOjXiXoiUDaNdsh+Om70E6QsrFQuxcGrdRSJffyZ5bBjw2GeLu18rOp+Rt6tf5f4atxjE1JC7TdGwSh5/rqrLrTfS+jfAqackAVjXglCwEsSB78nZ8TUfTt2G1y9rLNIURI51EHYF4bb0qKrlsKbYBm3FqFaE+uR67R6H4SjXfkwRq4KwtdyeHJQ1FvXLZfNMkKQ3ciY3BQGSSIZPpv+OdvULyTTXhdBbbZbQBGFCKojx7ApickDOooE3t/UTjRv89ICDFztyGhpXpz18bkyetAmLCRI208b2eg5bFMSJfnkBr1tSQ32Vn1vWL2F0KsLq5iqW1MlBtKOligahLh4j994/kWl8EYtaUfGHlRkIItGwr8hxiOhMelKAehyk1y088PIjcOa54u5boXOX/M3bt7q/JlAjZ6FpCmLQefYLUkFEp5KB0mwITyQtJSsueaM8744+mlqToKAIItQLT/yjbPlx8W+lbkMIc1U5c+AcOmnWvGSxmKIzMlZmj0GAcy3ETCi9lsMXlLUuTgoi1Ju6DoQVua4JEZ2yxCBsQerJAanwGjuSFtNIp2wHki1ArdC0VpKU/XeMTqevnaKsvEUQh9AEYSLmrZQzInXx+2yWh/qxLdWjy6deYsOyOr7xm5MM2FXE8GnpW9pwziySa6ursMxIpTW0ob2OzqFJxqZlnYSKR6xrlRfwmy+XWUvKXgIZu2jCWmGbo830q3u4+tkPJz9P1255gbVtcn9PtmKnQhGL2ILUtjU4xs7CxjfLWeav/q40M7PTT8v0S3sPKiuEkL+ZNQZhGJktpgYzcJ1LHCJTb6T2y+Wg/OJP5f6FN5VIAtXyO9x9n8yauvlTzjERa5XvyZ2w+lr3mAtI1TE5ABipCiITQbh9BrdCS7c2G5AHQdgqqSE1BlHVLK9HZTGpgHOuCiKRyWSLQ8TC6eeMPQZyHkMThImomn2ojAevPWhqKohxMyDs8UPPPj77po30jc3w/vt3E5ox/djwpPRnTQVxqHuUD35rD7f985Pc9b19ALQ3VCQH4zPPApIgAF40VcTx/gk8AlabvZpuvngJr7mkjbdeviJxaKubqy0KgtwJonMX/ug4/PeHpW3WtVvOnp1abChka5dQKOyBPq9FQcSi8rtsvgBu/Lhc6/n4r4u7/3gczh1MdmLNhMqGVAUxMy6XyswUg4DcCCJTbySPB9b/Nhz7tTwHK+pTCUAIqSLGe2Dl1XDBq5334auU3+t4Lwy8DB03ZD4mbyA5a660dLupMwvknALVbjaZ27KjE/3uiRGZgtsKhpFseQEpi/aIeEQqXqUgJvrk9alSVnONQajX2TOZ7OoXMBRBlSLjb46hCcJEzGsjiBTLI5BqdwCsuRF69nHFqka+9u7LOXJ2jD/69vPMRGNJn9M8qf71sWM8dWyAtrogd2xt5wtv2cyy+kqZTlm7LNHxc6NJEIcTBBFiZVMVFX45wwv4PPzHe7elFOfVV/pZ5rcE8HIhiFgE+o4wVbEUTjwOu74ig5r2AiY78lnhKx/Yel+lWEyhXjlo1i6DK94nPf1iq4iJfjnIN6zK/tqK+tQYhDpfXGMQJkHkEqieSaaHRmJx/uA/9/D8acvveckbpZXy0v+kzuYV1ADuph7ATMGcglNPyvtrbsx8TN6AtGIg1WKqapGBZUcF4UIQAYeU1XjcJIgsCiLTpCRRu5SuIPwRc3+KIEBen0MnJZE4ZU45oXE1INJrIRwIYu+IJLXxXoe0WDcs0HiFJggTSYIws2lTLKZgMu1y/Jz0wy+6VQ4Oo128+pI2/s9bL+WpYwN88keHkj5nw2rGpiM89nIfb9+2kvvffxWfe9Nm3nGVORAJAetukZ0i4zGW1FbQWhtMEkRfiLUtGQKIJpb5p5gR8niNySH+7KH9/POvMix32f8yxMKcXPMuWX39y7+VCmllhgwmsMzmijwzSgtSK4KYTg5Ade2SqK//Mzj3QnIhJicMn4Z7b05t150JqngqU08ehQqbglC1J24KoqJBDoy5KAgVwA1Uc3pwgl+92MsTL/cln199XXL/FQ4E0XKRbBCYadBXGTYnd8qaD4c6nRRYfxcrKXk8sneSUtQpnyPk3MurulmSgRVTwzK2Up1HDOLsC/BvNyXbjausrARBJC0ev4qzWQli+LS0iprWuBOpHb6gLHy0K4jYTFoM4uUZSdShc8dz2/a+/4IvrIZjv8rt9XMITRAm0hSE16YgQA5kYz3yZF5uzrZ7pGX0O1es4I9uWscP93bRf0ZmGtG4ml8c7iUcjXP7Zek9awBJEFPDibqJDcvqOHJ2jHjc4OTARCL+kAkt3gk6kTOh451n+NHebv79yRNMhV0ymszBNVSzDm7/SnJwy5TBBJmLnWYD+0WWiEGEkzES5XlvuEP670f+2317Lz4su6t25RjQVvuoc/mNrLDHINSEwi1ILYQcWHJREMrKqW5NdOntGbUEOr3+ZODZSUG87T/hnQ9mHvR8poI4uVM2E8wUf4BU689OSrVtyZXgrHCLQTgtNDRhEqBr7Y0DQXTuktfLoDkJSqxH7aQgLAShYoLDp3KvgbCisSM9BuGQ5nom1kzcEMSc0mKtiEzBT/4YfvIRud73uYP5Hc8cQBOEibQYRIrlYUm7HD8rZWnbRimxTYIA+MMb1hD0eXj5pUNyFlPdyk/2d7OyqZKtKx0uaEj2djmWtJle6R3n5OAEM9E465ZkJ4hGxjgWlTOwZw8foyboIzQT5eeHXQqZzr0A/iomq5bJi/xt35TrKGeT2yW1mJxiEDYFAdLKWXMjHPmJuyw/adon1qKoTMhHQdhjENksJjCL5XJot6E+a01bYp2Ps6O2QOclb5S31hRXBY9HthnPAMNXQXzgFTlAZos/gLuCALOa2okgXCymWlNxWH+3TFXU4ByDUPtUhJpY1c1eB2EjiOoWmbU1fFJaRUpR5IqmNS4WU2qa6+C0wVmaECMZfvPpUbko1b5vww1/IceYTAsTzRM0QZhIVxAOA1YsLE/OunY5W1myIYUgmmuCvOXyFUz1nSRat5KBiTBPHx/kjZe2I9xmddUtUuYn4hD1ROMGPz8kL4JcFERVbIwBo55pby3h0BCfe9MmVjVV8f09Lr2izr4gC/iEOXtccyO85p6s+8lrjeB8kNZqQxGyqSC8gVQLZ+Ob5Eyu95DDtqLJNR1G8iAI+z7cUFEvL241yE1msZgg92I51ZOodhmnB00FMWJLlVx3i/wdnFpj54DTY3E8yu7KFn+ALApiaX4xiLp2+VtbB8KQaTm5WUxq2VHrORcyVYeyqxIEYV6nHq+8ZiOTqQQhhIwldO6SqjVfBdG0VmZ0KbKKx2XsymYxDU1E6DJaCYxn+M0f/wepGN7xPXj136Sv57FAoAnCRNYgNcgTcawnOdNu3yoJwjIj+sD1HayglzPxVh45eJZY3OCOy7LMTNfdIu2Q6bFEoPrh/dL2WNeaJQYRjxOIjDJMDb3RSjqqprl9Szu/c8UKnj4+mL4IkcrYWZp7W/AEPF6pjIq9JkRasz6H79tKsOvfIONAhx1sprP7k15+zgqiRw5eToVadlQ0mMWNlj4/wus8o1doWCltqWzfW8isKK5qTiiInpGp1KVu/ZXwgV/KjC4b/r9HX+Yrv84QewJGInJSMOGtlxOcbEis8hdILXwD+btMDadXDc+MO9dyqOvG2sMpoSBcCCKx7Kjlu1O2lp0gUta+qLApCFPhNXbICRLkXgOhoDKZlIpItOVJJYiRyTBdRiuVky4xsN7D8Ny9sO39sP42+ZgmiIWNtCC1k4KYGZdBSbXkYvtWeeFbZqoXtNbQ4R3g2ZFafvh8Fxe31SbaaLhi3S0yUHfqKVY1VVET9PFy7zgNVX6aqh2W/rRiegRhxBk2ahk2atjSbODxCN5y+XKEgKeeeDS1uGz4pBxAlxVA911s1AAAIABJREFUEJB9beFCELNZTEpBxMKmpWeLDVS3QMf1Mg5ht5lO7pS3q6+TxVC5YKwnN3sJLP2YTJtpclAOPpl8//ocM5nGzyUqipWCmInGGZ6MpL6ubYMM+FpgGAbffa6TH+/PHJgfjUoLakf4YvZ355BsoCymiob0z6jiQtY4xNSInO072ZWJpUotr5/ok9daJoIN1qXamopUlMUUsSkISPRD8kfG5LbV52hYDZjnTN4KwlYL4dT5GRieDHPGaKV6pi+9LY1hwM/+Qh7TLX+TfNy+ZOwCgSYIE0mCME86p7RLNeCoJRdVIz6LzcTUMJXGJK+EmznQNeoenLZi5dXSGz3+GB6P4JJlklDWtlS7W1MKliCpqGyk0SNnnisaq3jVumY2HfwHjAfenawEV9k/2bJX3OCWy14oDENeRCmEbFMQ6vu2YsOb5BKSfS+mPn7qSWi9RLbeHunMbbnPse7cAtRg6cdkXsxTGYrkFFT6bLZMpvFzUNtGOBqna3iSi9qkpWfv8OuEruEphibCnB6cdFyBUGE0LBXEIf8W/vYnh4jHs6RXqt/CKSieUASWAV9dIw5FoonXW5cqDfVLUsx0ntu7CI/bCMIeg4DEqnL+yHjq76PiDh4f1CXriXKCvRbClSAinIkvQWCYbWIsOPh96HwaXvPp1LiVVhALG4bHm9qGwCmrRlVhqhN9yQZ5AVkJwnxNvF4OCrdvyWHg8QXljNgSh4Dc4g8qzfKPfutKLlnXgbD4u2+7YiWtsT7ERJ8M6oIMUHv8chA1MTIZ5tkTg+SEYE1xg9TxKGCkrwcBySC1XUGAGawVqdlM0bDsqbTmBjlAxWacewVZYRhJiykXpCmIIfcMJoWEgsiiaEK9ULuM7pEp4gZcu1YObGdHpzO/D9h/RhJWLG5wetC5sV00FmfIJIgrtt/BC12jPLQnC2kpgnBKq3Wqpk7UAGUgCCuhZGqzoWCdlMRjyUlcmsVkySbyV0F0Gn9k1EYQ5nE1rM4a0E9DRZ2s/7BbTJZzNx43GDEVBJDaHHBmHH7x17IqfuvvpW5bE8R5AJXG6fGl+tFeO0GYg4kvKLOZuvcmX2teIL/zmuv45G3rWdmUoVOmFetugaHjMHyKDctkHCKXDCYVM2lb2k6gpjnlJLt1fRNLMGe6z90rb8++AEvWJywdwzD40H/t5c57n+FLvzya6nc7IdcFXHKFU3NE9f/EgOyn46QgapZIG0kRH8iFeyKTMvhqLYrKhMlBeQw5W0yqKd5I8v3Z1hOoaZMDbS4KwpLBdE2CILIriANnkvbEsT7n36dvfIbn4xfS03o9r77+Oq7saOSLj75MNJZBZSlrxlFBKIKwDPiWGiDHbVW3psYgJvpyIAiLrTnRLwsn1f+QjAdZ003NRXv8kTFnBZFv/EGhaU1GBTE+HSVuwBnD/EzW8+/YryUhvvbv0uNdmiDOA6gsHXvzLTVg2RUEyMGoc1dywDBfs3HDpXzwxnW573uNmXJ4ehdXdDTi9Qi2rHBJjbXCmodf2ShntmZH18rpPjzC4CVWyyB4zz5pMVnspR/u7WbXiUE2La/jX379Cp/88aHMA0Yw/0WDpiMx3v5vu/jusw4z6ERzRIcYhJqp1ToQBMCmt0D/S/Dcv8v7p54EhCQOZetkm7UrC2A2CiKbxeTxSAKy2w1WRMNyZly7lNMDkiCuWN2I3ysSKwlmwoGuES4xJxavuBDE2dEpfhp/FUdfcz/C4+FtV6xkcCKcefuZFERlo3zeriCCdaltOayota0jEcqFICwrGSpFWFFvsZhsldRgsZjG5KxfQZ0XubbYsKNprezUrKxRSCGIoUk54emlkQi+1ESJ7j3y+1p5dfp2KxtlfcoC69+kCcIKpSDs7XvViTd8Wv5vPfnXv0HaJGpBm+HTcrCuqCMvtK6Xs/Ou51jXWsPzf/2azOtdK1greSubSOnoag5I/xx+EzFflWxRMTkASyVBjIcNPv+zI1yxupGffOR6Prx9Hd97rpO7HtjnriQKWHb0//z8JZ47OcQOa1WwglIQTkkBipDdBu8r3gcX3wb/+5dyfeGTO2HpJjmjVwNBtkymfIrkIDUGYRi5KQiQmUyZgtSJgrE2Tg1OUh3w0lobZGl9BWftqa42RGNxDnaPcs3aJpY3VLoqiG5zO+0N0qtfZfb4UgFxR2SKQQiRrG1QGD4tv3u3mELtsiShxGNykHdLcVWwtuhQ8Ye2zaaaMNIrqUHaxeEJMwZh+X0C1fCGL8NVH8y8TzesuFIe/8hpx87PwyZBNNVU0ktL6gSl63mZPejUELLSpkwXCDRBWKHaA9gVhNeiIOwpl8u3SQvhpf+R913afGeFxwsrrpCL9gANVeY+43F49t/c20VPDkpLLFibvqqYWQDW6VvN7vrXyb5LkMhgevDlMOPTUf7+zZvxegR/+fr1/PHNF/DIwXOcGHBZoCVQk5fF9PTxAe7/zSk8goR1koKExWT5zj0eGScZzqIgPF546zdkNtkPPiCbHnaYuf3+Svm7jJzKfID5FMlBqoLI1qjPivpVmS2mlBqICVY3ywSF9vrKrBbTK30hpiNxLlvZwAVLalwJ4qypFJbVm63im2UK9Wl7KrQV1iwmJ9iL5UY6ne0lhToLQUwOyT5PbkVyCtYYhFIQbRvldz89mhyo/TYFMTmENx5O/322/T60XpR5n27ouF7ennrKMc11xCSItS3VdBqtlvUnojIF263fWeLaXVjFcpogrHBVEOYJEJlID5h6PHIWe+xXMt3Opc13TlhxFfQdTk0jPfOsnCE/8Y/O71EWh+rmCUmCMBXEhRdezJdHbzLfIKBtE7uOD/JUd5QP3rg2JQ33TVvl50tpEmdFHkHq8ekIH//+C6xpqeZdV6/i9OBketZM1EFBgPzOQ8lB0xWBKtleonapJJs1lurghtXZLaaxHkmw1S6tHuzw+mXG2dRI9j5MVjSslAOp28poKlW0to3Tg5N0tMjZfXtDZXqxnA0q/rBlhSSIEwMhx+yks6PT1AZ91FbIQX9JbZCgz0OnS1AbyKwgIFVBGEb2CVLtMjnzj0Uc22z0j89wqNu23oZ12VH1PbVtlLcTA5YYhDWLqSoZ68jl98kVrevl9k495WwxTciU5DUt1ZyKtWAoBdt3RMbHlmcjiIUVh9AEYYVbDMI6eDkFTNe/Qc5wjj8mB6RCFATIZnlGPDXo/cov5O2B7zkPLtbFapSUVnGJ0S6obOTmzWt4NtTGaPsN0LaJqK+KTz98iNZKwV2vvjBlc2tbaqiv9LPXjSACtVLSOy01acPn/udFzo5O8U9v38Ily+qYicY5O2Yb7GLJGEQkFmc6YvaPUhddZVPqzNAJNa3wnh/BNR+BtTcnH29YlZvFVLsse08iK1Q1tSqqzJbFBNC0DjBkU7Z7t8P/3p1aYGbOqqNVSzgzPMlqc3a/rL6C3rFpYhnSUQ90jVBf6Wd1cxUXLKlhOhJ3jCv0jEwl7CUAj0ewqqkqN4spFwWhkgoyTZCsgW1VEW2xmL76+DF+7z5bDy3rsqOhPvn915spqhP96ZXUIBWECmYXkyCEkCrChSCUguhoqabLWIKYHJATqu498gUrXFrKa4I4D5BQEA5rzCo4zWbX3CgDc7v/w2wbXaiCMGcXanU3kLGNmjYZGD74/fT3TA0nicHJYqpfwc3rl+D3Cr6x9NPwnh/xwO4zHO0NcefFgUQrcQWPR3DF6kb2uCoI1X45c7HcK73jPLjnDH94w1ouX9XIGnPAO2W3riwW013f28fb/22XnP0qks41NtC0Fl7/96lk0rhakmQmMhvrzt1eUqhskDGIXNpsKGx8M7z923Dth6V99uz/k2tbKIz3gvBwNlpLJGbQYcYHljVUEo0b9I+7rwO+/8woW1Y2IITgAjPzzclm6hmdYllD6rm9ujkbQWTIYgKpIGZG5eCdKcU18XoHgrBYTP2hGYYmwqmNJs2J20O/OYJhZnolFJ8iCF9FqvVrraqutgSpi4GOG6RdOHBU3vdaFUQYr0ewsqmSLpXqOtIp4w9Vze7B8VwI4tFPwb7vFOED5A5NEFaoGISbxQTOBOELwIWvTS5kk28TMIXKRtmyWRHEWA/0HoRrPiQXF9r9H+mVw9YgqZPFVLeCugo/165r4eGXQ4z5GvnyL49y9ZomrmhznjVfsbqRY32hxGwoBYllRzPbTPf95hRBn4cP3iirVTvMtuUn7QRhWkyjYfjFkV5e6BrlF0fOJb/zTPZSNjSslh73WIbq4nxqIBQSCkIRRA4KwuuDDbfDaz8D73pQPtZ7JPl86Jzs4josiUApiHYzXtDjEoeYCsc42jvOlhUyNnJBqztBnB2ZluuQWLCqqZrOoUn3pITGDtkWvHW98/M1ltoGlVSQLQYB0v5xsJjUOdc3blFX5tK8X//lAcKjDgRhXY9awW9JLy+mgoBkHEK15/ZZg9QRGqv8NFYFkrUQI51SQSy/wj14n40gDAOe/ybs/+7sjz8PaIKwIpiDxeTW8XT9byf/L5QgQMYhunbLE0JlRl14K1z5AdlDyaouILVQq6IeEElvfLQrIcVv3SizYz72wH6GJsP8zRs2uFZpX75Knqz7Oh0yKszZ3HNHO9Ntj8gUPPKXjHYe4kd7u3jz1uU018jvcmldBUGfx0FByAHxmc4QsbhBS02A//urVzB8eSoIJ2RLdc23SE6hokHGIHLp5OqEqiY5sFqrwMd7ExlMkAwgK0vILZPpcM8osbiRSIlurA7QXB1II4hwzGBwIsxyBwUxFYm5K5SmNfBXndDskrJtXg/Hjh8jPHhKPpZp4aUUBdErZ/7BZMbfiNlWpM96POZ1WcNUUkGoQX9iwFQQtj5RViWZ7++TDSoO0blL3rdZTA1VAeor/claiN6Dcg0Wt/gDyOwqj9+dIKaGpY3dd3hOFxfSBGFFIEuQGtwHkwteaxKJSPqjhWDllXLgGToh4w91K+TKc5vfLhXO7v9IvtYwUls9eMymcVPDcoY/PQL10j557YY2hIBfv9THWy9fwabl7r1vtqysx+sRzoFq02L6wo+f47vP2QbeRz8Fz/0bR391HzPROO+/LimnPR5BR3N1YgBMwLSYHj82ysVttXzqty/hpXPjjJlN5WZFEMrqcCuWmxqW8ZR8LSalIKaGzLWhM/QRcsOSS+TFrmC2kT89MEGF38OSWnnOtZszfrdMJlVBfenK5DGsW1LDsf5UghialoNKmoJQqa6ZMpkywRzwv/Lwkxw+fFCei2qi5YSqZjkQjvU4ttlIEMSYlSDkOVcjpvBN9ktS8gUkUU+aBGGPU5kKwsBT2O+TCSoOkUjRTrWYmqoCNFYHGKCOqLcSDv8EMNzjD2qbmYrl1CRnati5g26JoAnCipwUhIvlUVEnA6QNqzIvfJ8NK8xV3U49JVeau/C1yY6Wl70TDv8YJsyZ68yYrMGw93SZHEraKmabhyW1FVyxqpGqgJeP33pxxkOoCvjY2F7HntMOKXfmxVotprnvqZPJbJkjP4E93wAgdOYQN1zYktaksKOlKj3V1bSYDp2b4o6t7bzx0nbWtFTTPW560LOxmOpXyq6vKlA9PQbfeTu1Y2bH00SKa54klIhBDMrvO5cusHa0bZSzSrOoUbbZWMqpwUlWN1Xj8chBs67SR1XA65rJdKBrlOUNlSypTQ6QKtXVahslCMKmIBKprpniEJlgKogWY4jI4EmMbPE3IZKB7VBv2kJBo1NKQVg+rzlxa2MYX2wqWVhX3Zoag7DCjEFE/LWF/T7ZYF1LI0VBRGio8tNQ6QcEY8FlUkFA9jXPcyEISLUmSwxNEFa4xSCESJJGpkV1bv8XeNdDszuG1ovlcez6qpSUF74u+dy2D8hZywumh+0UJK1qkieZyrm3zI6/8NZL+fYHrqatLktWENJmOnBmlIitqjrilTOzlVUxTg7IZTEZPg0/+Sgsv4KzS29mVayT378uPRjX0VJN5+BkqjVlWkxh/Ny+pR2f18Mf33wBI2Hz1JyNgvD65edXCuKZr8Erj7L6tPkbJYrkClAQM2MyyFqov73kEjmwDZ00C8b6oWapWQOR9M+FECyrr3BUEJPhKE8fG+CyVakB5AtaaxidijAQSsaQhqbl79huUxDLGyrxCDKnumZCRT1RbwVtYoTW6DlGgzn8XnXLzBhE6lrUkVic0IxMKEi1mOR1ucajFlQyr8HqVjNzyokg5HcY8RdZPSioOATYYhBhGqsCVAW8+L2C4YB5rM0XuFeXK1Q1pS0aNB2JyevFWkPjtA5KiaAJwgo3BQHyJKhsTO+Jb0XtUtnnaDZQBXMDL0vlYl3UZcl62WRPpb46LXepZiFqPWaL3XXBkhquWJ3lJDVxxepGpiIxXjqbmq20t1dewO+8TFbtfmPnMfjhBwCD+Fu+wROjbXR4erlpbXqL8zXN1YRj8ZTupIapINYvb2FFo7yo77isHW/AvOBnoyBAKrqRTvld7foq+CppHtwjHytUQaiUz+HTsyAIcy2GviOJ/kLxmjZOD00mAvoKshYinSDu/80pBifCaWTslMmkFMTS+tSBNODz0N5QmW795QohGPe30C4GWS4GeGkmB79f1U6E+lLqT5R6gFSLKeaXn2etMNNpEwqixVQQUxkURJ4dDXKFikNAYrwwDEMSRHUAIQT1lQH6vCZBZIo/KNhafhuGwWu+9AT/+tgxWYXvr5Z1WH1aQcwPEjEIB4LwBmY/WOUKZTOtvi7dz73g1XD6NzKt0KlQq7JRPj7aJe2VAo9ZEcnzNpvpF8fkoLO+CX7/+jXMdD4PXbuJv/azfOKxMZ4cXYKXOJ6hY2nbVJk5Vpupe1AWRd2yKTmL93k9LG2SM79jM7O8wBtWy4H86a/IYqs7vy0f33OfVBDCk72S1w5VTT10ovAAaOt6QMiL3fSUh73NhKNxVtkaPLbXV6auTY0Mhn79ieO85pIlaaSfIAhLHGJwSiYA2NOawUx1LTQGAQzSxGW+UwREjKcHq7M3fKxtlxOYyYGU796aNWe1mAYjUtGvEaaCUCo+QRAzDjEIi8VUCqg4hKWx50Q4RiRm0FglU4Mbqvz0CJPM3CqorbBZTJ1Dk3QNT/HMiUGzQn2VtCZ7D2fYSHGhCcKKhIJwWKTHVzF3BLHSJIiLbk1/7oLXSJvp1FPOWTSVpsU01i2PN9+WxibaGyppr6/geUsmUyxu8LOX5KDjj05w55Ur2RqU1dr3HGrl+893cdXVr5Ivtq/TgKwuhdRaiBdOyVTHmzekBvbbmuqZMfz8+MUCrQ+FxtVyAH7267D5d+DC1zLQciXs/Za0d2qW5v8dqZqAyEThBBGokhlCvYcTbTaOT8rvZ70tdrOsoYKB0EzKOg9ff+IEoZkof+EQT1r2/7d35vFRlff+fz8zk2WyTvaQhISsQIAAggiCEFkquKHVurRWr61Wu1rb3lZtf72/trfXa28X2+q9ba1dtdVq1XqtgsgqLqCIQBL2sIWQlWSyJ5OZ5/7xnNmSyWQSEiLJ8369eCVzZs7kOXOG8z3f7fONjyQ63MyRWq/3d7ZL9ktQu8lOjB5+iAmocsaTJdXd/e7WeA7WBu+RITZdfXbS5SfU505QW8PMfh5EbYegV5rIM7k9CMOoRKcoz7CnvX8Vk2XoHsQf3jrGGxWDyMP7svg+v1G9Te3KwCUYMjk2axgHXdl4BCQHo4+B2Fulbp7Kq+1I+0nVje/OXTkdA73LiKINhC+eHEQADyLnUshb1n/7aJBXqr54cz4ZeB1hUaoG2xNi8rmDdCu6Np0Yemy9DxflJLDruNeDeO/4WWo6JE5TGHS3ERNh4ZrUBlqklT8dkHznqunccdUKdVcVwECkxUVgDTNzrEHdrTqcLiqqlMZUfKy/pxSZPIWqiHz+sefM4HekwbBlA4by5rIHAKjOuFIZ1/0vDxpe+uozu/nGc3v8pSt8p5+dS419arH6nAz5iL0tkQiBR5XVTUa8FSmh1uhCr2vp4g9vH2Pt7Aympfe/AAohyE+N4VCtb4jJRYYtcO4pJymKpg4HLV1Dv+i4XJLj3V6DVk0Kr+2rCbIH/p95AANRmBbj50HUtHbThhUr3XRLCy3C+K5EpwBS3Qz164NQBqInPLQcxInGdr7/SgVPbj8W0usBlXS+9Mueh26hvgRjCqQtKpw3XbPgq/vUFMDBsNqU4TQ6tPcZkiMtXb3IplOq6MKtQdUQfLTsSKENhC/BPIgbnlB3DOcDcxgsuT/wGEZLhMpLHN5gzEM2+csguI1FXfm5ldsC83MSqLZ38eutR3G5JOvKaoiwmDD5iKfNNJ/iZFguj9xQwl2X5akEf1KBkuHugxCCnCRvJdOmA3U4ut0Dmvp85iu+y75Vf6WqqXNgXahQcFfVzLkVkgsAaEqYDUmFyhOLH9iIHm9o56UPq3l+VxU/Wn/Q+4Tf5x2aB7Gvys49f36fjh6fru7UYs8MEID3G8LIS44mOsLfo3FXHlU3d+J0SWOGg+T+VQMLzi3KS2Ln8bOcNHILjZ0DexA5Rkjr5DDyENX2Tk473Z+HID27kNfKBinD9C308JHZaDZyEIWpsTR1ODweU21LF22otddj44zd8C7cHdKdTf1zg54kdWgexK+3VeKS9CsPHgru0bC+ISZ7p0Pd+YdCH0XXvVXNRIWbiaEDU3ezutnxzV2dB7SB8CVYDuKjRMFKpXR6+v3+ZZbukEdnU9CLXyjcdPFkrpiRxsOvHeCO3+/ktbIzLC1KQbjF01wuwhv3M3PuYm6+2Kc5KmVaQA8CDBEzI8T0zM6TJLhvavsWBpjMrCzJJjLMxEuDzFkOStZ8ZdiXf9e7TQi4+C71exAv6+8fVGEScFXJJH619SjPuaevDdGD6HI4ue/Z3awvr2XrwXrvE6nTVZjl2DaISmZvdYdnmqAv7gv7c7uq+NjPtvLcripuXzTFk9MJxJ2LczELwa+3HaWly0GXkwE9iJBkvwfgaH07tdK4sMVOYtWsbA7VtnE02IU2diAPQt2Bu0et1rcpQ1Db0kW7VJ9Bg4z3Jux9BRb7/p+NTQdrIm0xg899qGvp4vn3q4gON1Pf2u2XLB8KnhBTtDfE1DyU9/Lppna5JGWnW1gzcxJZJkPJ2TZZKS2YLOetkkkbCF/Co5XwXvaisV5JcApWqJ/HtvW/QPmGm+JDvHMZgKhwC7+6bR7/cf0s3jt+ltqWblbPSPcOkW8+rjyJ9Jn+O6YWq7viHuOC43LCYwtgyyOq1PVsB6fOdrD1UD2z063KCwqQB4iJsLByehr/3HumX7ltyFgilLxFbBplp+2sfnQbe+p7lUcRl6nGPwbA5ZL8fVcVlxWm8OjNc1hckMRDL+5j++EGf12iEAzETzccorK+nQiLiY0HfGZiuBVJq3fTG51Gtb2LmZn973jdF/bnd1VhNgn++1MX8Z2rpvd7nS/p8ZHcMC+L596v8qi9+gr1+RKoeCBUKuvbqMP4ziXksHqmytOtLw8SZvL1IPqEmEzCO2q3zgip1di76DbKq+ukzStE6Gcg+hyb1QbfOobd1ue7GYAn3zpGr8vl8cgqh+lFeEJM7hxEVBgdPU66e53BdvNZs9dAHG9sp627l0vyEpkXb6wnPlt56MlF560XQhsIX4SAW572XoA/qiTmKXVQ6eof4vA1EOeYgwAVFvrkJdn875eW8OXlBVxVMsmYCdEKNcZdTPos/51SpwFSleqCmvTWcBA++BO5iVH0uiSPvnEYl4QZaZGBQ3oG183JpKnDwbZD9QO+pi9n23t4+NX9lFd7ZaPLTtv51G93cKCmlT+V99BljoH7y6HkEwHf453KRqrtXdw4L4sws4n//uQ8shOjuO3JHdzxVAVSGNVAgySpd51o4ok3K/nkJdlcMSOdzQfqvPmMxHx17NJFi0W9TyAPIircwveuncEvb53LuvuWcuWsSZ5GumDcuyyPXpeLH/5TeXMDhZhiIiwkx4QPK8RUWd9OW5gR6rHlkB4fSW5ydH/Jbl8iYtRNhsXq9dqB5k4lU+EuxXX3QtS2duO0KCPWiC2wBzGY4u8A2DsdPP3uSa4qyWDFdJX8Plo/vIR9U4cDISDeqkJM8YahsHeE6EX4GAh3/mFWZjxzYo0Jjm4Jk7QZOsSkGYSClepnUA/i3A2Em8K0WL7+samqTNI9E6Jmn7r7T+2TgEsx7m7rjDzEXndjWhUzUMm1F3ZXsaQgmbgwGbjvxGBpUQq2qDBe+rB6wNf4IqXkoRf28ettlVz9y+188/k9bD5YxyefeJeYCAv/dWMJjV2S375ZObBwGupuPTbSwqpiddGIjwrjhS8s5hsfK6KsuoUml3GxDeJBtHX38q/P7yEj3spDV05nxfRUGtt72FNlVIaZLZCsqpDqpPJKZmQEjpnfcekUrpmdEZJhcJOTFM21szM4UKOqigYKMQFK9vvsMDyIhjaik7PU9yBRCTMWpMZwuHaQu/DYdOU99JHZsFnDPDIjHgNh78JpGJKOyBSvBxFpU1In0L8PIkSeevcEbd293Lssj8kJVsLMYsCBS4PR1N5DvDUMs3GO3LmIkMNMPkOD9lbZibCYKEyNoTCiiW4ZRpMwbh5Si1Xj3HmYPqcNxIWKx0D0aXwbwRDTgIQbOYjaMpWQ7psgTMxTd8b1+1WYqeJlmH4tmMPJrVkHKBmpWxZMVp3UfTvXff+UxcS1szNYV3aGHZWNgy7tpQ9Ps668hq8sL+CuJbm8uPs0d/7+PeKsYTx7z0I+MX8y89LMPL75KDX2wPIVLV0OXis7w7WzM/z6BuKtYXxpeSFvPbAcl6HvYxf+F/TGtm5++M8Krnv8LeZ873Uq69t55IYSYiIsLCtKwSRgs1+YSRnX4z1xZCVYvZMER4jPl6rEvEngJ8fRl5yk6GF7EBmpKXDbC7DgbgAKU2M41tAePCyYVKjKfH2wdzqIjwojKSYCk4B6d4ippQthdFO7rCleD8Liv5BpAAAbv0lEQVRk8iaqh2kgnn73BJcVJjMjIx6L2cSUpOjg+ZMguLuo3dis6vfm4XgQVXZmZMRhMZvIFA1UyWQqaox1pRlhswHyfCOJNhAXKlOWqLLcvkbArehqiRx5mWM37iqmmjLvl9UXs0XFSesOwKHXVDhqwd1QsBLr4VeICRckRIWpu/PenqAhJoCvr5pKdmIU9zy1q79cuA9n7J189x/lzM9J4L6VRXz7qmI23L+ML5Tm8+w9izyd2jdPDcfpkvxoXf9KK4BX956hy+HixnmBq8Aiw8xYY5NwSsFbVf6S6A+/doDfvXWcMLPg7qV5/O2eRSwpVBcxW1Q483IS/PMQqcrbOtgWPaD3cC5MTY9lzcx00qOF5842ENmJUZxp6fIObAqBjp5ezti7yEuOhvzLPeG2wrQYel2SE8FyGmsfU+NifXB7EGaTICkmgtqWbrocTuydDixW9dmY4ib561JFDd9A2DscVNu7WFLgnRdRkBozbAPRbEh9u7G5PYhAsvmBiIgDYcbV0URZtZ0St0JvTw2nZbI3ZOoumT0PiepRNRBCiNVCiINCiCNCiAcGeM1NQogKIUS5EOIvPtudQogPjX8vj+Y6L0jCo+Dz2/3qsAEl1WG1qfxDkBDKORERqzRw7Cf7J6jduCuZ9v5NVa3kLIEZ1yNaq/n6dDv3ryoiwmJWpaaDGIj4qDB+/y8LMAnBnb/f6akW8UVKybf+vo9ep+THn5jtuRhOSY7mm6unkemToE2NMvHZy3J5Yfdpnt9VRa/Pne7ukypnkJ8SzZzJAwzJAaxxiTSLWLYd9no1vU4Xb+yv5drZGTx376V8a/U0FuT65yiWT0ujvLrF672kqkT1/rYoZgbIP4wEP7t5Dg8uCCIRA0yfFIuU3vGloVBpxOrzUvx7WApT1d1+0DBTVGK/QT5NhlQ2qHGoda1dnt6PsChlICJsk6hp6fKeM/d7DCMHcaRehd7cneegEuQnGjv8mhJD5Wy7vwfhzkWEHGIyFF1bm+ro6HF6FJctrVU0haVRUW3kIuIylULteeioHjUDIYQwA48Da4Bi4FYhRHGf1xQCDwKLpZQzgK/6PN0ppZxj/Lt2tNZ5QZMwRVVe9cWaMKL5h36Ex6hmHYD0ksCvSZ2mDMiRN1QHs8kERavBHMGdtg+5fdEU9Tpnd0hlxdlJUTxx+zyq7V3c+9Sufs1z68pq2HaonoeunNZPyygQX7y8gKK0GL7x3B4u+9FmfrbhELf/bifX//fbNLb38MCa6QPOywAwJeRgj8hk26F6z1p2HjtLc4eDK2YMLOi4Yrqq2tnk9iLyllE15362ukqYEaCCaSSIDDMTGx78ZmFJYQrhZpMSXwyRSsOby0/1/7zzU2IQAg4PMZZv73B4LqrKQHR7DGlkjDLWMclZOF3SK+bnTlT3rWIKAXeuwc9ApEbjdElODiMf0+xj4GAYHgQYBkIVZJRkxasZK+31OOMmU+42EEIotYVD67xjT0eJ0fQgFgBHpJSVUsoe4BlgbZ/X3A08LqVsApBS1qE5d5Z8DS75/Oi9v68+VKAQE3gT1a5eKLlZ/R4Zp+TLy18Cl3GH1tvjHWs5CPNyEvnu1cXsOHaWt4/65yP+svMkmTYrn7oktHGvMREWXrtvKU/cPp/8lBh+vvEw5aftPLBmGtu/tdyTnB6QK/6DD5b8hmp7l+dCs668hsgwE8uKUgbcrTA1hqwEq9dAWCJ4PfkOOokcNQ8iFGIiLCzMT2JDRW3IneuV9W1KkqhPP4Y13ExWgnVIBsLhdNHa3eu5qKbGRlLX2k2tYQhM06+Bpd8kYdIUgP6VTMPoXTpS10a4xeQJPQIUpMQazw3dQDR1OEiM9n6XYyIsWEwi9BwEgDWB7tZGrGFmVe7brHpvrClTOFrf5h3FuuiLSkJmlCfMjaaByAR8NGqpMrb5UgQUCSHeEkK8K4RY7fNcpBDifWP7daO4zvHHRZ+GaVeO3vu751JHJQ0sf27E1kkt9g9DzbheSUucelc9dvYErWLqy43zskiMDufP73iHAJ0628Gbhxu4af7kIVX5mE2CVcVpPHXXJbz74Aq2f2s59y7LJyYiBG2miBgWzlQJ4K2H6nG5JOvLaygtSsUaHniUK6iy4eXTUtl+pN7zn72s2k5KbASpIciwjyaritVEu1Bj8Efr28m0WQMKABamxnI4iCZT2Wm7Z9gRQEunuwvZCDHFRdDY1u0xBAmTp8Hyb5OZoDwFby+EO8Q0dA/icF0becnRfrmZvJRo49iG5v10OZx0Opx+HoQQAlvUMJrlOpuYmRmn1mVXcyASMgtwSbw6V3mlqofnrUfp7hk9L2J4Sm4j+/cLgVIgC9gmhJglpWwGcqSUp4UQecAmIcQ+KeVR352FEJ8DPgeQlpbGli1bhr2Qtra2c9r/QmS4x5xae4pioCk8kz1btwZ+kXRycVQWVbbLOePzN8y9UVxqCqfr2c9Rk76C1LpKnOYoPhzCOhamStZV1PDCuk0kRpp44XAPAshynGLLlsG7rkfyXE+KFry04xA0HqO2pZtsc9Og753hdNLlcHHlT17n87Mj2Hmoi0mRplH9/oVyzNHGzIhfvfIOV+cNXk2191gntnAR8H0juns4Uudg46bNAZPj33+nk14XfH+xMTGvTf3t6uNH2NJznOYaBy4JWz48TLgZPnh3O0IIunqVd7P9g3Limw8zqfosU4EPyw/QXN3/RiPYcZed7CA/vv/nnhgpeGvfUWaIqkE/AzfueRv1VcfYssW7X5h0cPjEabZsGbwCDyC9votohx2bbGXLli1Mqt7IVKChqQOI5sXN79GcrbyU5IQrmFn9ML969AesF4v55sXWQY95qIymgTgN+JbYZBnbfKkCdkgpHcAxIcQhlMF4T0p5GkBKWSmE2ALMBfwMhJTyN8BvAObPny9LS0uHvdgtW7ZwLvtfiAz7mA92wn5ImL40+P6XlzMV6Kc3mvo40W//gvzKP6jH+cuHtI68WR289uPNHDdnsXZpIQ+8vYllU23csGZBSPuP5Lle3VrOX3ac5JRII8x8ki9ev8wTRx+IUmBK0Rm++fxefrDDQYcDrrs4l9LS4JP+zoVQj/n3h7dT2SUoLQ2uPiqlpH7Tei6fOZnS0hn9nq+POcVrx/aSV7LAo+Lrptfp4vQb6zGbBMuWLUMIY7zt9rdZNK+E0qmpdJXV8OeKXdQ5IsmwSS6//HLP/ra3XycyMYPS0plwqBsOPc6ci5cEHOk50HF39jhpXL+OTy/Op7S00O+54iM7aO1yUFq6pN9+A1FebYct21k4dyalM72qzxn73ybMYqK0dGHQ/du7e/nP1w6Q22DlZksb3/7EEpVLe2MrHLFw1bUf58E9G+mOTqO01Mj7uZbiqnuRNXUvUVtyI6Wlc4Ie83AYzRDTe0ChECJXCBEO3AL0rUZ6CfX/BSFEMirkVCmESBBCRPhsXwycvykZmuC4Q0x9O6hDpeQmuHc7fLUMrvoJlD40pN2zk6IoLUrhrztPsnF/LTUtXdxy8Sj1fAzC0qIUuntdPL3jJJfmJw9qHNysnjmJf37lMgrTYnC6pEpIfgRYOT2N3aeaqW8NHrY4ebaDjh6nX4LXl8I0dyVT/zDT0fp2untddPQ4PclmdyLXHaJJi1PeQGVDe78JiBnxPgOU8lfA9b+GjLkhHqF7DW1IScD1q1LX9iGpCLvzDH37WGzWsEFzEJ09Tq55bDtP7ThBfnYW0XQyJcF4H/spiMtEmC0sLUxhQ0Wtt4LLZOJA/l0UiVPcahudy+OoGQgpZS/wJWA9sB/4m5SyXAjxfSGEuyppPdAohKgANgP/KqVsBKYD7wsh9hjb/1NKqQ3ER4VMQwBv6ppzex/bZCWaN/niIe/66UU51Ld289CLZSTHhLN82hCH/owQC3OTCLeY6HVJVs8MMo42AJMTo3j2nkX85e5LBk+KnydWFachJWw6ELyayS19srggOeDz7gtvoES1rwyHu6/Fc4F1VzH5GIW+U/AybFZvDsJsgdm3DHnutDvHEMhA5KdE09bdS21L6LF9tw5TYrS/gYh3K7oGYeuheirr2/nFLXNZNtvwIt1d0s2nPBIb187JoLG9h7d8CjSeapvHKZnGjKNPqO7TEWZU+yCklK9KKYuklPlSyh8a274rpXzZ+F1KKb8mpSyWUs6SUj5jbH/beDzb+PlksL+jOc+ERSoBvEBy5OeJZUWpZNqsNLR1c8NFWYRbxqbn0xpu5pLcRIRgWBf5MLOJS/OTg5bUnk+mT4ol02ZlQ0XwgsLNB+vJSYrqFz5yExNhISM+MqBshadcEzzNdO5ErruKKSXGm0/o60Fk2iK9BmKYHKlrwyRgSnJUv+fcYoFDSVS7e3NsUf4eZEJU+KBlrhsqaomLtKgbDJ9uapy9amqh0QxbOjWF2EgL/zDUjZ0uyfr9jbySdT+mlf8W8lqHgu6k1lyQmE2C2xflYDYJbhqj8JKbr64s5HvXziA55iMuEx8CQqjKru1H6mloC3wH3eVw8vbRBkqDlPMCFKTFcriuf4iprNrO7Kx4wszCMzzK3tGDEBAXqS6w4RaTpyu5X4jJZqW1q7ffgKMuh5MXd1eFpJ56pK6NnKRo1azZd90BZnoPxpuHG4iLtJAYIMTU3uMcsPGu1+li04FaLp+WSpjZ5G8gtj4C7XUwVRV3RljMXDlzEuvLauhyONl1oonG9h4mX7JWVTWNwk2GNhCaC5a7Lstj49eWee74xop5OYnexr9xwMcvysTpklzxs22sCzD8Z+exs3Q5XJROTQ2wt5fC1BiO1LX5TeNzuST7q1soybIxOTHKMxukuVM1yfmWKbu1o9L7GAh3h/G3Xyzz6D119ji564/vc/+ze3hm5ykG40hd24Dfm5TYCGIjLCF7EBXVLbxeUctnluRiMftfUj3Ncp2BvYhdJ5po6nB4vU+3gdj/Mmz7L5hzGxR728fWzsmgvcfJxv11rC+vIdxiGvQ8nAvaQGguWMwmEVLXtGZolGTZ+N8vL2GSLZJ7n/qAr/x1t7dBC9h8sI4Ii4mFecG1vgpTY+hyuPzCQSfPdtDa3cuMjDhyk6I9MyiaDB0mX1KNRLU7Ye1mcUEyD66Zxv/uqeZLf/kAe4eDO/+wk7eONpAYHR5wwJRvwrnX6eJ4Y/uACXb3yNYKn1BYMB7bfJjYCAt3Xtp/OJFb8ttPP8qHN/bXEmYW3uZK96yRdx5TQphX/sjv9ZfkJZEaG8FLH55mfXkNSwqSQ+vbGSbaQGg0mn5MS4/jxS8s5murinh5TzU/3+idgbz1YD0L85KCNgSCEu0D/MJM7vzDzMx4piRHc6KxAyklzR09noupm5RYt4Ho30B4z7J8/v81xawvr2XxI5vYeewsj948h88tzWP3yWY/ocDGtm4u//EWntmpms5OnO3A4ZQDGgiAJQXJ7D7VHFD3y5eDNa28uq+GOy6dQnxU/wq2RXlJxEZaePjV/f5zzVFGa0NFLYvyk4k1QmseD8IcATf+rp+UjtkkuGZ2Bm/sr6WqqZMrZoxucYM2EBqNJiBhZhNfWVHIJ+Zl8ds3KzlY08rJxg4qG9opnRo8/wBe2Qpf0b7yajsWk6AwLYYpSVF0OpzUtqgxn309iIx4K2aT8HgSffmXxbk8/PFZmAT8/Ja5rJ2TyTWz1TjTf/jMD/nNm5Ucb+zgB69UUOMjjRLMQKwqTsPpkmw5FDxZ/9jmI0SFm/nsksCjTVNiI/jOVdPZcewsz7znH/o6UtfG8cYO/+KGSJsStrz6pzApsM7Z2jkZSKkk3FdO1wZCo9GMIQ9eOZ2YSAvfeWmfp/w1lLh3fFQY6XGRfrpZZdUtFKbFEmExe8KDxxvbldR3nzvwf1k8hT99ZkHARLKbWxdks+ffPuYxDJk2KwtyE3npw9NIKWntkfz5nRMsykvC4ZL8+z8rPAYiP2Xg8OSszHhSYyPYUDFwue+RujZe2VvN7YumeOZQB+Km+ZO5ND+Jh1/dzxm7N9z2uvHeq3wv8iYT3PlPmHtb0LXlp0SzMC+JpFEujNAGQqPRBCUxOpyH1kznveNNPLrxMFOClLf25dOLcth6qJ4dlY1IKSk/bWemMffCLfJ3vKFdKaH28SCSYyIG7LPwpW+J8HVzMqmsb6fsdAvrjzvodDj5wXUz+GJpAa/sPcPzu6pIj4v0hnUCYDIJVkxPY+vB+gGrop7ecYIws4m7LgvsPfiu7z8/XoLD5eI7L5bR1N7jCS+VZMX36/MI5Xj/cvdCfnnr0JoDh4M2EBqNZlBunJfF/JwEmjscQ6qa+eySXCbFR/Ifr+6npqWLxvYez2CkDJuVcLOJo/VttHT1jtg0vStnpRNmFvzh7eO8ccLBVbMmUZAayz3L8shNjuZYQ7snPxKMjxWn0d7j5J2jgXWU3jnayMVTEkIqb85OiuIbH5vKxgN1zP3BBgq//Rofnmr29x6GQFpc5Kh7D6ANhEajCQGTSfDD62eRFhfhCeeEQmSYma+tKmJPlZ3/WncQ8Japmk2CyYlW9lSpzuq+IabhYosKp3RqKn//oIpuJ3xlRaFnLd9fq3SjguUf3CzKT8IaZg44I6O5o4eDta1ckhv61MbPLM7lyTvm8/+uLubupXncviiHmxeMbQ/PYIy1mqtGo7lAmJoey46HVg55v49flMWT24/xwu7TCAHTJ3kHI+UmR/PWEXWHPlIGAlSYaUNFLfPTzRQZulAAlxWm8Ngn5wadFugmMszM0qJk3qio4wdrpV8oa+exs0jJoKW+vrjDVhcS2oPQaDSjitkkeGDNNAByk6KJ9qnbn5IUTacxB9tmHZkQE8DK4lQ+sziXm4r6v+fVJRl+Q4KCsao4nZqWLspO+/dEvFt5lgiLidmTPxoii6OFNhAajWbUWVaUwvVzM7m6T3gqxyfZHaiPYLhEWMx895piUqLO7RJ3+dQUTAI29Akz7TjWyNxsW9AKq/GANhAajWbUEULws5vn8LVVRX7bc33GlfatYvookBQTwbycBF7ZW+1pdLN3Oqg40zKk8NKFijYQGo1mzPBVUx2pKqaR5raFOVTWt7OuvAaA94+r/MNQEtQXKtpAaDSaMSMj3uqRag912NL55uqSDPKSo/nlpiNIKXm3spFws4m52YMnui90tIHQaDRjhskkyE6MIi7SEnB29UcBs0nwhcsL2H+mhTf217Hj2FnmTLYRGTa+8w+gDYRGoxlj8lOiP/KzNNbOyWByopWfvH6QstN2FuYljvWSzgu6D0Kj0YwpD105fdCxnGNNmNnEF0sLeOCFfYCS3Z4IaA9Co9GMKTlJ0ZRkffTj+R+/KItMm5Uws+Ci7ISxXs55QXsQGo1GEwLhFhOP3FDCkbrWQWdhjBe0gdBoNJoQWVKYzJLCwRVmxws6xKTRaDSagGgDodFoNJqAaAOh0Wg0moBoA6HRaDSagGgDodFoNJqAaAOh0Wg0moBoA6HRaDSagGgDodFoNJqACCnlWK9hRBBC1AMnzuEtkoGGEVrOhcJEPGaYmMc9EY8ZJuZxD/WYc6SUKYGeGDcG4lwRQrwvpZw/1us4n0zEY4aJedwT8ZhhYh73SB6zDjFpNBqNJiDaQGg0Go0mINpAePnNWC9gDJiIxwwT87gn4jHDxDzuETtmnYPQaDQaTUC0B6HRaDSagGgDodFoNJqATHgDIYRYLYQ4KIQ4IoR4YKzXM1oIISYLITYLISqEEOVCiPuM7YlCiA1CiMPGz3E3S1EIYRZC7BZCvGI8zhVC7DDO+bNCiPCxXuNII4SwCSGeF0IcEELsF0IsGu/nWghxv/HdLhNC/FUIETkez7UQ4ndCiDohRJnPtoDnVih+YRz/XiHERUP5WxPaQAghzMDjwBqgGLhVCFE8tqsaNXqBr0spi4GFwBeNY30A2CilLAQ2Go/HG/cB+30ePwL8TEpZADQBnx2TVY0uPwfWSSmnAbNRxz9uz7UQIhP4CjBfSjkTMAO3MD7P9R+A1X22DXRu1wCFxr/PAf8zlD80oQ0EsAA4IqWslFL2AM8Aa8d4TaOClPKMlPID4/dW1AUjE3W8fzRe9kfgurFZ4egghMgCrgJ+azwWwHLgeeMl4/GY44GlwJMAUsoeKWUz4/xco0YoW4UQFiAKOMM4PNdSym3A2T6bBzq3a4E/ScW7gE0IMSnUvzXRDUQmcMrncZWxbVwjhJgCzAV2AGlSyjPGUzVA2hgta7R4FPgm4DIeJwHNUspe4/F4POe5QD3weyO09lshRDTj+FxLKU8DPwZOogyDHdjF+D/XbgY6t+d0jZvoBmLCIYSIAf4OfFVK2eL7nFQ1z+Om7lkIcTVQJ6XcNdZrOc9YgIuA/5FSzgXa6RNOGofnOgF1t5wLZADR9A/DTAhG8txOdANxGpjs8zjL2DYuEUKEoYzD01LKF4zNtW6X0/hZN1brGwUWA9cKIY6jwofLUbF5mxGGgPF5zquAKinlDuPx8yiDMZ7P9UrgmJSyXkrpAF5Anf/xfq7dDHRuz+kaN9ENxHtAoVHpEI5Kar08xmsaFYzY+5PAfinlT32eehm4w/j9DuAf53tto4WU8kEpZZaUcgrq3G6SUn4K2AzcaLxsXB0zgJSyBjglhJhqbFoBVDCOzzUqtLRQCBFlfNfdxzyuz7UPA53bl4HbjWqmhYDdJxQ1KBO+k1oIcSUqTm0Gfiel/OEYL2lUEEIsAd4E9uGNxz+EykP8DchGyaXfJKXsmwC74BFClALfkFJeLYTIQ3kUicBu4DYpZfdYrm+kEULMQSXmw4FK4E7UDeG4PddCiO8BN6Mq9nYDd6Hi7ePqXAsh/gqUomS9a4F/A14iwLk1jOVjqHBbB3CnlPL9kP/WRDcQGo1GownMRA8xaTQajWYAtIHQaDQaTUC0gdBoNBpNQLSB0Gg0Gk1AtIHQaDQaTUC0gdBohoAQwimE+NDn34gJ3gkhpvgqdGo0Y41l8JdoNBofOqWUc8Z6ERrN+UB7EBrNCCCEOC6E+JEQYp8QYqcQosDYPkUIscnQ4t8ohMg2tqcJIV4UQuwx/l1qvJVZCPGEMdfgdSGEdcwOSjPh0QZCoxka1j4hppt9nrNLKWehOlcfNbb9EvijlLIEeBr4hbH9F8BWKeVslE5SubG9EHhcSjkDaAZuGOXj0WgGRHdSazRDQAjRJqWMCbD9OLBcSllpiCLWSCmThBANwCQppcPYfkZKmSyEqAeyfGUfDBn2DcbQF4QQ3wLCpJT/PvpHptH0R3sQGs3IIQf4fSj46gQ50XlCzRiiDYRGM3Lc7PPzHeP3t1FKsgCfQgkmghoL+XnwzMyOP1+L1GhCRd+daDRDwyqE+NDn8ToppbvUNUEIsRflBdxqbPsyarLbv6KmvN1pbL8P+I0Q4rMoT+HzqEloGs1HBp2D0GhGACMHMV9K2TDWa9FoRgodYtJoNBpNQLQHodFoNJqAaA9Co9FoNAHRBkKj0Wg0AdEGQqPRaDQB0QZCo9FoNAHRBkKj0Wg0Afk/AG2oBeeaVggAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpCdwiQFp-sr"
      },
      "source": [
        "####Adamax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USalMSvaqC7d",
        "outputId": "fdbe639e-fbd2-4aa6-992b-1dcde09435d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wide_opt(opt_Adamax)"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9109 - val_loss: 0.7844\n",
            "Epoch 2/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7723 - val_loss: 0.7107\n",
            "Epoch 3/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7220 - val_loss: 0.6882\n",
            "Epoch 4/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7031 - val_loss: 0.6784\n",
            "Epoch 5/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6937 - val_loss: 0.6743\n",
            "Epoch 6/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6867 - val_loss: 0.6715\n",
            "Epoch 7/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6820 - val_loss: 0.6670\n",
            "Epoch 8/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6766 - val_loss: 0.6656\n",
            "Epoch 9/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6726 - val_loss: 0.6606\n",
            "Epoch 10/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6689 - val_loss: 0.6578\n",
            "Epoch 11/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6655 - val_loss: 0.6584\n",
            "Epoch 12/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6627 - val_loss: 0.6537\n",
            "Epoch 13/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6596 - val_loss: 0.6514\n",
            "Epoch 14/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6576 - val_loss: 0.6502\n",
            "Epoch 15/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6559 - val_loss: 0.6513\n",
            "Epoch 16/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6541 - val_loss: 0.6525\n",
            "Epoch 17/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6522 - val_loss: 0.6509\n",
            "Epoch 18/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6508 - val_loss: 0.6480\n",
            "Epoch 19/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6490 - val_loss: 0.6488\n",
            "Epoch 20/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6477 - val_loss: 0.6486\n",
            "Epoch 21/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6459 - val_loss: 0.6456\n",
            "Epoch 22/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6453 - val_loss: 0.6482\n",
            "Epoch 23/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6440 - val_loss: 0.6465\n",
            "Epoch 24/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6431 - val_loss: 0.6455\n",
            "Epoch 25/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6416 - val_loss: 0.6454\n",
            "Epoch 26/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6411 - val_loss: 0.6456\n",
            "Epoch 27/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6401 - val_loss: 0.6475\n",
            "Epoch 28/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6395 - val_loss: 0.6448\n",
            "Epoch 29/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6389 - val_loss: 0.6450\n",
            "Epoch 30/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6380 - val_loss: 0.6462\n",
            "Epoch 31/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6368 - val_loss: 0.6444\n",
            "Epoch 32/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6356 - val_loss: 0.6459\n",
            "Epoch 33/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6356 - val_loss: 0.6475\n",
            "Epoch 34/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6350 - val_loss: 0.6463\n",
            "Epoch 35/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6343 - val_loss: 0.6435\n",
            "Epoch 36/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6337 - val_loss: 0.6440\n",
            "Epoch 37/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6333 - val_loss: 0.6444\n",
            "Epoch 38/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6327 - val_loss: 0.6424\n",
            "Epoch 39/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6318 - val_loss: 0.6442\n",
            "Epoch 40/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6313 - val_loss: 0.6426\n",
            "Epoch 41/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6308 - val_loss: 0.6420\n",
            "Epoch 42/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6297 - val_loss: 0.6423\n",
            "Epoch 43/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6290 - val_loss: 0.6443\n",
            "Epoch 44/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6288 - val_loss: 0.6424\n",
            "Epoch 45/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6281 - val_loss: 0.6408\n",
            "Epoch 46/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6273 - val_loss: 0.6428\n",
            "Epoch 47/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6269 - val_loss: 0.6404\n",
            "Epoch 48/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6266 - val_loss: 0.6410\n",
            "Epoch 49/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6256 - val_loss: 0.6421\n",
            "Epoch 50/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6253 - val_loss: 0.6402\n",
            "Epoch 51/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6242 - val_loss: 0.6414\n",
            "Epoch 52/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6240 - val_loss: 0.6421\n",
            "Epoch 53/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6233 - val_loss: 0.6394\n",
            "Epoch 54/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6228 - val_loss: 0.6391\n",
            "Epoch 55/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6219 - val_loss: 0.6407\n",
            "Epoch 56/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6213 - val_loss: 0.6402\n",
            "Epoch 57/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6213 - val_loss: 0.6407\n",
            "Epoch 58/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6206 - val_loss: 0.6408\n",
            "Epoch 59/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6196 - val_loss: 0.6405\n",
            "Epoch 60/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6197 - val_loss: 0.6402\n",
            "Epoch 61/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6191 - val_loss: 0.6397\n",
            "Epoch 62/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6182 - val_loss: 0.6413\n",
            "Epoch 63/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6179 - val_loss: 0.6388\n",
            "Epoch 64/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6178 - val_loss: 0.6409\n",
            "Epoch 65/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6173 - val_loss: 0.6400\n",
            "Epoch 66/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6166 - val_loss: 0.6407\n",
            "Epoch 67/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6165 - val_loss: 0.6406\n",
            "Epoch 68/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6154 - val_loss: 0.6410\n",
            "Epoch 69/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6155 - val_loss: 0.6386\n",
            "Epoch 70/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6149 - val_loss: 0.6398\n",
            "Epoch 71/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6148 - val_loss: 0.6410\n",
            "Epoch 72/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6144 - val_loss: 0.6409\n",
            "Epoch 73/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6141 - val_loss: 0.6397\n",
            "Epoch 74/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6139 - val_loss: 0.6379\n",
            "Epoch 75/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6135 - val_loss: 0.6381\n",
            "Epoch 76/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6123 - val_loss: 0.6391\n",
            "Epoch 77/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6123 - val_loss: 0.6387\n",
            "Epoch 78/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6122 - val_loss: 0.6377\n",
            "Epoch 79/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6114 - val_loss: 0.6376\n",
            "Epoch 80/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6113 - val_loss: 0.6371\n",
            "Epoch 81/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6112 - val_loss: 0.6375\n",
            "Epoch 82/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6101 - val_loss: 0.6372\n",
            "Epoch 83/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6106 - val_loss: 0.6378\n",
            "Epoch 84/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6097 - val_loss: 0.6391\n",
            "Epoch 85/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6096 - val_loss: 0.6390\n",
            "Epoch 86/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6092 - val_loss: 0.6351\n",
            "Epoch 87/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6088 - val_loss: 0.6379\n",
            "Epoch 88/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6082 - val_loss: 0.6357\n",
            "Epoch 89/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6084 - val_loss: 0.6374\n",
            "Epoch 90/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6086 - val_loss: 0.6376\n",
            "Epoch 91/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6079 - val_loss: 0.6348\n",
            "Epoch 92/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6083 - val_loss: 0.6354\n",
            "Epoch 93/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6073 - val_loss: 0.6348\n",
            "Epoch 94/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6063 - val_loss: 0.6349\n",
            "Epoch 95/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6071 - val_loss: 0.6359\n",
            "Epoch 96/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6067 - val_loss: 0.6367\n",
            "Epoch 97/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6064 - val_loss: 0.6335\n",
            "Epoch 98/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6058 - val_loss: 0.6345\n",
            "Epoch 99/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6063 - val_loss: 0.6338\n",
            "Epoch 100/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6055 - val_loss: 0.6338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu7Aj1Ewqf-Q"
      },
      "source": [
        "####Adadelta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MfxgnFoqitd",
        "outputId": "25562dd7-c976-4a61-8764-21b58f7268c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wide_opt(opt_Adadelta)"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0046 - val_loss: 0.9698\n",
            "Epoch 2/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0042 - val_loss: 0.9694\n",
            "Epoch 3/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0037 - val_loss: 0.9689\n",
            "Epoch 4/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0033 - val_loss: 0.9685\n",
            "Epoch 5/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0028 - val_loss: 0.9681\n",
            "Epoch 6/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0024 - val_loss: 0.9676\n",
            "Epoch 7/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0020 - val_loss: 0.9672\n",
            "Epoch 8/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0015 - val_loss: 0.9668\n",
            "Epoch 9/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0011 - val_loss: 0.9663\n",
            "Epoch 10/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0007 - val_loss: 0.9659\n",
            "Epoch 11/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0002 - val_loss: 0.9655\n",
            "Epoch 12/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9998 - val_loss: 0.9651\n",
            "Epoch 13/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9994 - val_loss: 0.9646\n",
            "Epoch 14/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9990 - val_loss: 0.9642\n",
            "Epoch 15/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9985 - val_loss: 0.9637\n",
            "Epoch 16/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9981 - val_loss: 0.9633\n",
            "Epoch 17/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9977 - val_loss: 0.9629\n",
            "Epoch 18/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9972 - val_loss: 0.9624\n",
            "Epoch 19/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9968 - val_loss: 0.9620\n",
            "Epoch 20/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9964 - val_loss: 0.9616\n",
            "Epoch 21/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9960 - val_loss: 0.9611\n",
            "Epoch 22/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9955 - val_loss: 0.9607\n",
            "Epoch 23/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9951 - val_loss: 0.9603\n",
            "Epoch 24/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9947 - val_loss: 0.9598\n",
            "Epoch 25/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9943 - val_loss: 0.9594\n",
            "Epoch 26/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9938 - val_loss: 0.9590\n",
            "Epoch 27/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9934 - val_loss: 0.9585\n",
            "Epoch 28/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9930 - val_loss: 0.9581\n",
            "Epoch 29/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9925 - val_loss: 0.9576\n",
            "Epoch 30/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9921 - val_loss: 0.9572\n",
            "Epoch 31/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9917 - val_loss: 0.9568\n",
            "Epoch 32/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9912 - val_loss: 0.9563\n",
            "Epoch 33/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9908 - val_loss: 0.9559\n",
            "Epoch 34/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9904 - val_loss: 0.9554\n",
            "Epoch 35/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9899 - val_loss: 0.9550\n",
            "Epoch 36/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9895 - val_loss: 0.9545\n",
            "Epoch 37/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9890 - val_loss: 0.9541\n",
            "Epoch 38/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9886 - val_loss: 0.9536\n",
            "Epoch 39/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9882 - val_loss: 0.9532\n",
            "Epoch 40/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9877 - val_loss: 0.9527\n",
            "Epoch 41/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9873 - val_loss: 0.9523\n",
            "Epoch 42/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9868 - val_loss: 0.9518\n",
            "Epoch 43/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9864 - val_loss: 0.9513\n",
            "Epoch 44/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9859 - val_loss: 0.9509\n",
            "Epoch 45/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9855 - val_loss: 0.9504\n",
            "Epoch 46/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9851 - val_loss: 0.9500\n",
            "Epoch 47/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9846 - val_loss: 0.9495\n",
            "Epoch 48/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9842 - val_loss: 0.9491\n",
            "Epoch 49/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9837 - val_loss: 0.9486\n",
            "Epoch 50/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9833 - val_loss: 0.9481\n",
            "Epoch 51/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9828 - val_loss: 0.9477\n",
            "Epoch 52/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9824 - val_loss: 0.9472\n",
            "Epoch 53/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9819 - val_loss: 0.9467\n",
            "Epoch 54/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9815 - val_loss: 0.9463\n",
            "Epoch 55/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9810 - val_loss: 0.9458\n",
            "Epoch 56/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9806 - val_loss: 0.9453\n",
            "Epoch 57/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9801 - val_loss: 0.9449\n",
            "Epoch 58/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9797 - val_loss: 0.9444\n",
            "Epoch 59/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9792 - val_loss: 0.9439\n",
            "Epoch 60/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9788 - val_loss: 0.9435\n",
            "Epoch 61/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9783 - val_loss: 0.9430\n",
            "Epoch 62/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9779 - val_loss: 0.9425\n",
            "Epoch 63/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9774 - val_loss: 0.9421\n",
            "Epoch 64/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9770 - val_loss: 0.9416\n",
            "Epoch 65/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9765 - val_loss: 0.9411\n",
            "Epoch 66/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9761 - val_loss: 0.9407\n",
            "Epoch 67/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9757 - val_loss: 0.9402\n",
            "Epoch 68/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9752 - val_loss: 0.9397\n",
            "Epoch 69/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9748 - val_loss: 0.9393\n",
            "Epoch 70/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9743 - val_loss: 0.9388\n",
            "Epoch 71/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9739 - val_loss: 0.9383\n",
            "Epoch 72/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9734 - val_loss: 0.9378\n",
            "Epoch 73/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9729 - val_loss: 0.9374\n",
            "Epoch 74/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9725 - val_loss: 0.9369\n",
            "Epoch 75/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9720 - val_loss: 0.9364\n",
            "Epoch 76/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9716 - val_loss: 0.9360\n",
            "Epoch 77/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9711 - val_loss: 0.9355\n",
            "Epoch 78/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9706 - val_loss: 0.9350\n",
            "Epoch 79/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9702 - val_loss: 0.9345\n",
            "Epoch 80/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9697 - val_loss: 0.9340\n",
            "Epoch 81/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9693 - val_loss: 0.9336\n",
            "Epoch 82/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9688 - val_loss: 0.9331\n",
            "Epoch 83/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9683 - val_loss: 0.9326\n",
            "Epoch 84/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9679 - val_loss: 0.9321\n",
            "Epoch 85/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9674 - val_loss: 0.9316\n",
            "Epoch 86/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9670 - val_loss: 0.9311\n",
            "Epoch 87/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9665 - val_loss: 0.9307\n",
            "Epoch 88/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9660 - val_loss: 0.9302\n",
            "Epoch 89/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9655 - val_loss: 0.9297\n",
            "Epoch 90/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9651 - val_loss: 0.9292\n",
            "Epoch 91/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9646 - val_loss: 0.9287\n",
            "Epoch 92/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9641 - val_loss: 0.9282\n",
            "Epoch 93/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9637 - val_loss: 0.9277\n",
            "Epoch 94/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9632 - val_loss: 0.9272\n",
            "Epoch 95/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9627 - val_loss: 0.9267\n",
            "Epoch 96/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9622 - val_loss: 0.9262\n",
            "Epoch 97/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9617 - val_loss: 0.9258\n",
            "Epoch 98/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9613 - val_loss: 0.9253\n",
            "Epoch 99/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9608 - val_loss: 0.9248\n",
            "Epoch 100/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9603 - val_loss: 0.9242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIOoFHwYqnWo"
      },
      "source": [
        "####RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3Ol1MB4qm59",
        "outputId": "be4e854a-37f1-4eee-8eb0-5aef33d69f25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wide_opt(opt_RMSprop)"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7975 - val_loss: 0.6771\n",
            "Epoch 2/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6931 - val_loss: 0.6575\n",
            "Epoch 3/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6791 - val_loss: 0.6527\n",
            "Epoch 4/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6674 - val_loss: 0.6542\n",
            "Epoch 5/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6600 - val_loss: 0.6502\n",
            "Epoch 6/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6543 - val_loss: 0.6464\n",
            "Epoch 7/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6497 - val_loss: 0.6561\n",
            "Epoch 8/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6468 - val_loss: 0.6458\n",
            "Epoch 9/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6424 - val_loss: 0.6411\n",
            "Epoch 10/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6409 - val_loss: 0.6415\n",
            "Epoch 11/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6385 - val_loss: 0.6415\n",
            "Epoch 12/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6362 - val_loss: 0.6362\n",
            "Epoch 13/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6337 - val_loss: 0.6351\n",
            "Epoch 14/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6325 - val_loss: 0.6322\n",
            "Epoch 15/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6292 - val_loss: 0.6346\n",
            "Epoch 16/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6273 - val_loss: 0.6334\n",
            "Epoch 17/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6260 - val_loss: 0.6318\n",
            "Epoch 18/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6253 - val_loss: 0.6295\n",
            "Epoch 19/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6245 - val_loss: 0.6335\n",
            "Epoch 20/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6237 - val_loss: 0.6318\n",
            "Epoch 21/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6220 - val_loss: 0.6344\n",
            "Epoch 22/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6201 - val_loss: 0.6292\n",
            "Epoch 23/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6198 - val_loss: 0.6380\n",
            "Epoch 24/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6199 - val_loss: 0.6328\n",
            "Epoch 25/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6183 - val_loss: 0.6387\n",
            "Epoch 26/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6200 - val_loss: 0.6322\n",
            "Epoch 27/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6157 - val_loss: 0.6299\n",
            "Epoch 28/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6167 - val_loss: 0.6336\n",
            "Epoch 29/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6171 - val_loss: 0.6272\n",
            "Epoch 30/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6162 - val_loss: 0.6288\n",
            "Epoch 31/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6141 - val_loss: 0.6297\n",
            "Epoch 32/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6163 - val_loss: 0.6339\n",
            "Epoch 33/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6140 - val_loss: 0.6276\n",
            "Epoch 34/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6132 - val_loss: 0.6315\n",
            "Epoch 35/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6148 - val_loss: 0.6255\n",
            "Epoch 36/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6130 - val_loss: 0.6325\n",
            "Epoch 37/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6141 - val_loss: 0.6298\n",
            "Epoch 38/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6119 - val_loss: 0.6359\n",
            "Epoch 39/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6122 - val_loss: 0.6273\n",
            "Epoch 40/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6123 - val_loss: 0.6307\n",
            "Epoch 41/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6081 - val_loss: 0.6374\n",
            "Epoch 42/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6108 - val_loss: 0.6286\n",
            "Epoch 43/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6092 - val_loss: 0.6301\n",
            "Epoch 44/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6115 - val_loss: 0.6323\n",
            "Epoch 45/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6109 - val_loss: 0.6239\n",
            "Epoch 46/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6087 - val_loss: 0.6293\n",
            "Epoch 47/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6094 - val_loss: 0.6300\n",
            "Epoch 48/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6069 - val_loss: 0.6480\n",
            "Epoch 49/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6060 - val_loss: 0.6228\n",
            "Epoch 50/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6071 - val_loss: 0.6235\n",
            "Epoch 51/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6081 - val_loss: 0.6319\n",
            "Epoch 52/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6050 - val_loss: 0.6305\n",
            "Epoch 53/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6035 - val_loss: 0.6398\n",
            "Epoch 54/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6040 - val_loss: 0.6291\n",
            "Epoch 55/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6067 - val_loss: 0.6238\n",
            "Epoch 56/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6030 - val_loss: 0.6295\n",
            "Epoch 57/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5993 - val_loss: 0.6263\n",
            "Epoch 58/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6039 - val_loss: 0.6244\n",
            "Epoch 59/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6021 - val_loss: 0.6189\n",
            "Epoch 60/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6048 - val_loss: 0.6257\n",
            "Epoch 61/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6003 - val_loss: 0.6340\n",
            "Epoch 62/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5997 - val_loss: 0.6347\n",
            "Epoch 63/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5980 - val_loss: 0.6299\n",
            "Epoch 64/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5961 - val_loss: 0.6272\n",
            "Epoch 65/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5992 - val_loss: 0.6259\n",
            "Epoch 66/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5924 - val_loss: 0.6371\n",
            "Epoch 67/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5981 - val_loss: 0.6308\n",
            "Epoch 68/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5971 - val_loss: 0.6259\n",
            "Epoch 69/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5965 - val_loss: 0.6315\n",
            "Epoch 70/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5960 - val_loss: 0.6320\n",
            "Epoch 71/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5980 - val_loss: 0.6324\n",
            "Epoch 72/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5975 - val_loss: 0.6278\n",
            "Epoch 73/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5926 - val_loss: 0.6375\n",
            "Epoch 74/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5930 - val_loss: 0.6492\n",
            "Epoch 75/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5931 - val_loss: 0.6329\n",
            "Epoch 76/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5944 - val_loss: 0.6449\n",
            "Epoch 77/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5923 - val_loss: 0.6345\n",
            "Epoch 78/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5914 - val_loss: 0.6327\n",
            "Epoch 79/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5890 - val_loss: 0.6573\n",
            "Epoch 80/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5886 - val_loss: 0.6373\n",
            "Epoch 81/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5900 - val_loss: 0.6461\n",
            "Epoch 82/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5890 - val_loss: 0.6294\n",
            "Epoch 83/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5935 - val_loss: 0.6316\n",
            "Epoch 84/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5898 - val_loss: 0.6319\n",
            "Epoch 85/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5891 - val_loss: 0.6372\n",
            "Epoch 86/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5926 - val_loss: 0.6357\n",
            "Epoch 87/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5905 - val_loss: 0.6452\n",
            "Epoch 88/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5881 - val_loss: 0.6454\n",
            "Epoch 89/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5936 - val_loss: 0.6296\n",
            "Epoch 90/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5865 - val_loss: 0.6344\n",
            "Epoch 91/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5876 - val_loss: 0.6366\n",
            "Epoch 92/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5871 - val_loss: 0.6402\n",
            "Epoch 93/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5886 - val_loss: 0.6375\n",
            "Epoch 94/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5888 - val_loss: 0.6448\n",
            "Epoch 95/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5862 - val_loss: 0.6411\n",
            "Epoch 96/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5868 - val_loss: 0.6442\n",
            "Epoch 97/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5882 - val_loss: 0.6324\n",
            "Epoch 98/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5888 - val_loss: 0.6306\n",
            "Epoch 99/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5879 - val_loss: 0.6353\n",
            "Epoch 100/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5842 - val_loss: 0.6472\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7zPSuYnr5j9"
      },
      "source": [
        "###Deeper Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLtkerkqr8hQ"
      },
      "source": [
        "def deep_mode(optim):\n",
        "  deeper_model4 = Sequential()\n",
        "  deeper_model4.add(Dense(11, input_dim=11, kernel_initializer='normal', activation='relu')) #menggunakan 3 layer, dengan featur = input_dim yaitu 11\n",
        "  deeper_model4.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
        "  deeper_model4.add(Dense(1, kernel_initializer='normal'))\n",
        "  opt=optim\n",
        "  deeper_model4.compile(loss='mean_squared_error', optimizer=opt)\n",
        "  historyd4 = deeper_model4.fit(x=feature_train4, y=label_train4, validation_data=(feature_test4, label_test4), epochs=100, batch_size=8)\n",
        "  plot_loss(historyd4)"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB1eHmYDsjwX"
      },
      "source": [
        "####SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1t7u93Asuh4",
        "outputId": "1569a7e0-2a86-4556-a71a-3d86887f00ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "deep_mode(opt_sgd)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9029 - val_loss: 0.7371\n",
            "Epoch 2/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7326 - val_loss: 0.7569\n",
            "Epoch 3/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7171 - val_loss: 0.6718\n",
            "Epoch 4/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7240 - val_loss: 0.6840\n",
            "Epoch 5/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7010 - val_loss: 0.8622\n",
            "Epoch 6/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7062 - val_loss: 0.6999\n",
            "Epoch 7/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6894 - val_loss: 0.6930\n",
            "Epoch 8/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6935 - val_loss: 0.6521\n",
            "Epoch 9/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6937 - val_loss: 0.6746\n",
            "Epoch 10/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6880 - val_loss: 0.6731\n",
            "Epoch 11/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6938 - val_loss: 0.6865\n",
            "Epoch 12/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6990 - val_loss: 0.6874\n",
            "Epoch 13/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7012 - val_loss: 0.6694\n",
            "Epoch 14/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6888 - val_loss: 0.6716\n",
            "Epoch 15/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6790 - val_loss: 0.6569\n",
            "Epoch 16/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7018 - val_loss: 0.6812\n",
            "Epoch 17/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6886 - val_loss: 0.6708\n",
            "Epoch 18/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6876 - val_loss: 0.6737\n",
            "Epoch 19/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6766 - val_loss: 0.6650\n",
            "Epoch 20/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6676 - val_loss: 0.6637\n",
            "Epoch 21/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6652 - val_loss: 0.6767\n",
            "Epoch 22/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6705 - val_loss: 0.6669\n",
            "Epoch 23/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6761 - val_loss: 0.6577\n",
            "Epoch 24/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6649 - val_loss: 0.6578\n",
            "Epoch 25/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6759 - val_loss: 0.7447\n",
            "Epoch 26/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6679 - val_loss: 0.6629\n",
            "Epoch 27/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6616 - val_loss: 0.6580\n",
            "Epoch 28/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6840 - val_loss: 0.6673\n",
            "Epoch 29/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6765 - val_loss: 0.7121\n",
            "Epoch 30/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7037 - val_loss: 0.6484\n",
            "Epoch 31/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6745 - val_loss: 0.6508\n",
            "Epoch 32/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6580 - val_loss: 0.6633\n",
            "Epoch 33/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6603 - val_loss: 0.8207\n",
            "Epoch 34/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6732 - val_loss: 0.6801\n",
            "Epoch 35/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6598 - val_loss: 0.7063\n",
            "Epoch 36/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6812 - val_loss: 0.7280\n",
            "Epoch 37/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6737 - val_loss: 0.6586\n",
            "Epoch 38/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7032 - val_loss: 0.6561\n",
            "Epoch 39/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6670 - val_loss: 0.6929\n",
            "Epoch 40/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6550 - val_loss: 0.6525\n",
            "Epoch 41/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6676 - val_loss: 0.6492\n",
            "Epoch 42/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6588 - val_loss: 0.6779\n",
            "Epoch 43/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6537 - val_loss: 0.6647\n",
            "Epoch 44/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6661 - val_loss: 0.7235\n",
            "Epoch 45/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6486 - val_loss: 0.6684\n",
            "Epoch 46/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6605 - val_loss: 0.7192\n",
            "Epoch 47/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6783 - val_loss: 0.6586\n",
            "Epoch 48/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6785 - val_loss: 0.7048\n",
            "Epoch 49/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6724 - val_loss: 0.7117\n",
            "Epoch 50/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6791 - val_loss: 0.7235\n",
            "Epoch 51/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6604 - val_loss: 0.7272\n",
            "Epoch 52/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6537 - val_loss: 0.6749\n",
            "Epoch 53/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6442 - val_loss: 0.6921\n",
            "Epoch 54/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6740 - val_loss: 0.6593\n",
            "Epoch 55/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6544 - val_loss: 0.7217\n",
            "Epoch 56/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6601 - val_loss: 0.6636\n",
            "Epoch 57/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6737 - val_loss: 0.6528\n",
            "Epoch 58/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6584 - val_loss: 0.7456\n",
            "Epoch 59/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6736 - val_loss: 0.6703\n",
            "Epoch 60/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6545 - val_loss: 0.6803\n",
            "Epoch 61/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6634 - val_loss: 0.6758\n",
            "Epoch 62/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6486 - val_loss: 0.7119\n",
            "Epoch 63/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6638 - val_loss: 0.6568\n",
            "Epoch 64/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6735 - val_loss: 0.6873\n",
            "Epoch 65/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6635 - val_loss: 0.7288\n",
            "Epoch 66/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6667 - val_loss: 0.6414\n",
            "Epoch 67/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6566 - val_loss: 0.9323\n",
            "Epoch 68/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6636 - val_loss: 0.6562\n",
            "Epoch 69/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6742 - val_loss: 0.6930\n",
            "Epoch 70/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6484 - val_loss: 0.6483\n",
            "Epoch 71/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6494 - val_loss: 0.6826\n",
            "Epoch 72/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6498 - val_loss: 0.7976\n",
            "Epoch 73/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6465 - val_loss: 0.6637\n",
            "Epoch 74/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6559 - val_loss: 0.6540\n",
            "Epoch 75/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6481 - val_loss: 0.7127\n",
            "Epoch 76/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6714 - val_loss: 0.7173\n",
            "Epoch 77/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6818 - val_loss: 0.6873\n",
            "Epoch 78/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6823 - val_loss: 0.6734\n",
            "Epoch 79/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6754 - val_loss: 0.7120\n",
            "Epoch 80/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6670 - val_loss: 0.6554\n",
            "Epoch 81/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6675 - val_loss: 0.6486\n",
            "Epoch 82/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6642 - val_loss: 0.6841\n",
            "Epoch 83/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6535 - val_loss: 0.7043\n",
            "Epoch 84/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6529 - val_loss: 0.6645\n",
            "Epoch 85/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6478 - val_loss: 0.6565\n",
            "Epoch 86/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6499 - val_loss: 0.7649\n",
            "Epoch 87/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6707 - val_loss: 0.8041\n",
            "Epoch 88/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6499 - val_loss: 0.6606\n",
            "Epoch 89/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6567 - val_loss: 0.6856\n",
            "Epoch 90/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6752 - val_loss: 0.6719\n",
            "Epoch 91/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6797 - val_loss: 0.6763\n",
            "Epoch 92/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6530 - val_loss: 0.7037\n",
            "Epoch 93/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6677 - val_loss: 0.7258\n",
            "Epoch 94/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6737 - val_loss: 0.6684\n",
            "Epoch 95/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6717 - val_loss: 0.6657\n",
            "Epoch 96/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6547 - val_loss: 0.7124\n",
            "Epoch 97/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6605 - val_loss: 0.7364\n",
            "Epoch 98/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6633 - val_loss: 0.6850\n",
            "Epoch 99/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6392 - val_loss: 0.7097\n",
            "Epoch 100/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6561 - val_loss: 0.6526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmCMFXENsmtS"
      },
      "source": [
        "####Adamax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w82ZImxHsvCC",
        "outputId": "7e89c260-4cdf-43d1-9828-e4e5932309c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "deep_mode(opt_Adamax)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.9929 - val_loss: 0.9283\n",
            "Epoch 2/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.8902 - val_loss: 0.7949\n",
            "Epoch 3/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7861 - val_loss: 0.7172\n",
            "Epoch 4/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7344 - val_loss: 0.6885\n",
            "Epoch 5/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7084 - val_loss: 0.6787\n",
            "Epoch 6/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6963 - val_loss: 0.6743\n",
            "Epoch 7/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6889 - val_loss: 0.6688\n",
            "Epoch 8/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6837 - val_loss: 0.6646\n",
            "Epoch 9/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6794 - val_loss: 0.6621\n",
            "Epoch 10/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6754 - val_loss: 0.6605\n",
            "Epoch 11/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6728 - val_loss: 0.6598\n",
            "Epoch 12/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6696 - val_loss: 0.6598\n",
            "Epoch 13/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6674 - val_loss: 0.6579\n",
            "Epoch 14/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6651 - val_loss: 0.6560\n",
            "Epoch 15/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6632 - val_loss: 0.6558\n",
            "Epoch 16/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6616 - val_loss: 0.6554\n",
            "Epoch 17/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6598 - val_loss: 0.6534\n",
            "Epoch 18/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6577 - val_loss: 0.6514\n",
            "Epoch 19/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6565 - val_loss: 0.6511\n",
            "Epoch 20/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6560 - val_loss: 0.6527\n",
            "Epoch 21/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6547 - val_loss: 0.6515\n",
            "Epoch 22/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6530 - val_loss: 0.6515\n",
            "Epoch 23/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6523 - val_loss: 0.6549\n",
            "Epoch 24/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6516 - val_loss: 0.6497\n",
            "Epoch 25/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6510 - val_loss: 0.6494\n",
            "Epoch 26/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6505 - val_loss: 0.6505\n",
            "Epoch 27/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6496 - val_loss: 0.6502\n",
            "Epoch 28/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6483 - val_loss: 0.6504\n",
            "Epoch 29/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6480 - val_loss: 0.6466\n",
            "Epoch 30/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6467 - val_loss: 0.6519\n",
            "Epoch 31/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6465 - val_loss: 0.6467\n",
            "Epoch 32/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6459 - val_loss: 0.6464\n",
            "Epoch 33/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6444 - val_loss: 0.6476\n",
            "Epoch 34/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6442 - val_loss: 0.6458\n",
            "Epoch 35/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6437 - val_loss: 0.6448\n",
            "Epoch 36/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6427 - val_loss: 0.6426\n",
            "Epoch 37/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6425 - val_loss: 0.6491\n",
            "Epoch 38/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6417 - val_loss: 0.6454\n",
            "Epoch 39/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6411 - val_loss: 0.6440\n",
            "Epoch 40/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6408 - val_loss: 0.6423\n",
            "Epoch 41/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6399 - val_loss: 0.6442\n",
            "Epoch 42/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6389 - val_loss: 0.6423\n",
            "Epoch 43/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6388 - val_loss: 0.6418\n",
            "Epoch 44/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6379 - val_loss: 0.6436\n",
            "Epoch 45/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6379 - val_loss: 0.6415\n",
            "Epoch 46/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6367 - val_loss: 0.6408\n",
            "Epoch 47/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6364 - val_loss: 0.6397\n",
            "Epoch 48/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6354 - val_loss: 0.6410\n",
            "Epoch 49/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6354 - val_loss: 0.6388\n",
            "Epoch 50/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6331 - val_loss: 0.6439\n",
            "Epoch 51/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6334 - val_loss: 0.6407\n",
            "Epoch 52/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6329 - val_loss: 0.6409\n",
            "Epoch 53/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6317 - val_loss: 0.6371\n",
            "Epoch 54/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6312 - val_loss: 0.6389\n",
            "Epoch 55/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6304 - val_loss: 0.6416\n",
            "Epoch 56/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6305 - val_loss: 0.6369\n",
            "Epoch 57/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6298 - val_loss: 0.6360\n",
            "Epoch 58/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6290 - val_loss: 0.6339\n",
            "Epoch 59/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6287 - val_loss: 0.6344\n",
            "Epoch 60/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6274 - val_loss: 0.6356\n",
            "Epoch 61/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6264 - val_loss: 0.6302\n",
            "Epoch 62/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6269 - val_loss: 0.6311\n",
            "Epoch 63/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6260 - val_loss: 0.6328\n",
            "Epoch 64/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6253 - val_loss: 0.6346\n",
            "Epoch 65/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6241 - val_loss: 0.6297\n",
            "Epoch 66/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6240 - val_loss: 0.6321\n",
            "Epoch 67/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6234 - val_loss: 0.6289\n",
            "Epoch 68/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6227 - val_loss: 0.6281\n",
            "Epoch 69/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6223 - val_loss: 0.6295\n",
            "Epoch 70/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6217 - val_loss: 0.6315\n",
            "Epoch 71/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6211 - val_loss: 0.6329\n",
            "Epoch 72/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6211 - val_loss: 0.6303\n",
            "Epoch 73/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6205 - val_loss: 0.6284\n",
            "Epoch 74/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6201 - val_loss: 0.6305\n",
            "Epoch 75/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6205 - val_loss: 0.6312\n",
            "Epoch 76/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6195 - val_loss: 0.6290\n",
            "Epoch 77/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6195 - val_loss: 0.6263\n",
            "Epoch 78/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6180 - val_loss: 0.6313\n",
            "Epoch 79/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6188 - val_loss: 0.6265\n",
            "Epoch 80/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6179 - val_loss: 0.6289\n",
            "Epoch 81/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6184 - val_loss: 0.6293\n",
            "Epoch 82/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6172 - val_loss: 0.6264\n",
            "Epoch 83/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6174 - val_loss: 0.6287\n",
            "Epoch 84/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6164 - val_loss: 0.6318\n",
            "Epoch 85/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6161 - val_loss: 0.6334\n",
            "Epoch 86/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6169 - val_loss: 0.6268\n",
            "Epoch 87/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6152 - val_loss: 0.6284\n",
            "Epoch 88/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6158 - val_loss: 0.6284\n",
            "Epoch 89/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6154 - val_loss: 0.6243\n",
            "Epoch 90/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6153 - val_loss: 0.6247\n",
            "Epoch 91/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6145 - val_loss: 0.6245\n",
            "Epoch 92/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6151 - val_loss: 0.6246\n",
            "Epoch 93/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6135 - val_loss: 0.6244\n",
            "Epoch 94/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6138 - val_loss: 0.6223\n",
            "Epoch 95/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6137 - val_loss: 0.6224\n",
            "Epoch 96/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6133 - val_loss: 0.6233\n",
            "Epoch 97/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6124 - val_loss: 0.6231\n",
            "Epoch 98/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6122 - val_loss: 0.6259\n",
            "Epoch 99/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6119 - val_loss: 0.6231\n",
            "Epoch 100/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6115 - val_loss: 0.6247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjMS0Qe7soS6"
      },
      "source": [
        "####Adadelta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9b8TTZtsvux",
        "outputId": "9b19a9d7-e813-44b1-b305-83454b2446a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "deep_mode(opt_Adadelta)"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0063 - val_loss: 0.9744\n",
            "Epoch 2/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0063 - val_loss: 0.9744\n",
            "Epoch 3/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0063 - val_loss: 0.9744\n",
            "Epoch 4/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0063 - val_loss: 0.9744\n",
            "Epoch 5/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0062 - val_loss: 0.9744\n",
            "Epoch 6/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0062 - val_loss: 0.9743\n",
            "Epoch 7/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0062 - val_loss: 0.9743\n",
            "Epoch 8/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0062 - val_loss: 0.9743\n",
            "Epoch 9/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0062 - val_loss: 0.9743\n",
            "Epoch 10/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0062 - val_loss: 0.9743\n",
            "Epoch 11/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0061 - val_loss: 0.9743\n",
            "Epoch 12/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0061 - val_loss: 0.9743\n",
            "Epoch 13/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0061 - val_loss: 0.9742\n",
            "Epoch 14/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0061 - val_loss: 0.9742\n",
            "Epoch 15/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0060 - val_loss: 0.9742\n",
            "Epoch 16/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0060 - val_loss: 0.9742\n",
            "Epoch 17/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0060 - val_loss: 0.9742\n",
            "Epoch 18/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0060 - val_loss: 0.9741\n",
            "Epoch 19/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0059 - val_loss: 0.9741\n",
            "Epoch 20/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0059 - val_loss: 0.9741\n",
            "Epoch 21/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0059 - val_loss: 0.9741\n",
            "Epoch 22/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0059 - val_loss: 0.9741\n",
            "Epoch 23/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0059 - val_loss: 0.9741\n",
            "Epoch 24/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0058 - val_loss: 0.9740\n",
            "Epoch 25/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0058 - val_loss: 0.9740\n",
            "Epoch 26/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0058 - val_loss: 0.9740\n",
            "Epoch 27/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0058 - val_loss: 0.9740\n",
            "Epoch 28/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0057 - val_loss: 0.9740\n",
            "Epoch 29/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0057 - val_loss: 0.9739\n",
            "Epoch 30/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0057 - val_loss: 0.9739\n",
            "Epoch 31/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0057 - val_loss: 0.9739\n",
            "Epoch 32/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0056 - val_loss: 0.9739\n",
            "Epoch 33/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0056 - val_loss: 0.9738\n",
            "Epoch 34/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0056 - val_loss: 0.9738\n",
            "Epoch 35/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0055 - val_loss: 0.9738\n",
            "Epoch 36/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0055 - val_loss: 0.9738\n",
            "Epoch 37/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0055 - val_loss: 0.9738\n",
            "Epoch 38/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0055 - val_loss: 0.9737\n",
            "Epoch 39/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0054 - val_loss: 0.9737\n",
            "Epoch 40/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0054 - val_loss: 0.9737\n",
            "Epoch 41/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0054 - val_loss: 0.9737\n",
            "Epoch 42/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0053 - val_loss: 0.9736\n",
            "Epoch 43/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0053 - val_loss: 0.9736\n",
            "Epoch 44/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0053 - val_loss: 0.9736\n",
            "Epoch 45/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0053 - val_loss: 0.9736\n",
            "Epoch 46/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0052 - val_loss: 0.9735\n",
            "Epoch 47/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0052 - val_loss: 0.9735\n",
            "Epoch 48/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0052 - val_loss: 0.9735\n",
            "Epoch 49/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0051 - val_loss: 0.9735\n",
            "Epoch 50/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0051 - val_loss: 0.9734\n",
            "Epoch 51/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0051 - val_loss: 0.9734\n",
            "Epoch 52/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0050 - val_loss: 0.9734\n",
            "Epoch 53/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0050 - val_loss: 0.9734\n",
            "Epoch 54/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0050 - val_loss: 0.9733\n",
            "Epoch 55/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0049 - val_loss: 0.9733\n",
            "Epoch 56/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0049 - val_loss: 0.9733\n",
            "Epoch 57/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0049 - val_loss: 0.9732\n",
            "Epoch 58/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0048 - val_loss: 0.9732\n",
            "Epoch 59/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0048 - val_loss: 0.9732\n",
            "Epoch 60/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0048 - val_loss: 0.9732\n",
            "Epoch 61/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0047 - val_loss: 0.9731\n",
            "Epoch 62/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0047 - val_loss: 0.9731\n",
            "Epoch 63/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0047 - val_loss: 0.9731\n",
            "Epoch 64/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0046 - val_loss: 0.9730\n",
            "Epoch 65/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0046 - val_loss: 0.9730\n",
            "Epoch 66/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0046 - val_loss: 0.9730\n",
            "Epoch 67/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0045 - val_loss: 0.9729\n",
            "Epoch 68/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0045 - val_loss: 0.9729\n",
            "Epoch 69/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0045 - val_loss: 0.9729\n",
            "Epoch 70/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0044 - val_loss: 0.9728\n",
            "Epoch 71/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0044 - val_loss: 0.9728\n",
            "Epoch 72/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0043 - val_loss: 0.9728\n",
            "Epoch 73/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0043 - val_loss: 0.9727\n",
            "Epoch 74/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0043 - val_loss: 0.9727\n",
            "Epoch 75/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0042 - val_loss: 0.9727\n",
            "Epoch 76/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0042 - val_loss: 0.9726\n",
            "Epoch 77/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0042 - val_loss: 0.9726\n",
            "Epoch 78/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0041 - val_loss: 0.9726\n",
            "Epoch 79/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0041 - val_loss: 0.9725\n",
            "Epoch 80/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0040 - val_loss: 0.9725\n",
            "Epoch 81/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0040 - val_loss: 0.9725\n",
            "Epoch 82/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0040 - val_loss: 0.9724\n",
            "Epoch 83/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0039 - val_loss: 0.9724\n",
            "Epoch 84/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0039 - val_loss: 0.9723\n",
            "Epoch 85/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0038 - val_loss: 0.9723\n",
            "Epoch 86/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0038 - val_loss: 0.9723\n",
            "Epoch 87/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0038 - val_loss: 0.9722\n",
            "Epoch 88/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0037 - val_loss: 0.9722\n",
            "Epoch 89/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0037 - val_loss: 0.9722\n",
            "Epoch 90/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0036 - val_loss: 0.9721\n",
            "Epoch 91/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0036 - val_loss: 0.9721\n",
            "Epoch 92/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0035 - val_loss: 0.9720\n",
            "Epoch 93/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0035 - val_loss: 0.9720\n",
            "Epoch 94/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0034 - val_loss: 0.9720\n",
            "Epoch 95/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0034 - val_loss: 0.9719\n",
            "Epoch 96/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0034 - val_loss: 0.9719\n",
            "Epoch 97/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0033 - val_loss: 0.9718\n",
            "Epoch 98/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0033 - val_loss: 0.9718\n",
            "Epoch 99/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0032 - val_loss: 0.9717\n",
            "Epoch 100/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 1.0032 - val_loss: 0.9717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UriMSwCLsr7N"
      },
      "source": [
        "####RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQsXcM70sxou",
        "outputId": "23f592bb-c987-46f7-bb8c-169d8cae3513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "deep_mode(opt_RMSprop)"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.8632 - val_loss: 0.7064\n",
            "Epoch 2/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.7118 - val_loss: 0.6655\n",
            "Epoch 3/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6958 - val_loss: 0.6550\n",
            "Epoch 4/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6792 - val_loss: 0.6502\n",
            "Epoch 5/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6676 - val_loss: 0.6360\n",
            "Epoch 6/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6550 - val_loss: 0.6365\n",
            "Epoch 7/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6483 - val_loss: 0.6290\n",
            "Epoch 8/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6424 - val_loss: 0.6353\n",
            "Epoch 9/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6405 - val_loss: 0.6310\n",
            "Epoch 10/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6364 - val_loss: 0.6318\n",
            "Epoch 11/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6330 - val_loss: 0.6273\n",
            "Epoch 12/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6334 - val_loss: 0.6419\n",
            "Epoch 13/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6324 - val_loss: 0.6283\n",
            "Epoch 14/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6286 - val_loss: 0.6278\n",
            "Epoch 15/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6295 - val_loss: 0.6283\n",
            "Epoch 16/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6259 - val_loss: 0.6305\n",
            "Epoch 17/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6267 - val_loss: 0.6278\n",
            "Epoch 18/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6253 - val_loss: 0.6452\n",
            "Epoch 19/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6239 - val_loss: 0.6371\n",
            "Epoch 20/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6234 - val_loss: 0.6353\n",
            "Epoch 21/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6214 - val_loss: 0.6287\n",
            "Epoch 22/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6197 - val_loss: 0.6325\n",
            "Epoch 23/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6214 - val_loss: 0.6272\n",
            "Epoch 24/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6193 - val_loss: 0.6320\n",
            "Epoch 25/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6171 - val_loss: 0.6303\n",
            "Epoch 26/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6149 - val_loss: 0.6355\n",
            "Epoch 27/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6161 - val_loss: 0.6388\n",
            "Epoch 28/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6161 - val_loss: 0.6352\n",
            "Epoch 29/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6130 - val_loss: 0.6424\n",
            "Epoch 30/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6137 - val_loss: 0.6325\n",
            "Epoch 31/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6129 - val_loss: 0.6327\n",
            "Epoch 32/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6133 - val_loss: 0.6312\n",
            "Epoch 33/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6113 - val_loss: 0.6303\n",
            "Epoch 34/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6108 - val_loss: 0.6319\n",
            "Epoch 35/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6106 - val_loss: 0.6285\n",
            "Epoch 36/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6093 - val_loss: 0.6397\n",
            "Epoch 37/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6069 - val_loss: 0.6322\n",
            "Epoch 38/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6088 - val_loss: 0.6365\n",
            "Epoch 39/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6059 - val_loss: 0.6389\n",
            "Epoch 40/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6058 - val_loss: 0.6366\n",
            "Epoch 41/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6053 - val_loss: 0.6370\n",
            "Epoch 42/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6035 - val_loss: 0.6329\n",
            "Epoch 43/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6037 - val_loss: 0.6296\n",
            "Epoch 44/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6019 - val_loss: 0.6324\n",
            "Epoch 45/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6009 - val_loss: 0.6413\n",
            "Epoch 46/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6018 - val_loss: 0.6289\n",
            "Epoch 47/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5980 - val_loss: 0.6313\n",
            "Epoch 48/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6002 - val_loss: 0.6328\n",
            "Epoch 49/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5998 - val_loss: 0.6315\n",
            "Epoch 50/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6005 - val_loss: 0.6295\n",
            "Epoch 51/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.6000 - val_loss: 0.6332\n",
            "Epoch 52/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5969 - val_loss: 0.6359\n",
            "Epoch 53/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5980 - val_loss: 0.6343\n",
            "Epoch 54/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5972 - val_loss: 0.6296\n",
            "Epoch 55/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5984 - val_loss: 0.6304\n",
            "Epoch 56/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5946 - val_loss: 0.6410\n",
            "Epoch 57/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5975 - val_loss: 0.6327\n",
            "Epoch 58/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5966 - val_loss: 0.6335\n",
            "Epoch 59/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5967 - val_loss: 0.6263\n",
            "Epoch 60/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5955 - val_loss: 0.6287\n",
            "Epoch 61/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5963 - val_loss: 0.6308\n",
            "Epoch 62/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5956 - val_loss: 0.6299\n",
            "Epoch 63/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5959 - val_loss: 0.6298\n",
            "Epoch 64/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5940 - val_loss: 0.6275\n",
            "Epoch 65/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5954 - val_loss: 0.6329\n",
            "Epoch 66/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5949 - val_loss: 0.6346\n",
            "Epoch 67/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5956 - val_loss: 0.6255\n",
            "Epoch 68/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5935 - val_loss: 0.6249\n",
            "Epoch 69/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5929 - val_loss: 0.6338\n",
            "Epoch 70/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5914 - val_loss: 0.6281\n",
            "Epoch 71/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5928 - val_loss: 0.6269\n",
            "Epoch 72/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5925 - val_loss: 0.6287\n",
            "Epoch 73/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5905 - val_loss: 0.6306\n",
            "Epoch 74/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5908 - val_loss: 0.6382\n",
            "Epoch 75/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5907 - val_loss: 0.6274\n",
            "Epoch 76/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5914 - val_loss: 0.6353\n",
            "Epoch 77/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5908 - val_loss: 0.6282\n",
            "Epoch 78/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5908 - val_loss: 0.6332\n",
            "Epoch 79/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5900 - val_loss: 0.6245\n",
            "Epoch 80/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5898 - val_loss: 0.6311\n",
            "Epoch 81/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5902 - val_loss: 0.6319\n",
            "Epoch 82/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5881 - val_loss: 0.6318\n",
            "Epoch 83/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5893 - val_loss: 0.6352\n",
            "Epoch 84/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5897 - val_loss: 0.6294\n",
            "Epoch 85/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5897 - val_loss: 0.6346\n",
            "Epoch 86/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5885 - val_loss: 0.6316\n",
            "Epoch 87/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5887 - val_loss: 0.6343\n",
            "Epoch 88/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5893 - val_loss: 0.6321\n",
            "Epoch 89/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5891 - val_loss: 0.6317\n",
            "Epoch 90/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5853 - val_loss: 0.6352\n",
            "Epoch 91/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5889 - val_loss: 0.6364\n",
            "Epoch 92/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5863 - val_loss: 0.6332\n",
            "Epoch 93/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5889 - val_loss: 0.6301\n",
            "Epoch 94/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5871 - val_loss: 0.6351\n",
            "Epoch 95/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5866 - val_loss: 0.6360\n",
            "Epoch 96/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5854 - val_loss: 0.6383\n",
            "Epoch 97/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5841 - val_loss: 0.6494\n",
            "Epoch 98/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5859 - val_loss: 0.6298\n",
            "Epoch 99/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5862 - val_loss: 0.6330\n",
            "Epoch 100/100\n",
            "490/490 [==============================] - 1s 2ms/step - loss: 0.5845 - val_loss: 0.6323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUS_gx3TEJKS"
      },
      "source": [
        "Jika melihat kedalam grafik, untuk deeper model, optimizer adamax adalah yang paling baik, karena grafiknya mulai menunjukan nilai yg konstan, namun masih memiliki val_los yg kurang baik di sekitar 0.62 pada epoch ke 90"
      ]
    }
  ]
}